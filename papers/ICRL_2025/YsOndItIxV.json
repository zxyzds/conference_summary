{
    "id": "YsOndItIxV",
    "title": "Neural Dynamic Pricing: Provable and Practical Efficiency",
    "abstract": "Despite theoretical guarantees of existing dynamic pricing (DP) methods, their strong model assumptions may not reflect real-world conditions and are often unverifiable. This poses major challenges in practice since the performance of an algorithm may significantly degrade if the assumptions are not satisfied. Moreover, many DP algorithms show unfavorable empirical performance due to the lack of data efficiency. \n    To address these challenges, we design a practical contextual DP algorithm that utilizes regression oracles. Our proposed algorithm assumes only Lipschitz continuity on the true conditional probability of purchase.\n    We prove $\\tilde{\\mathcal{O}}(T^{\\frac{2}{3}}\\text{regret}_R(T)^{\\frac{1}{3}})$ regret upper bound where $T$ is the horizon and $\\text{regret}_R(T)$ is the regret of the oracle. The bound is nearly minimax optimal in the canonical case of finite function class, and our analysis generically applies to other function approximators including neural networks. To the best of our knowledge, our work is the first algorithm to utilize the powerful generalization capability of neural networks with provable guarantees in dynamic pricing literature.\n    Extensive numerical experiments show that our algorithm outperforms existing state-of-the-art dynamic pricing algorithms in various settings, which demonstrates both provable efficiency and practicality.",
    "keywords": [
        "dynamic pricing",
        "neural networks"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=YsOndItIxV",
    "pdf_link": "https://openreview.net/pdf?id=YsOndItIxV",
    "comments": [
        {
            "summary": {
                "value": "The authors introduce a contextual dynamic pricing algorithm called DP-IGW, which aims to address some of the limitations in the existing dynamic pricing literature, such as strong modeling assumptions or poor performance under real-world conditions. \nThe idea of DP-IGW is to leverage regression oracles (in particular, neural networks) to enable contextual dynamic pricing.\nThe main assumption is that the function $f^\\star$ that maps the contexts $x$ and prices $p$ to the probability of selling at a price $p$ when the context is $x$ is uniformly Lipschitz in the prices (Assumption 5.2 --- note that it is assumed that the same $L$ works for all contexts).\nThe authors prove that the algorithm achieves an upper regret bound of order $T^{2/3} \\mathrm{Regret}_R(T)^{1/3}$, where $\\mathrm{Regret}_R(T)$ is the regret after $T$ time steps of the regression oracle used by DP-IGW. \nThe regret rate is proved to be optimal only in the special case where $f^\\star$ belongs to a known _finite_ family and the regression oracle only outputs regressors in this family.\nExperiments illustrate the theoretical findings."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is mostly clear in its descriptions, presenting both algorithmic and theoretical insights with sufficient effectiveness.\n\n- The problem is of broad interest, and the idea of mixing neural network technology with dynamic pricing is appealing."
            },
            "weaknesses": {
                "value": "The originality of the contribution appears somewhat limited, given that the key ideas are adaptations of somewhat standard techniques. This is not necessarily a reason to reject a paper. In fact, it could even be a plus to have a simple change that leads to a large improvement. It is not clear to me that this is the case here, though. The lower bound near-matches the upper bound only in a very narrow case (finite $\\mathcal F$), and I am not sure about the optimality of this approach in the general case."
            },
            "questions": {
                "value": "- I suggest the authors close the gap between the upper and lower bound in the general case, or at least in a significantly broader case.\n\n- Can the assumption be relaxed to: for all contexts $x$, there exists a Lipschitz constant $L_x$ such that $f^\\star(x,\\cdot)$ is $L_x$-Lipschitz? What about piece-wise Lipschitz?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper designs a practical contextual DP algorithm that utilizes regression oracles. Our proposed algorithm assumes only Lipschitz continuity on the true conditional probability of purchase. It proves a $O(T^{2/3} reg_R(T)^{1/3})$ regret upper bound which is nearly minimax optimal in the canonical case of finite function class. Numerical experiments are conducted to verify the theory."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. the presentation is clear.\n2. the author provides both theoretical and experiments to verify their results."
            },
            "weaknesses": {
                "value": "The novelty is not enough.\n - Recent works have already considered using function approximation (e.g. [1]), so replacing such semi-parametric / non-parametric regression oracles with neural networks is not meaningful enough.\n - The authors state that their algorithm is fully sequential and flexible w.r.t. model assumptions, but both issues are tackled in the bandit settings, e.g., [2]. Since DP and bandits are extremely similar in problem structures, this paper is merely a combination of the two techniques and is not of much real significance.\n - The paper does not compare its assumption and regret with previous works, so no superiority of the proposed algorithm is illustrated.\n - The experiment does not highlight under which circumstances will it perform better than other models (e.g. log concavity of cdf $F_0$).\n\n\n[1] Jianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. Journal of the American Statistical Association, pp. 1\u201329, 2022.\n[2] Yinglun Zhu and Paul Mineiro. Contextual bandits with smooth regret: Efficient learning in continuous action spaces. In International Conference on Machine Learning, pp. 27574\u201327590. PMLR,2022."
            },
            "questions": {
                "value": "No questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses limitations in current dynamic pricing (DP) algorithms, particularly those that rely on assumptions unfit for real-world applications and show poor data efficiency. The authors propose a new algorithm, DP-IGW, which incorporates neural networks as regression oracles and employs an exploration method called inverse gap weighting (IGW) to enhance data utilization and adaptability. Their method assumes minimal model assumptions, specifically Lipschitz continuity, and provides nearly optimal regret bounds, demonstrating both theoretical and practical efficiency across various settings."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. By using neural networks as regression oracles, DP-IGW leverages their powerful generalization capabilities, allowing it to adapt to complex, high-dimensional data while maintaining provable guarantees.\n2. The paper is technical sound. The authors provide a near-optimal regret bound, which establishes the efficiency and reliability of DP-IGW in theory. \n3. The paper is well-written. The authors have a good summary of the current literature."
            },
            "weaknesses": {
                "value": "1. The design ideas and proof techniques seem to be very similar to Simchi-Levi and Xu (2022). Is there any technical challenge and contribution that the authors want to highlight?\n2. For the lower bound (Section 5.2), I am wondering the purpose of the section. Usually, we are expecting a matched lower bound with the upper bound as Simchi-Levi and Xu (2022). The lower bound in Section 5.2 does not directly match with the upper bound, and even under different assumptions (i.e., the difference between Assumption 5.2 and Assumption 5.4). Does this mean that it is very hard to directly get a lower bound under Assumption 5.2?\n2. Although the use of neural networks offers powerful generalization, it also introduces challenges like potential overfitting, sensitivity to hyperparameters, and higher computational demands. I will not push along this line, but want to point out this since the paper is a very practical relevant paper."
            },
            "questions": {
                "value": "Please see the weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}