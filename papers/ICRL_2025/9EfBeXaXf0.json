{
    "id": "9EfBeXaXf0",
    "title": "Optimization by Parallel Quasi-Quantum Annealing with Gradient-Based Sampling",
    "abstract": "Learning-based methods have gained attention as general-purpose solvers due to their ability to automatically learn problem-specific heuristics, reducing the need for manually crafted heuristics. However, these methods often face scalability challenges. To address these issues, the improved Sampling algorithm for Combinatorial Optimization (iSCO), using discrete Langevin dynamics, has been proposed, demonstrating better performance than several learning-based solvers. This study proposes a different approach that integrates gradient-based update through continuous relaxation, combined with Quasi-Quantum Annealing (QQA). QQA smoothly transitions the objective function, starting from a simple convex function, minimized at half-integral values, to the original objective function, where the relaxed variables are minimized only in the discrete space. Furthermore, we incorporate parallel run communication leveraging GPUs to enhance exploration capabilities and accelerate convergence. Numerical experiments demonstrate that our method is a competitive general-purpose solver, achieving performance comparable to iSCO and learning-based solvers across various benchmark problems. Notably, our method exhibits superior speed-quality trade-offs for large-scale instances compared to iSCO, learning-based solvers, commercial solvers, and specialized algorithms.",
    "keywords": [
        "Combinatorial Optimization",
        "Discrete Optimization",
        "Learning for Combinatorial Optimization",
        "Unsupervised Learning for Combinatorial Optimization",
        "Learning for Combinatorial Optimization"
    ],
    "primary_area": "optimization",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=9EfBeXaXf0",
    "pdf_link": "https://openreview.net/pdf?id=9EfBeXaXf0",
    "comments": [
        {
            "summary": {
                "value": "In this study, the authors present PQQA, an optimization approach that integrates QQA, gradient-based updates, and parallel run communication. The results indicate that PQQA performs comparably to or better than iSCO and other learning-based solvers across a range of combinatorial optimization (CO) problems. Notably, for larger problem instances, PQQA offers a superior trade-off between speed and solution quality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The authors did a great job explaining the problem being considered, including the background, methodology, theoretical properties, and related work. The numerical experiments also effectively highlight their proposed method. While I did not check the validity of the proof in the Appendix, the setup and results are very convincing."
            },
            "weaknesses": {
                "value": "n/a"
            },
            "questions": {
                "value": "1. In Table 1, some of the ApR values are greater than 1. Could the authors clarify what this means?\n\n2.  While the authors mention runtime in the paper, there seems to be a discrepancy that needs further explanation. For example, in Table 1, iSCO takes about 5\u201315 minutes to achieve an ApR of 0.996, whereas PQQA takes over an hour for the same result. \n\n3.  Line 314 refers to Table 1 as Table 5.1. Please check for similar mistakes in other parts of the paper and ensure that table references are consistent throughout.\n\n4. In line 60, the term \"parameters\" is used. Could the authors clarify what specific parameters are being referred to in this context?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes Parallel Quasi-Quantum Annealing (PQQA), a sampling-based algorithm for combinatorial optimization problems.  Specifically, with a continuous relaxation of the combinatorial optimization problem, an entropy metric to measure discreteness and sampling based on the Boltzmann Distribution, the authors develop an efficient general-purpose approach for combinatorial optimization.  Empirically, this approach yields high-quality solutions efficiently."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- **Novelty.**  Overall, this paper proposes a novel sampling-based approach for finding high-quality solutions to combinatorial optimization problems.  In particular, using $\\alpha$-entropy with the extended Boltzmann Distribution is a well-motivated and novel approach for combinatorial optimization.  \n\n- **Numerical Results.**  The authors provide extensive numerical comparisons on a wide variety of benchmarks.  These results demonstrate the PQQA can compute high-quality solutions on all instances, often at a reduced runtime compared to other methods."
            },
            "weaknesses": {
                "value": "Overall, I have quite a favorable opinion of the paper.  However, one significant weakness/limitation is provided below.  \n- **Simple Constraints in Benchmarks.**  The authors evaluate the maximum independent set, max clique, max cut, graph partitioning, and graph coloring.  While these constitute many combinatorial optimization problems, they all have relatively simple constraints compared to problems such as TSP, which has an exponential number of constraints.  Approaches such as iSCO are capable of dealing with this type of structure.  However, it is unclear if something similar can be done with PQAA, given the reliance on continuous relaxation, which may be less tractable for problems with exponentially many constraints.  Overall, this may limit the applicability of such approaches.  Furthermore, the authors do not acknowledge this as a limitation or discuss this at all.  I would be happy to discuss this further in the discussion period."
            },
            "questions": {
                "value": "**Questions**\n- How are the binary solutions obtained after running PQQA?  \n- How often are these solutions feasible?  If infeasible, what is done with the solutions?\n- Do the authors have any insight into how the strength of the LP relaxation of a problem affects the downstream solution quality?  \n- Why is iSCO not compared against in Table 2?\n- Why is this method not benchmarked on TSP?\n- Is there a reason iSCO is much faster on Maximum Independent Set but slower on Max Clique?  \n\n**Minor Remarks**\n-  I suggest keeping the evaluation of times consistent, i.e., always use seconds or average time to solve an instance.  Comparing performance is difficult when switching between metrics for different tables and even within tables.  \n-  Incorrect reference in Table E.1 in line 1125."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors proposed a learning based method for CO problems by combing Quasi-Quantum Annealling and gradient-based update\nthrough continuous relaxation. Performance are compared with iSCO on various benchmark problems."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "parallel implementation on GPUs accelerates the solution process."
            },
            "weaknesses": {
                "value": "It seems that the algorithm does not have converence guarantees. \n\nThe algorithm cannot guarantee finding a feasible solution. constraints are moved to the objective function as a penalty term. \n\nOn benchmarks like SATLIB, it performs worse than traditional OR solvers like Gurobi. \n\nThe authors may consider larger benchmarks like MIPLIB 2017 to test the performance."
            },
            "questions": {
                "value": "The paper is based on the continuous relaxation of the discrete variable. Then why not directly solving the resulting linear programming problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The manuscript proposes a new methodology for combinatorial optimization, based on the integration of gradient-based updates and Quasi-Quantum Annealing. The manuscript is well-written using easy-to-comprehend language which led to a joyful read. The background is well-explained including prior work in the field. The computational experiments are well-chosen and comprehensive."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "This is a strong paper. \n- Very good coverage of prior work (While I am not an expert in this field the sheer amount and frequency of citations is convincing)\n- Clear introduction and background\n- The main contribution seems novel\n- The experimental results are very convincing"
            },
            "weaknesses": {
                "value": "This is a strong paper in my opinion, and I identified only a few shortcomings. \n-  The results of the computational experiments are somewhat confusing. How can time be measured when so many different algorithms are involved? Aren't these codes in different languages? You might be able to give the reader a better intuition of your compute-time measurements."
            },
            "questions": {
                "value": "- What do time measurements [s/g] really mean when different algorithms are compared? \nWhat is the time spent on? \nAre the time differences purely due to implementation differences? \nHow do the different approaches scale?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}