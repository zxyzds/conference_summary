{
    "id": "CU7QfWJ6nC",
    "title": "FreeTraj: Tuning-Free Trajectory Control via Noise Guided Video Diffusion",
    "abstract": "Diffusion model has demonstrated remarkable capability in video generation, which further sparks interest in introducing trajectory control into the generation process. While existing works mainly focus on training-based methods (e.g., conditional adapter), we argue that diffusion model itself allows decent control over the generated content without requiring any training. In this study, we introduce a tuning-free framework to achieve trajectory-controllable video generation, by imposing guidance on both noise construction and attention computation. Specifically, 1) we first show several instructive phenomena and analyze how initial noises influence the motion trajectory of generated content. 2) Subsequently, we propose FreeTraj, a tuning-free approach that enables trajectory control by modifying noise sampling and attention mechanisms. 3) Furthermore, we extend FreeTraj to facilitate longer and larger video generation with controllable trajectories. Equipped with these designs, users have the flexibility to provide trajectories manually or opt for trajectories automatically generated by the LLM trajectory planner. Extensive experiments validate the efficacy of our approach in enhancing the trajectory controllability of video diffusion models. Generated video samples are available at the anonymous website: https://FreeTraj.github.io.",
    "keywords": [
        "Diffusion Model",
        "Video Diffusion",
        "Trajectory Control",
        "Motion Control"
    ],
    "primary_area": "generative models",
    "TLDR": "A tuning-free method for trajectory-controllable video generation with guidance of initial noise.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CU7QfWJ6nC",
    "pdf_link": "https://openreview.net/pdf?id=CU7QfWJ6nC",
    "comments": [
        {
            "summary": {
                "value": "This paper analyze the trajectory-controllable video generation and introduce Free_Traj, a training-free motion control method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- It is intuitive and reasonable to use noise and motion guidance.\n\n- Noise resampling is an interesting idea.\n\n- The analysis is comprehensive, and the results seem good to me."
            },
            "weaknesses": {
                "value": "- Is mIoU a good metric for trajectory control? \n\n\n- Can this method unify trajectory control and motion control? For example, a man waves his hand. In terms of motion, it is a \"wave\" action; regarding trajectory, the hand follows its specific path. Can we unify them to achieve more realistic motion control?"
            },
            "questions": {
                "value": "Please see the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a diffusion-based video generation method for controlling the trajectory of moving objects in a zero-shot manner and investigates the impact of initial noise on the trajectories of moving objects. By guiding the generated target in noise and attention, the proposed method can generate controlled trajectory of the target. Experimental results demonstrate the effectiveness of this method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The method described in this paper does not require any training, which can significantly reduce computational overhead.\n- This method analyzes the high and low frequencies of the initial noise and Attention Isolation, and proposes corresponding utilization methods and solutions.\n- The provided generated video looks good in controlling."
            },
            "weaknesses": {
                "value": "- In the paper, the author uses a box to control the motion of objects, but in the experiments, the objects are not actually inside the box; they merely maintain a trajectory consistent with that of the box.\n- The method performs significantly worse than the Direct approach on the FVD and KVD metrics, and the author does not analyze this. This could potentially have negative effects on the clarity of the generated videos and on maintaining the identity of the objects.\n- This method shows some weaknesses in generating complex and random trajectories. However, it seems feasible to achieve better results by increasing the control strength, according to the method. The author does not further analyze this aspect. The degree of control could potentially impact video quality. It would be beneficial for the author to include an ablation study on the intensity of control to better understand its effects."
            },
            "questions": {
                "value": "- The author mentions that this method can be used for LLM trajectory planners, but how this can be implemented? This lack of detail could leave readers uncertain about the practical application of the method in such contexts.\n- Since the method does not require training, it could be applicable to any diffusion-based video generation method, such as Stable Video Diffusion or OpenSora. Could you provide more experiments with different video-diffusion baselines? This universality could potentially make it a versatile tool in the field of video synthesis, especially for applications requiring rapid deployment without the need for extensive training data.\n- As in zero-shot setting, Motion-Zero[1] has some similar features, modifying initial noise, and guidance in attention. in video generation. What's the difference between the proposed method and [1]?\n\n[1] C. Chen et al. Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation. Arxiv 2024."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a tuning-free video diffusion framework for object trajectory control. The authors in this paper first analyze the influence of noise construction for video motion generation and then introduce the FreeTraj. The proposed framework modifies the noise sampling and involves the local trajectory injection in the noise initialization. Besides, the object mask is also integrated into the attention to emphasize the content generation across frames. Experiments on both controllable short- and long-video generation tasks verify the proposed approach."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe exploration on the noise initialization for object motion control is interesting and demonstrates the importance of noise structure for content generation in video diffusion models. \n2.\tBoth of the qualitative and quantitative experimental results demonstrate the effectiveness of the proposed approach for tuning-free motion control.  \n3.\tThe potential of complex motion control is verified by the model that is combined with FreeNoise under the setting of long video generation."
            },
            "weaknesses": {
                "value": "1.\tMy major concern is about the technical contribution which could be limited. The investigation of noise construction is more like an intuitive engineering work and there is no rationale behind. The influence of high-frequency noise part has been also explored in FreeNoise. The trajectory injection seems reasonable but more details should be included. Meanwhile, the authors argue that Peekaboo exploits the hard mask in attention. The motivation of the proposed soft Gaussian mask is not clear either. The hyper-parameter of such Gaussian kernel is not mentioned in the paper.\n2.\tIn the experimental section, the comparison and discussion (line 465 to 470) between FreeTraj and MotionCtrl should be detailed. It is very difficult for readers to judge the technical differences or improvements from these descriptions. Why dose MotionCtrl only roughly control the object trajectory but not align the trajectory? The reason behind these results is not provided or discussed. \n3.\tOne suggestion is about ablation studies. There could be some quantitative analysis for different variants rather than only showing the visual cases. The quantitative evaluation results can reflect the performance from a global view.\n4.\tSome of the definitions should be aligned. For instance, the $F_{z_T}^{low}$ and $F_{z_T}^{L}$ in Eq. (7)."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces FreeTraj, a tuning-free framework for trajectory-controllable video generation using diffusion models, eliminating the need for additional training. It controls motion trajectories by guiding noise sampling and attention mechanisms. FreeTraj supports both manual and LLM-generated trajectories and enables longer video generation with precise trajectory control. Extensive experiments validate its effectiveness in enhancing trajectory controllability in video diffusion models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The method is training free unlike most existing works.\n2. Extensive quantitative evaluation.\n3. Methods are intuitive and the paper is easy to follow.\n4. Superiority over baselines compared.\n5. Providing observation before they build their method sounds convincing and well-structured.\n6. Applications of Longer / Larger video generation."
            },
            "weaknesses": {
                "value": "1. By \"LLM trajectory planner\", do the authors mean like LLM-grounded video diffusion [1]. Plus, I think LLM-grounded video diffusion would serve as a good baseline to be compared (ignoring the llm planning part). Also, if the LLM trajectory planner is not implemented or showcased, the authors should not sell this point.\n\n2. Does the method increase computation burden? Providing and comparing information on the memory / time consumption would increase value of the paper.\n\n3. How long and big are the \"long\" and \"large\" video generation in the results of appendix?\n\n4. I think the intuition behind High-Frequency Noise Resampling is well explored in both image/video diffusion works. Not just FreeInit, but also in Diffusion-Motion-Transfer [2] (their initial noise preparation stage). And the novelty is limited.\n\n5. It's hard to grasp what attention isolation is easily. Providing visualizations in relevant sections would help reviewers understand the issue and how they overcome it.\n\n6. Is Cross Attention Guidance method not explored in diffusion-based image generation/editing literature?\n\n7. Isn't TrackDiffusion [3] a relevant work? If so, how does the model perform compared to the work? \n\n8. Quantitative ablations studies would add value of the paper.\n\n[1] LLM-grounded Video Diffusion Models, ICLR 2024\n\n[2] Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer, CVPR 2024\n\n[3] TrackDiffusion: Tracklet-Conditioned Video Generation via Diffusion Models, Arxiv 2023"
            },
            "questions": {
                "value": "Please refer to the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}