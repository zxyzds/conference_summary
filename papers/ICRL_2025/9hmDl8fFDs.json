{
    "id": "9hmDl8fFDs",
    "title": "Deep Complex Spatio-Spectral Networks with Complex Visual Inputs",
    "abstract": "Complex-valued neural networks have attracted growing attention for their ability to handle complex-valued data with enhanced representational capacity. However, their potential in computer vision remains relatively untapped. \nIn this paper, we introduce Deep Complex Spatio-Spectral Network (DCSNet), a fully complex-valued token-based, end-to-end neural network designed for foreground extraction tasks. Additionally, our DCSNet encoder can be used for image classification.\nWe also propose an invertible real-to-complex (R2C) transform, which generates two complex-valued input channels, complex intensity, and complex hue, while producing complex-valued images with distinct real and imaginary components.\nDCSNet operates in both spatial and spectral domains by leveraging complex-valued inputs and complex Fourier transform.\nAs a result, the complex-valued representation is maintained throughout DCSNet, and we avoid the information loss typically associated with Real$\\leftrightarrow$Complex transformations.\n Extensive experiments show that DCSNet surpasses existing complex-valued methods across various tasks on both real and complex-valued data and achieves competitive performance compared to state-of-the-art real-valued methods, establishing a robust framework for handling both data types effectively.",
    "keywords": [
        "Deep Complex Newtworks",
        "Complex-valued color transformation"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "A robust complex-valued approach in Spatio-spectral domain for multiple tasks on both real and complex data.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=9hmDl8fFDs",
    "pdf_link": "https://openreview.net/pdf?id=9hmDl8fFDs",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a transformation to map RGB images into complex domain and an associate network comprising a loss function to handle such complex inputs.\n\nOverall, the contributions are significant and may be of interest to the community, but the paper organization could be improved and more focus should be placed on the transformation."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1) The proposed transformation is novel and may be an important contribution for the community working in complex and hypercomplex domains.\n2) Although not novel, using the fourier filter module is good to handle complex inputs."
            },
            "weaknesses": {
                "value": "1) While the method sounds, the results are not impressive and surely they are not statistically significant. As of my experience, complex, quaternion, and in general hypercomplex models clearly outperform real-valued counterparts when they are able to catch some underlying physical process intrinsic into data. Maybe, the tasks chosen by the authors do not highlight the effectiveness of their method. Maybe, the authors could stress more the parameters saving of using a complex model with respect to a real-valued one, which can help reducing the computational load while obtaining comparable results.\n2) The authors should have focused more on the transformation, which is a novel contribution, and better show its properties (see questions).\n3) Some key references to related works are missing, the authors should at least give credit to them, or better try to compare their method with them. Some of them follow, but I encourage the authors to better explore previous literature on complex, quaternion and hypercomplex networks.\n\n[1] C. Trabelsi, O. Bilaniuk, Dmitriy Serdyuk, Sandeep Subramanian, J. F. Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, C. Pal, \"Deep Complex Networks\", ICLR 2017.\n\n[2] E. Grassucci, A. Zhang, D. Comminiello, \"PHNNs: Lightweight Neural Networks via Parameterized Hypercomplex Convolutions\", IEEE Transactions on Neural Networks and Learning Systems, (Volume: 35, Issue: 6, June 2024).\n\n\nMinor comments:\n\nThe Saxon Genitive should be avoided in scientific writing, although I know that both ChatGPT and Grammarly insert it. I suggest the authors to remove all the Saxon genitives in the paper."
            },
            "questions": {
                "value": "1) I am very curious about the invertibility of the proposed transform. Given the Algorithm 2 in Appendix A, would it be possible to have some experiments to prove its effectiveness? I think that this transformation is the real contribution of the paper, as it allows a direct mapping between greyscale and RGB images, which was lacking in complex and quaternion papers that often struggle to do so.\n2) Which is the computational load in terms of FLOPs, runtime memory, and time of the proposed model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The work proposes a complex-value deep neural network for computing vision tasks. First, the authors propose an inevitable real-to-complex transformation. Then, the work proposes an architecture comprising spectral convolution and a complex T2T module. \nThe authors evaluated their model on image classification, smooth object detection, and defocus blur detection."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The work proposes a novel invertible real-to-complex conversion for RGB images in complex-valued neural networks. The procedures are clearly stated using pseudocode and figures."
            },
            "weaknesses": {
                "value": "1. The authors seem to miss the seminal work on complex values networks and didn\u2019t compare/discuss with the techniques discussed in [1]\n2. The work is directed at using complex-valued networks for real-valued images. The majority of the paper involves devising an invertible conversion from real to complex representation. However, the paper fails to demonstrate its utility. For example, for classification on ImageNets, the authors did not consider state-of-the-art models, such as Vit, Swin-v2, etc., which achieve above 90% accuracy. \n\n3. The paper does not discuss the motivation of the specific real to complex conversion. There are many invertible conversions between real and complex.\n\n[1] DEEP COMPLEX NETWORKS"
            },
            "questions": {
                "value": "1. Line 317: Citation link broken for T2T-ViTYuan et al. (2021)\n\n2. Line 269: Do you use complex-valued  \u201c normalization\u201d as discussed in [1]\n\n3. How well does the model perform if we consider trivial real to complex conversion that considers the real numbers as complex numbers with $0$ imaginary part? This is also a very crucial ablation that the authors should perform.\n\n4. Does using spectral convolution make it challenging to capture local features as it performs global convolution?\n\n\n[1] DEEP COMPLEX NETWORKS"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Deep Complex Patio-Spectral Network (DCSNet), a fully complex-valued, token-based neural network developed for end-to-end foreground extraction and adaptable for image classification. Extensive experiments show that DCSNet surpasses current complex-valued approaches across various tasks with real and complex-valued data, achieving results on par with leading real-valued models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper presents a novel complex-valued neural network, the Deep Complex Patio-Spectral Network (DCSNet), a fully complex-valued, token-based, end-to-end architecture designed for foreground extraction and adaptable to image classification tasks. Extensive experiments demonstrate that DCSNet outperforms existing complex-valued methods across diverse tasks involving both real and complex-valued data, achieving competitive results relative to state-of-the-art real-valued models. The paper is well-written, concise, and easy to follow."
            },
            "weaknesses": {
                "value": "Novelty: The novelty of this paper appears questionable. The authors claim that they propose the first token-based complex-valued network that maintains complex-valued information throughout. However, the fully Complex-valued Convolutional Network (FCCN) [1] also processes complex-valued data through the entire model. Could the authors clarify any differences between these two models? What advantages does DCSNet offer over FCCN?\n\n[1] Saurabh Yadav; Koteswar Rao Jerripothula, FCCNs: Fully Complex-valued Convolutional Networks using Complex-valued Color Model and Loss Function. ICCV 2023.\n\nComplex-valued Image Generation (R2C Method): The authors propose an R2C method for generating complex-valued images from real-valued images, presenting it as a novel complex-valued color transformation. However, methods such as quaternion representation, complex logarithmic transformation, and the Hilbert transform are well-established for generating complex-valued images. Could the authors specify the advantages of the R2C method over these alternatives?\n\nDCSNet Architecture:\n1. Fourier filters replace self-attention in DCSNet to retain information within the complex domain while preserving global context. How do Fourier filters achieve global information retention in this context, and why were they chosen?\n2. The paper briefly mentions dense tokens for image embedding but doesn\u2019t fully explain their purpose. Are these tokens meant to capture pixel-level details (dense information) of the image? If so, why not use high-resolution Fourier filters as localized filters to capture this information directly?\n3. If large Fourier filters serve as global filters in the frequency domain while dense tokens capture image details, could a bank of wavelet filters offer a more effective solution? Wavelet filters with multiple resolutions could extract both global (large scale) and local (small scale) image features.\n\nResolution Tokens: The paper mentions multiple resolution tokens \\T_{i} for i \\in {0,1,2,3}. What was the reasoning for using exactly four resolutions? Would using more or fewer resolutions impact the results?\n\nTable 7 Clarification: In Table 7, there is a term \\calL_{isal}. Is this a typo? Please clarify its meaning if not."
            },
            "questions": {
                "value": "Please see the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This study investigates a novel complex-valued deep CNN designed for foreground extraction. It proposes a new method for encoding RGB images as complex values, an end-to-end token-based architecture that maintains the complex representation throughout, and an improved training pipeline. The authors demonstrate superior performance on a variety of complex-valued image benchmarks."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "I am unfamiliar with the literature on complex-valued neural networks, and defer to the opinion of more reviewers. As a neophyte to this field, I found the manuscript overall to be very readable, well-written, interesting, and convincing. The novel encoding, architecture, and training pipeline seem to work well, and produce a very capable model for handling complex-valued inputs."
            },
            "weaknesses": {
                "value": "This may be my ascribed to my naivety for the field, but I'm unsure how to interpret the benchmark results. While DCSNet certainly seems to outperform other complex-valued neural networks, the margin of victory is often in the range of 1-5 percent. It is difficult to tell whether this represents a fundamental advance, or a marginal improvement. Further, Table 2 seems to indicate that complex-valued neural networks in general frequently fail to outperform their real-valued counterparts. How should these results be interpreted with respect to the broader viability of complex-valued neural networks?"
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}