{
    "id": "EUSkm2sVJ6",
    "title": "How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning",
    "abstract": "How much of a given dataset was used to train a machine learning model? This is a critical question for data owners assessing the risk of unauthorized data usage and protecting their right (United States Code, 1976). However, previous work mistakenly treats this as a binary problem\u2014inferring whether \\textit{all or none} or \\textit{any or none} of the data was used\u2014which is fragile when faced with real, non-binary data usage risks. To address this, we propose a fine-grained analysis called Dataset Usage Cardinality Inference (\\ourmethod{}), which estimates the exact proportion of data used. Our algorithm, leveraging debiased membership guesses, matches the performance of the optimal MLE approach (with a maximum error <0.1) but with significantly lower (e.g., $300 \\times$ less) computational cost.",
    "keywords": [
        "Machine Learning",
        "Privacy",
        "Dataset Usage Inference",
        "Dataset Ownership",
        "Membership Inference Attack",
        "Dataset Copyright"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "The first method to quantitatively and non-binarily answer the question ``How much has a dataset been used in the training of a given model?''",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=EUSkm2sVJ6",
    "pdf_link": "https://openreview.net/pdf?id=EUSkm2sVJ6",
    "comments": [
        {
            "summary": {
                "value": "The paper formalizes the problem of dataset cardinality inference, which aims to measure _how much_ of a given dataset has been used in model training. The paper shows how existing out-of-the-box membership inference methods fail to solve this problem and show how that can be remedied with de-biasing. Experimental results show the benefits of the proposed approach."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper introduces on a very important problem and gives some solid baselines to tackle it. \n\nThe method, error metrics, experimental settings, baselines, and evaluations are thoughtfully designed (in general). For example, I particularly appreciate:\n- the extra mile effort in deriving confidence intervals;\n- the use of dataset selection methods in experimental evaluations;\n- an analysis of why the confidence intervals are large around $p=1/2$;\n- the experimental setting of book copyright infringement;"
            },
            "weaknesses": {
                "value": "The main drawback, in my opinion, is that there are approximations involved in deriving the confidence estimates, making them potentially incorrect. There appear to be two approximations (please correct me if I'm mistaken): \n1. replacing $TPR_i$, $FPR_i$ with a single TPR/FPR across all samples, so the de-biasing is not exact;\n2. assuming independence of $\\hat p_i$'s to compute the confidence intervals.\n\nWhile the authors empirically show in Fig 4 that the correlations in item 2 above are small, it would be nice to see that the bias induced by item 1 is also not too large.\n\nFinally, I would have liked to see some approaches for rigorously correct (asymptotic or non-asymptotic) confidence intervals in addition to the heuristic ones used here. I believe that the XBern confidence intervals given by [Pillutla et al](https://arxiv.org/abs/2305.18447) can be used (XBern confidence intervals for $TPR_i$ and $FPR_i$ can automatically adapt to the correlation, leading to better intervals for $\\hat p$).\n\n**Other comments**: \n- I do not understand the derivation of footnote 1. It would be nice to expand on it (possibly in the supplement). \n- Figure 2 can be clearer if the x axis is in log scale\n- Missing relevant refs: [Kandpal et al](https://arxiv.org/pdf/2310.09266) for membership inference of users (groups of data) and is related to dataset inference, [Vyas et al](https://arxiv.org/pdf/2302.10870) for copyright protection, [Zhang et al.](https://arxiv.org/pdf/2406.15968) for a recent MIA"
            },
            "questions": {
                "value": "- **Poor results around $p=0$**: The results of Table 4 show that the method is not very reliable around $p=0$. This would make it unsuitable to answer the question of _if_ a dataset has been used. Are any modifications possible to adapt the proposed method to [dataset inference](https://arxiv.org/abs/2406.06443)?\n\n- Further, how does the proposed method work if our goal is to provide a multiplicative guarantee of the form that $\\hat p / p \\in (1/c, c)$? These would be more realistic in the small $p$ regime.\n\n- Like differential privacy is designed to protect against membership inference, are there any provable protections against DUCI?\n- Why do you think MIA Guess fails to work?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this manuscript the authors identify key issues of current techniques that aim to ascertain if a dataset was used to train a Machine Learning model. To alleviate these problems:\n\n1. The authors formally define the concept of Data Usage Cardinality Inference (DUCI). The authors state that, compared to other binary types of inference, DUCI better reflects real world scenarios, where models are trained on fractions of different datasets. \n2. The authors propose a way of de-biasing current models that estimate individual membership, i.e. if one individual sample was part of the training dataset. Then, they propose to use these unbiased estimators to compute the overall proportion of the dataset used for training. They also present an asymptotic method to design a confidence interval for this overall proportion used for training. \n\nFinally, the authors provide some numerical experiments where they compare the proposed procedure with four other adapted techniques that also perform DUCI. Throughout their experiments, the authors' de-biased method outperforms the other four techniques."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Identifying the dataset used to train a Machine Learning model could have a direct impact on privacy rights or copyright infringement, as mentioned in the Introduction. Hence, I think that this article deals with a relevant problem. I also appreciate that their proposed procedure is cost-effective and intuitive. In my opinion, there is a lot of merit in noticing that Member Identification methods suffer from biases and then presenting an straight-forward tool to address this issue."
            },
            "weaknesses": {
                "value": "I think that the main weakness here is the presentation. A lot of times the authors describe mathematical objects by vaguely saying what they are or make rushed arguments. However, this approach is not intuitive enough to give any insight about the matter nor formal enough to have any actual meaning. This overshadows the interesting contributions made in this paper.\n\nFrom Lines 108-115, I wonder what is \"a number of population data\", what is $\\theta(x)_y$ (as this is the first time they use this notation with y as a subscript; in fact, what is y?). What is the reference model modelling, i.e. are these models for membership inference or are these models that represent a real world classifier or regressor?. In Line 285-286, it is difficult to understand what \"the probability of observing that i-th record\u2019s likelihood to be a member is greater than randomly sampled population data points\" means. This is not even relevant to understand the paper main contributions, so it should be remove it the authors are not willing to explain it clearly or should be rewritten, if they prefer to do so. \n\nDependence/correlation of records is handled in a confusing manner. In particular, the authors pose the question \"Will the ignorance of \u201ccorrelations\u201d between records make our method sub-optimal?\" in Lines 490-491. The answer here is clearly \"Yes\", as the authors themselves have stated in Lines 444-448 that under special sampling one should divide the dataset into subgroups and then de-bias using the TPR and FPR within each subgroup. However, this additional step, which accounts for possible high-correlation, is not carefully mentioned in Section 4, so I would not assume that this is a fundamental part of their proposed technique. However, it reads as if Lines 489-497 argue that correlation between records is not an issue and that there seems to be limited potential to improve their method in this regard. Maybe the authors here are considering different methods of sampling or different settings but this is not clearly stated in Lines 489-497. This is something that should be addressed. \n\nRegarding the numerical experiments, there are two things to consider: two methods were adapted from Individual Membership Attacks and the other two baseline estimators were inspired by maximum likelihood estimation but rely on additional modeling decisions, like assuming some joint/mean logits follow a normal distribution. Although this choice is based on a theoretical result, as mentioned in Line 298, it is not clear to me that this assumption would not hinder the performance of these baselines. The authors do mention in Line 276 that they use MIA Guess and MIA Score \"To demonstrate the importance of debiasing [...]\", but I think they would need to address why the MLE with joint logits is presented as an idealized baseline. At least the MLE with average logits has good performance in various experiments, so there is evidence in favor of presenting it as an idealized baseline. However, I feel like the experiments in this paper do indicate that the proposed method performs well, under the scenarios considered here."
            },
            "questions": {
                "value": "What is the the sampling error mentioned in Line 228 in this particular setting?. \nWhat is the definition of weak independence in Line 269?."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new variation of membership attack: estimating the fraction of data from training set. Unlike normal MIA, which determine individual membership, the proposed task estimate the data usage directly. The proposed algorithm is based on the fact that the  unbiased data usage estimator can be written as a function of FPR and TPR (Eq. 6) of MIA. In other words, the proposed estimator can adapt any existing MIA attack with FPR and TPR evaluation. The experiments demonstrate the effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper introduces a new task in privacy attacks. The main contribution is a practical and scalable data usage estimator that could encourage further research in this area."
            },
            "weaknesses": {
                "value": "My main concern is that this method requires known training set for estimating FPR and TPR. In practice, the train set is usually private (see following reference Zhang at el 2024).\n\n\n\nZhang, Jie, Debeshee Das, Gautam Kamath, and Florian Tram\u00e8r. \"Membership Inference Attacks Cannot Prove that a Model Was Trained On Your Data.\" arXiv preprint arXiv:2409.19798 (2024)."
            },
            "questions": {
                "value": "1. In Figure 3, the length of confidence interval seems to be large compared to the absolute error. Is this true?\n\n2. Would this debiasing method downgrade the test power?\n\n3. Is there any connection with auditing differential privacy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Given a dataset, this paper presents an algorithm (DUCI) which estimates the proportion of that dataset used in the training of a model. The algorithm estimates the false positive rate (FPR) and true positive rate (TPR) of the membership inference guess across the entire dataset to avoid the accumulation of errors that occurs when estimating the FPR and TPR of each individual in the dataset. They conduct experiments to compare the performance of their algorithm (DUCI) against traditional membership inference baselines and an idealized, computationally inefficient MLE baseline. They also analyze the performance of DUCI and membership inference baselines under special sampling conditions and varying dataset sizes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "The paper is well motivated and addresses a gap in the literature by taking a fine grained approach to the data usage problem.\n\nThe proposed approach (DUCI) is significantly more computationally efficient compared to previous approaches."
            },
            "weaknesses": {
                "value": "I don't see any major weaknesses. It would be nice to show a comparison between DUCI and SOTA \u201cbinary\u201d data usage algorithms for the specific case for when p=1 and p=0 to demonstrate that DUCI still has comparable performance to \u201cbinary\u201d data usage algorithms in these specific cases."
            },
            "questions": {
                "value": "If TPR=FPR, how does this affect the debiasing results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an algorithm framework that can figure out whether data points in the data sets are used to train a model. This problem seems interesting, and there are some works on a similar problem called membership inference. The authors propose that instead of predicting each member by {0,1}, a better way is to predict a probability in [0,1] and design an algorithm for DUCI based on this idea. The authors also did many experiments comparing their method with several baselines on errors and confidence intervals."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper studies an interesting problem and proposes a new algorithm to predict a probability in [0,1] instead of {0,1} for the problem. Though the authors proposed a specific algorithm, the technique here can be used for any algorithm that serves the purpose of membership query. This paper is well-written and easy to read. The authors also did experiments thoroughly by comparing with baselines and on different datasets."
            },
            "weaknesses": {
                "value": "Though this paper has some novelty, the technique here seems to be quite simple and straightforward. It is hard for me to say this paper has good contribution confidently."
            },
            "questions": {
                "value": "The authors mention two possible improvements in Appendix G. I think this paper would be really strong if the authors could be more concrete on how to apply one of the ideas to their algorithm and show some results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}