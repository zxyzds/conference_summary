{
    "id": "rGGwXo0Fo0",
    "title": "SONAR: A Synthetic AI-Audio Detection Framework and Benchmark",
    "abstract": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using generative Artificial Intelligence (AI) technology have made it possible to generate high-quality and realistic human-like audio. This introduces significant challenges to distinguishing AI-synthesized speech from the authentic human voice and could raise potential issues of misuse for malicious purposes such as impersonation and fraud, spreading misinformation, deepfakes, and scams. However, existing detection techniques for AI-synthesized audio have not kept pace and often exhibit poor generalization across diverse datasets. In this paper, we introduce SONAR, a **s**ynthetic AI-Audi**o** Detectio**n** Fr**a**mework and Benchma**r**k, aiming to provide a comprehensive evaluation for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation dataset sourced from 9 diverse audio synthesis platforms, including leading TTS providers and state-of-the-art TTS models. It is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based deepfake detection systems. Through extensive experiments, we reveal the generalization limitations of existing detection methods and demonstrate that foundation models exhibit stronger generalization capabilities, which can be attributed to their model size and the scale and quality of pretraining data. Additionally, we explore the effectiveness and efficiency of few-shot fine-tuning in improving generalization, highlighting its potential for tailored applications, such as personalized detection systems for specific entities or individuals. Code and dataset are available at https://anonymous.4open.science/r/SONAR",
    "keywords": [
        "Audio deepfake detection",
        "benchmarking"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=rGGwXo0Fo0",
    "pdf_link": "https://openreview.net/pdf?id=rGGwXo0Fo0",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces an AI audio detection framework and benchmark named SONAR, designed to evaluate the generalization capability of existing AI-generated audio detection methods. A new evaluation dataset was constructed, comprising AI-generated audio samples from nine different audio synthesis platforms. Extensive experiments on both traditional and foundation models demonstrate the effectiveness of various models in detecting high-quality AI-generated audio. The results indicate that foundation models exhibit strong generalization capabilities, especially when pre-trained on a large scale. Additionally, the paper explores the effectiveness of few-shot fine-tuning in enhancing model generalization performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This study provides the  systematic evaluation of the generalization capabilities of various AI audio detection methods, introducing a rich and diverse dataset that helps bridge the gap in current research regarding generalization testing.\n\n2. The framework includes multiple traditional and foundation models, and uses multidimensional evaluation metrics\u2014such as accuracy, AUROC, and EER\u2014to analyze the strengths and weaknesses of each model, offering a comprehensive benchmark.\n\n3. The paper demonstrates the potential of few-shot fine-tuning to improve detection performance, making it especially suitable for customized or personalized detection systems.\n\n4. By incorporating data from multiple audio synthesis platforms, the study covers a wide range of audio synthesis techniques, enhancing the framework's robustness for real-world applications."
            },
            "weaknesses": {
                "value": "This paper presents a substantial amount of work, collecting various state-of-the-art TTS-generated speech samples and conducting a comprehensive evaluation and comparative analysis of existing detection methods. The primary contributions lie in the construction of a novel dataset and the systematic testing of current approaches. However, from an innovation perspective, the paper appears relatively limited, as there are already several reviews and comparative studies on forgery speech detection methods. Therefore, it is suggested to further enhance the innovation of this paper on the basis of dataset construction and method testing. \n\n1. M\u00fcller, Nicolas M., et al. \"Mlaad: The multi-language audio anti-spoofing dataset.\" arXiv preprint arXiv:2401.09512 (2024).\n2. Alali, Abdulazeez, and George Theodorakopoulos. \"Review of existing methods for generating and detecting fake and partially fake audio.\" Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics. 2024.\n3. Chen, Tianxiang, et al. \"Generalization of Audio Deepfake Detection.\" Odyssey. 2020."
            },
            "questions": {
                "value": "1. In the dataset constructed by the authors, there is significant variability in the number of samples across different types, resulting in an unbalanced distribution among categories (e.g., only 25 samples for PromptTTS2 compared to 600 for OpenAI). It would be helpful to understand the reasoning behind this design choice. Additionally, the dataset lacks details about the speakers and speech content, and the total sample size appears limited. These factors may significantly affect detection performance. Have the authors considered variables like speech encoding compression, format, and background noise? These aspects could impact the performance of forgery detection tasks, and increasing the dataset\u2019s diversity and representativeness would improve the comparison of different models' robustness and generalization capabilities.\n\n2. The MLAAD dataset includes 59 state-of-the-art TTS models, such as XTTS and Wishperspeech, covering multiple languages. Supplementing experiments with different models on this dataset would further enhance the credibility of the experimental conclusions.\n\nM\u00fcller, Nicolas M., et al. \"Mlaad: The multi-language audio anti-spoofing dataset.\" arXiv preprint arXiv:2401.09512 (2024).\n\n3. In the setup of comparative experiments, aside from model architecture, did the authors consider the impact of techniques such as training data augmentation strategies and loss functions on model performance? These factors could play a significant role in shaping detection accuracy and robustness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To assess the performance of speech forgery detection models against advanced TTS technologies, this paper proposes the SONAR framework. SONAR constructs a new evaluation dataset from nine different audio synthesis platforms based on the current leading TTS methods. Extensive experiments on this dataset are conducted using three metrics: EER, AUROC, and Accuracy, and subsequently analyzes the limitations of current detection methods in terms of generality. The aim is to provide an evaluation benchmark to promote forgery speech detection methods to cope with new forgery technologies. Such work is meaningful for current speech detection methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper introduces existing forgery speech detection methods, tests their performance against leading TTS-generated forgery speech, and the experiments are comprehensive. The proposed methods and the new evaluation dataset are a supplement to existing speech forgery detection research."
            },
            "weaknesses": {
                "value": "The dataset proposed in this work seems to focus only on TTS as a forgery method, but does not pay attention to forgery methods such as voice conversion and voice splicing, which is a deficiency of this work."
            },
            "questions": {
                "value": "see in weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors present SONAR, a new benchmark for AI-audio detection, derived from 9 TTS platforms. They claim this is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based deepfake detection systems. The authors also conduct extensive experiments to assess the model\u2019s generalization capabilities and evaluate how factors such as model size and data scale affect model's performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The field of audio deepfake detection is an emerging area that has garnered significant attention.\n2. The paper presents the ideas in a generally understandable way, with clear explanations of key concepts.\n3. The authors are open about the study\u2019s potential limitations and provide suggestions for future research directions."
            },
            "weaknesses": {
                "value": "1. **Related Works**: The paper does not adequately reference similar prior work in audio deepfake detection datasets. For instance, Voicewukong [1] offers a benchmark with more diverse data sourced from 34 speech synthesis platforms and includes multiple models, both traditional and advanced. Additionally, there are other works [2, 3] that also evaluate deepfake detectors using data from state-of-the-art generation methods, such as VALL-E and NaturalSpeech 3. Moreover, widely-used datasets like ASVspoof 2019 and 2021 [4, 5], although based on more traditional generation methods, are well-known benchmarks in this domain. It would strengthen the paper to acknowledge these datasets and clarify the specific advantages of SONAR compared to these established benchmarks.\n2. **Dataset Construction**: The dataset presented (2274 fake samples) is relatively small compared to existing datasets, which typically contain more than 10,000 samples. Furthermore, the dataset is limited to 9 generation methods, with 6 of them sourced from demo pages or provided test set. The range of languages and voices is also quite restricted, which may limit the generalizability of the findings.\n3. **Experiments**: While the authors conduct experiments to study generalization, many of the conclusions drawn are already well-established in previous research. For example, it is widely recognized that using foundation models significantly improves performance, and that increasing model size or adding data for fine-tuning enhances results. Additionally, due to the small size of the SONAR dataset, the results on each subset may not be sufficient to fully reflect the broader performance implications.\n\n**References**: \n\n[1] Yan, Z., Zhao, Y., & Wang, H. (2024). VoiceWukong: Benchmarking Deepfake Voice Detection. *arXiv preprint arXiv:2409.06348*.\n\n[2] Xie, Y., Xiong, C., Wang, X., Wang, Z., Lu, Y., Qi, X., ... & Ye, L. (2024). Does Current Deepfake Audio Detection Model Effectively Detect ALM-based Deepfake Audio?. *arXiv preprint arXiv:2408.10853*.\n\n[3] Li, Y., Zhang, M., Ren, M., Ma, M., Wei, D., & Yang, H. (2024). Cross-Domain Audio Deepfake Detection: Dataset and Analysis. *arXiv preprint arXiv:2404.04904*.\n\n[4]  Nautsch, A., Wang, X., Evans, N., Kinnunen, T. H., Vestman, V., Todisco, M., ... & Lee, K. A. (2021). ASVspoof 2019: spoofing countermeasures for the detection of synthesized, converted and replayed speech. *IEEE Transactions on Biometrics, Behavior, and Identity Science*, *3*(2), 252-265.\n\n[5] Liu, X., Wang, X., Sahidullah, M., Patino, J., Delgado, H., Kinnunen, T., ... & Lee, K. A. (2023). Asvspoof 2021: Towards spoofed and deepfake speech detection in the wild. *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, *31*, 2507-2522."
            },
            "questions": {
                "value": "1. **Data Preprocessing**: In Figure 1, the data preprocessing is shown at the evaluation stage, but it\u2019s unclear what preprocessing steps were applied to the data that was collected or generated. Since the data may vary in aspects such as sample rate and audio format, it would be helpful to explain the specific preprocessing methods used to ensure consistency across the dataset.\n2. **AudioGen Data**: It is unclear why data from AudioGen, which consists of synthetic acoustic scenes, was included in SONAR, as these scenes don\u2019t seem directly related to the paper\u2019s proposed motivation. If the goal is to explore differences between detecting fake speech and synthetic sounds, it would be more effective to create two distinct subsets for speech and non-speech audio and incorporate a wider range of sound generation methods for a more thorough analysis.\n3. **Training and Testing Settings**: The most common setting in deepfake detection involves training on the ASVspoof 2019 LA dataset [4] and testing on other datasets. It\u2019s not clear why this setting wasn\u2019t followed in the paper, or why test results on the ASVspoof dataset weren\u2019t provided."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}