{
    "id": "GfuJR76Sfo",
    "title": "ContraSim: Contrastive Similarity Space Learning for Financial Market Predictions",
    "abstract": "We introduce the Contrastive Similarity Space (ContraSim) paradigm that is able to form global semantic understanding between how daily financial headlines can affect market movement. ContraSim consists of two steps. 1) Weighted Headline Augmentation: We propose a method of augmenting financial headlines to create new headlines with known semantic distances to the original. 2) Weighted-Self Supervised Contrastive Learning (WSSCL): An extension of classical binary contrastive learning algorithms, WSSCL leverages the known distances between anchor and augmented prompts to generate finely grained embedding space that optimizes for similar news to be clumped together. We measure how well ContraSim is able to learn global financial information by parsing whether or not it inherently groups newslines of homogeneous market movement directions together, using a novel information density metric Info-kNN. We find that incorporating features from ContraSim into financial forecasting tasks has a 7\\% increase in classification accuracy. Additionally, we highlight that ContraSim can be used to find historic news-days that most resemble pertinent financial headlines of the day to help analysts to make better decisions for predicting market movement.",
    "keywords": [
        "Learning Representations",
        "Large Language Models",
        "Financial Forecasting"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We introduce a method of clustering financial headlines together using a novel weighted self-supervised contrastive learning approach, and we find it can help improve market movement prediction accuracy.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=GfuJR76Sfo",
    "pdf_link": "https://openreview.net/pdf?id=GfuJR76Sfo",
    "comments": [
        {
            "summary": {
                "value": "In this paper, a novel Weighted Self-Supervised Contrastive Learning (WSSCL) method is introduced to cluster news-lines based on learned semantic embeddings. LLMs are used to create modified prompts containing semantically identical or augmented news-lines. An enhanced version of KNN algorithm based on information theory is also introduced for clustering, in order to handle imbalanced labelled classes. Experiments on the task of stock market direction prediction show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper focuses on an interesting problem, that is stock market direction prediction. The proposed method based on contrastive learning of text embeddings is reasonable. The example about rephrasing, slight ablation, and negative modification of the headline in Table 1 is illustrative and to the point."
            },
            "weaknesses": {
                "value": "Only one dataset (the NIFTY dataset) is used. It'd be great if the authors could use more datasets for evaluation."
            },
            "questions": {
                "value": "The estimated baseline values are a mean of random samples following the (23%, 60%, 17%) label split in Table 3. Does it mean if a trivial classifier always predicts the label of a sample is Neutral, it would achieve 60% accuracy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a model for stock movement prediction."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "N/A"
            },
            "weaknesses": {
                "value": "1. Low-quality presentation.\n2. Lack of serious experiments.\n3. Lack of contributions."
            },
            "questions": {
                "value": "The presentation of this paper is poor, which directly affects readers' understanding of the model design and problem formulation. It is unclear whether some model details are omitted or buried under misleading representations\n1. There are numerous grammar mistakes and typos in the first paragraph of Section 3.1, with almost every sentence containing issues. This makes understanding the motivation behind building the proposed embedding space difficult.\n2. It is unclear why the authors chose to use 10 and 30 to control the number of news articles sampled per day. Are these numbers theoretically justified, suggested by domain experts, or supported by empirical results? Also, what happens if there are fewer than 10 financial-related news articles in a day?\n3. What is the motivation behind using random sampling when there are more than 30 news articles per day? The use of randomness makes it difficult to ensure that the space will cover all topics described in the news for that day. In the worst-case scenario, important topics might be completely omitted.\n4. The authors claim that they only keep newslines and ignore tabular data. What does this mean? This statement seems to come out of nowhere.\n5. In the description of creating headlines, it is unclear why \"prompts\" are sometimes created and, at other times, \"headlines\" are created. Is there a specific reason for this, or are these typos?\n6. In Equation 3, it is unclear what the text refers to.\n7. The notation $N_i$ in the description below Equation 3 should be $N_k$\n8. The symbol $h$ in Equation 3 should be $\\hat{h}$\n9. The augmentation method lacks a quality control mechanism for headline generation. Also, the definitions of \"slight ablation\" and \"negative\" are unclear. In the given example, it appears that the authors only used a language model to generate fake company names, which lacks a clear motivation.\n10. The section on \"generating newsline buckets\" is difficult to understand due to grammar mistakes and undefined terms, making the entire subsection challenging to follow.\n11. The method used by the authors to achieve \"known semantic distance\" lacks motivation. It appears that the authors manually assigned values of 1, 0.5, and 0 to three different augmentations without justification.\n12. Grammar mistakes and typos continue throughout the rest of the paper, making it challenging to list them all. However, there are some critical ones. For example, in the WSSCL section, the authors state that there are only three movements: Fall, Natural, and Fall again.\n13. The experiment section lacks serious comparisons to justify the performance of the proposed model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Potentially harmful insights, methodologies and applications"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The authors used an LLM to augment news headlines without any constraints. In the example provided, some of the generated headlines are misleading and fake."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents ContraSim, a contrastive learning framework for financial market prediction that creates a dense embedding space for financial news headlines. The approach has two main components:\n\n1. Weighted Headline Augmentation: This technique generates variations of financial headlines with known semantic distances, including reworded, slightly ablated, and negative versions, allowing the model to capture rich semantic relationships between headlines.\n2. Weighted Self-Supervised Contrastive Learning (WSSCL): Extending traditional contrastive learning, WSSCL uses augmented headlines to establish a continuous similarity space, clustering semantically similar headlines and separating dissimilar ones.\n\nThe framework introduces a novel metric, Info-kNN, to measure the density of semantically similar clusters. When integrated with a language model-based classifier, ContraSim achieves a 7% improvement in classification accuracy and a 13% boost in balanced accuracy over the baseline. Additionally, it provides practical support for financial analysts by identifying similar historical market days, offering valuable insights for forecasting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Innovative and Practical Framework: The integration of contrastive learning through Weighted Headline Augmentation and WSSCL in financial market prediction presents a novel approach that assists financial analysts by enabling the identification of historical market conditions.\n2. Enhanced Performance: The framework\u2019s substantial improvements in classification accuracy (+7%) and balanced accuracy (+13%) validate its effectiveness.\n3. Info-kNN Metric: The introduction of the Info-kNN metric, which evaluates clustering in the embedding space using information-theoretic principles, is a notable contribution. This metric provides a new way to assess contrastive learning models and has potential applications beyond financial data."
            },
            "weaknesses": {
                "value": "1. Limited Ablation Studies: The current ablation studies are limited, particularly in assessing the individual impact of the headline augmentations (reworded, slightly ablated, and negative). Examining how each augmentation affects accuracy and clustering\u2014especially by showing the effect of their removal\u2014would strengthen the claims. A similar analysis could be extended to Info-kNN and WSSCL components.\n2. Narrow Scope in Experiments: Although the authors mention plans for broader application, the current validation is confined to financial data, which limits the immediate generalizability of the findings. Including experiments from other domains or providing a more in-depth discussion of potential applications would enhance the broader impact of this work."
            },
            "questions": {
                "value": "Could you provide more detailed insights into how the different headline augmentation types (reworded, slightly\nablated, negative) contribute individually to the observed improvements in classification accuracy and clustering\neffectiveness? While the paper outlines these augmentations, it would be helpful to understand the individual\nimpact of each augmentation type on the model's learning process. Additionally, a more detailed ablation study\nof key components, such as augmentation types, Info-kNN, and WSSCL, would offer a clearer understanding of\ntheir respective contributions to the overall performance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces ContraSim, an innovative approach for predicting financial market movements that employs a two-part method: it first creates semantically varied financial headlines through Weighted Headline Augmentation, and then applies Weighted-Self Supervised Contrastive Learning (WSSCL) to refine the embedding space. This combination allows ContraSim to effectively group newslines that reflect similar market trends, achieving a notable 7% improvement in classification accuracy for financial forecasts. Additionally, the authors present a novel metric called Info-kNN to assess how well the embedding space captures significant semantic relationships within financial news."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "It presents a methodology that integrates advanced techniques such as Weighted Headline Augmentation and Weighted-Self Supervised Contrastive Learning (WSSCL), providing a fresh perspective on the interplay between financial news and market behavior.  The introduction of the Info-kNN metric to evaluate semantic clustering in the embedding space is another key contribution, offering researchers a robust tool for assessing how well models capture the complexities of financial data."
            },
            "weaknesses": {
                "value": "First, the paper does not inform the reader how ContraSim contributes to the field relative to other approaches. Second, apparently LLMs bring their own biases to the model. Any biases inherited from the LLM can affect the quality of the data and predictions. Predictions based on headlines provides limited scope and prediction errors as headlines are usually written to take attention."
            },
            "questions": {
                "value": "What are the types of augmentations utilized?\nWhat are the characteristics of the learned embedding space that influences the interpretability of financial predictions? \nCan you elaborate the hyperparameter tuning process in more detail?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}