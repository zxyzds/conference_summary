{
    "id": "INFfvQArFY",
    "title": "Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing",
    "abstract": "The locate-then-edit paradigm has shown significant promise for knowledge editing (KE) in Large Language Models (LLMs). While previous methods perform well on single-hop fact recall tasks, they consistently struggle with multi-hop factual recall tasks involving newly edited knowledge. In this paper, leveraging tools in mechanistic interpretability, we first identify that in multi-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper MLP layers, unlike single-hop tasks, which rely on earlier layers. This distinction explains the poor performance of current methods in multi-hop queries, as they primarily focus on editing shallow layers, leaving deeper layers unchanged. To address this, we propose IFMET, a novel locate-then-edit KE approach designed to edit both shallow and deep MLP layers. IFMET employs multi-hop editing prompts and supplementary sets to locate and modify knowledge across different reasoning stages. Experimental results demonstrate that IFMET significantly improves performance on multi-hop factual recall tasks, effectively overcoming the limitations of previous locate-then-edit methods.",
    "keywords": [
        "Knowledge Editing"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=INFfvQArFY",
    "pdf_link": "https://openreview.net/pdf?id=INFfvQArFY",
    "comments": [
        {
            "summary": {
                "value": "The paper addresses challenges in existing locate-then-edit knowledge editing methods, particularly focusing on multi-hop knowledge editing. The authors first investigate why locate-then-edit approaches struggle with multi-hop fact editing using tools from mechanistic interpretability, such as the logit lens and causal intervention. Their findings suggest that later MLP layers play a crucial role in storing multi-hop knowledge. To better update these knowledge-storing MLPs, the authors introduce a supplementary set construction method for each edit, transforming each edit into a multi-hop chain. This supplementary set then generates virtual multi-hop prompts specifically targeting the knowledge being edited. The authors utilize two-hop templates from this supplementary set to modify the model\u2019s later layers, thereby enhancing multi-hop knowledge editing."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- **Comprehensive Analysis**: The paper presents a thorough analysis in Section 3, identifying that information related to multi-hop knowledge is stored in later MLP layers. Using interpretability tools such as the logit lens and causal interventions, the authors confirm this and propose edits to the last layer based on these findings.\n- **Empirical Validation**: Experiments in Tables 3 and 4 show that the proposed method outperforms previous methods on multi-hop knowledge editing tasks, providing compelling evidence for its effectiveness."
            },
            "weaknesses": {
                "value": "- **Insufficient Presentation**: Section 5.2 lacks clarity as Tables 5 and 6 are referenced but not included in the main paper, instead being located in the appendix. While space constraints are understandable, omitting key results from the main discussion detracts from readability and coherence. Additionally, the absence of descriptions for the \"base\" in Tables 5 and 6 and missing details on the datasets used in Table 4 (e.g., whether MQuAKE is consistently used) leaves gaps in understanding.\n- **Questionable Analysis of Results**: In Table 3, performance seems to decline post-editing compared to the original, but there is no discussion on the possible causes for this drop. If editing knowledge reduces performance, the rationale for the edits becomes unclear. It appears that \u201coriginal\u201d performance refers to accuracy on the unedited answer, but if so, why wasn\u2019t accuracy on the correct answer also reported for the original model? Clearer explanations are necessary to clarify these performance metrics.\n- **Limited Novelty in Method and Analysis**: The primary contribution of this work lies in the insight, obtained through interpretability tools, that multi-hop knowledge editing requires updating the later MLP layers. However, there is no clear experimental analysis showing that editing the later layers specifically contributes to performance improvement. It raises the question of whether merely expanding the support set was sufficient for better performance, implying that gains may not be attributed solely to the proposed method. To substantiate this claim, it would be useful to report the impact of the editing layers on performance, comparing different layers with and without the supplementary set."
            },
            "questions": {
                "value": "- **Figures**: Consider widening Figures 2(a) and 2(b) to improve readability and enlarge the subfigures in Figure 6 for better visibility.\n- **Tables**: Provide a clearer explanation of the term \u201cbase\u201d in Tables 5 and 6. It\u2019s unclear whether this refers to the \u201coriginal\u201d in Table 3 or another baseline. Clear labels and descriptions would enhance understanding."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces IFMET, a novel locate-then-edit method for knowledge editing for language models.\nIt aims to improve the multi-hop factual recall by modifying both shallow and deep layers of model weights.\nPrevious methods focus on shallow layers and thus struggle with multi-hop editing.\nIFMET addresses this by using multi-hop prompts and supplementary sets to locate and edit knowledge across multiple layers.\nThis allows the language model to answer multi-hop queries more accurately post-edit.\nExperimental results show that IFMET outperforms existing knowledge editing methods (such as Mello, and MEMIT) on multi-hop knowledge editing."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper fills a gap in KE for multi-hop knowledge editing. It addresses the limitations of traditional local-then-edit methods that primarily operate in shallow layers.\n2. The paper gives detailed explanations and experiments about how single-hop and multi-hop queries are handled differently within language models. The used LogitsLen and causal intervention experiments are interesting.\n3. The proposed IFMET is compared with strong baselines across experiments and shows great performance."
            },
            "weaknesses": {
                "value": "1. The used language model GPT-J (6B) is a bit outdated. More recent language models are expected to be considered.\n2. How about the performance of the generality and locality of knowledge editing? The editing should also affect related facts but not affect other unrelated facts.\n3. The paper lacks discussions about editing efficiency. What is the time complexity of IFMET?\n4. Compared to Mello, IFMET requires supplementary set construction from external sources (same for MEMIT and ROME). This may hinder its applications in real cases."
            },
            "questions": {
                "value": "1. The biblology style should be consistent. Some lines are underlined and others are not.\n2. How does IFMET perform on other language models? Like recent Llama-3.\n3. How long does IFMET take to edit one multi-hop sample?\n4. Can IFMET deal with unstructured facts for knowledge editing as in [1]?\n5. Line 387, cizizenship --> citizenship.\n6. Figure 1, Mardrid --> Madrid.\n\n [1] Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses an important limitation in knowledge editing for LLMs - their poor performance on multi-hop factual recall tasks after editing. Through careful mechanistic analysis using tools like LogitLens and causal intervention experiments, the authors discover that LLMs process multi-hop queries differently from single-hop ones - they accumulate implicit subject information in middle layers before retrieving the final answer from deeper MLP layers. This explains why current KE methods, which focus on editing shallow layers, fail at multi-hop tasks. Based on these insights, they propose IFMET, a novel locate-then-edit approach that edits both shallow and deep MLP layers using supplementary knowledge sets and multi-hop prompts. Their experimental results on the MQuAKE dataset show improvements over existing methods, particularly for complex multi-hop queries."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Strong Empirical Analysis: The authors provide a thorough, well-designed investigation into how LLMs process multi-hop queries differently from single-hop ones. The use of LogitLens and causal intervention experiments to track information flow through different layers is particularly impressive.\n\n2. Novel Theoretical Insight: The discovery that implicit subject information accumulates in middle layers before being used to retrieve answers from deeper MLP layers is an important contribution to our understanding of LLM reasoning. This finding not only explains the limitations of current KE methods but also has broader implications for LLM interpretability research.\n\n3. Good result: The proposed IFMET solution is elegant and well-motivated by the theoretical findings. This is a practical solution that improves performance on multi-hop queries."
            },
            "weaknesses": {
                "value": "Overall, this paper is solid. But some parts of this paper are missing:\n\n1. Why do we need to conduct \"Locate-then-edit\" editing when we have some very good performance RAG-based editing methods [1][2]? There is no need for this paper to compare performance with RAG-based editing in the experiments part, but a short discussion should be included on why IFMET is superior to these RAG-based methods.\n\n2. Currently, only experiments are conducted on MQUAKE-3k; more benchmarks, such as MQUAKE-T, could be included.\n\n[1] Shi, Yucheng, et al. \"Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering.\" CIKM, 2024.\n[2] Gu, Hengrui, et al. \"Pokemqa: Programmable knowledge editing for multi-hop question answering.\" ACL, 2024."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces IFMET, a novel locate-then-edit approach for knowledge editing in Large Language Models (LLMs), specifically targeting multi-hop factual recall tasks. The authors leverage mechanistic interpretability to identify that LLMs retrieve implicit subject knowledge from deeper MLP layers in multi-hop tasks, unlike single-hop tasks, which rely on earlier layers. This insight leads to the development of IFMET, which edits both shallow and deep MLP layers. Experimental results show that IFMET significantly outperforms existing methods on multi-hop factual recall tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper provides a thorough and interesting analysis of the differences between single-hop and multi-hop tasks, highlighting the importance of editing deeper layers in LLMs.\n\n2. The writing is clear, making the proposed method easy to understand and follow.\n\n3. The experimental results are impressive, demonstrating significant improvements over existing methods in multi-hop factual recall tasks."
            },
            "weaknesses": {
                "value": "1. The method may have certain limitations. Specifically, using WikiData and SPARQL queries to construct the supplementary dataset may not be applicable to non-factual or non-encyclopedic data, limiting the generalizability of the approach.\n\n2. The organization of the paper could be improved. The experimental section is relatively short, with some important experimental tables relegated to the appendix. Additionally, the paper lacks a comprehensive ablation study.\n\n3. The explanation and analysis of the experimental results are somewhat lacking. For instance, in Table 3, it is unclear what the values represent (e.g., accuracy) and why the performance of IFMET improves as the edit batch size increases, while the performance of other baselines decreases. More detailed explanations and discussions of these observations would strengthen the paper."
            },
            "questions": {
                "value": "Please refer to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}