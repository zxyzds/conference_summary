{
    "id": "wCwz1F8qY8",
    "title": "Prediction of Protein-protein Contacts with Structure-aware Single-sequence Protein Language Models",
    "abstract": "Accurate prediction of the interface residue-residue contacts between interacting proteins is valuable for determining the structure and function of protein complexes. Recent deep learning methods have drastically improved the accuracy of predicting the interface contacts of protein complexes. However, existing methods rely on Multiple Sequence Alignments (MSA) features which pose limitations on prediction accuracy, speed, and computational efficiency. Here, we propose a transformer-powered deep learning method to predict the inter-protein residue-residue contacts based on both single-sequence and structure-aware protein language models (PLM), called DeepSSInter. Utilizing the intra-protein distance and graph representations and the ESM2 and SaProt protein language models, we are able to generate the structure-aware features for the protein receptor, ligand, and complex. These structure-aware features are passed into the Resnet Inception module and the Triangle-aware module to effectively produce the predicted inter-protein contact map. Extensive experiments on both homo- and hetero-dimeric complexes show that our DeepSSInter model significantly improves the performance compared to previous state-of-the-art methods.",
    "keywords": [
        "Protein bioinformatics",
        "Protein language models",
        "Protein-protein contact prediction",
        "Protein representations",
        "Deep neural networks"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=wCwz1F8qY8",
    "pdf_link": "https://openreview.net/pdf?id=wCwz1F8qY8",
    "comments": [
        {
            "summary": {
                "value": "This work proposes DeepSSInter, a transformer-based deep learning model for predicting protein-protein interface contacts without relying on Multiple Sequence Alignments (MSA). DeepSSInter combines single-sequence and structure-aware protein language models, utilizing intra-protein distance and graph representations to capture the structural and evolutionary properties of interacting proteins. In particular, the model leverages ESM2 and SaProt representations, a ResNet-Inception module, and a geometric triangle-aware module to enhance prediction accuracy. Experiments on homo- and heterodimeric complexes demonstrate that DeepSSInter outperforms state-of-the-art methods, particularly in challenging heterodimeric cases."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The work's primary strength lies in its approach to protein-protein contact prediction, addressing the limitation of existing methods by eliminating the need for Multiple Sequence Alignments (MSA). The method\u2019s reliance on single-sequence data and its use of structure-aware language models (ESM2 and SaProt) offer computational efficiency and scalability, broadening its applicability to proteins with limited or no homologous sequences."
            },
            "weaknesses": {
                "value": "The whole work is like a variant of DeepInter [1] with incremental improvements. The architecture of the proposed model only changes the way of extracting embeddings from input when compared to DeepInter. The datasets and experimental settings are all the same as those in DeepInter.\n\nThe description of the proposed method is not clear. It is unknown about the details of the \"ResNet-Inception module\" and \"triangle-aware module\". It seems that they are directly borrowed from DeepInter, but the authors didn't mention that in the manuscript. \n\nIn Table 4, it is misleading that the results of the proposed DeepSSInter are all highlighted but they all perform worse than DeepInter.\n\n\n[1] Lin, P., Tao, H., Li, H., & Huang, SY. Protein-protein contact prediction by geometric triangle-aware protein language models. Nature machine intelligence, 5, 1275-1284 (2023)."
            },
            "questions": {
                "value": "How the ligand 1D and receptor 1D features are combined with those 2D features?\n\nHow the attention representations are generated by ESM2 and SaProt? Each hidden layer of PLMs can have attention representations.\n\nAre there multimers for the receptors in the datasets? If so, how are they processed by the PLMs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces DeepSSInter, which predicts protein-protein interactions by combining existing protein language models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "evaluation performances are better than selected baselines."
            },
            "weaknesses": {
                "value": "The paper seems more like a wrapped-up of existing methods and provides little new insights on the problem, making the submission a workshop-level paper instead of research paper.\n\nThe paper largely ignores existing methods in multimeric protein structure predictions with MSAs ([1,2]) or PLMs ([3,4]). These methods share identical motivations to the proposed one, especially [4] which proposes to predict protein-protein interactions using protein language models. Discussions and comparisons should be made against these methods. Also comparisons with protein-protein docking methods ([5,6]) should be discussed, as these methods are already broadly used in real applications.\n\n[1] AlphaFold Multimer https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1 ;\n[2] RosettaFold https://www.science.org/doi/10.1126/science.abj8754 ;\n[3] ESM-Fold https://www.science.org/doi/10.1126/science.ade2574;\n[4] Uni-Fold MuSSe: https://www.biorxiv.org/content/10.1101/2023.02.14.528571v1 ;\n[5] HDock: https://www.nature.com/articles/s41596-020-0312-x ;\n[6] Haddock: https://rascar.science.uu.nl/haddock2.4/ ;"
            },
            "questions": {
                "value": "Figure 3 and 4 should be reorganized  for readers to extract information more easily. Currently it is hard for readers to accurately compare all the colored bars."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents DeepSSInter, a novel transformer-based deep learning model designed to predict protein-protein interface contacts using structure-aware single-sequence protein language models. This model's efficiency and predictive power mark a significant advancement in protein interaction prediction, particularly beneficial for cases where MSA is unavailable or inefficient."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality: The model creatively combines advanced components like graph-based features, ResNet-Inception, and a triangle-aware module, innovatively moving beyond MSA. These elements effectively address challenges in both computational complexity and prediction accuracy, especially for heterodimers, which are historically difficult for MSA-based models.\n\nQuality: The authors validate DeepSSInter rigorously through extensive experiments on homodimeric and heterodimeric datasets, consistently outperforming five state-of-the-art methods in precision metrics. Ablation studies and evaluations with AlphaFold2-predicted structures further strengthen the model\u2019s demonstrated robustness and confirm the necessity of each architectural component.\n\nClarity: The paper is well-organized, with clear descriptions of model components, experimental setup, and visual aids like architecture figures. Though some technical terms could use more explanation, the methodology and results are easy to follow.\n\nSignificance: By eliminating the need for MSA, DeepSSInter is both faster and more accurate, marking a significant advancement for applications in structural biology and drug discovery. This approach paves the way for single-sequence modeling in protein interaction research, making it impactful for high-throughput and resource-efficient studies."
            },
            "weaknesses": {
                "value": "1. Model Limitations with AlphaFold2-Predicted Structures\nDeepSSInter's performance declines with AlphaFold2-predicted structures, especially for heterodimeric complexes, where it underperforms compared to DeepInter. This discrepancy suggests that single-sequence protein language models may lack the coevolutionary information MSA provides, which is crucial for some complex predictions. The paper would benefit from deeper analysis on this limitation, perhaps through: Alternative or augmented data inputs: Exploring ways to integrate low-dimensional coevolutionary features from paired MSAs, even minimally, could help bridge the gap between structure-aware single-sequence models and MSA-based predictions. Fine-tuning: Considering an additional fine-tuning phase on AlphaFold2-generated complexes could improve robustness to predicted structures, enhancing real-world applicability.\n2. Limited Interpretability of Model Outputs\nAlthough the paper shows improved prediction precision, the interpretability of the model outputs remains unaddressed. For practical applications in structural biology, understanding why certain contacts are predicted is often as important as the predictions themselves. Including feature attribution methods, like attention weight visualizations or feature importance analyses on the ESM2 and SaProt modules, could provide insights into how the model makes predictions, aiding users in the interpretation of contact predictions.\n3. Broader Benchmarking and Testing\nThe paper focuses on precision metrics in homodimeric and heterodimeric complexes, but testing could be broadened to include more diverse protein types, such as oligomeric or multimeric complexes. These more complex structures are increasingly common in real-world biological contexts. Expanding benchmarks to these protein forms could provide a fuller view of DeepSSInter\u2019s performance and generalizability."
            },
            "questions": {
                "value": "1.Could you provide more interpretative insights into which features or attention patterns are most important for your model's predictions?\n2.Given the reliance on specific protein language models (ESM2 and SaProt), have you evaluated the model\u2019s adaptability to other \n3.Have you considered evaluating DeepSSInter on other types of protein complexes, such as oligomeric or multimeric structures? If so, what were the outcomes?\n4.Could you elaborate on the choice of using both ResNet-Inception and triangle-aware modules? How do these components interact, and do they provide overlapping or distinct contributions to model performance?\n5.Given the performance decline with AlphaFold2-predicted structures, have you considered fine-tuning the model on such predicted structures? If so, what were the results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors present a state-of-the-art model for protein-protein contact map predictions, without the use of MSA, which indeed are hard to come by in the case of heteromers and represent a big improvement in tackling protein-protein contact map problem.\nTo do so they essentially built a model that processed each binding  partner separately as well as the complex formed by the partners, and  they did it using different types of information:\n- An EGNN is used to discover useful amino acid representations of both partners as separate entities, from structure information.\n- A RBF is used to enrich the description of distances between residue at different scales, leading to the building of an intra-distance matrix for both partners as separate entities.\n- ESM embeddings are used to derive useful amino acid representations of both partners as separate entities, from evolutionary information.\n- ESM attention is used as a counterpart for the distance-based matrix from the RBF transformation.\n- The same that was done using ESM is now done using SaProt for retrieval of amino acid information more focused on the local structural environment.\n- Finally, both ESM-derived features and SaProt-derived features are also produced for the partner pair. For ESM-related features, it comes with the addition of a linker, and for SaProt, a sequence of unknown tokens as foldseek has no complex structures to work with.\nAll of those part are then run through a ResNet Inception module followed by a triangle aware module, to produce a protein-protein contact map."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Apart from the fact that authors present a model that reaches state-of-the-art performance in most conditions and that it doesn't need MSA (and that's not a small achievement), the paper's strength lays in how it breaks down its conclusions: homodimers, heterodimers, real pdbs, alphafold-generated pdbs, and ablation study. The study by pdb type is super interesting, and seems to show that this model is still useful in the alphafold pdb case but probably more in the homodimeric case, and in the heterodimer case one can still work with this model MSA-based counterpart model."
            },
            "weaknesses": {
                "value": "This paper has 3 main caveats which I believe are not deal-breakers but for which at least 2 would (and could) benefit for improvement in how it is presented in the paper. \nThe first one is that it is a very massive pipeline and understanding what really matters seems hard.\nThe second one is the lack of a clear description of how to use the model at prediction time.\nThe last point is about the overall presentation of results and data, mainly incorporating more evaluation metrics and a bit deeper description of the data involved."
            },
            "questions": {
                "value": "Indeed, it is quite hard to make sense of the ablation study (not the author's fault, the results are what they are). For example for the homodimer case: no_gt_esm as good or even better than the full model? Reverse conclusion for heterodimers? I left the reading with the feeling: it works great but is all of that really necessary? Of course, having a (performant !) model straying away from MSA is very welcomed and necessary, but what matters in the model is not obvious. A way maybe to add to this ablation study would be to have a comparison (just plotting side by side with some metrics for example: F1 score , area under the ROC, difference between contact map, where is the difference on the structure ) for a few complexes for different models.\n\nThe second one is the lack of a clear description of how to use the model at prediction time. By that I mean the following. Sequences have to be truncated when they are too big, for obvious memory and time complexity reasons, but those truncations, at least given how they are explained, rely on some ground truth of a sequence window that has maximum PPI. At prediction time if we have a pair of big proteins and no idea how to choose this window how do we do? Moreover, how can we assess the confidence of those pairings in the contact map? Could we have then a study where for long protein sliding or random windows are chosen and distribution of predicted contact residue numbers are plotted: in that case is the model most of the time predicting the maximum number of contact at the right ground truth window? How often does it not? Is this a strategy at prediction time, and can we use this distribution to have a confidence about the window chosen?\n\nThe last point is about the overall presentation of results and data:\n- Results: Could we have more metrics (F1 score, area under the ROC) than the precision which would give more information about the different types of errors? Maybe a few confusion matrices for some cases where the model works fine and for when the model works worse. Also, a few of those contact maps predicted as well as how that translates on the structures. I find it really hard to draw a good picture from a paper when only one metric (a statistical one in this case) is used for the whole discussion.\n- Data: Some data analysis of the training data. For example, I have no idea what is the distribution of number of contact interactions given some protein length. Mainly as the sequence has to be cropped around part of the sequence with maximum contact with the other protein partner, I would like to have an idea of what that maximum represents:  are we still in the super imbalanced class regime, how easy it is to reach 80% precision in that case by just putting every pairs of residue  as contact residue and so on. Is this cropping strategy leading to a very different distribution of contact fraction than the non-cropped one? How sensitive is it to this choice of 320 residues and so on...\n\nSide questions: \nWould a more stringent but identical preprocessing step for both pdb types (real vs alphafold) be a possible way to reduce the drop in performance?\nFor the drop of performance between homodimers and heterodimers, did the author try to bump up the loss weight for heterodimers?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}