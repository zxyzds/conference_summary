{
    "id": "gsShHPxkUW",
    "title": "Beyond Surface Structure: A Causal Assessment of LLMs' Comprehension ability",
    "abstract": "Large language models (LLMs) have shown remarkable capability in natural language tasks, yet debate persists on whether they truly comprehend deep structure (i.e., core semantics) or merely rely on surface structure (e.g., presentation format). Prior studies observe that LLMs' performance declines when intervening on surface structure, arguing their success relies on surface structure recognition. However, surface structure sensitivity does not prevent deep structure comprehension. Rigorously evaluating LLMs' capability requires analyzing both, yet deep structure is often overlooked. To this end, we assess LLMs' comprehension ability using causal mediation analysis, aiming to fully discover the capability of using both deep and surface structures. Specifically, we formulate the comprehension of deep structure as direct causal effect (DCE) and that of surface structure as indirect causal effect (ICE), respectively. To address the non-estimability of original DCE and ICE --- stemming from the infeasibility of isolating mutual influences of deep and surface structures, we develop the corresponding quantifiable surrogates, including approximated DCE (ADCE) and approximated ICE (AICE). We further apply the ADCE to evaluate a series of mainstream LLMs (and the one with random weights), showing that most of them exhibit deep structure comprehension ability, which grows along with the prediction accuracy. Comparing ADCE and AICE demonstrates closed-source LLMs (e.g., GPT) rely more on deep structure, while open-source LLMs (e.g., Llama) are more surface-sensitive, which decreases with model scale. Theoretically, ADCE is a bidirectional evaluation, which measures both the sufficiency and necessity of deep structure changes in causing output variations, thus offering a more comprehensive assessment than accuracy, a common evaluation in LLMs. Our work provides new insights into LLMs' deep structure comprehension and offers novel methods for LLMs evaluation. The code for our project is available at  [https://anonymous.4open.science](https://anonymous.4open.science/r/DiD-based-Causal-Mediation-Framework-417A).",
    "keywords": [
        "Large Language Models",
        "Causality",
        "Interpretability"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=gsShHPxkUW",
    "pdf_link": "https://openreview.net/pdf?id=gsShHPxkUW",
    "comments": [
        {
            "summary": {
                "value": "The manuscript investigates the comprehension abilities of large language models (LLMs) beyond superficial structures by introducing a causal mediation framework. The authors propose the use of approximated direct causal effect (ADCE) and approximated indirect causal effect (AICE) as proxies to quantify comprehension of deep and surface structures, respectively. Through this framework, they empirically evaluate the reliance of mainstream LLMs, such as GPT and Llama, on deep versus surface structures across a range of tasks, including mathematical reasoning and commonsense understanding."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "+ The paper presents an innovative method to quantify the comprehension of deep structures in LLMs through causal analysis.\n+ Comprehensive datasets and models are used for evaluation.\n+ Experimental results across multiple tasks suggest that ADCE is a valuable metric for assessing model comprehension."
            },
            "weaknesses": {
                "value": "- It is unclear how deep structures are accurately identified and separated from surface structures, which is crucial for the validity of the interventions.\n- The ADCE and AICE are presented as approximations, but it is unclear how accurately they reflect the true causal effects intended for evaluation."
            },
            "questions": {
                "value": "Overall, I appreciate the authors\u2019 efforts in introducing a novel approach to assessing the comprehension ability of LLMs, especially in quantifying deep structure reliance. However, I have a few questions and points for clarification:\n\n- Your approach relies on interventions targeting deep and surface structures. In your experiments, how are deep structures accurately identified and separated from surface structures? It would be helpful to understand the criteria or methods used to make this distinction reliably.\n\n- Since ADCE and AICE are approximations, have you conducted any experiments to validate these metrics against true causal effects? Any validation results would help clarify the accuracy and reliability of these metrics in capturing the LLMs\u2019 reliance on different structural components.\n\n- I have a question regarding the use of causal mediation analysis within the causal structure presented in Figure 3.\nAs I understand it, causal mediation analysis is typically used to assess how the effect of a treatment variable X on an outcome Y is mediated through an in intermediate variable Z. This approach is often applied to measure both the direct effect of X on Y and the indirect effect mediated by Z (i.e., X -> Z -> Y). For example, a drug X might have a direct effect on a disease Y, but it may also cause patients to take aspirin Z, which further impacts Y through this indirect pathway.\nIn your causal graph, however, it seems that the deep structure d and surface structure s within the input x, independently affect the outcome Y through separate pathways (d -> Y and s -> Y). Since d does not mediate or influence s, these pathways appear to act in parallel rather than in a sequential manner where one variable mediates the effect of another.\nGiven this structure, could you please clarify whether causal mediation analysis is appropriate in this context? It would be helpful to understand how the direct and indirect effects are conceptualized in this framework, especially if the mediation structure does not strictly follow the conventional X -> Z -> Y pathway."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a framework to evaluate LLMs by distinguishing between their reliance on deep structures and surface structures. Using causal mediation analysis, it proposes metrics called Approximated Direct Causal Effect for deep structure comprehension and Approximated Indirect Causal Effect for surface structure, offering a more nuanced assessment of model understanding than accuracy alone. The findings reveal that closed-source models, like GPT, rely more on deep structure, whereas open-source models, like Llama, are more sensitive to surface structures, though this sensitivity decreases with model size"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper introduces a unique framework that goes beyond accuracy to assess how language models rely on deep versus surface structures.\n2. The ADCE and AICE metrics are interpretable and allow for precise distinctions between models' reliance on core semantics and surface-level structures.\n3. The framework highlights significant differences between closed-source and open-source models in their reliance on deep vs. surface structures, contributing valuable insights into model development trends."
            },
            "weaknesses": {
                "value": "1. Although the metrics provide valuable insights, their exact interpretations may vary depending on model architecture, making it difficult to generalize findings across diverse LLMs without further context.\n2. The approach may require internal access to models for accurate analysis, potentially limiting its use with proprietary or black-box models where such transparency isn\u2019t feasible."
            },
            "questions": {
                "value": "1. Could the authors clarify how practitioners might interpret ADCE and AICE values across different model architectures?\n2. How does the approach perform on NLP tasks involving noisy or unstructured data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a causal mediation analysis framework to assess LLMs' comprehension ability of deep structure versus surface structure. The authors propose ADCE and AICE metrics to quantify comprehension of deep and surface structures. They demonstrate that most LLMs exhibit genuine deep structure comprehension that increases with model scale, while dependence on surface structure varies between open and closed-source models."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "- Paper is well-written.\n- Comprehensive empirical evaluation across multiple tasks and model families with insightful findings about deep vs surface structure reliance\n- This paper is novel; proposes ADCE and AICE for quantification based on causal mediation analysis.\n- The method is task-agnostic; evaluation on 5 tasks across math, logic, common sense benchmarks."
            },
            "weaknesses": {
                "value": "- The relationship between ADCE and fine-tuning (Section 4.3) is only briefly explored."
            },
            "questions": {
                "value": "- ADCE seems to capture both sufficiency and necessity of deep structure changes in causing output variations. How might different post training strategies influence a model's reliance on deep vs. surface structure?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes to use the casual mediation analysis method to examine the following question: does the LLM really understand the deep semantic meaning for problem-solving or merely rely on text surface forms? Authors claim that previous methods usually investigate this effect in specific tasks without generalization. This paper presents approximated direct causal effect (ADCE) and approximated indirect causal effect (AICE) to empirically quantify the LLM dependencies on deep structure understanding or shallow surfaces. \n\nThe reviewer is not familiar with related works in this field, and therefore, the commentary below is from a general NLP researcher's point of view. The confidence score is set to 2 to reflect this point."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper presents a novel point of view to evaluate if the LM relies on the deep structures or surface forms to answer questions. Empirical and theoretical results show that the proposed ADCE is a better metric when evaluating LLM deep structure dependency.\n\n2. The findings that closed-source LLMs rely more on deep structure while open-source models are sensitive to surface indicate that the current open-source SFT / alignment stages still need further investigation to have a higher reliance for the models on deep structure.\n\n3. The proposed ADCE metric indicates that the accuracy of specific tasks could be misleading."
            },
            "weaknesses": {
                "value": "1. I am concerned about the necessity of applying causal mediation analysis to this research question. Mask, Replace, Swapping, etc., are common practices for augmenting text data as well as examining the sensitivity of LLMs to slight variations in the input text. The motivation for the CMA application in this submission is not clear to me, given the current writing. \n\n2. Following 1, Section 3.3 is intuitive by itself without the theories in Section 3.1 and 3.2. If I understand correctly, Equation 5 is a simple combination of several indicator functions that reflects if intervention to the question has actual effects."
            },
            "questions": {
                "value": "Refer to the Weaknesses Part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}