{
    "id": "HkPz96fgOv",
    "title": "Energy-Efficient Sampling Using Stochastic Magnetic Tunnel Junctions",
    "abstract": "(Pseudo)random sampling, a costly yet widely used method in (probabilistic) machine learning and Markov Chain Monte Carlo algorithms, remains unfeasible on a truly large scale due to unmet computational requirements. We introduce an energy-efficient algorithm for uniform Float16 sampling, utilizing a room-temperature stochastic magnetic tunnel junction device to generate truly random floating-point numbers. By avoiding expensive symbolic computation and mapping physical phenomena directly to the statistical properties of the floating-point format and uniform distribution, our approach achieves a higher level of energy efficiency than the state-of-the-art Mersenne-Twister algorithm by a minimum factor of 9721 and an improvement factor of 5649 compared to the more energy-efficient PCG algorithm. Building on this sampling technique and hardware framework, we decompose arbitrary distributions into many non-overlapping approximative uniform distributions along with convolution and prior-likelihood operations, which allows us to sample from any 1D distribution without closed-form solutions. We provide measurements of the potential accumulated approximation errors, demonstrating the effectiveness of our method.",
    "keywords": [
        "Sampling",
        "Random Number Generation",
        "Probabilistic Machine Learning",
        "Hardware",
        "Power Consumption",
        "Spintronics",
        "Sustainability"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "We introduce a highly energy-efficient spintronics-based algorithm for truly random Float16 samples, outperforming traditional methods and allowing for effective sampling from arbitrary 1D distributions without closed-form solutions.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=HkPz96fgOv",
    "pdf_link": "https://openreview.net/pdf?id=HkPz96fgOv",
    "comments": [
        {
            "title": {
                "value": "Answer"
            },
            "comment": {
                "value": "Dear Reviewer QDDw,\n\nThank you for reviewing our paper. We appreciate your time and would like to address your questions and discuss the noted weaknesses.\n\n*\"The reliance on specific s-MTJ hardware may limit the method\u2019s accessibility and applicability, particularly for researchers or practitioners who lack access to such specialized components, potentially requiring additional investment.\"*\n\nWe believe it's important to distinguish between the current prototypical stage of our fundamental research setting and the subsequent adoption stage that will follow the publication of this approach. In the current stage, novel materials and devices are typically limited to those with specialized knowledge and resources; this stage is not intended for practitioners. \nIn the adoption stage, companies such as NVIDIA, AMD, or Intel will integrate these components into their products (e.g., as a separate unit within a GPU) and make them available to researchers and practitioners. **This principle applies to any hardware-based device; we do not consider this a weakness of our paper**. \nTo emphasize that this is a realistic pathway, we can point to deterministic MTJs, which, with similar materials and device structures, have already been adopted into commercial computer chips in the form of MRAMs. These components are now accessible to all researchers and practitioners.\n\n*\"It was also unclear if the ambient temperature of the chip would also impact the distributions (which is hard to control).\"*\n\nIn general, s-MTJs are susceptible to process reliability and environmental effects just as any other semiconducting devices. Variation of temperature can alter natural frequency of the stochastic devices, as shown in Figure 4b of the manuscript. However, note again that deterministic MTJs have been successfully adopted into commercial computer chips and this is a solvable manufacturing-related problem.\n\n*\"How does the presence of genuine randomness affect model stability and repeatability in long-running applications, especially in training deep models with dropout or other probabilistic methods?\"*\n\nThe repeatability of experiments is a legitimate concern when it comes to using genuine randomness. However, we believe that, in many real-world applications, cost-effectiveness is more important than repeatability. For instance, a search engine or a large online retailer that requires billions of inferences may prioritize efficiency over consistent results. It really depends on the individual use case.\nAlso, the trade-off between repeatability and energy efficiency may need to be reconsidered in light of the significant energy consumption associated with current large-scale AI systems. However, addressing all those (legitimate) trade-offs falls outside the reasonable scope of our paper. Our focus is on proposing a new energy-efficient computing paradigm.\n\n*\"Can you further clarify how the s-MJT would implement equations the operations on the sampled distributions (Eqns 11-16). Is the idea that these equations are done in some way off-line such that these operations amount to sampling? I think this can be more clear. It would also be useful to understand if any other operation is typically necessary, such as a non-linear operation.\"*\n\nOur paper introduces two novel sampling paradigms. First, we present highly energy-efficient uniform sampling. Second, we propose a mixture of uniforms to create a universal sampler capable of handling arbitrary distributions. Additionally, Equations 11-16 enable the application of convolutions and prior-likelihood transformations directly within the representation space of the distributions. These transformations can be implemented in two different ways, depending on how a hardware manufacturer chooses to apply our approach.\nThe first option involves directly implementing the transformations as digital logic at the circuit level, near the s-MTJ devices. This approach allows for more efficient execution and integration into applications. The second way, if a direct implementation is not intended, is computing them at the software level while leveraging the highly efficient uniform sampling provided by the s-MTJ devices at the hardware level. In both scenarios, the transformations can be interpreted as a learning stage (or inference stage in probabilistic terminology) that occurs before sampling, as in other machine learning applications. We are happy to clarify that in the camera-ready version.\n\nWe hope that we answered your questions and addressed your concerns! We would be happy if you give us your acceptance to present this new paradigm to our community!"
            }
        },
        {
            "summary": {
                "value": "This paper presents an energy-efficient algorithm for random sampling using stochastically switching magnetic tunnel junction (s-MTJ) devices. By directly mapping the physical properties of the s-MTJ to a uniform Float16 distribution, the proposed method avoids the computational overhead of symbolic calculations. Additionally, it introduces a method to sample from arbitrary 1D distributions using a mixture model approach, achieving low approximation errors.\n\n\n\nQuestion:"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed framework is innovative, demonstrating both originality and significant potential in energy-efficient random sampling. The authors support these claims through simulations that indicate notable energy savings compared to existing methods.\n\n2. By aligning the random generation process with the statistical properties of the Float16 format, this method sidesteps complex symbolic computations, enhancing both efficiency and simplicity.\n\n3. By decomposing complex distributions into mixtures of uniform distributions, this approach allows for sampling from arbitrary 1D distributions without closed-form solutions, thus expanding the practical utility"
            },
            "weaknesses": {
                "value": "1. The reliance on specific s-MTJ hardware may limit the method\u2019s accessibility and applicability, particularly for researchers or practitioners who lack access to such specialized components, potentially requiring additional investment.  \n\n2. Due to physical constraints in setting bias currents and control bits, there may be small approximation errors in generating the intended Bernoulli distributions, which could impact applications requiring precise random number distributions.  It was also unclear if the ambient temperature of the chip would also impact the distributions (which is hard to control)."
            },
            "questions": {
                "value": "How does the presence of genuine randomness affect model stability and repeatability in long-running applications, especially in training deep models with dropout or other probabilistic methods?\n\nCan you further clarify how the s-MJT would implement equations the operations on the sampled distributions (Eqns 11-16). Is the idea that these equations are done in some way off-line such that these operations amount to sampling?  I think this can be more clear. It would also be useful to understand if any other operation is typically necessary, such as a non-linear operation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a framework to generate uniform Floating-point numbers with stochastically switching magnetic tunnel junction (MTJ) devices. A collection of devices produces correctly sampled mantissa and exponent bits by tuning their Bernoulli distribution according to a closed-form solution. The authors compare their MTJ approach with the pseudo-random number algorithms Mersenne-Twister/PCG. Through SPICE simulation and measurements (Antunes & Hil 2024, Noureddine, 2022), an energy reduction of 9721x/5649x is shown. In addition, the authors explain the construction of general distribution from uniform ones and methods to sum and multiply them. They also present the analysis of the approximation errors."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "A potential low-energy integrated framework for large-scale random number generation is shown. The methodology is straightforward and applicable to any source of tunable Bernoulli distributions. One of the applications includes probabilistic machine learning."
            },
            "weaknesses": {
                "value": "The paper presents a general framework for random number generation with MTJ or any Bernoulli source. Random number generation is part of many machine learning methods, but it is not clear how this is specifically relevant to an ML audience.\n\nThe paper presents the energy consumption resulting from the SPICE simulation of the devices and parts of the additional circuitry needed. Whereas for the reference measurements for the pseudo algorithms, there\u2019s no indication of what kind of intermediate computations and memory operations are being done. In addition, the comparison is between the generation of Float16 and Int32 where it is not elaborated on how this affects energy consumption. Overall it is not clear how it is a fair comparison.\nThe methodology is only compared against pseudo-random generation algorithms, but not against other hardware solutions. Other previous work on generating random numbers with MTJs (Example of R. Zhang et al. https://doi.org/10.1002/advs.202402182) are not discussed. Thus, there is not sufficient coverage of existing work."
            },
            "questions": {
                "value": "- How does it compare to other relevant works on hardware random number generation?\n- What parts of the framework are novel and not seen in other works?\n- How much would the energy consumption increase if the devices were integrated into modern architecture? In other words, what other consumption of energy is required?\n- How much is the energy consumption reduction for relevant ML applications?\n- Would the integrated MTJ devices have a similar lifetime to current hardware?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Authors present a device capable of sampling one-dimensional distributions with arbitrary distributions, in float16 precisions. They describe how their device is more efficient at this task than standard hardware, and provide benchmarks which indicate orders of magnitude of energy efficiency gains through simulations of their hardware, both through cadence and through custom micromagnetic simulations."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is well written, and the approach is clearly explained. \nThe idea is scientifically sound, and the benchmarks are extensive and include very recent work (2024) that compares samplers. Two types of simulations were considered: i) through cadence, with the global foundries PDK, which includes realistic effects (though it is unclear what is/isn't included), and ii) through custom micromagnetic simulations, which are shown to match well theoretical predictions. I am not expert in these devices but it seems to me they have shown significant promise for a few years and this paper pushes the idea further and seems like a solid contribution to the field of sampling."
            },
            "weaknesses": {
                "value": "One weakness is that the device was only simulated and not actually realized, so uncertainty remains with respect to practical performance   (although the simulations are extensive, so I do not think this is a reason to reject).\nI think the paper would benefit from a Limitations section, which would make it clear what effects were not captured in the simulations. For example, what about PVT variations?\n\nAnother weakness that may be improved on is the energy efficiency gain on downstream tasks, i.e., you show dramatic improvement over digital samplers, but how much impact would this have on a downstream task, say of a MCMC sampling task of a given probability distribution? This would be interesting to run with a software with pyro and show the overall energy efficiency improvement."
            },
            "questions": {
                "value": "Did you think about an extension to multidimensional probability distributions? I understand that this is a much more difficult problem, but it would be interesting to at least discuss it in the paper. Maybe some form of correlations may be implementable between s-MTJs which would allow for sampling of a given class of multidimensional probability distributions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a hardware framework based on spintronic devices. By aggressively scaling the device down to nanoscale, thermal noise dominates the resistance state to enable randomness. In addition, the randomness can be biased by applying current through the device to accommodate arbitrary probability p in Bernoulli distribution. The authors use the above features to facilitate 16-bit floating point uniform sampling."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Sampling is essential in probabilistic models. The idea of using physical devices for efficient sampling is promising."
            },
            "weaknesses": {
                "value": "The devices do not seem to be readily deployable and may face manufacturing issues, thus may require further development."
            },
            "questions": {
                "value": "1. Sampling from a uniform distribution is the primary objective of this work and I greatly appreciate the authors' efforts in evaluating the error. Still, would it be possible to illustrate the actual distribution that the system is sampling from, given the limited number of control bits and the precision requirements indicated in Equation 6? So readers can have intuitive understandings. It would be great to show some zoom-in subfigures for detailed pdf variation in less-precise areas, too. \n2. For a 32-bit floating point, how would the actual distribution be like? How many control bits would it require to achieve sufficient sampling precision for 32-bit float? \n3. Since the probability of each bit can be atomically manipulated, is it feasible to use the system to sample an arbitrary distribution for arbitrary data format? I find this potential very intriguing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}