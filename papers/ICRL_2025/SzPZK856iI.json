{
    "id": "SzPZK856iI",
    "title": "Text-to-Image Rectified Flow as Plug-and-Play Priors",
    "abstract": "Large-scale diffusion models have achieved remarkable performance in generative tasks. Beyond their initial training applications, these models have proven their ability to function as versatile plug-and-play priors. For instance, 2D diffusion models can serve as loss functions to optimize 3D implicit models. Rectified Flow, a novel class of generative models, has demonstrated superior performance across various domains. Compared to diffusion-based methods, rectified flow approaches surpass them in terms of generation quality and efficiency. In this work, we present theoretical and experimental evidence demonstrating that rectified flow based methods offer similar functionalities to diffusion models \u2014 they can also serve as effective priors. Besides the generative capabilities of diffusion priors, motivated by the unique time-symmetry properties of rectified flow models, a variant of our method can additionally perform image inversion. Experimentally, our rectified flow based priors outperform their diffusion counterparts \u2014 the SDS and VSD losses \u2014 in text-to-3D generation. Our method also displays competitive performance in image inversion and editing.",
    "keywords": [
        "3D Generation",
        "Rectified Flow",
        "Flow Matching"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=SzPZK856iI",
    "pdf_link": "https://openreview.net/pdf?id=SzPZK856iI",
    "comments": [
        {
            "summary": {
                "value": "The submitted work propose a way of utilizing rectified flow models a prior, that implies the internal knowledge of the model as in the form of an objective. Throughout the manuscript, the authors propose three different algorithms in this regard, where they are named as RFDS (Rectified Flow Distillation Sampling), iRFDS (inverse RFDS) and RFDS-Rev (RFDS Reversal). While discussing the analogy between the SDS (Score Distillation Sampling), which serves as a prior for models trained with score-matching objective (e.g. diffusion models), they demonstrate how these algorithms can be utilized as a loss objective reflecting the knowledge of the rectified flow model and the image inversion & editing task. Furthermore, the authors propose RFDS-Rev algorithm as the improved version of the baseline algorithm (RFDS).\n\nTo demonstrate the effectiveness of the set of the proposed algorithms, authors show the effectiveness of them on a variety of tasks. Initially, the authors demonstrate how does the proposed method improve over SDS in diffusion models in terms of generation quality. Following, they illustrate the applications of the proposed algorithms in inversion based tasks (e.g. image editing) and text-to-3D generation with a 2D prior from rectified flow models. For all of the demonstrated algorithms, authors provide qualitative and quantitative results that shows the effectiveness of the proposed framework."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper proposed the first algorithm that utilizes rectified flow models as priors, to both enable implicit information encoded in the rectified flow model and inversion based image editing with such models.\n- In addition to the baseline method provided, authors also propose an extension named RFDS-Rev, that improves over the baseline objective RFDS, that combines the algorithms proposed together and promises improved generation quality.\n- Proposed method showcases satisfactory results on Text-to-3D generation, which shows the effectiveness of the proposed method over providing a prior on multiple views.\n- Authors introduce a simplifying assumption enabling to efficiently using rectified flow models as priors, by simplifying the generator Jacobian. This serves as a modification for improving the efficiency of the proposed method.\n- The paper provides sufficient amount of experiments demonstrating the effect of the design decisions made on the algorithms, which also serve as insightful observations (number of steps, effect of the Jacobian)."
            },
            "weaknesses": {
                "value": "- In the examples provided, there is a significant saturation effect on the provided results (see Fig. 5, row 2 and Fig. 6, examples from SD3). It is unclear if that effect is a result of the proposed method or a property of the rectified flow models. \n- While the image editing results seem semantically correct, there seems to be significant changes in the provided images (See Fig. 5) compared to methods such as Null-text Inversion. Despite the fact that the authors provide a user study and CLIP score based comparisons, the faithful reconstruction property is not discussed and it is unclear that how successful the provided approach is.\n- In generation results provided in Fig. 7 (fox example), the generation results seem degraded in terms of quality and provides artifacts. It also seems that RFDS in general produces these artifacts. If the alternative method RFDS-Rev recovers those, authors need to provide related discussions and examples on its performance on the performed tasks (such as inversion based editing). If this algorithm is not applicable for such a scenario, it should be mentioned as a limitation of the method."
            },
            "questions": {
                "value": "- The authors are strongly encouraged to discuss more on the quality degradation issues mentioned in weaknesses. If this is an effect of the proposed algorithm, it should be discussed throughly. \n- Authors should consider  extending the quantitative results on the reconstruction properties of the iRFDS. Despite the fact that the current evaluation assesses the edit in terms of success in reflecting the semantics, the qualitative results seems that the algorithm fails in preserving edit independent details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes to use rectified flow for SDS instead of diffusion models.\n\nThe propose method has three components:\n* Rectified flow distillation sampling (RFDS) = typical SDS but with rectified flow\n    * Equations are the same with SDS except having *flow residual* instead of denoising loss\n    * It uses random noises to compute the *flow residual*.\n* Optimizing the *noise* (iRFDS) with the same flow residual\n* Full algorithm (RFDS-Rev) with RFDS and iRFDS\n    * iRFDS starting from a random noise\n    * RFDS with the optimized noise\n\niRFDS and RFDS-Rev are applicable to diffusion models, especially with classifier-free guidance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper tackles a long-standing problem: SDS. SDS with rectified flow is not good enough and the proposed method generates sharp results.\n2. The proposed method is easy to understand and mostly sound.\n3. The proposed method is generalizable to a wide range of flow-based methods.\n4. Preliminary is thorough enough to provide the knowledge base.\n5. Figure 2 greatly helps understanding the intuition of RFDS-Rev.\n6. Experiments are well-organized from 2D to 3D."
            },
            "weaknesses": {
                "value": "(Ordered by importance. Resolving them will raise my rating.)\n\n1. Subsection 3.2 should provide the theoretical justification for the reason why optimizing the noise helps RFDS.\n2. Choice of the competitors for text-based image editing is not sound because it covers only inversion variants. Answering following questions may improve soundness: Why should we compare only with inversion variants? Why prompt-to-prompt variants (e.g., DDPM inversion + P2P) should be ignored?\n3. The text-to-3D results still suffer from Janus problem. Discussion in this direction would enrich the paper.\n4. Question of the user study is ambiguous: Given the source image, \"a boat in a river\", which method is better by changing boat -> rock? There are different aspects of being \"better\", e.g., consistency except the boat, and they should be separately evaluated.\n5. Results of generated 3D assets (Figure 4) should be rendered in multiple views to be evaluated. Supp. materials have viewpoint-varying videos. Mentioning a Supp. would suffice.\n6. Introduction is verbose. It would be clearer if non-essential sentences are removed.\n\nMisc.\n\nL169 using pretrained rectified flow models v_phi -> using a pre-trained rectified flow model v_phi"
            },
            "questions": {
                "value": "1. Why do the bottles change across n=1 and n\u200e\u2009=\u20092 while boots stay the same in Figure 6? The only difference I catch between boots and bottles is 2D and 3D.\n2. Why does the network Jacobian harm the results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper uses the SOTA rectified-flow-based model as plug-and-play priors to lift the text-to-2D model into a text-to-3D model, with RFDS and RFDS-Rev. By removing the Jacobian of the rectified flow network, RFDS can generate meaningful images or 3D objects given text conditions. RFDS-Rev iteratively applies iRFDS for flow reversal to determine the original noise, and RFDS for knowledge distillation to refine the input."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper analyzes the refined process of the rectified flow.\n\n2. Using the rectified flow as the priors is interesting.\n\n3. The experiments are sufficient."
            },
            "weaknesses": {
                "value": "* Writing needed to be improved, especially, from Lines 100-107, which is important but the logic is somewhat unclear.\n\n* The focus of the paper is a little confusing, including Image inversion, editing, and text-to-3D generation. In my view, text-to-3d must be the key contribution as it use the 2D model as the priors.\n\n* What is the difference between RFDS Loss and SDS loss. It seems that RFDS is the version of the flow-based model.\n\n* What is the speed impact of the iterative application of iRED in REDS-rev?"
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a framework that distills knowledge from the pre-trained text-to-image rectified flow models, which serve as a strong prior and apply to various downstream tasks such as image editing and text-to-3D. Similar to \u2018Score Distillation Sampling\u2019 (SDS) loss, authors propose a novel loss termed \u2018Rectified Flow Distillation Sampling\u2019 (RFDS) that is fully compatible with Rectified Flow models and partially with Diffusion models. Furthermore, they suggest iRFDS and RFDS-Reversal, the variant of their proposed loss, that can be applied to the image inversion and RFDS-based enhancement mechanism, respectively. The authors conducted extensive experiments to validate the efficiency and efficacy of their method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The proposed RFDS, which poses similarity to SDS, presents an effective way to adapt pre-trained Rectified Flow models to tasks such as text-to-3D. This contribution is fundamental since there is a growing trend toward Rectified Flow models in the community.\n\n2. The authors conducted extensive experiments with various Rectified Flow/Diffusion baselines, which proves the versatility and efficacy of the proposed RFDS framework.\n\n3. The proposed method shows solid performance and faster convergence speed compared to baselines, which is noticeable.\n\n4. This paper is easy to follow and comprehend."
            },
            "weaknesses": {
                "value": "1. As far as my understanding is correct, RFDS-Rev redirects the gradients (velocities) of the rendered image to points close to the same data distribution mode given different noisy samples to handle common issues such as blurriness that could arise from averaging different-mode directing gradients. For this reviewer, it is unclear how iRFDS can enhance the performance of models without Reflow since these models would not have perfect straight-line paths. Approximated starting points (initial noise) would not guarantee a \u2018static position\u2019 within the noise distribution, and I think the more detailed explanation or empirical evidence would further make this work concrete. \n\n2. The results in image editing (Fig.5) do not seem convincing since semantics that are supposed to remain still are also being changed, such as the global contrast of the image, textures, and object shapes. This makes me doubtful if the proposed iRFDS can indeed optimize the valid initial noise given data. Maybe a simple reconstruction test (from optimized noise to the original data) would further provide a concrete evaluation.\n\n3. I think the explanation of faster convergence speed compared to SDS/VSD is weak since it is an important property in the field of 3D generation methods using diffusion priors. Further elaboration or evidence of this feature would help readers fully comprehend their work (e.g., comparing convergence curves with respect to the number of iterations or wall-clock time).\n\n4. Weak baseline methods. While I appreciate the paper's contribution (the first attempt to use Rectified Flow as priors) and the results are quite promising, baseline methods are rather weak (DreamFusion and VSD are quite outdated at the moment). It would be great if the authors compared against state-of-the-art text-to-3D methods, e.g., LucidDreamer [1], DreamCraft3D [2] or even GaussianDreamer [3] using different 3D representations.\n\n[1] LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching, Liang et al., CVPR 2024\n\n[2] DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior, Sun et al., ICLR 2024\n\n[3] Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models, Yi et al., CVPR 2024"
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}