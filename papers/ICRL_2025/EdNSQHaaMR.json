{
    "id": "EdNSQHaaMR",
    "title": "Selective Task Group Updates for Multi-Task Optimization",
    "abstract": "Multi-task learning enables the acquisition of task-generic knowledge by training multiple tasks within a unified architecture. However, training all tasks together in a single architecture can lead to performance degradation, known as negative transfer, which is a main concern in multi-task learning. Previous works have addressed this issue by optimizing the multi-task network through gradient manipulation or weighted loss adjustments. However, their optimization strategy focuses on addressing task imbalance in shared parameters, neglecting the learning of task-specific parameters. As a result, they show limitations in mitigating negative transfer, since the learning of shared space and task-specific information influences each other during optimization. To address this, we propose a different approach to enhance multi-task performance by selectively grouping tasks and updating them for each batch during optimization. We introduce an algorithm that adaptively determines how to effectively group tasks and update them during the learning process. To track inter-task relations and optimize multi-task networks simultaneously, we propose proximal inter-task affinity, which can be measured during the optimization process. We provide a theoretical analysis on how dividing tasks into multiple groups and updating them sequentially significantly affects multi-task performance by enhancing the learning of task-specific parameters. Our methods substantially outperform previous multi-task optimization approaches and are scalable to different architectures and various numbers of tasks.",
    "keywords": [
        "Multi-Task Learning",
        "Multi-Task Optimization",
        "Proximal Inter-Task Affinity"
    ],
    "primary_area": "learning theory",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=EdNSQHaaMR",
    "pdf_link": "https://openreview.net/pdf?id=EdNSQHaaMR",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a multi-task learning method that adaptively groups tasks based on proximal inter-task affinity and then sequentially updates each group. It provides a theoretical explanation of the benefits of sequentially updating task groups and the role of incorporating task-specific parameters in reducing conflicts. Experimental results demonstrate the method's superior performance across various benchmarks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Solid analysis from a theoretical perspective: The paper provides theoretical insights to explain the effectiveness of the proposed method, including (i) the benefits of sequential updating of groups, and (ii) the role of incorporating task-specific parameters in reducing conflicts.\n\n2. The paper is well-written and well-organized."
            },
            "weaknesses": {
                "value": "1. Based on proximal inter-task affinity, what principle do we use for task grouping? Discussion on other principles should be included. For example, in [1], they use the Fisher Information Matrix, grouping the most heterogeneous tasks to mitigate conflicts.\n\n2. The motivation for introducing proximal inter-task affinity: After reading Appendix A.1, I still find it difficult to understand the motivation for introducing proximal inter-task affinity.\n\n3. Sequential learning on tasks [1], domains [3,4], and mini-batches [2] for alignment has been studied previously. It would be beneficial to compare the different theoretical perspectives between the proposed method and these prior studies.\n\n[1] Task Groupings Regularization: Data-Free Meta-Learning with Heterogeneous Pre-trained Models, ICML 2024  \n[2] On the Origin of Implicit Regularization in Stochastic Gradient Descent, ICLR 2021  \n[3] Sequential Learning for Domain Generalization, ECCV 2022  \n[4] Gradient Matching for Domain Generalization, ICLR 2022"
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The author proposes a method for addressing multi-objective problems by grouping objectives.\nIn the process of considering relations between tasks (objectives), the concept of inter-task affinity was introduced, but additional computation was reduced by focusing on the update of task-specific parameters.\nAdditionally, introducing the concept of affinity to group objectives is the author\u2019s original idea and has been thoroughly analyzed both theoretically and experimentally."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Experimental Analysis\nIn the field of deep learning, the analysis of batch sequences has not been extensively explored. The author argues that grouping certain objectives in multi-objective problems can be significantly beneficial from a global perspective and has demonstrated this experimentally. In cases where the multi-task learning (MTL) results outperform those of single-task learning (STL), the author\u2019s method consistently achieves the highest performance, which serves as strong empirical support for the validity of the proposed approach.\n\n2. Logical Approach\nThe author\u2019s approach to deriving proxy task affinity is reasonable.\nBy utilizing the loss after task parameter updates, the author effectively reduced additional computations\nAlso, the proposed method has been theoretically proven to remain useful.\nAdditionally, the explanation of the benefits of grouping derived from Theorem 2 is clearly written and easy to understand."
            },
            "weaknesses": {
                "value": "In my understanding, some questions remain regarding the actual utility of certain theoretical approaches.\nThe author addresses the utility of multiple objectives in a local context, but optimization in the field of deep learning is far more complex.\nIn practice, grouping the same classes together for optimization in classification tasks may be optimal for the currently updated classes locally; however, it is challenging to reach a global optimum.\nI would like to see additional experimental evaluation on this matter.\nI will leave detailed suggestions in the questions section."
            },
            "questions": {
                "value": "As I mentioned in the weaknesses section, I do not interpret the author\u2019s theoretical analysis as indicating that the proposed multiple-objective method can be effectively solved on a global scale.\nHowever, I am not suggesting the necessity of a stringent theoretical foundation.\nI would like to see evidence that the author\u2019s method can consistently provide an optimal point.\nDemonstrating that the proposed method is robust across different batch sizes, numbers of groups, and optimization hyperparameters would effectively support its consistency and reliability."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper discusses the challenges of multi-task learning, where training multiple tasks together in one architecture can lead to negative transfer or performance degradation. Traditional solutions focus on optimizing shared parameters but neglect task-specific ones. The proposed solution involves grouping tasks selectively and updating them in each batch, along with an algorithm that adapts to determine effective task grouping. The concept of proximal inter-task affinity is introduced to track task relations during optimization. This approach is said to improve multi-task performance by enhancing the learning of task-specific parameters and is shown to outperform previous methods, being scalable to different architectures and task numbers."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper investigates an important problem of multi-task learning. \n2. This paper is well-written and easy to follow.\n3.  Realizing that traditional solutions focus on optimizing shared parameters but neglect task-specific ones, the authors delve into the concept of proximal inter-task affinity, making this paper well-motivated.\n4.  The proposed method is new to me and gives a fresh perspective to further improve the performance of MTL.\n5. This approach is said to improve multi-task performance by enhancing the learning of task-specific parameters and is shown to outperform previous methods, being scalable to different architectures and task numbers."
            },
            "weaknesses": {
                "value": "1. The task grouping result in Figure 3c seems out of converge. Will the number of groups further increase as the iteration becomes larger?\n2. Why Nash-MTL is not reported in Table 2?\n3. In the theoretical analysis (Section 4), the authors explain how this sequential update strategy can improve multi-task performance from an optimization standpoint. What about the generalization standpoint? I think the generalization of a model is more important.\n4. In real-world applications, a typical MTL problem may have only a few tasks (e.g., 3). Will the proposed method work in such a circumstance? What is the task grouping result if there are only three tasks?"
            },
            "questions": {
                "value": "Please refer to the weaknesss section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel MTL method in which tasks are dynamically grouped according to the conflict of different tasks during the optimization process and the model is optimized based on these grouped tasks. The method introduces only a limited computation cost and the experiment results show strong performance of their method compared to several existing MTL methods"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper proposes a novel optimization method to optimize the multi-task learning process from a new perspective.\n\n2. The method demonstrates promising results on the NYUv2, PASCAL-Context, and Taskonomy datasets.\n\n3. The paper provides a theoretical explanation of the advantages of sequential optimization of task groups and provides an analysis of convergence."
            },
            "weaknesses": {
                "value": "1. There are some incorrect statements in the article. For example, in Line 092, \u201cThis perspective is not addressed in traditional multi-task optimization, which typically focuses solely on the learning of shared parameters.\u201d is wrong, because the learning of task-specific parameters is considered in IMTL [1].\n\n2. The conclusion in Line 373-374, \u201cThis suggests that grouping tasks with proximal inter-task affinity and subsequently updating these groups sequentially result in lower multi-task optimization. sequentially result in lower multi-task loss compared to jointly backpropagating all tasks.\u201d does not seem relevant to the theorem above. Can you give a more detailed explanation?\n\n3. For the conclusion in Line 525-526, \u201cWe observe that the affinity decay rate ... within a reasonable range.\u201d, there is a lack of experimental results on the performance of models with different $\\beta$.\n\n[1] Liu, L., Li, Y., Kuang, Z., Xue, J.-H., Chen, Y., Yang, W., Liao, Q., & Zhang, W. Towards Impartial Multi-task Learning. ICLR, 2021."
            },
            "questions": {
                "value": "1. Why is the number of groups in Figure 3c not an integer?\n\n2. Line 523, \"Table 4c\" means \"Figure 4c\"?\n\n3. Can you compare the performance of random grouping during optimization?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}