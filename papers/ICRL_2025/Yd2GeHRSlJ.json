{
    "id": "Yd2GeHRSlJ",
    "title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution",
    "abstract": "In Open-Set Domain Adaptation (OSDA) we wish to perform classification in a target domain which contains a novel class along with $k$ non-novel classes. This work formally studies OSDA under the assumption that classes are separable, and the supports of source and target domains coincide, while other aspects of the distribution may change.\nWe develop a simple and scalable method that attains robustness to distribution shift and is guaranteed to solve the problem, while showing that it cannot be solved under weaker conditions that have been studied for OSDA in the past, particularly in the presence of covariate shift. We formally define the realistic assumptions within the scope of OSDA problem that the previous literature has either overlooked or not explicitly addressed. In a thorough empirical evaluation on both image and text data, we observe that existing OSDA methods are not robust to the distribution shifts we consider.\nThe results demonstrate the efficacy of joint representation learning for classification of known classes and detection of novel ones using principled methods. We find that optimizing these two objectives in unison leads to mutual improvements in task performance contrary to what might be expected when objectives are considered independently. Our rigorous empirical study also examines how OSDA performance under distribution shift is affected by parameters of the problem such as the size of novel class. \n Taken together, our observations emphasize the importance of formalizing assumptions under which OSDA methods operate and to develop appropriate methodology that are capable of scaling with large datasets and models for different scenarios of OSDA.",
    "keywords": [
        "Distribution Shift",
        "Open Set Domain Adaptation",
        "Novel Category Detection",
        "Anomaly Detection",
        "Out of Distribution"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We study the problem of Open-Set Domain Adaptation under distribution shift of non-novel classes and study the impact of various factors affecting the performance of existing methods such as novel class ratio.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Yd2GeHRSlJ",
    "pdf_link": "https://openreview.net/pdf?id=Yd2GeHRSlJ",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses a gap in Open-Set Domain Adaptation (OSDA): handling both novel class detection and distribution shifts in known classes (\"background shift\"). The authors propose a scalable solution combining principled novelty detection with shared representation learning, demonstrating strong results across multiple domains."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- identification and formalization of understudied OSDA challenges\n- Specific attention to challenging real-world scenarios like low-proportion novel classes"
            },
            "weaknesses": {
                "value": "- All datasets are semi-synthetic. It would be interesting if authors can show results on practical datasets. \n- While the problem addressed is quite interesting theoretically, practical relevance is unclear. As mentioned above, the paper may benefit from including results on datasets which inherently satisfy the problem discussed in the paper\n- The paper may also benefit from discussing how using stronger CLIP models alters the behavior of the baselines and the proposed method."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses Open-Set Domain Adaptation under a specific scenario referred to as \"background shift,\" where known classes have partial overlap between source and target domains, while novel classes remain distinct. The authors introduce CoLOR (Constrained Learning for Open-set Recognition), a multitask learning framework that applies constraints on target data to reduce bias in the feature extractor. The key insight is that traditional partial domain alignment methods struggle when source-private classes significantly outnumber common classes. CoLOR addresses this by jointly optimizing for closed-set classification and novel class detection through a constrained learning approach. The method is evaluated comprehensively across three datasets (CIFAR100, SUN397, Amazon Reviews), demonstrating improved performance, particularly in scenarios with low novel class ratios. The theoretical contributions include a formal analysis of necessary/sufficient conditions for OSDA under background shift."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Strong theoretical foundation with formal analysis of background shift in OSDA, including necessary/sufficient conditions and limitations of existing approaches.\n- Comprehensive empirical evaluation across multiple modalities (images and text) and varying novel class ratios."
            },
            "weaknesses": {
                "value": "- While background shift is justified with potential applications in medical imaging (e.g., identifying known and novel tumor cells), this application is not addressed in the experiments. Including other real-world cases would strengthen the relevance of background shift beyond this initial mention.\n\n- The abstract could be improved by defining \u201cbackground shift\u201d and avoiding vague phrases like \"principled methods.\"\n\n- The claim \u201cwe observe that existing OSDA methods are not robust to the distribution shifts we consider\u201d is strong, but the baselines used are limited. Adding recent OSDA and UniDA baselines would support this claim.\nSuggested OSDA baselines: Adjustment and Alignment for OSDA [1], Open-Set Domain Adaptation for Semantic Segmentation [2], Source-Free Progressive Graph Learning for OSDA [3].\nSuggested UniDA baselines: Compressive Attention Matching for UniDA [4], Classifiers of Prototypes and Reciprocal Points for UniDA [5].\n\n- The paper assumes \u201cnotable separability\u201d between known and novel classes, which might be feasible for images or text using pretrained models like ViT-CLIP. However, this separability may not hold in fields like medical imaging, where pretrained models aren\u2019t available.\n\n- The authors should clarify how they determine the number of classes (k) for any additional classifier head and discuss the impact of varying k.\n\n- In Table 2, BODA outperforms CoLOR on CIFAR100, but this result isn\u2019t highlighted in bold.\n\n- In Table 3, only one baseline is used, which is outdated. The chosen method isn\u2019t clear either, given the three references listed (\u2018These baselines are domain discriminator (DD), Elkan & Noto (2008); du Plessis et al. (2014); Garg et al. (2021)\u2019).\n\n- Is the \u201cOSCR\u201d metric referring to the commonly used H-score in open-set papers?\n\n- The method is sensitive to hyperparameters like the FPR; details on selecting FPR and setting the threshold  \u03b2 for optimization should be included.\n\n-  The code is missing .\n \n[1] LI, Wuyang, LIU, Jie, HAN, Bo, et al. Adjustment and alignment for unbiased open set domain adaptation. In : Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. p. 24110-24119.\n\n[2] CHOE, Seun-An, SHIN, Ah-Hyung, PARK, Keon-Hee, et al. Open-Set Domain Adaptation for Semantic Segmentation. In : Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024. p. 23943-23953.\n\n[3] LUO, Yadan, WANG, Zijian, CHEN, Zhuoxiao, et al. Source-free progressive graph learning for open-set domain adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023, vol. 45, no 9, p. 11240-11255.\n\n[4] ZHU, Didi, LI, Yinchuan, YUAN, Junkun, et al. Universal domain adaptation via compressive attention matching. In : Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023. p. 6974-6985.\n\n[5] HUR, Sungsu, SHIN, Inkyu, PARK, Kwanyong, et al. Learning classifiers of prototypes and reciprocal points for universal domain adaptation. In : Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2023. p. 531-540."
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work suggests a new Open-Set Domain Adaptation (OSDA) scenario, \u201cbackground shift\u201d which is a distribution shift with overlapping supports between source and target distributions exists within the known classes. Also, the existing OSDA methods are experimentally shown to be insufficient in addressing background shifts. To handling this new scenario, this work proposes a new method dubbed as CoLOR. Experimental results show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. Introducing background shift in OSDA community is interesting and novel.\n\n2. Proposed method is based on theoretical evidence.\n\n3. Experiments are well structured to verify the effectiveness of background shift."
            },
            "weaknesses": {
                "value": "1. This work has limited novelty and originality since it relies heavily on [1], which provide theoretical analysis of OOD novel category detection. Lemma 1 and Theorem 1 in this manuscript are quite similar claim with Proposition 3.1 and Theorem 4.3 in [1] though they focus different task. Furthermore, it is unclear that Theorem 1 in this manuscript can be easily extended on OSDA since there is no proof in the manuscript and supplementary material.\n\n2. Proposed method is rather incremental. I think it is concatenate the cross-entropy loss on [1].\n\n3. Baselines for performance comparison is insufficient and outdated. I think several recent UDA methods should be included.\n\n[1] Birds of an Odd Feather: Guaranteed Out-of-Distribution (OOD) Novel Category Detection"
            },
            "questions": {
                "value": "1. Why did the authors define background shift not as a distinction between support of $P_{T,[k]}$ and $P_S$ i.e. $Supp(P_{T,[k]}) \\neq Supp(P_S)$ but rather as $Supp(P_{T,[k]}) \\subseteq Supp(P_S)$???? \n\n2. Could you elaborate on the differences in assumptions and results between Theorem 1 in this manuscript and Theorem 4.3 in [1]? If there are differences, please explain how these differences are reflected in the proof process of Theorem 1.\n\n3. I am curious whether the recent UDA methods demonstrate low performance even when applied in OSDA with background shift."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work sets out to address the open set domain adaptation (OSDA) problem under so-called background shifts. This problem amounts to solving the domain adaptation problem while also identifying datapoints which are novel classes which were not seen in the source domain. Domain adaptation is the problem of finding a model which performs well in a target domain when it has been trained on labeled data from some source domain and unlabeled data from the target domain. Background shifts are defined as any distribution shift between source and target domains which retains overlapping support between source and target domain distributions with the non-novel label set. \n\nThe authors show that strong positivity and overlapping support is not a sufficient condition to ensure better than random performance. \nThe work proposes a model partly based on previous work in OOD detection. The work proposes to use this method to detect the novel classes while at the same time learning to do the classification. The architecture of the model has a shared base structure which is used for both the detection and classification heads.\n\nThe model is then compared on image and text dataset benchmark against several baselines. It performs favourably on these tasks compared to baselines, especially when the ratio of novel class datapoints is low."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The setting of OSDA is both an important and challenging area  \n\n- The paper uses an OOD method in combination with learning a classifier to do OSDA which is a reasonable approach which seems to work well\n\n- Method performs well on chosen datasets compared to baselines"
            },
            "weaknesses": {
                "value": "- The introduction and related work together makes up ~3 pages which is a substantial part of the paper.\n\n- It seems rather inefficient to solve the problem for a large number of possible values of $\\alpha$. How does this compare to the other baseline methods? \n\n\n- The experimental details are somewhat unclear. Some things are not clearly stated. \n    * How many repetitions of experiments were done?\n    * How is the separability of the novel classes ensured? \n\n- Why does the amount of 'wins' not tally up to the total number of repetitions? I assume that this is what the Wins column in table 2 means, since I cannot find it explained in the text. Does this mean that the models tie in performance in some runs? \n\n- Not clear to me how the choice of $\\beta$ threshold impacts the results. \n\nTypos and other comments:\n\n- Unclear what the bolding in table 3b means, it almost seems random.\n\n- Figure 2 is small and admits a large amount of white space for seemingly little reason.\n\n- The bullet points headers for the paragraphs in the introduction seem distracting to me\n\n\nline 283: largrangian\nline 355: Expertiments\nline 385: table table\nline 480: Refer 5,6,7,10 in for further results. - Supposed to be reference to some section here?\nline 481: AUORC"
            },
            "questions": {
                "value": "See questions posed in the above section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates Open-Set Domain Adaptation (OSDA) under a background distribution shift. In OSDA, the objective is to classify known categories while detecting novel, previously unobserved classes in the target domain. This study addresses background shifts, where the distribution of known classes in source and target domains differs. The authors present a scalable method named CoLOR (Constrained Learning for Open-Set Recognition) to robustly classify known classes and detect novel ones under this shift. They demonstrate that CoLOR outperforms existing baselines by jointly learning representations for both classification and novelty detection."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper addresses the overlooked issue of background distribution shifts in OSDA, relevant for dynamic applications like medical imaging and autonomous systems.\n\n2. Extensive experiments across diverse datasets validate CoLOR's performance and robustness against strong baselines.\n\n3. The paper is well-organized, with clear explanations, detailed methodology, and effective visual aids for complex concepts."
            },
            "weaknesses": {
                "value": "1. The separability assumption (Assumption 1) is central to CoLOR\u2019s effectiveness. Could you discuss scenarios where this assumption might not hold in practical applications? How would CoLOR perform if the separability or background shift assumptions were relaxed or violated?\n\n2. The writing quality could be enhanced by ensuring consistency in formatting, particularly in the Related Works section, where the subheading styles appear inconsistent. Standardizing these subheading formats would improve the paper\u2019s overall readability and professionalism."
            },
            "questions": {
                "value": "Please see Weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}