{
    "id": "glgvpS1dD1",
    "title": "Robust Heterogeneous Treatment Effect Estimation under Covariate Perturbation",
    "abstract": "Heterogeneous treatment effect estimation has important applications in fields such as healthcare, economics, and education, attracting increasing attention from both research and the industrial community. However, most existing causal machine learning methods may not perform well in practice due to the lack of robustness of the treatment effect estimation predicted by deep neural networks when an imperceptible perturbation has been added to the covariate. In this paper, we alleviate this problem using the idea of adversarial machine learning. We first show that our loss of interest, the adversarial loss, is partly bounded by the Lipschitz constant of the casual model. Next, we propose a representation learning framework called RHTE which estimates heterogeneous treatment effect under covariate perturbation by controlling the empirical loss, Lipschitz constant, and distance metric simulta neously. Theories are then derived to guarantee the performance and robustness of our estimation. To the best of our knowledge, this is the first work proposing robust representation learning methods under variable perturbation. Extensive experiments on both synthetic examples and standard benchmarks demonstrate the effectiveness and generality of our framework.",
    "keywords": [
        "causal inference",
        "treatment effect estimation",
        "robust estimation"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=glgvpS1dD1",
    "pdf_link": "https://openreview.net/pdf?id=glgvpS1dD1",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces the RHTE framework, for estimating heterogeneous treatment effects under covariate perturbations. The main contribution is a novel representation learning approach that enhances the robustness of treatment effect estimations by incorporating adversarial machine learning techniques, with a specific focus on handling covariate perturbations."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The framework is well-supported by theoretical derivations, including generalization bounds for adversarial PEHE loss.\n- Experiments on both synthetic and real-world datasets are conducted, demonstrating the model's robustness and effectiveness."
            },
            "weaknesses": {
                "value": "- The paper only considers spherical perturbations, which may limit the method's applicability to broader real-world perturbations.\n- The use of adversarial training and Lipschitz regularization may complicate implementation, which could be a barrier for practitioners without expertise in adversarial machine learning."
            },
            "questions": {
                "value": "- How does the choice of spherical perturbations impact the robustness of the RHTE framework? Could other forms of perturbations (e.g., elliptical or non-uniform) be more representative of real-world scenarios?\n- What are the limitations of using Integral Probability Metric (IPM) in this context? Would other distance metrics perform differently in aligning treated and control representations?\n- What insights can be drawn about the model\u2019s performance in balancing the treated and control distributions? Does the RHTE consistently outperform traditional models, even under extreme perturbations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a robust method for training CATE estimators by introducing an additional regularizer to control the model's Lipschitz continuity. The authors provide theoretical performance results and evaluate their method across several datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper studies an interesting problem, i.e, the robustness of CATE estimation models to distribution shift. It presents few interesting theoretical results and presents good empirical evaluation."
            },
            "weaknesses": {
                "value": "My main concern with the paper is its incremental nature. While the results are interesting, they are a direct consequence of prior results in adversarial settings for general learning scenarios. Moreover, the paper lacks motivation on why the adversarial setting is particularly relevant for causal inference\u2014specifically, how it differs from the general learning problem. For instance, can a model be robust to adversarial attacks over the factual distribution but not over its counterfactual distribution?"
            },
            "questions": {
                "value": "1. How do the robustness measure interact with the violation of the assumption, especially the conditional unconfoundedness assumption?\n\n2. Is there an informative way to know when to use which one of the presented regularizer (Orthonormality Regularization and RKHS Regularization). And under what conditions might one be preferred over the other? Since in practice only the factual distribution, I understand that this can be challenging.\n\n3. Can you provide details on hyperparmeters tuning and if you have any insights on how to do this in real world settings when no counterfactual samples are available to validate?\n\n4. Which of the two presented approaches was used in practice (Orthonormality Regularization and RKHS Regularization)?\n\n5. While the bound in theorem 2 is interesting, how to guarantee that all three terms can converge together? Are there any possible experiments to conduct over simple data to see how the convergences of the three terms are interacting?\n\n6. Are there potential scenarios where this method might fail? For example, if the true underlying function is not Lipschitz for any order, would this method still risk significant degradation in performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work addresses the covariate perturbation problem for CATE estimation. Building on the insights that the worst-case PEHE under adversarial perturbation can be effectively controlled through restricting the Lipschitz constant of the potential outcome predictors, this work proposes a representation-learning framework Robust HTE (RHTE). In particular, the authors propose two types of regularizations to control the Lipschitz constant - the Orthonormality Regularization and RKHS Regularization. On top of the theoretical results to justify their framework, the authors also provide empirical studies to corroborate RHTE's efficacy."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Robust CATE is an important problem to investigate. \n- The proposed method is intuitive and reasonable.\n- The experiments appear comprehensive (though with some aspects needing clarification)"
            },
            "weaknesses": {
                "value": "## Technical (Framework) Novelty \n- The proposed framework is simply the well-known balancing framework for CATE [1] with the an additional regularization of the predictor's Lipschitz constant. Personally I think this is not a big problem.  \n- Notably, the two \"proposed\" regularization methods are also well-known results: the techniques of upper bounding the Lipschitz constant with spectral norm are already widely used [2,3]; the RKHS result is a standard result in kernel-based learning. \n\n## Theoretical Novelty\n- It is more than intuitive that controlling the Lipschitz constant of the predictor can help control the adversarial loss because it represents the maximum change of prediction one adversarial perturbation can cause. However, note that by controlling the Lipchitz constant of the predictor, you are also making an **implicit assumption** that the true potential outcome function has a Lipchitz constant **on the same scale**. **In other words, the EPHE can be arbitrarily bad if you are controlling the Lipschitz constant of your predictor yet the true potential outcome function has large-enough Lipchitz constant**. Please ruminate Theorem 2 and you should see this implicit assumption. This needs to be discussed.\n- Lemma 1 is a fairly obvious result. But **I believe it is fine since it only serves to motivate your framework**.\n- The theoretical results (Theorem 1 and 2) appear **disconnected and unnecessary** to the framework. See more details below. \n- Theorem 1 is just an empirical process result based on the covering number argument to upper bound the true factual (adversary) loss with the empirical one and a finite-sample gap. And, to the best of my knowledge, leaving theoretical results with raw covering number **does not convey any insights** because we usually continue to give instance-specific upper bounds for the covering number. The fact that the empirical process on compact space (i.e., with bounded covering number) has \\sqrt{1/n} concentration is standard in the community. \n- To continue on the last comment, the remark after Theorem 1 that \"Theorem 1 ... rationalizes the control on Lipschitz constant\" has nothing to do Theorem 1. **You can already reach this conclusion with Lemma 1**. The finite-sample concentration result in Theorem 1 has nothing to do with it.  \n- Theorem 2 is a simple (if not entirely trivial) extension of the results in [1]. **I don't think it justifies to be an original theorem in the main text.** Just writing it in plain language and referring [1] should be enough. Please consider editing it.  \n\n\n[1] Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-\nization bounds and algorithms. In International Conference on Machine Learning, pp. 3076\u20133085.\nPMLR, 2017.\n[2] https://towardsdatascience.com/lipschitz-continuity-and-spectral-normalization-b03b36066b0d\n[3] K. Kurach, M. Lucic, X. Zhai, M. Michalski, and S. Gelly. A Large-Scale Study on Regularization and Normalization in GANs (2019), ICML 2019."
            },
            "questions": {
                "value": "## Comparison with Existing Methods\nIn the introduction, the authors comment on the existing approaches that \"these\nassumptions cannot be tested from observed data, and restrict the generality of the methods\". However, if my understanding is correct, the assumptions in this framework are also **very difficult to verify**. For example, how to verify the \"spherical perturbation\" assumption and the Lipschitzness of the potential outcome functions?\n\n## Technical Questions \nThe experiment section is poorly written and needs some clarification. \n- There are two regularizations. Which one is used in the experiments? \n- I think it is better to illustrate the meaning of \"in-sample\" and \"out-sample\" in your manuscript. \n- In Table 1, why the performance of \"in-sample\" is also significantly improved? \n- The experiment setting of \"Robustness Comparison\" is unclear. Are you directly applying 3 adversarial ML methods for CATE estimation? How exactly is this performed?  \n- How do you choose the hyperparameter \\beta? The authors state at the end of Section that \"by tuning \\beta in proper ranges, we are allowed to achieve better trade-offs to improve the treatment effects estimation performance\". However, without counterfactual outcomes in real-world applications, based on what criterion can you tune this hyperparameter? \n\n## Minors \n1. (p-1)!! on line 185 is undefined\n2. x_i, t_i, y_i in Equation (7) was undefined later in Section 4.3 yet their first appearance is in Section 4.2.\n3. The left ' in 'X(T)', 'X(A)', 'X(D)' are flipped. \n4. All the specific section references, e.g., Section 3, should be capitalized. \n5. There are quite some typos in Section 5. I recommend the authors to edit it carefully during rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The methodology outlined in the paper focuses on addressing covariate perturbation\u2014essentially measurement errors in covariates\u2014in Conditional Average Treatment Effect (CATE) estimation. The approach involves using adversarial learning techniques to enhance the robustness of treatment effect estimations under such perturbations. Theoretical guarantees are provided in terms of PEHE (Precision in Estimation of Heterogeneous Effect) loss, ensuring that these methods perform reliably even when the covariate observations are perturbed. They evaluate the effectiveness of their proposed CATE estimation methods using two standard benchmark datasets\u2014ACIC and IHDP\u2014and two synthetic datasets, UTK-sim and TC-sim."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper introduces novel regularizations\u2014Orthonormality Regularization and RKHS Regularization\u2014to control the Lipschitz constant of the causal prediction model. \n- Their theoretical framework provides generalization bounds showing that the model's error on adversarial samples can be controlled."
            },
            "weaknesses": {
                "value": "- The paper does not sufficiently discuss the practical relevance of adversarial perturbations in treatment effect estimation. It's unclear if real-world scenarios would commonly present such adversarial challenges, which raises questions about the relevance of the proposed approach.\n- The specific choice of uniform noise for the perturbations  in the experiments  may be tailored to showcase the strengths of the proposed method. Unfortunately, the paper is lacking ablations for different noise types. \n-  While the authors provide details about the hyperparameters used, these settings are fixed throughout all experiments, and no hyperparameter search is conducted. This lack of finetuning could limit the reproducibility of the findings, as the performance of the baselines  might vary with different hyperparameter configurations."
            },
            "questions": {
                "value": "- How does the proposed method perform when the covariates are perturbed with different noises, eg gaussian or exponential?\n- Why are the hyperparameters of the baselines never tuned? \n- Can the author provide some real examples where covariates are perturbed in a treatment effect estimation setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}