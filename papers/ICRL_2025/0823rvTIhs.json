{
    "id": "0823rvTIhs",
    "title": "Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors",
    "abstract": "In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. \nPrevious works are mostly built upon class activation maps, which are effective for semantic segmentation but may not be suitable for locating actions and functions. Leveraging recent advanced foundation models, we develop a supervised training pipeline based on pseudo labels. The pseudo labels are generated from an off-the-shelf part segmentation model, guided by a mapping from affordance to part names.\nFurthermore, we introduce three key enhancements to the baseline model: a label refining stage, a fine-grained feature alignment process, and a lightweight reasoning module. These techniques harness the semantic knowledge of static objects embedded in off-the-shelf foundation models to improve affordance learning, effectively bridging the gap between objects and actions.\nExtensive experiments demonstrate that the performance of the proposed model has achieved a breakthrough improvement over existing methods.",
    "keywords": [
        "weakly supervised affordance grounding",
        "foundation model",
        "pseudo label"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We propose a pseudo-label based method for weakly supervised affordance grounding, utilizing the semantic priors of vision foundation models.",
    "creation_date": "2024-09-19",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=0823rvTIhs",
    "pdf_link": "https://openreview.net/pdf?id=0823rvTIhs",
    "comments": [
        {
            "summary": {
                "value": "This paper tackles weakly supervised affordance grounding (WSAG) by leveraging foundation models to generate pseudo labels, departing from previous CAM-based approaches. The authors propose a three-stage pipeline: (1) using VLpart and SAM to generate initial pseudo labels by mapping affordance-object pairs to part names, (2) refining these labels using human-object interaction cues from exocentric images, and (3) training an affordance grounding model with the refined pseudo labels. The method also includes cross-view feature alignment and a reasoning module to handle unseen objects. The approach shows significant improvements over existing WSAG methods"
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The problem is important and well-motivated, as affordance grounding is crucial for robotic manipulation and human-object interaction understanding\n- The proposed pseudo-labeling approach effectively leverages existing foundation models (VLpart, SAM) to provide supervision, addressing limitations of previous CAM-based methods\n- The label refinement process using exocentric images is novel and well-designed, providing a clever way to improve initial pseudo labels\n- The reasoning module helps generalize to unseen objects, which is crucial for practical applications\n- The writing is clear and the method is well-explained with appropriate visualizations"
            },
            "weaknesses": {
                "value": "The choice of CLIP as the vision encoder could be better justified given previous work suggesting limitations (vs DINO, OWLViT, SAM). For example, the paper will be stronger with an ablation study of different visual encoders."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the task of weakly supervised affordance grounding (WSAG), where the goal is to identify affordance regions on objects using only image-level labels and human-object interaction images. \nThe key contributions include:\n- A novel pseudo-supervised training framework and pipeline that leverages visual foundation models to generate affordance heatmaps, mapping affordance classes to object parts.\n- Three key enhancements to improve performance:\n    - Label refinement using interaction cues\n    - Fine-grained object feature alignment with exocentric images\n    - Reasoning module for better generalization\n- Extensive experiments demonstrating significant performance improvements over existing methods"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Clear writing and organization.\n- Well-motivated technical approach with clear problem formulation.\n- This paper propose a novel approach that uses visual foundation models and part-level semantic priors for WSAG, unleashing the power of these models for affordance learning.\n- Using human occlusion cues for label refinement, which is an innovative insight.\n- Comprehensive experimental validation and thoughtful analysis of limitations in existing methods."
            },
            "weaknesses": {
                "value": "- Could benefit from more analysis of failure cases.\n- The label refinement stage using human occlusion cues may be problematic when interactions are ambiguous or when multiple affordances exist.\n- The mapping from affordance to part names is ad-hoc and manually crafted, which limits the scalability to new affordance types and more complex objects."
            },
            "questions": {
                "value": "1. Could you provide more details about failure cases and limitations of the proposed approach?\n2. How sensitive is the method to the results of VFM? How well can the refine state correct possible errors by VLpart and SAM?\n3.  How does the computational cost (training & inference) compare to existing CAM-based methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper propose a weakly supervised affordance grounding framework. It uses off-the-shelf foundation models to generate pseudo labels of object parts. To further improve the performance, a label refining strategy, a fine-grained feature alignment process, and a lightweight reasoning module are introduced. Experiments show promising results."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Training affordance grounding models with object labels is an interesting question.\n2. Using off-the-shelf foundation models to generate affordance label is an interesting idea.\n3. Experiments show promising results."
            },
            "weaknesses": {
                "value": "1. As shown in the ablation study table 2, the improvements of using all these three modules look marginal over using one module. It seems that the effectiveness of the three components are not significant.\n2. In section 3.4, the authors propose to align the features of exo- and egocentric images after SAM segmentation while the existing methods directly align the features of the two images. However, there is no solid experiments to show the effectiveness of this design.\n3. The framework refines the affordance labels with the need of the corresponding exocentric image which may not be available sometimes."
            },
            "questions": {
                "value": "1. Aligning the features of an object from different views is a commonly used strategy for feature learning. How is this strategy related to pseudo label generation and refinement.\n2. Some designs need more detailed ablation studies. E.g., how does the proposed fine-grained feature alignment process with SAM perform when compared with the previous work aligning the features directly. Is there any significant performance difference?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}