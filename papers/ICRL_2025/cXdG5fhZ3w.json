{
    "id": "cXdG5fhZ3w",
    "title": "Enhancing Group Fairness in Federated Learning through Personalization",
    "abstract": "Personalized Federated Learning (FL) algorithms collaboratively train customized models for each client, enhancing the accuracy of the learned models on the client's local data (e.g., by clustering similar clients, by fine-tuning models locally, or by imposing regularization terms). In this paper, we investigate the impact of such personalization techniques on the group fairness of the learned models, and show that personalization can also lead to improved (local) fairness as an unintended benefit. We begin by illustrating these benefits of personalization through numerical experiments comparing several classes of personalized FL algorithms against a baseline FedAvg algorithm, elaborating on the reasons behind improved fairness using personalized FL, and then providing analytical support. Motivated by these, we then show how to build on this (unintended) fairness benefit, by further integrating a fairness metric into the cluster-selection procedure of clustering-based personalized FL algorithms, and improve the fairness-accuracy trade-off attainable through them. Specifically, we propose two new fairness-aware federated clustering algorithms, Fair-FCA and Fair-FL+HC, extending the existing IFCA and FL+HC algorithms, and demonstrate their ability to strike a (tuneable) balance between accuracy and fairness at the client level.",
    "keywords": [
        "Federated Learning",
        "Personalization",
        "Fairness"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We show that personalized Federated learning can have unintended fairness benefits, and build on this to propose fairness-aware federated clustering algorithms.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=cXdG5fhZ3w",
    "pdf_link": "https://openreview.net/pdf?id=cXdG5fhZ3w",
    "comments": [
        {
            "summary": {
                "value": "This paper explores the impact of personalization techniques on local fairness (i.e., the model\u2019s fairness on each client\u2019s local data) in federated learning. Extensive experiments compare the accuracy and fairness of personalized federated algorithms with FedAvg and standalone learning.  Results indicate that some personalized algorithms can improve model fairness while maintaining accuracy. Finally, this paper proposes fairness-aware Federated clustering algorithms based on existing methods to enforce local group fairness while enhancing accuracy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper investigates fairness in FL from an interesting perspective, namely the effect of personalization techniques on local fairness.\n2. The paper provides extensive numerical experiments comparing the accuracy and fairness of personalization methods with FedAvg across various scenarios (dataset, heterogeneity).\n3. The experiments and methods are clear and easy to read."
            },
            "weaknesses": {
                "value": "1. Concerns about contributions. The paper spends a significant amount of space presenting experimental results that demonstrate the dual benefits of personalized federated approaches in accuracy and fairness, indicating that personalization is a promising research avenue for fair FL. However, the subsequent analytical support and the proposed approaches appear to lack significant contributions.\n- Only federated clustering algorithms are analyzed, and the assumptions in the theoretical analysis are too strong for practical FL settings.\n- The proposed methods build upon existing methods by incorporating an additional fairness performance metric. The detailed algorithmic steps (Algorithm 1,2) resemble those in prior studies Ghosh et al. (2020) and Briggs et al. (2020).\n2. No effective local fair baseline in the experiments. The authors claim that the proposed method can enhance local accuracy while unintentionally improving local fairness. For empirical validation, the authors should compare the proposed methods against existing federated learning methods designed to improve local fairness. However, the experiments in Section 5 do not include FL methods specifically designed for local fairness.\n3. The empirical analysis of the proposed methods may not be entirely convincing. Experiments in this paper are limited to comparisons. Additional experiments are required to validate its stability in different federated setting, e.g. heterogeneity, client numbers.\n4. It is inappropriate to evaluate local fairness on methods specifically designed for global fairness (section 4.4), since previous work [1] has pointed out that global fairness differs from local fairness.\n5. Including the theoretical analysis and more detailed experimental results of the proposed method in the main text, rather than in the appendix, would strengthen the paper.\n[1] Hamman, Faisal, and Sanghamitra Dutta. Demystifying local & global fairness trade-offs in federated learning using partial information decomposition. ICLR, 2024."
            },
            "questions": {
                "value": "Beyond the above weak points, there are also additional questions:\n\nWhat motivated the authors to utilize federated clustering algorithms to improve local fairness? Figure 1(C) indicates that, in highly heterogeneous data settings, these methods underperform FedAvg and MAML in the accuracy-fairness trade-off.\n\nGiven that fairness constraints are non-convex and non-differentiable, does incorporating fairness metrics in existing federated clustering algorithms pose potential convergence challenges?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the problem of group fairness in federated learning. The authors find that personalized federated learning unintentionally benefits group fairness. The authors further introduce a fairness metric into clustering to improve the trade-off between fairness and accuracy. Experiments were conducted on real-world datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1.\tThe idea of unintentionally benefiting group fairness through personalization is indeed interesting.\n2.\tThe paper is generally well-written, with a clear structure that is easy to follow."
            },
            "weaknesses": {
                "value": "1.\tSince personalization can reduce the impact of dominant clients, the finding that personalization benefits group fairness is intuitive and not particularly surprising. Also, the results presented in the paper do not consistently support this finding. For instance, in Figure 3, federated methods improve the accuracy while increasing the fairness gap, which is inconsistent with Figures 1 and 2.\n2.\tThe technical contribution of this paper is limited. The first introduced metric is merely a linear combination of fairness terms with a hyperparameter, making it unconvincing to claim that it \"improves the fairness-accuracy trade-off\" through hyperparameter tuning. How to determine the value of hyperparameters in practice? The second introduced metric is an incremental combination of hierarchical clustering."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This manuscript explores the intersection of personalized Federated Learning (FL) and group fairness. It effectively demonstrates that personalization techniques, which are typically employed to enhance model accuracy on local data, can also inadvertently improve fairness. The paper substantiates these claims through comprehensive numerical experiments comparing various FL algorithms and introduces novel fairness-aware federated clustering algorithms. These algorithms, Fair-FCA and Fair-FL+HC, extend existing IFCA and FL+HC frameworks to incorporate a fairness metric into the cluster-selection process, aiming to optimize both fairness and accuracy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1\uff0e\tThe manuscript is well-organized, clearly presenting the methodology and findings. \n\n2\uff0e\tThe manuscript offers a comprehensive experimental analysis across various algorithms, fairness notions, and datasets."
            },
            "weaknesses": {
                "value": "1.\tThe authors demonstrate that personalized federated learning (FL) improves fairness through experiments and intuitive analysis; however, the manuscript lacks theoretical justification for these findings.\n\n2.\tThe experimental methods used to assess the impact of personalization on fairness are outdated and do not incorporate relevant studies from the past three years.\n\n3.\tThe proposed approach merely adds a fairness-related loss to existing FL methods, offering insufficient innovation to significantly advance fairness in federated learning."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors investigate the impact of such personalization techniques on the group fairness of the learned models, and show that personalization can also lead to improved (local) fairness as an unintended benefit. The authors propose Fair-FCA and Fair-FL+HC algorithms which achieve state-of-the-art performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "+ The authors investigate personalization to improve fairness which is somewhat interesting.\n\n+ The authors conduct extensive experiments to validate their claims."
            },
            "weaknesses": {
                "value": "+ It is still unclear to me why personalization can also improve fairness. After reading through the paper, it seems that clustering could somewhat improve fairness. \n\n+ The mathematical proof and illustrations should appear in the main paper since they are relatively important.\n\n+ Some similar works should be discussed, e.g., [1]\n\nRef:\n\n[1] Intra-and Inter-group Optimal Transport for User-Oriented Fairness in Recommender Systems"
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}