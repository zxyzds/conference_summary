{
    "id": "isHiGhFwVV",
    "title": "Anomaly Detection by Context Contrasting",
    "abstract": "Anomaly detection focuses on identifying samples that deviate from the norm.\nWhen working with high-dimensional data such as images, a crucial requirement for detecting anomalous patterns is learning lower-dimensional representations that capture concepts of normality. \nRecent advances in self-supervised learning have shown great promise in this regard. \nHowever, many successful self-supervised anomaly detection methods assume prior knowledge about anomalies to create synthetic outliers during training. \nYet, in real-world applications, we often do not know what to expect from unseen data, and we can solely leverage knowledge about normal data. \nIn this work, we propose Con$_2$, which learns representations through context augmentations that allow us to observe samples from\ntwo distinct perspectives while keeping the invariances of normal data. \nCon$_2$ learns rich representations of context-augmented samples by clustering them according to their context while simultaneously \naligning their positions across clusters. \nAt test time, representations of anomalies that do not adhere to the invariances of normal data then deviate from their respective context cluster. \nLearning representations in such a way thus allows us to detect anomalies without making\nassumptions about anomalous data.",
    "keywords": [
        "anomaly detection",
        "one class classification",
        "novelty detection",
        "contrastive representation learning",
        "context clustering"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We propose a novel model for self-supervised representation learning and demonstrate how to perform anomaly detection on the resulting representations.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=isHiGhFwVV",
    "pdf_link": "https://openreview.net/pdf?id=isHiGhFwVV",
    "comments": [
        {
            "summary": {
                "value": "Dear Authors, thanks for submitting to ICLR.\n\nIn this paper, the authors propose a novel anomaly detection method with context-aware data augmentation, termed $CON_2$. Given only normal training data, $CON_2$ augments the dataset through a generator, producing a diverse set of synthetic instances that retain similarity to the original data while introducing unique variations. This generator is designed using an AutoEncoder structure enhanced by contrastive learning and a specialized loss function.\n\nThe anomaly detection component in $CON_2$ utilizes two primary metrics: (1) it assesses the presence of similar instances to the input data, incorporating the generator\u2019s output, and (2) it applies data augmentation to the input at test time, subsequently measuring the average similarity between the real and generated data. Evaluation on representative datasets demonstrates that $CON_2$ outperforms state-of-the-art methods in certain cases when optimally configured."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method mitigates bias introduced by synthetic anomalies by exclusively leveraging augmented normal data for anomaly detection. Rather than relying on artificially generated anomalies, it detects anomalies by augmenting the normal dataset and comparing the input against an expanded set of potential normal instances, including both real and synthetic normal data.\n2. This algorithm requires no anomalous data during training, a practical approach given the rarity and unpredictability of anomalies.\n3. Leveraging AutoEncoder and contrastive learning, the model effectively extracts critical information and represents it from multiple perspectives, enabling it to discern whether anomalies arise from content, context, or both."
            },
            "weaknesses": {
                "value": "Technical Aspect:\n1. The method is sensitive to context augmentation methods, which is demonstrated in evaluation part as well. However, there is no systematic method about how to choose proper augmentation method. If use wrong augmentation, this method may perform worse than baselines. (see Table 1). Suggestion: you may consider using validation data to automatically choose augmentations, or if you could provide guidelines for selecting augmentations based on dataset characteristics.\n2. Even consider optimal augmentation method only, the performance gain to baselines is marginal in many cases. For example, I cannot tell $CON_2$ is better than baselines in Figure. 4. For instance in Figure 4, UniCon-HA outperform $CON_2$ on Bird, Deer, Horse, and Ship, 4 out of 11 classes. I would suggest statistical tests to demonstrate the significance of their performance gains over baselines, such as t-Test. It would also be helpful to measure the epistemic uncertainty by runing multiple times with different random seed, so that you will know if the the 7 out 11 performance gain is the worst case or best case.\n3. The second anomaly score is questionable, start from line 306, page 6. With augmentation, we should obtain different representations of the input data, some of them maybe aligned with existing normal data well. Therefore, we should use some metric like maximal score to highlight the matching, instead of averaging out the potential matching (might be sparse). Suggestion: you might compare the current approach with a max-based score and discuss the trade-offs between the two approaches.\n4. Ablation study is not comprehensive. It cannot show how the loss function influence the performance, and does not mention how the anomaly detection metric influence the detection result. As a result, the loss function and metrics are not properly reasoned and tested. Suggestion: please add the experiment with solely one of two loss functions, and also add the result the anomaly detection result with just one anomaly score as metric.\n\nWriting:\n1. Figure 1 is not referred at the beginning of the paper but it is put to page 2, and it is hard to understand. The loss function is introduced on page 5, section 3.2, but it is mentioned here without any explanation or reference. To address this, the author may refer to figure 1 in the later part of introduction, when introducing the proposed solutions. Please add a cross reference to the definition of loss function in the caption of Figure 1.\n2. Figure 2 and Figure 3 are not on the page they are refered to. Please nsure all figures are properly placed and referenced in the final version.\n3. Page 6, line 311, the anomaly score function have a new symbol at the last component. I would suggest a clarification in the following text right after the equation to explain what the \"$\\circ$\" means.\n4. Please add number to the equations."
            },
            "questions": {
                "value": "1. Please correct or clarify the writing issues in the weaknesses. \n2. Can you please clarify what the \"$\\circ$\" means in page 6 line 311?\n3. Can you please explain the second metric for anomaly score? Why take the average 1/A and why sum between 1~A/2 interval? \n4. Please clarify why the average is used in the second anomaly score? From the definition, I think a maximal value based metric makes more sense. Please add this comparision in section 4, or around the ablation study.\n5. Can you please add the following ablation study: (1) using L_{context} or L_{content} only, (2) show how each of the two anomaly score contribute to the anomaly detection decision.\n6. In the evaluation, please add more details about the result, including a breakdown of precision, recall, and F1 score.\n7. Can you please clarify if we can select optimal augmentation method automatically? Otherwise, it may not able to guarantee the performance gain."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No such concern"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to address anomaly detection in a setting where no outliers or pre-trained models are available. The author aims to use a set of augmentations such that augmented images are (i) distinct - images from different augmentations are separated (ii) aligned - augmentations are distance preserving. They use a contrastive loss to ensure (ii). Anomalies are scored using this representation in one of two ways: kNN and Mahalanobis distance. Results are better than other SSL methods in standard datasets and better than CLIP-AD on two medical datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Detailing the desiderata of augmentation in terms of distinctiveness and alignment is interesting, and to the best of my knowledge, novel.\n2. Results are strong w.r.t. to other SSL methods.\n3. Figure 3 is a very nice illustration of the main technical point."
            },
            "weaknesses": {
                "value": "1. There is somewhat misleading about covering pre-trained based methods as \"outlier detection\". There is a vast number of papers showing that pre-trained features, while reliant on seeing images not in the training set, are much more generalizable than outlier exposure. Namely, strong visual features go beyond purely adding prior knowledge about specific anomalies [1][2].\n2. Only one none-SSL method is compared, and not the most standard one\n3. The main results table, justifying the focus on SSL, shows only two datasets.\n\nMinor comments:\n4. The paper claims (line 46) \"without assuming prior knowledge about anomalies\". I find that misleading, prior are always needed in order to generalize anything to an unseen test. Even more so in unsupervised settings. In this case, the priors are the inductive biases induced by the augmentations among other things.\n5. I found Figure.1 more confusing than helpful.\n\n[1] Reiss, Tal, et al. \"Panda: Adapting pretrained features for anomaly detection and segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n[2] Roth, Karsten, et al. \"Towards total recall in industrial anomaly detection.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022."
            },
            "questions": {
                "value": "1. Please compare to more pre-trained-based methods. E.g., (Cohen & Avidan, 2022; Reiss & Hoshen, 2023;\nLi et al., 2023) cited by your paper.\n2. Please extend this comparison to more medical datasets. E.g., ChestX-ray14, HAM10000."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an anomaly detection method, where encoders are trained such that the images with different context have separated representations while keeping the relationship among images within each context. With experiments using medical and natural images, the effectiveness of the proposed method is evaluated."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper proposes a new anomaly detection method with context augmentations.\n\nThe experiments with medical images."
            },
            "weaknesses": {
                "value": "The novelty of the proposed method is limited.\n\nThe advantage of the proposed method is unclear compared with the existing anomaly detection methods with data augmentation by flipping, inverting, and equalizing."
            },
            "questions": {
                "value": "Preparing contexts might require prior knowledge for anomaly. Can any context that fullfills distinctiveness and alignment be useful in the proposed method?\n\nHow can we tune alpha? \n\nHow to chose LH or NND?\n\nWhat are the advantages of the proposed method compared with the existing anomaly detection methods with data augmentation?\n\nThe proposed method depends on the context transformation to be used (Equalize, Invert, Flip). How can we choose appropriate transformation for given applications? \n\nWhat does happen when all transformations are included in the proposed method?\n\nWhat happens when alpha is fixed at zero or one?\n\nWhy the context-specific cluster structure is important for anomaly detection? In the experiments, alpha is linearly annealed from zero to one."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an anomaly detection method that uses context contrastive learning to learn useful representations of normal data.\nSpecifically, this paper proposes context augmentations that are transformations satisfying two properties (distinctiveness and alignment).\nUsing them, the invariance of normal patterns can be encoded well into the representations. The experiments with image datasets show the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is generally well-written and is easy to follow.\n- The proposed method is simple and thus may be easy for practitioners to use.\n- The experiments with medical image data show that the proposed approach outperforms the existing contrastive anomaly detection methods."
            },
            "weaknesses": {
                "value": "- Since there are existing contrastive anomaly detection methods as described in the experiments, I think the proposed approach's novelty is not outstanding. Also, the differences between context and other ordinary transformations are not clearly explained. For example, can we use context transformations in the same way as ordinary transformations? (The same applies in reverse). I want to know the key differences between context augmentations and ordinary transformations.\n- There are many anomaly detection approaches other than the contrasting-based approach described in Section 2. Thus, this paper would be improved by showing the effectiveness of the proposed method through experimental comparisons with these methods.\n- In Figure 4, the significant difference between the proposed and existing methods is unclear."
            },
            "questions": {
                "value": "- The problem settings only have unlabelled or normal data. How are the hyperparameters of the proposed method practically determined?\n- Can the proposed method be applied to domains other than the image domain?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}