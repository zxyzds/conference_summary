{
    "id": "DNBwlQYA90",
    "title": "UDC-VIT: A Real-World Video Dataset for Under-Display Cameras",
    "abstract": "Under Display Camera (UDC) is an advanced imaging system that places a digital camera lens underneath a display panel, effectively concealing the camera. However, the display panel significantly degrades captured images or videos, introducing low transmittance, blur, noise, and flare issues. Tackling such issues is challenging because of the complex degradation of UDCs, including diverse flare patterns. Despite extensive research on UDC images and their restoration models, studies on videos have yet to be significantly explored. While two UDC video datasets exist, they primarily focus on unrealistic or synthetic UDC degradation rather than real-world UDC degradation. In this paper, we propose a real-world UDC video dataset called UDC-VIX. Unlike existing datasets, only UDC-VIX exclusively includes human motions that target facial recognition. We propose a video-capturing system to simultaneously acquire non-degraded and UDC-degraded videos of the same scene. Then, we align a pair of captured videos frame by frame, using discrete Fourier transform (DFT). We compare UDC-VIX with seven representative UDC still image datasets and two existing UDC video datasets. Using six deep-learning models, we compare UDC-VIX and an existing synthetic UDC video dataset. The results indicate the ineffectiveness of models trained on earlier synthetic UDC video datasets, as they do not reflect the actual characteristics of UDC-degraded videos. We also demonstrate the importance of effective UDC restoration by evaluating face recognition accuracy concerning PSNR, SSIM, and LPIPS scores. UDC-VIX enables further exploration in the UDC video restoration and offers better insights into the challenge. UDC-VIX is available at our project site.",
    "keywords": [
        "Under-Display Camera",
        "Dataset",
        "Benchmark",
        "Alignment",
        "Flare"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=DNBwlQYA90",
    "pdf_link": "https://openreview.net/pdf?id=DNBwlQYA90",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes a video-capturing system that can simultaneously record UDC-degraded and ground-truth videos for the same scene. Applying this system and discrete Fourier transform, the authors collect an aligned real-world UDC video dataset called UDC-VIX that accurately represents real-world UDC video degradations. The paper demonstrates the effectiveness of UDC-VIX by comparing it with an existing synthetic UDC video dataset using six deep-learning restoration models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This is the first real-world UDC video dataset that accurately represents real-world UDC video degradations.\nThe design of the video-capturing system is good.\nThe presentation of the paper is well and sound.\nGreat efforts are shown by the experiment parts."
            },
            "weaknesses": {
                "value": "The paper lacks theoretical analysis and novelty in algorithms related to deep learning."
            },
            "questions": {
                "value": "This is a good paper and will contribute to the UDC video restoration community. However, this venue is targeting for creation of learning theory and I don't see anything novel in terms of the algorithms or data alignment."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Differing from unrealistic or synthetic UDC degradation in previous works, in this paper, the authors construct a video-capturing system to simultaneously acquire non-degraded and UDC-degraded videos of the same scene. The real-world UDC video dataset is collected and then aligned using DFT. Six representative methods are trained and tested on the dataset. Based on the UDC-VIX, the authors evaluate the image quality and face recognition accuracy of UDC restoration."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The objective of the paper is clear, the overall narrative is fairly complete, and the amount of work is substantial. According to the description in the paper, the collected dataset is more diverse in scenarios compared to previous datasets in the UDC field, and the types of degradation are also closer to real-world conditions."
            },
            "weaknesses": {
                "value": "1. The comparison of Table 3 shows the results of different methods trained and tested on two separate datasets and no cross-testing was conducted. This makes it difficult to assess the impact of different datasets on restoration methods.\n2. As mentioned in LIMITATION, UDC degradations vary with the display pixel design, so which types of degradation will be affected? This requires more detailed explanation and analysis."
            },
            "questions": {
                "value": "Refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposes a UDC video dataset UDC-VIX that contains realistic UDC degradations (e.g., low transmittance, blur, noise, and glare). Specifically, this work proposes an efficient video capture system to acquire a pair of matched UDC-degraded videos and ground truth videos through precise synchronization of two cameras. In addition, this work uses DFT to align UDC-VIX frame by frame, showing the highest alignment accuracy, which is sufficient for training deep learning models. Through comparative experiments, this work demonstrates the effectiveness of UDC-VIX."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1\u3001This paper introduces the data set collection and processing process in detail, and the content is clear and concise.\n2\u3001This paper analyzes and compares the differences between existing data sets and the collected data sets, highlighting the necessity of creating new data sets.\n3\u3001This paper shows the results of the collected data sets in video reconstruction and face recognition, reflecting the effectiveness of this paper's data set."
            },
            "weaknesses": {
                "value": "1\u3001There are some unclear introductions in this paper, such as the corresponding English abbreviations in Figure 1 are not introduced.\n2\u3001This paper focuses on describing the implementation details and does not reflect the innovation.\n3\u3001The experimental data in this paper is not sufficient to fully demonstrate the advantages of the dataset."
            },
            "questions": {
                "value": "1\u3001This paper mentions that capturing paired videos through a beam splitter is an innovation of this work, but the method of capturing paired videos based on a beam splitter is not new, and there have been some works in other fields. In addition, capturing GT videos through a beam splitter will degrade because the amount of light is halved. Did the author consider this problem?\n\n2\u3001Fast-moving objects are excluded from the dataset, which has an impact on handling such situations. Compared with other datasets, does this dataset have a disadvantage in handling such videos, and how big is the disadvantage?\n\n3\u3001When visually comparing different datasets, different video frames are used for comparison, which is not convincing. It is recommended to use the same video frames for comparison.\n\n4\u3001This article emphasizes the superiority of the dataset, but lacks specific experimental results. For example, will the results of training on a new dataset be better when tested on other datasets?\n\n5\u3001This paper introduces the methods used in the data collection and processing process, but these methods are existing technologies and do not reflect the innovation of this paper.\n\n6\u3001This paper is more like an engineering implementation, and the innovation is not sufficient. Please rethink the innovation of this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors provide a real-world UDC video dataset called UDC-VIX, which accurately reflects actual UDC video degradations. Besides, They compare UDC-VIX with an existing synthetic UDC video dataset using six deeplearning restoration models to demonstrate its effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The authors provide a real-world UDC video dataset called UDC-VIX, which accurately reflects actual UDC video degradations.\n2. The authors compare UDC-VIX with an existing synthetic UDC video dataset using six deep\u0002learning restoration models to demonstrate its effectiveness."
            },
            "weaknesses": {
                "value": "1. In section 5.2 FACE RECOGNITION, the description of the experimental setup for face recognition is difficult to understand, but in theory, it should be well understood, so the author needs to sort out this part.\n2. Even if it is not UDC, it will produce exaggerated flares under strong light. Another question is, does the rear camera of the iPhone belong to UDC?\n3. Regarding the data distribution problem generated by specific devices mentioned in LIMITATIONS, since this problem exists, did the author solve it to some extent when proposing the data set, such as collecting data based on mobile phone brands with larger market share?\n4. Does face recognition under UDC have practical application significance? Does UDC currently limit the performance of the face recognition algorithm? Are there any other problems?"
            },
            "questions": {
                "value": "See Weaknesses for details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}