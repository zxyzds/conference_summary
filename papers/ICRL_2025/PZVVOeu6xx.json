{
    "id": "PZVVOeu6xx",
    "title": "Predicting Network Motif Fingerprints with Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif prediction remains underexplored, with no established benchmarks in the literature. We propose to address this problem, framing motif prediction as an extension of subgraph frequency estimation. Our approach formulates motif estimation as a multitarget regression problem, optimising for interpretability and improving stability and scalability on large graphs. We validate our method using a large synthetic dataset generated by graph generators that mimic real-world data, and further test it on real-world graphs. Our experiments reveal that 1-WL limited models trained on synthetic data struggle to predict accurately motif profiles of real-world networks. However, apart from their reasonable performance within synthetic data, they can generalise to approximate the graph generation processes of real-world networks by comparing their predicted motif profiles with the ones originating from synthetic data. This first study on GNN-based motif prediction sets a benchmark and should open pathways for further developing the connection between motif profiles and subgraph frequency from a graph representation learning perspective.",
    "keywords": [
        "motifs",
        "graph representation learning",
        "synthetic data",
        "significance profiles"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "Studying the ability of MPNNs to predict motif profiles.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=PZVVOeu6xx",
    "pdf_link": "https://openreview.net/pdf?id=PZVVOeu6xx",
    "comments": [
        {
            "summary": {
                "value": "The authors constructed a large synthetic dataset to test the motif discovery ability of MPNNs, and showed in general that MPNNs do not generalize well beyond synthetic dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors formulated the motif discovery into a multitarget regression problem on normalized z-scores. And have done an empirical study on a large synthetic dataset to understand the boundaries of MPNNs on motif discovery. The problem they are trying to understand is close to many real world scientific questions (such as motifs in biology)."
            },
            "weaknesses": {
                "value": "I found the conclusions in the paper a bit weaker and satisfying. \n\nThe authors spent some time explaining the differences between subgraph counting and motif discovery. The latter can be easier or harder than the subgraph counter depending on the null hypothesis construction. Then the authors tried to answer three key questions (line 402-404), and found the model seems to learn the graph generators and perform better on intra-generator graphs. Following that, the model trained on synthetic data does not generalize well onto real-world graphs. Such findings are pretty expected and I wonder if the readers would learn more from the study."
            },
            "questions": {
                "value": "The authors mentioned normalizing the z-scores imposes a \u201cmathematical interconnectivity\u201d and further supports multi-target regression tasks, adding an additional layer of interdependence. I wonder if the authors could elaborate on how such a simple constraint has a meaningful impact on the model. Shouldn\u2019t it be a trivial task to learn?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a GNN model for estimating the frequency of a set of subgraphs (called motifs) in a given graph.\nThe described estimator predicts the standardized occurrence counts (Z-counts) $z_i$ for subgraph H_i in a target graph $\\mathcal{G}$ relative to a set of reference graphs $\\mathcal{G}_\\mathrm{NULL}$, i.e., the model is trained to predict how many standard deviations the occurrence count of H_i in $\\mathcal{G}$ is above or below that in G_NULL.\n\nThe proposed approach normalizes the Z-counts to the interval $[-1, 1]$. Additionally, the Z-count vector $z$ is normalized via the Euclidean norm to obtain a so-called *significance profile* vector $s$.\nThe model is trained by minimizing the MSE between the true and the predicted significance profiles of synthetically generated training graphs.\n\nThe model is evaluated by comparing the significance profile MSEs on unseen synthetic and real-world graphs. The proposed approach performs well on the synthetic validation and test data. However, on real-world graphs, the estimator performs significantly worse."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The proposed approach is well motivated and contextualized by giving a good overview of the strength and weaknesses of prior work in the field.\n\nThe idea of predicting Z-scores instead of absolute occurrences to circumvent potential generalization  issues with directly predicting absolute counts which might grow super-exponentially is convincing. \n\nAdditionally, the relations between absolute counts and significance profile estimation described in Section 4.2 raise interesting questions about the possibility of difficulty classes for different counting problems wrt. different NULL models.\n\nThe analysis of the reported empirical results is thorough with many details being provided in the supplement."
            },
            "weaknesses": {
                "value": "As described by the authors, the proposed approach does not appear to produce satisfactory results on real world data. However, since \"negative\" results can also be of interest, I will not focus on that here.\n\nFirst, while theoretically interesting, I found it difficult to assess to which degree the proposed approach might be useful for practical purposes, mainly due to the following reasons:\n1. The approach is only compared to itself. As described in Section 3, there has been prior work on substructure counting with GNNs. An empirical comparison to another counting model (e.g., [1]), would have been helpful.\n2. The performance of the estimator is only evaluated wrt. the MSE of the predicted significance profiles. While interesting, it is unclear to me to which extent those significance profiles are useful in downstream tasks. Why was the quality of the predicted Z-scores or possibly the absolute occurrence counts not evaluated?\n3. Related to my previous point, it would have been interesting to highlight potential applications for the proposed approach in the experiments, e.g., via a case study showcasing how the estimator might be used in practice.\n\nSecond, I found the motivation for using significance profiles at all to be lacking.\nIn Section 4.1 the authors write that this \"imposes a mathematical interconnectivity between the Z-scores\"; no explanation as to why such a constraint is desirable is given.\nFor induced subgraphs one can argue that an increase of one subgraph of a certain size might lead to a decrease in occurrence of other subgraphs of that size, assuming that the set of motifs contains **all** subgraphs of a given size.\nHowever, since this is a constraint on the sum of the Z-scores, L1 normalization instead of the used Euclidean norm would have been appropriate.\nCan you elaborate on why you chose to use L2-normalized significance profiles and discuss the advantages (and potential disadvantages) of this choice?\n\nThird, in Section 7.2 conjecture that the GNN models used in the estimator might not be expressive enough to properly learn occurrence counts in the evaluated setting.\nGiven this observation, it is unclear why the authors did not also evaluate more expressive GNN models.\nIn Section 4.2, they mention that more expressive models have high computational complexity; however, there are a number of higher-order GNN architectures with different performance characteristics [2,3,4], e.g., 2-FWL approximations with a tunable complexity parameter [3].\nEven if all currently proposed higher-order approaches were infeasible for the intended setting, a small scale evaluation of more expressive models would have been interesting.\nCould you run such an experiment, e.g., using one of the mentioned higher-order GNN approaches?\n\nLast, I have a few minor comments regarding the presentation:\n- Figure 1 is difficult to parse by itself; more specifically, repeating the x-labels on all six subplots and adding a meaningful y-axis label would be helpful.\n- In Table 1, the distinction between SAGE and GIN using underline and italics is unnecessarily hard to parse; adding an explicit heading to the already existing columns for both would be better.\n- On page 2, line 54, I found the choice of the word \"myriad\" to be vague and misleading, when the number of used generators is \"just\" 23.\n- On page 6, line 304: Grammar. \"being those\" should read \"those being\".\n\n---\n[1] Chen, Z., Chen, L., Villar, S., Bruna, J.: Can graph neural networks count substructures? In: Proceedings of the 34th International Conference on Neural Information Processing Systems. pp. 10383\u201310395. Curran Associates Inc., Red Hook, NY, USA (2020).\n\n[2] Maron, H. et al.: Provably Powerful Graph Networks. arXiv. (2019).\n\n[3] Damke, C. et al.: A Novel Higher-order Weisfeiler-Lehman Graph Convolution. In: Proceedings of The 12th Asian Conference on Machine Learning. pp. 49\u201364 PMLR (2020).\n\n[4] Tahmasebi, B. et al.: Counting Substructures with Higher-Order Graph Neural Networks: Possibility and Impossibility Results, [http://arxiv.org/abs/2012.03174](http://arxiv.org/abs/2012.03174), (2021). [https://doi.org/10.48550/arXiv.2012.03174](https://doi.org/10.48550/arXiv.2012.03174)."
            },
            "questions": {
                "value": "A few questions were already raised in the weaknesses, namely:\n- Why were no other occurrence estimations approaches used for comparison in the evaluation?\n- Which downstream applications do you envision for your proposed approach?\n- Why the focus on significance profiles instead of Z-scores?\n- Why are the significance profiles normalized using L2 instead of L1?\n\nAdditionally, out of curiosity, I would like to ask why the set of significance values specified in Section 5 (line 305) is as described. The explanation for why $\\frac{1}{\\sqrt{2}}$ appears is understandable, but why are 0 and 1 also part of the set and why is -1 not in it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a method that frames motif estimation as a multitarget regression problem, which enhances interpretability and scalability for large graphs. The findings indicate that while models trained on synthetic data perform reasonably well, they struggle with real-world networks, highlighting a gap in generalization."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper presents a unique formulation of motif estimation as a multitarget regression problem.\n2. The paper sets a benchmark for future research in the field."
            },
            "weaknesses": {
                "value": "1. The introduction section requires significant improvement, as it contains poorly defined terms and vague sentences. For instance:\nIn line 40, the phrase \u201cwhat is a good network model for protein-protein interactions\u201d lacks clarity. The authors may have intended to ask which architecture is preferred for this purpose. Additionally, the term \"control networks\" in line 42 is not clearly defined.\nThe phrase \u201cvery hard computational task\u201d in line 43 is not professionally articulated. The term \"very\" is ambiguous; it would be more precise to state that the task is NP-hard.\nThe statement in lines 46-48 lacks supporting references, making the claim questionable. Additionally, phrases such as \u201ctypically do not give very interpretable results\u201d are vague. What exactly is meant by \u201cvery interpretable\u201d? This concept requires clearer definition and explanation.\nLines 49-52, which aim to outline the main contributions of the paper, are overly vague. The term \u201cinterpretable scores\u201d needs further clarification. In the context of motif discovery, what does \u201cscore\u201d refer to? Furthermore, the phrase \u201censuring the possibility of further insight into the conclusions obtained\u201d is unclear; which conclusions are being referred to?\nLine 43 states, \u201cAdditionally, our method is robust and versatile, capable of operating effectively on graphs of any size.\u201d The term \"robust\" is ambiguous in this context, and since many graph neural networks (GNNs) can operate on graphs of varying sizes, this statement does not clearly highlight the uniqueness of the authors' approach.\nThe sentence in line 53, \u201cKnowing how difficult it is to obtain a high volume of real-world graph datasets that have both high quality and variety,\u201d lacks supporting references, which undermines the claim.\nFinally, lines 62-63 are poorly constructed: \u201cWe make available a large diverse synthetic dataset in terms of graph topology and motif significance-profile generated with 23 synthetic generators.\u201d This statement could benefit from clearer phrasing and more specificity regarding what is meant by \u201cmotif significance-profile.\u201d\nMore vague and poorly written lines: 192-193.\u2028\nOverall, the introduction requires substantial revision for clarity, precision, and supporting evidence.\n\n\n2. The motivation for the proposed method is unclear, primarily due to the lack of references supporting the claims made in the introduction (lines 46-48). Additionally, Section 3.2 outlines numerous methods for detecting substructures and motifs but fails to address their limitations or specify how the proposed method intends to resolve these issues.\n\n3. The structure of the paper could be enhanced for better clarity and coherence. For example, dedicating an entire section (Section 2) to preliminaries that consists of only four lines seems excessive, especially since these preliminaries are only referenced in Section 4. This placement raises questions about its necessity. Additionally, the title of Section 4, \u201cINITIAL PROBLEM DESCRIPTION,\u201d is misleading, as the majority of the section focuses on the proposed method rather than outlining the problem. Furthermore, lines 180-188 appear to contain preliminary information; starting a section with such lines without appropriate context is unprofessional and detracts from the overall readability of the paper.\n\n4. Ultimately, the method is limited to small graphs of sizes 3 and 4, which restricts its overall contribution. Additionally, there is a lack of explanation regarding why existing approaches fail to detect such graphs, as previously mentioned in comment 2.\n\n5. While the authors assert that interpretability is one of the main contributions of the paper in the abstract and introduction, the topic is not addressed further, nor is there any demonstration of how the method achieves interpretability. In the context of explainable artificial intelligence (XAI), which emphasizes transparent, white-box models, it is unclear how the proposed approach qualifies as interpretable. Additionally, the paper fails to establish how their method offers enhanced interpretability compared to existing approaches.\n\n6.The paper does not provide any comparisons to existing approaches, which is a significant oversight. Without such comparisons, it is difficult to assess the effectiveness and advantages of the proposed method in relation to established techniques. Including a comparative analysis would enhance the paper's contributions and provide clearer context for the claims made about the method's performance and interpretability"
            },
            "questions": {
                "value": "1. What is the motivation behind the proposed method? Specifically, what problems associated with existing approaches does it address, particularly in relation to the methods discussed in Section 3.2?\n2.The method focuses on small graphs of sizes 3 and 4. What are the implications of this limitation for the broader applicability of your approach\n3.Can you provide more insight into the limitations of existing methods for detecting small graphs? What specific challenges do they face that your method aims to address?\n4.How does your method enhance interpretability compared to existing approaches? Can you provide specific examples or references to studies that illustrate the limitations of current methods in this regard?\n5.I kindly request that you include a comparative analysis of your proposed method against existing approaches."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the challenge of predicting network motifs using Graph Neural Networks (GNNs). Given the known expressiveness limitations of GNNs, the authors reframe motif estimation as a multitarget regression task, where curated regression targets are assigned to each input graph. This method is validated on a large, diverse synthetic dataset. The study reveals that 1-WL-limited models trained on synthetic data struggle to generalize effectively to more complex, real-world networks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper tackles an important and challenging problem of using GNNs for network motif estimation."
            },
            "weaknesses": {
                "value": "- The proposed workaround\u2014framing motif prediction as a multitarget regression task instead of directly predicting network motifs\u2014relies heavily on heuristics and lacks sufficient motivation. Neither theoretical justification nor empirical evidence is provided to explain why altering the task would enable GNNs to perform better. For example, the statement in line 275, \"We might have made the problem easier (or harder) than substructure counting,\" adds to the ambiguity surrounding the authors\u2019 approach.\n\n- As a heuristic-based study, the experiments are restricted to synthetic data, limiting the findings\u2019 relevance to practical applications in complex real-world networks.\n\n- While acknowledging the inherent limitations of GNNs, the authors overlook recent approaches leveraging large language models for classical graph problems like subgraph counting (e.g., [1]). Such methods, despite their own limitations, have shown performance improvements over GNNs but are neither cited nor compared here.\n\n- Limited backbone choices: Only SAGE and GIN are used as backbones, while more expressive GNN models are not included (see, e.g., [2\u20134]).\n\n[1] Understanding Transformer Reasoning Capabilities via Graph Algorithms.\n\n[2] From stars to subgraphs: Uplifting any GNN with local structure awareness.\n\n[3] Building powerful and equivariant graph neural networks with structural message-passing.\n\n[4] Understanding and extending subgraph gnns by rethinking their symmetries."
            },
            "questions": {
                "value": "Aforementioned in weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a framework to extract network motifs, i.e., subgraph patterns that have some kind of significance, with graph neural networks. They formulate the task as a multitarget regression problem, where the targets are the significance scores of the (fixed) pattern graphs. The authors also provide a dataset of synthetic graphs that contain specific types of motifs/patterns.\nIn a nutshell, the topic is very interesting but I believe that the contributions of this paper are too limited for ICLR."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- the motif mining problem is a very relevant task, that has multiple applications in computational chemistry as well as social network analysis. Moreover, the approach proposed by the authors, albeit not very novel, is reasonable and seemingly effective.\n- The code to generate the large and diverse dataset of synthetic graphs created by the authors could be useful for subsequent articles on motif discovery."
            },
            "weaknesses": {
                "value": "- The idea is not particularly novel, as the model seems to be (although the description is not very clear) just a GNN trained to regress a vector of significance values for a set of patterns of interest.\n- The model can only obtain the significance of a fixed and pre-determined set of patterns, which limits the applicability of the method. In particular, the authors focus on unlabeled graphs of size 3 and 4. In practice, this is not ideal, as node labels carry a lot of information (e.g., in molecules, unlabeled patterns have little meaning, while labeled patterns can identify functional groups). Since the number of labeled patterns grows very fast, one could train the model only for a small fraction of them, and most of the subgraph pattern queries would not be able to be answered by the proposed model. If the model was able to learn the interesting motifs directly, the model could be much more useful.\n- The authors give an unclear discussion in Section 4.2 of the relation between the ability of GNNs to count subgraphs and their task, but the explanation of why 1-WL MPNNs are sufficient for the motif mining task is not satisfactory and vague (\u201cMPNNs remain highly valuable and find numerous practical applications in real-world scenarios\u201d). It would be helpful if the authors provided proof of their statements or at least some experimental evidence.\n- The experimental results are not only unsatisfactory (see point below), but they are also very hard to understand (e.g., I can\u2019t understand the results in Table 1). The definition of \u201ccorrect\u201d and \u201cincorrect\u201d is unclear, and should be clarified and formalized better.\n- The model has performance on real-world data that is close to the one of a model guessing at random and is much worse than the results on the synthetic data. This is a severe limitation to the applicability of the model to any real word task.\n- Overall, the paper feels unpolished. Many statements are too vague or unclear. See some of my questions below.\n\n#### Minor remarks:\n- line 491: you have an extra comma.\n- I appreciate that the authors provide the code to generate the synthetic datasets, but it is unclear whether a precomputed version is available for download."
            },
            "questions": {
                "value": "- line 196: \u201cThus, we start with a vector of Z-scores\u201d. You mean that the vector is your ground-truth label? This is unclear\n- the paragraph on \u201cCorrect predictions, line 340\u201d is very unclear to me. Can you please elaborate on your metrics?\n- line 458: \u201cdue to failing to approximate an injective function or because the bound does not work well in practical scenarios.\u201d Which bound are you referring to? This needs further elaboration.\n- which null model are you using to generate the ground truth significances? I can\u2019t find this in the paper.\n- what is the \u201cmargin of error\u201d that you mention?\n- Do you have any insights on how to obtain better performance on real world data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}