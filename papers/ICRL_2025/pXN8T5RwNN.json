{
    "id": "pXN8T5RwNN",
    "title": "Explanations of GNN on Evolving Graphs via Axiomatic  Layer edges",
    "abstract": "Graphs are ubiquitous in social networks, chemical molecules, and financial data, where Graph Neural Networks (GNNs) achieve superior predictive accuracy. Graphs can be\nevolving, while understanding how GNN predictions respond to the evolution provides significant insight and trust. \nWe explore the problem of explaining evolving GNN predictions due to continuously changing edge weights.\nWe first propose a layer edge-based explanation to balance\nexplanation fidelity and interpretability, as opposed to message flow and input edge.\nThen we propose a novel framework to address the challenges of axiomatic attribution and the entanglement of multiple computational graph paths due to continuous change of edge weights. We first design an axiomatic attribution of the evolution of the model prediction to message flows, then develop Shapley value to fairly map message flow contributions to layer edges.\nWe formulate a novel optimization problem to find the critical layer edges based on KL-divergence minimization. Extensive experiments on eight datasets for node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better fidelity and interpretability of the proposed method over the baseline methods.",
    "keywords": [
        "explainability; dynamic graphs; message flows; layeredges"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=pXN8T5RwNN",
    "pdf_link": "https://openreview.net/pdf?id=pXN8T5RwNN",
    "comments": [
        {
            "summary": {
                "value": "The paper presents Axiom Layer Edge, a novel explanation framework designed for dynamic graph learning models, particularly focusing on Graph Neural Networks (GNNs). The framework aims to identify the most influential \"layer edges\" \u2014 connections within the GNN layers that have a significant impact on the model\u2019s predictions. This approach is based on the use of Shapley values to fairly attribute contribution scores to individual layer edges and provides a principled and interpretable explanation for prediction shifts that occur as the graph changes over time. The results on several datasets and graph task show that method outperforms other existing baseline methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The work focuses on problem of explainability in evolving/dynamic graphs which is an important task\n- Extending concepts of shapley value to many dynamic graphs is also key contribution of the work\n- The work aims to focus on the trade-offs between quality of interpretablity and fidelity"
            },
            "weaknesses": {
                "value": "- Applying shapley value and KL divergence to large or highly dynamic graphs can be challenge especially due to combinatorial nature of computation\n- No theoretical analysis on computation complexity is provided for evolving graphs\n- There are several limitations with Shapley such as the lack of robustness, stability etc [1]. It is unclear what are the limitations of Shapley in this setting. \n\n[1] Kumar, I. Elizabeth, Suresh Venkatasubramanian, Carlos Scheidegger, and Sorelle Friedler. \"Problems with Shapley-value-based explanations as feature importance measures.\" In International conference on machine learning, pp. 5491-5500. PMLR, 2020."
            },
            "questions": {
                "value": "- It would be helpful if the authors can justify the use of Shapley value instead of other game-theoretic methods  (e.g., core, Banzhaf etc)?\n- How can we approximate the calculations of shapley and KL divergence in large/dynamic graphs?\n\n- Can we have a discussion on the usefulness of the explanations from the point of view domain experts? Also, are the explanations stable to graph operations like attention, pooling, etc.?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper works on the problem of explaining challenges in GNNs' predictions when the weights of the input edges are continuously changing. Prior work has weaknesses in axiomatic attribution of message flows, unfair distribution, and optimality. The proposed algorithm from the authors addresses the challenges by decomposing the changes in the message flow and introducing the Shapley value for fair attribution. Extensive experiments have been conducted to show the effectiveness of the proposed method. The paper is well-written and organized."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The intuition behind this paper is interesting and novel. The design of the framework is feasible and detailed explained. There are also sufficient experiments to demonstrate the effectiveness of the proposed methods."
            },
            "weaknesses": {
                "value": "The goal of this paper is to address the challenges of explanation on GNN in evolving graphs. Thus, it should include more dynamic graph baselines instead of simply using static GNNs. Besides, the authors should introduce more on the relationship between the proposed evaluator through the temporal dimension."
            },
            "questions": {
                "value": "1. There are typos in line 221. Please carefully check them.\n2. As the goal of this paper is to understand how GNN predictions respond to the evolution of graphs. However, in this paper, the GNNs are all static GNNs. What is the effectiveness of the proposed method in explaining the dynamic GNN methods? For example, TGN or TGAT?\n3. What is the relationship between the Shapley value through temporal dimension? Does the proposed method capture the influence of evolving nature in dynamic graphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethical concerns."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a method for the explainability of evolving graphs, where edge weights of a graph changes over time. The authors explore this problem across three tasks of node classification, link prediction, and graph classification and show that their approach demonstrates superior performance compared to other baselines. Furthermore, in their problem setting Pr(Y |G0; \u03b8) will evolve to Pr(Y |G1; \u03b8), and they aim to explain the evolution of Pr(Y |G; \u03b8) with respect to G0 \u2192 G1. They formulate the changes in hidden vectors on G0 and G1 and apply chain rule of DeepLIFT to assign the changes in logits to message flows. Finally, they show that their approach outperforms other baselines on KL divergence metric."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The problem of explainability for Graph Neural Networks (GNNs) in the context of evolving graphs is both interesting and novel. \n\n- The proposed model demonstrates superior performance compared to other baseline methods."
            },
            "weaknesses": {
                "value": "- The metric used for evaluation is not clearly justified. There are standard metrics, such as fidelity, that could provide a better understanding of the method's performance.\n- For an explainability method, it is crucial to include at least one visualization of a dataset. This would allow readers to visually assess the method's effectiveness.\n- It would be beneficial to experimentally demonstrate that this method works with different Graph Neural Networks (GNNs). Additionally, including a table that shows the performance of the pre-trained GNNs across various datasets would be helpful."
            },
            "questions": {
                "value": "- What pre-trained GNN has been used in this work?\n- Could you provide visualizations of your results for datasets such as MUTAG?\n- What is the rational behind choosing KL divergence as the evaluation metric?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper provides explanations for predictions on evolving graphs. In the case of continuously changing edge weights, the authors propose an explanation method based on Axiomatic Layer Edges, mapping the contribution of message flows to layer edges using Shapley values, and selecting key layer edges by minimizing the KL divergence optimization problem. Experimental results show that this method outperforms existing baseline methods across multiple datasets and tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. The paper presents an explanation method based on layer edges, which can more accurately capture the variations in message passing, thereby improving the fidelity of the explanations. The method is innovative.\n2. The authors explain prediction changes by selecting a small number of key layer edges at multiple scales through a KL divergence-based optimization problem.\n3. The paper conducts experiments on multiple datasets and tasks, including node classification, link prediction, and graph classification tasks."
            },
            "weaknesses": {
                "value": "1. The authors should conduct a complexity analysis, as the computation of Shapley values generally has a high complexity. Additionally, since the authors select a small number of key layer edges in their method, will this impact the complexity of the model?\n2. In this paper, the authors use a series of carefully designed methods to balance the fidelity and interpretability of explanations. However, I still have a question: is there an optimal balance point (for example, the optimal point reached in Figure 2(b))?\n3. The paper assumes that changes in edge weights are continuous; however, could the authors also explore sudden or discontinuous changes (such as the addition or deletion of nodes or edges)? Changes in graph structure can be quite complex and unpredictable, which may affect the robustness of the method."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}