{
    "id": "2gTEW29qsM",
    "title": "Masked Generative Priors Improve World Models Sequence Modelling Capabilities",
    "abstract": "Deep Reinforcement Learning (RL) has become the leading approach for creating artificial agents in complex environments. Model-based approaches, which are RL methods with world models that predict environment dynamics, are among the most promising directions for improving data efficiency, forming a critical step toward bridging the gap between research and real-world deployment. In particular, world models enhance sample efficiency by learning in imagination, which involves training a generative sequence model of the environment in a self-supervised manner.\nRecently, Masked Generative Modelling has emerged as a more efficient and superior inductive bias for modelling and generating token sequences. Building on the Efficient Stochastic Transformer-based World Models (STORM) architecture, we replace the traditional MLP prior with a Masked Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM.\nWe evaluate our model on two downstream tasks: reinforcement learning and video prediction. GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari 100k benchmark.\nMoreover, we apply Transformer-based World Models to continuous action environments for the first time, addressing a significant gap in prior research. To achieve this, we employ a state mixer function that integrates latent state representations with actions, enabling our model to handle continuous control tasks. We validate this approach through qualitative and quantitative analyses on the DeepMind Control Suite, showcasing the effectiveness of Transformer-based World Models in this new domain.\nOur results highlight the versatility and efficacy of the MaskGIT dynamics prior, paving the way for more accurate world models and effective RL policies.",
    "keywords": [
        "World Modeling",
        "Model based RL"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=2gTEW29qsM",
    "pdf_link": "https://openreview.net/pdf?id=2gTEW29qsM",
    "comments": [
        {
            "title": {
                "value": "Q&A 4"
            },
            "comment": {
                "value": "Q4: Why does it fail to close the performance gap with DreamerV3 in environments beyond Atari 100k. What is the rationale for improving STORM over directly utilizing DreamerV3, which appears to perform better in many scenarios? Or put differently: why would one care to improve STORM with the proposed modifications when there is DreamerV3 and I could just use it or improve over DreamerV3?\n\n\n\nA4: We thank the reviewer for such a fundamental\u00a0and important question.\u00a0\n\nThe rationale for improving STORM over directly utilizing DreamerV3 comes from the advantages of transformer-based world models over RSSMs, like the one used in Dreamer-based architectures. Indeed, as stated in the Introduction section:\u00a0\n\n\u201cAs RNNs impede parallelised computing due to its recurrent nature, some works (Micheli et al., 2022; Robine et al., 2023; Zhang et al., 2023) have incorporated autoregressive transformer architectures (Vaswani et al., 2017), which have been shown to be effective across various domains, such as language (Devlin et al., 2019; Radford et al., 2019; Brown et al., 2020; Raffel et al., 2020), images (Dosovitskiy et al., 2021; He et al., 2022; Liu et al., 2023), and offline RL (Janner et al., 2021; Chen et al., 2021). For instance, IRIS (Micheli et al., 2022) utilises discrete autoencoders (Oord et al., 2017) to map raw pixels into a smaller set of image tokens to be used as the input to the world model, achieving super-human performance in ten different environments of the Atari 100k benchmark (Kaiser et al., 2019).\u201d\n\n\n\nExpanding this paragraph, transformer-based world models are very promising considering that dynamic state transitions can be performed in parallel. Indeed, iVideoGPT [2], a transformer-based world model, was the first-ever world model trained on the Open X-Embodiment dataset [3], an extremely big robotics dataset built from 22 different robots collected through a collaboration between 21 institutions, demonstrating 527 skills (160266 tasks).\u00a0\n\nMoreover, iVideoGPT authors state:\n\n\u201ciVideoGPT is scalable for action-free video prediction across a mixture of over one million robotic and human manipulation trajectories.\u201d\n\nThis sentence, together with the whole introduction and methodology sections, shows how using a scalable model (e.g., transformers) to learn a world model allows us to tackle way harder and more realistic environments than game environments.\u00a0\n\nTo sum up and answer your question explicitly, pursuing research within the domain of transformer-based transformers rather than using DreamerV3-based models that rely on RSSMs will eventually allow the community to build scalable models that are able to handle real-world environments\u2014the ultimate goal of this community.\u00a0\n\nFinally, we would like to add that the goal of the paper is to inform the community about the fact that Masked generative priors (e.g., MaskGIT priors) improve the sequence modelling capabilities of transformer-based world models. This, although tested on simpler environments, is something that definitely is worth exploring in more realistic environments and architectures, such as iVideoGPT, which would be a perfect fit for this method. If we had more time and world model weights were available, we would have validated the usage of MaskGIT prior to it as well.\u00a0\n\n\n\n[2] Jialong Wu and Shaofeng Yin and Ningya Feng and Xu He and Dong Li and Jianye Hao and Mingsheng Long. iVideoGPT: Interactive VideoGPTs are Scalable World Models, 2024, https://arxiv.org/abs/2405.15223.\n\n[3] Open X-Embodiment Collaboration et al. Open X-Embodiment:Robotic Learning Datasets on RT-X Models, 2024, https://robotics-transformer-x.github.io/."
            }
        },
        {
            "title": {
                "value": "Q&A 3"
            },
            "comment": {
                "value": "Q3: The paper claims state-of-the-art results for GIT-STORM on select environments, yet Table 6 seems to indicate that DrQ-v2 outperforms GIT-STORM on two environments (where the authors claim they are better?). Regarding the reported state-of-the-art claim, Table 6 suggests that DrQ-v2 outperforms GIT-STORM in some highlighted environments. Could the authors comment on why they claim GIT-STORM provides SOTA results on these? It is not the case, right?\n\n\n\nA3: We understand the confusion that the results table may bring, and we hope to address any doubts you may have regarding this question here.\u00a0\n\nIn Deep Reinforcement Learning at the Edge of the Statistical Precipice: https://proceedings.neurips.cc/paper/2021/hash/f514cec81cb148559cf475e7426eed5e-Abstract.html , the authors write:\n\n\u201cOnly reporting point estimates obscures nuances in comparisons [85] and can erroneously lead the field to conclude which methods are state-of-the-art [63, 84], ensuing wasted effort when applied in practice [108].\u201d\n\nMoreover, also because of these reasons, within this field the results within the 5% of variation of state-of-the-art (SOTA) values are also considered SOTA performances [1].\n\n\n\nTherefore, the results and comparisons within single environments cannot be considered to define which model is state-of-the-art, and following the community standards, we defined as state-of-the-art the results where GIT-STORM performs above every other model, or within the 5% of variation from SOTA values. That\u2019s why we state:\u00a0\n\n\u201cGIT-STORM presents state-of-the-art scores on two environments, Walker Stand, and Quadruped Run.\u201d\n\n\u00a0\n\n[1] Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap. Mastering diverse domains through world models. arXiv preprint arXiv:2301.04104, 2023.\n\n[63] Jimmy Lin, Daniel Campos, Nick Craswell, Bhaskar Mitra, and Emine Yilmaz. Significant improvements over the state of the art? a case study of the ms marco document ranking leaderboard. arXiv preprint arXiv:2102.12887, 2021.\n\n[84] Nils Reimers and Iryna Gurevych. Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 338\u2013348, 2017.\n\n[85] Samuel Ritter, David GT Barrett, Adam Santoro, and Matt M Botvinick. Cognitive psychology for deed neural networks: A shape bias case study. In International conference on machine learning, 2017.\n\n[108] Ga\u00ebl Varoquaux and Veronika Cheplygina. How i failed machine learning in medical imaging\u2013shortcomings and recommendations. arXiv preprint arXiv:2103.10292, 2021."
            }
        },
        {
            "title": {
                "value": "Q&A 2"
            },
            "comment": {
                "value": "Q2: It remains unclear why GIT-STORM does not consistently outperform STORM across all benchmarks. Could the authors elaborate on why GIT-STORM occasionally does not surpass STORM and the conditions where improvements are only minor? Understanding this would clarify the contextual efficacy of the MaskGIT prior.\n\n\n\nA2: We understand why this may be confusing and thank the reviewer for asking this question.\u00a0\n\nIn Deep Reinforcement Learning at the Edge of the Statistical Precipice: https://proceedings.neurips.cc/paper/2021/hash/f514cec81cb148559cf475e7426eed5e-Abstract.html , the authors write:\n\n\u201cOnly reporting point estimates obscures nuances in comparisons [85] and can erroneously lead the field to conclude which methods are state-of-the-art [63, 84], ensuing wasted effort when applied in practice [108].\u201d\n\nTherefore, the single values of each run cannot be really considered singularly, as the variation and stochasticity of these runs depend on a multitude of factors (e.g., used random seed, luck in exploration, etc.). Hence, whether GIT-STORM consistently outperforms STORM can only be assessed from a statistical perspective. In particular, following \u201cDeep Reinforcement Learning at the Edge of the Statistical Precipice\u201d, we use the metrics they propose to meaningfully assess models' capabilities in this field (e.g., mean, median, IQM, optimal GAP, and probability of improvement over other baselines P(GIT-STORM>Y), where Y are all other baselines). A more detailed explanation of these metrics can be found in Appendix J.\n\nAccording to these metrics, GIT-STORM consistently outperforms STORM.\u00a0\n\nFinally, not only the single values are not reliable but also assessing why a model performs better than another one cannot be done with confidence or rational arguments. That\u2019s why rather than writing conjectures on why GIT-STORM outperforms STORM in single environments, we base our arguments on the statistical metrics.\u00a0\n\nWe hope this addresses your question, but we are more than happy to keep discussing should there be any other concerns or\u00a0doubts."
            }
        },
        {
            "title": {
                "value": "Q&A 1"
            },
            "comment": {
                "value": "We thank the reviewer for such insightful and important questions. We are really happy to answer and fulfill any remaining doubts. Here we list aggregated questions and the related answers.\u00a0\n\n\nQ1: The paper does not fully explain the conditions under which GIT-STORM\u2019s improvements are more marginal, suggesting a need for clearer insights into the impact of individual architectural components. Most importantly, the modifications from STORM to GIT-STORM are extensive, involving MaskGIT, state mixer, policy adjustments from DreamerV3, and an observation module from STORM. The compounded modifications make it difficult to discern the exact contribution of each component to the reported performance improvements. A more focused ablation study could be required to isolate the impact of each modification.\n\n\n\nA1: We agree with the reviewer; we are working on an ablation study that assesses the contribution of the following components:\n\nMaskgit head: We compare the MaskGIT head to the MLP head.\nLogits computation using the dot product between eps_t and MaskGit embeddings: We compare the GIT-STORM setup against using the MLP head that takes as input eps_t and returns logits, validating how using the dot product between eps_t and MaskGit embeddings impacts the performances.\u00a0\nMixed states:\u00a0we compare using a state mixer against using the unmixed states as world model autoregressive transformer input. As a result, we can validate to what extent the capacity introduced by the state mixer affects GIT-STORM performances.\u00a0\n\n\nFollowing your suggestions, we believe that these are the key components to analyse to understand GIT-STORM capabilities and the exact contribution of each component to the reported performance improvements.\u00a0\n\n\n\nWe will validate the ablation on 3 Atari games (Hero, Freeway, and Boxing) and 3 DMC environments (Walker Walk, Walker Run, and Quadruped Run) over 3 seeds. We will send the ablations as soon as possible."
            }
        },
        {
            "summary": {
                "value": "The paper, Masked Generative Priors Improve World Models Sequence Modelling Capabilities, introduces GIT-STORM, an extension of the STORM architecture, incorporating MaskGIT as a dynamics prior to enhance sequence modeling in world models. The authors address two main gaps in previous research: the limitation of transformer-based world models in continuous action environments and the inadequacies of prior methods, like STORM, in capturing effective state representations. Through experiments on Atari 100k (discrete) and DeepMind Control Suite (continuous), GIT-STORM demonstrates improvements in RL and video prediction, suggesting that Masked Generative Priors could be a powerful inductive bias for world models, supporting broader applicability across diverse RL tasks and environments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The empirical evaluation spans discrete and continuous action benchmarks, providing a robust assessment of GIT-STORM\u2019s performance. The reported results demonstrate that GIT-STORM not only improves sample efficiency in RL tasks but also enhances video prediction quality, particularly in the Atari 100k benchmark, aligning well with the study's objectives. Moreover, the paper is well-written with a clear structure, providing a good experience as a reader. Extending the transformer-based world models to continuous action tasks also poses a sufficient novelty and broadens the utility of these models in RL and video prediction applications."
            },
            "weaknesses": {
                "value": "It remains unclear why GIT-STORM does not consistently outperform STORM across all benchmarks or why it fails to close the performance gap with DreamerV3 in environments beyond Atari 100k. The paper does not fully explain the conditions under which GIT-STORM\u2019s improvements are more marginal, suggesting a need for clearer insights into the impact of individual architectural components.\n\nThe paper claims state-of-the-art results for GIT-STORM on select environments, yet Table 6 seems to indicate that DrQ-v2 outperforms GIT-STORM on two environments (where the authors claim they are better?). Clarifying the conditions under which GIT-STORM achieves these results or adjusting the claim would help ensure consistency and accuracy in presenting the model's achievements.\n\nThe proposed approach for handling continuous action spaces is promising, yet lacks a comprehensive empirical analysis. Additional studies on more diverse continuous control tasks could provide stronger validation of the state mixer function's effectiveness and the broader applicability of the model in continuous settings. Most importantly, the modifications from STORM to GIT-STORM are extensive, involving MaskGIT, state mixer, policy adjustments from DreamerV3, and an observation module from STORM. The compounded modifications make it difficult to discern the exact contribution of each component to the reported performance improvements. A more focused ablation study could is required to isolate the impact of each modification."
            },
            "questions": {
                "value": "- Could the authors elaborate on why GIT-STORM occasionally does not surpass STORM and the conditions where improvements are only minor? Understanding this would clarify the contextual efficacy of the MaskGIT prior.\n- Regarding the reported state-of-the-art claim, Table 6 suggests that DrQ-v2 outperforms GIT-STORM in some highlighted environments. Could the authors comment why they claim GIT-STORM provides SOTA results on these? It is not the case, right?\n- What is the rationale for improving STORM over directly utilizing DreamerV3, which appears to perform better in many scenarios? Or put differently: why would one care to improve STORM with the proposed modifications when there is DreamerV3 and I could just use it or improve over DreamerV3? \n\nI am open to increase my score once there is clarity on these questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces GIT-STORM, which incorporates three modifications to the base algorithm STORM: a MaskGIT prior that replaces the MLP dynamics head, a draft-and-revise decoding scheme for enhanced consistency, and a state mixer for continuous action environments. Experimental results demonstrate that GIT-STORM surpasses STORM on both Atari 100K and DMC benchmarks. Video prediction results indicate that this improvement is attributed to more accurate representations."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The motivation of incorporating a MaskGIT prior into the STORM architecture is clear.\n- The proposed method is straightforward and easy to reproduce.\n- MaskGIT can effectively improve the video prediction quality of STORM,  indicating applicability of GIT-STORM to more complicated tasks."
            },
            "weaknesses": {
                "value": "- The paper contains a misstatement in its contributions. The authors claim that they \"apply transformer-based world models to continuous action environments for the first time\". This claim is inaccurate, as TransDreamer[1] can also be applied to continuous action environments. The authors are evidently aware of this paper, given that they have cited it in this work.\n- The state-mixer design is not properly addressed. If the authors claim this part of their contribution, they should either elaborate on the design, or provide empirical results to show the superiority of this method. Based on the overlapping tasks, TransDreamer appears to have better performance than GIT-STORM+state-mixer on the continuous control benchmark DMC.\n- The experimental results in Atari 100K only demonstrate marginal improvement. The gain over STORM seems to primarily originate from the gopher task alone, which contains inconsistent results, as detailed in the questions section.\n\n[1] Chen et al. TransDreamer: Reinforcement Learning with Transformer World Models."
            },
            "questions": {
                "value": "- Results on the Freeway task have very high variance according to Figure 10. How many out of the five runs does GIT-STORM actually achieve non-zero performance? \n- The most challenging aspect of learning the Freeway task is obtaining the first successful trajectory, which I believe is more related to the exploration strategy than state predictions, given the sparse rewards. How does GIT-STORM assist the agent in exploring more efficiently? Is this strategy stable, or are the successful trajectories obtained by random seeds?\n- Why would the pendulum swingup task fail for both STORM and GIT-STORM? DreamerV2, DreamerV3 and TransDreamer can learn this task fairly easily.\n- The experiment results in Table 5 and Figure 10 appear inconsistent. For instance, the Gopher score reported in Table 5 is 8562, but the last point in Figure 10 shows a performance of around 2500. Do these two results use different metrics?\n- Could you add the learning curves of STORM or DreamerV3 to Figure 10 for a better comparison, considering that you have reproduced these results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposed to replace the MLP head with MaskGIT prior in STORM to achieve a higher quality of latent generation, and therefore achieve better performance on the Atari100k benchmark.\nThis paper also bridges the gap of the lack of evaluation of transformer-based world models on continuous control tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper clearly distinguishes itself from previous work, with good comparison and illustration.\n\n2. One-hot categorical latent is widely used in recent model-based RL, yet the research on it is insufficient. This paper provides a novel view of it.\n\n3. This paper bridges the gap of the lack of evaluation of transformer-based world models on continuous control tasks."
            },
            "weaknesses": {
                "value": "1. The motivation and effect of using MaskGIT head in world models are unclear.\nIs there any evidence that the world models would have hallucinations, and how could a MaskGIT head mitigate such issues?\nHow to distinguish if the improved performance (both RL and FVD) comes from more parameters or the MaskGIT prior?\n\n    There should be some further investigation into the mechanism of the MaskGIT head. Such as:\n\n    (a) What's the difference between the latent variables (or distributions) generated with the MLP head and MaskGIT head?\n\n    (b) This MaskGIT head looks like a skip/residual connection from $z_{t}$ to $\\hat{z}_{t+1}$, would this reduce the KL divergence in the training or imagination?\n\n    (c) These are sample questions. An investigation like this would improve the soundness and contribution of this paper.\n\n2. Section 2.1 could be more concise, as these are not quite related to the key contributions and are frequently repeated in each of the model-based RL papers."
            },
            "questions": {
                "value": "1. On lines 307-309, I think STORM uses KV caching in both the conditioning phase and the imagination phase, see [here](https://github.com/weipu-zhang/STORM/blob/e0b3fd44320d7e213ec905c673ad3f35b61b89f4/sub_models/world_models.py#L363). The `predict_next()` uses `forward_with_kv_cache()` for decoding.\n\n2. Missing comma on line 214?\n\n3. What's new in the proposed state mixer compared to the STORM's action mixer?\n\n4. `Freeway` is a hard exploration environment, as the agent has to repeat the `up` operation many times to get a first reward, which is a rare event for a random policy. Without the first reward, the value space is all zero and the policy would be further optimized as a uniform random policy. STORM, IRIS, and DIAMOND have different tricks that can mitigate such an issue. But what is the underlying reason for GIT-STORM to reach a non-zero result? I think this is not related to the improved decoding or world modelling quality since DreamerV3 and STORM (w/o traj) could also produce a nearly perfect reconstruction and prediction on `Freeway`.\n\n5. For the `Quadruped Run` in Figure 6, I wonder if it's too small (compared to Figure 4 in [DreamerV3](https://arxiv.org/pdf/2301.04104)).\n\n6. Lines 529-530, \"Replacing...\", the order is reversed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes GIT-STORM, which utilizes a MaskGIT model instead of an MLP for the prior head in world models (based on STORM). It also makes minor modifications (a state mixer) to support continuous actions. Experiments are done on Atari100k and DMC benchmarks, considering both policy learning and video prediction performance. GIT-STORM outperforms its base method STORM."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "To my knowledge, MaskGIT models, with their strong expressiveness, are not yet utilized for world models in the MBRL community."
            },
            "weaknesses": {
                "value": "1. The illustration and descriptions of the model are confusing. Can authors provide more insights for their specific designs?\n   - In Figure 1 (left), it seems that GIT-STORM uses masked $z_t$ as inputs for reconstructing $z_{t+1}$. This is strange since, in the original MaskGIT, we mask and reconstruct masked target tokens. Similarly, I think it is more reasonable to mask $z_{t+1}$ as inputs. \n   - In Figure 1 (left), there is no $\\xi_t$ but only $\\eta_t$. \n   - Also, the dot product seems to be a commonly used trick that ties weights for embedding and linear layer before Softmax. If so, relevant literature should be cited.\n   - The Draft-and-Revise decoding scheme, if not proposed by this work, should be moved into a preliminary section.\u00a0\n2. The contribution to supporting continuous actions is overclaimed (as 'for the first time'). In fact, concatenating or summating continuous inputs with hidden states is a too straightforward approach in current VLA models (e.g., OpenVLA for inputting continuous visual representations) and action-conditioned video prediction models (e.g., iVideoGPT for inputting continuous actions).\n3. The performance of GIT-STORM on DMC is outperformed by its base method, DreamerV3."
            },
            "questions": {
                "value": "There are also some minor questions:\n\n1. In Line 309, why KV cache can improve sample efficiency? Do you mean computational efficiency?\n2. To my knowledge, perplexity is a metric whose lower values mean better. However, in Table 3, higher perplexity is marked as better.\n3. In Figure 6, the quadruped agents are too small in the images. This work seems to have used an unusual camera setting for these tasks.\n\nIf the authors well address my concerns, I am willing to improve my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}