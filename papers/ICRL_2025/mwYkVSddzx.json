{
    "id": "mwYkVSddzx",
    "title": "Orthogonal Representation Learning for Estimating Causal Quantities",
    "abstract": "Representation learning is widely used for estimating causal quantities (e.g., the conditional average treatment effect) from observational data. While existing representation learning methods have the benefit of allowing for end-to-end learning, they do not have favorable theoretical properties of Neyman-orthogonal learners, such as double robustness and quasi-oracle efficiency. Also, such representation learning methods often employ additional constraints, like balancing, which may even lead to inconsistent estimation. In this paper, we propose a novel class of Neyman-orthogonal learners for causal quantities defined at the representation level, which we call OR-learners. Our OR-learners have several practical advantages: they allow for consistent estimation of causal quantities based on any learned representation, while offering favorable theoretical properties including double robustness and quasi-oracle efficiency. In numerous experiments, we show that, under certain regularity conditions, our OR-learners improve existing representation learning methods and achieve state-of-the-art performance. To the best of our knowledge, our OR-learners are the first work to unify representation learning methods and Neyman-orthogonal learners.",
    "keywords": [
        "treatment effect estimation",
        "counterfactual outcomes estimation",
        "representation learning"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "We propose a novel class of Neyman-orthogonal learners for causal quantities defined at the representation level",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=mwYkVSddzx",
    "pdf_link": "https://openreview.net/pdf?id=mwYkVSddzx",
    "comments": [
        {
            "summary": {
                "value": "The manuscript introduces a new approach to estimating causal quantities by learned representation. With a carefully chosen target risk, a Neyman-orthogonal learner is proposed. Although claiming the theoretical guarantees, the authors do not provide any theoretical analysis. In addition, there is no foundation for some claims (see details in the questions). Lastly, there is still a large room for improvement in the writing to achieve a publication level."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors raise an interesting question, although the solution can still be improved."
            },
            "weaknesses": {
                "value": "The author may want to present some evidence for some claims in the manuscript. In addition, combining existing ideas may not be interesting enough. The writing can be much improved."
            },
            "questions": {
                "value": "1) The manuscript claims that any representation can work. However, proving $Y(0), Y(1)\\perp Z|\\Phi(X)$ is not easy, and the conditional independence does not hold for any representation. With this condition, the downstream analysis is biased. \n\n2) Formula (10) does not include $g$\n\n3) What is the difference between $V$ and $\\Phi(X)$?\n\n4) Estimating nuisance functions can be difficult sometimes. How does the accuracy in estimating nuisance functions affect the final estimation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper focuses on an important problem of estimating causal quantities, including effects and potential outcome mean. This paper proposes to use representations, instead of using original covariates, to learn the causal quantities in the second second stage of DR-learner/R-learner. This paper also provide detailed discussion on the advantages compared with original representation learning methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper provides a three-stage causal quantities estimation method, which achieves the DR property.\n2. Experimental results verify the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. A very key and similar work related to this paper is [1]. My biggest concerns are:\n   1. [1] is not well discussed in the main part of the paper. If I understand correctly, the difference between this paper and [1] is that [1] uses original covariates to learn target parameters and this paper uses representations. Could you clarify the advantages compared with [1]?\n   2. In experiments, $V=X$ can be seen as an implementation of [1] (please correct me if I misunderstand). However, the conducted experiments only use 1 hidden layer FC, which may explain why the improvement of $V=X$ is much less than $V=\\Phi(X)$. It would be fairer and better to use more deep neural networks.\n2. It would be better to provide the theoretical improvement that OR-learner brings.\n3. It could be better to move Figure 6 to the main body of the paper.\n\nI would be very happy to raise my score if the authors could address my concerns well.\n\n[1] Curth A, Van der Schaar M. Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms[C]//International Conference on Artificial Intelligence and Statistics. PMLR, 2021: 1810-1818."
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper builds on former work on representation learning for treatment effect estimation and pseudo-outcome-based meta-learners satisfying Neyman orthogonality to propose OR-learners, a general meta-learner framework where the pseudo-outcome is learnt not with the original covariates as input features, but with representations that are learnt beforehand using canonical representation learning for treatment effect methods. Intuitions to justify the contribution of the procedure are given, which are further demonstrated in experiments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Originality : It is indeed the first time that I see a contribution on using a two-stage learner, where the two stages are 1) learning a representation to be used as an input for treatment effect estimation, 2) feeding it to pseudo-outcome learning  (with nuisance functions to fit separately) for treatment effect estimation.\n\nQuality&Signifiance: The paper provides an extensive review of the previous literature, and provides an interesting taxonomy of representation learning for treatment effect estimation methods (e.g. without balancing constraints, (non-)invertible with balancing constraints). Experiments seem extensive and able to justify that the method does improve over former baselines.\n\nClarity : The paper is generally clear in its introductory parts up to Section 3 and in Appendices. I also appreciate the extensive use of figures."
            },
            "weaknesses": {
                "value": "EDIT Nov 13 : apologies, looks like links did not work! I have re-entered them.\n\nOriginalty&Signifiance : while it is the first work I see learning representations in a \"treatment effect estimation friendly\" way (i.e.using treatment and/or outcome information together with covariates) to be fed into pseudo-outcome learning, it is not the first method that generally feeds such representations to any treatment effect estimation, even doubly robust methods. More specifically, the submission seems to ignore the extensive and more classical, non-DL literature on such representations, and their use of inputs of treatment effect estimation methods. See for example [propensity scores](https://academic.oup.com/biomet/article/70/1/41/240879), [prognostic scores](https://www.jstor.org/stable/20441477), [sufficient dimension reduction](https://www.tandfonline.com/doi/full/10.1080/07350015.2019.1609974), and [deconfounding scores](https://arxiv.org/pdf/2104.05762). Note that the last reference explicitly feeds a learnt representation into AIPW, a classical doubly-robust method.\n\nQuality&Clarity : besides this former work, what I find is really missing is a mathematical analysis of the proposed method, which is critical as 1) the paper explicitly says that the method \"offer[s] favorable properties of Neyman-orthogonality\", which are typically demonstrated mathematically, and might be contradicted if the learnt representation is degenerate (e.g. constant), 2) the performance of the method would generally depend on special cases of the representations, e.g. a) it is a constant, as mentioned before, b) it has RICB different from 0, c) it has RICB zero or converging to zero, d) it converges or is equal to a perfect balancing score (predicts treatment assignment) or prognostic score (predicts outcome regression). Instead, the submission uses textual \"intuitions\" that I find might lack substance, justification or clarity (see questions)"
            },
            "questions": {
                "value": "(Please note that I am very open to increase my score if the above weaknesses and below questions are addressed)\n\n> l.234 : Also, for CATE estimation, we can consider an overlap-weighted MSE alternative of \n\nA reference is missing here.\n\n> l.304-306 : \"This can be formalized with the notion of (Holder) smoothness (Ohn & Kim, 2019): Each layer induces a new space in which the ground-truth regression function becomes smoother and thus easier to estimate.\"\n\nI do not understand exactly where in the reference the claim is justified?\n\n> l. 310-316 \n\nAny mathematical or bibliographical justification for why these methods \"can be also considered asymptotically valid\"? and why specify a dimension of 2 or more?\n\n> l.319-320 : \"Therefore, the second-stage model $g(\\phi)$ uses additional propensity information and achieves more efficient estimation.\"\n\nDo you have a mathematical and/or bibliographical (i.e. a reference) justification?\n\n> l.365-367 : \"Then, in order to minimize the original MSE loss, the representation network would scale up the parts of space to increase the smoothness of ...\"\n\nDo you have a mathematical and/or bibliographical (i.e. a reference) justification?\n\n> l.381-384 : \"Our OR-learners then will effectively try to \u201cundo\u201d the effect of balancing, as they reintroduce the propensity weighting. Specifically, DR-learners would \u201cre-focus\u201d the target models on the parts of the representation space with the lack of overlap, while R-learner would ignore them fully\"\n\nBy balancing, you generally mean minimizing the difference between the distributions of the representation between both groups, right? (Please be specific, as propensity weighting is generally considered balancing!) Also, can you elaborate on this re-focusing will be done? Indeed, with $\\Phi(X) = 0$, we have perfectly balanced and overlapping representation, but it cannot be used for any form of estimation!\n\nl> .396-398 : \", but also to fold it, project it, etc. When balancing is applied, non-overlapping parts of the space could be simply folded together or projected onto some subspace, so that they become balanced.\"\n\nWhat do you mean exactly by \"fold\"? That the representation is not injective?\n\n> l.404-405 : \"Asymptotically, our OR-learners will help to remove the RICB so that we can consistently estimate representation level CAPOs and CATE.\"\n\nJustification? Especially if $\\Phi(X) = 0$ (which seems to be encapsulated by this section), then the RICB will just never disappear!\n\n> l.407-410 : \"On the other hand, in the finite-sample setting, our OR-learners will \u201cundo\u201d the effect of balancing by employing the covariate propensity score. Therefore, our OR-learners on the one hand can \u201cundo\u201d the benefit brought by balancing (if there is such a setting), and, on the other, partially fix the damage after applying too much balancing.\" :\n\nTied to the above on l.381-384, but also : can you mathematically or bibliographically justify that this happens in finite-samples?\n\n> l.531-534 : \"Informally, balancing assumes that the lack of overlap implies a lack of potential outcomes/treatment effect heterogeneity.\" \n\nAny mathematical or bibliographical justification?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}