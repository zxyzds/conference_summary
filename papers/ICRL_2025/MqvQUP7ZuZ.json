{
    "id": "MqvQUP7ZuZ",
    "title": "DC3DO: Diffusion Classifier for 3D Objects",
    "abstract": "Inspired by Geoffrey Hinton\u2019s emphasis on generative modeling \"To recognize shapes, first learn to generate them\", we explore the use of 3D diffusion models for 3D object classification. Leveraging the density estimates from these models, our approach DC3DO, Diffusion Classifier for 3D Objects enables zero-shot classification of 3D shapes without additional training. Our method achieves on average 12.5\\% improvement compared with its multi-view counterparts, demonstrating superior performance compared to discriminative approaches. In DC3DO we use a class-conditional diffusion model trained on ShapeNet and validate our findings on two classes: chairs and cars. DC3DO has been tested for out-of-distribution (OOD) with IFCNet and ModelNet datasets. This work underscores the potential of generative models in 3D object classification.",
    "keywords": [
        "diffusion",
        "classifier",
        "3D",
        "deep generative models",
        "classification"
    ],
    "primary_area": "generative models",
    "TLDR": "3D Classification with Diffusion Models Compared With Multi-View 2D Diffusion Classifier",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=MqvQUP7ZuZ",
    "pdf_link": "https://openreview.net/pdf?id=MqvQUP7ZuZ",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a Diffusion Classifier designed for 3D objects (DC3DO). DC3DO combines the LION model with the 2D Diffusion Classifier to build a class-conditioned 3D Diffusion Classifier based on latent encoded from the 3D shape and points of objects. \n\nThe proposed DC3DO is mainly compared with the Multi-View Diffusion Classifier(MVDC), which combines the aggregated multi-view features and the 2D Diffusion Classifier. \n\nOut-of-distribution performance is evaluated on unseen datasets other than the training dataset."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea of building a 3D diffusion classifier is attractive. The paper compared two methods of combining 3D representation and 2D diffusion classifier. \n\nThe paper is well-written and clear to follow."
            },
            "weaknesses": {
                "value": "1. Limited number of classes are validated: only \u201cchairs\u201d and \u201ccars\u201d are evaluated for classification performance. Even though the current 3D datasets are relatively smaller than 2D datasets, two categories are insufficient for validating a classifier considering the MVCNN (Su et al., 2015) was validated on 40 classes. \n\n2. Limited comparison baselines: at least MVCCN is closely related to MVDC in this paper and as a frequently mentioned baseline method, can I know why the authors didn't compare the main classification results with MVCNN? And also other standard baseline 3D classification models are expected.\n\n3. Limited novelty: The main contribution of DC3DO is a simple combination of LION and Diffusion Classifier. Considering the combination is the same way as turning a 2D diffusion model into a classifier as Diffusion Classifier (Li et al., 2023), the novelty of this paper is limited.\n\n4. Misuse of the term \u201czero-shot classification\u201d: zero-shot classification is supposed to generalize a classifier to unseen \"classes\". In this paper only 3D models of the same class from unseen datasets/sources are validated as OOD data, it should be best described as a domain generalization instead of a zero-shot classification. Can the author provide further clarification on this?"
            },
            "questions": {
                "value": "1. Why no more categories are validated for a classifier? Please refer to Weaknesses 1.\n\n2. Why no other baseline method is compared? Please refer to Weaknesses 2. Especially for OOD settings, experiment without comparisons has very limited value."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes DC3DO, a pipeline that adopts 2D diffusion types of models to zero-shot 3D object classification. DC3DO is extended from previous work LION that adopts diffusion models to 2D classification model by introducing multi-view diffusion components. The model is tested on ShapeNet (only on chairs and cars categories)."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is easy to follow, the presentation of the work is good.\n2. Figures are clear and easily understandable, and they help reader conceive the main idea the paper is trying to present.\n3. Interesting illustrations of certain categories with high and low prediction accuracies of car and chair"
            },
            "weaknesses": {
                "value": "1. The biggest problem of this paper is the lack of enough experimentation. The experiments are only conducted on two selected categories (car and chairs) from one dataset (ShapeNet), which is definitely not enough for a paper at this conference. Also, not enough baselines are considered, and the paper only compares to baseline MVDC, which is not a recent work. The current experiment results cannot support the claim of the paper.\n\n2. The paper lacks technical novelties. MVDC seems only extend LION to multi-view without much structural and strategical changes. It seems to be a naive multi-view extension of LION. \n\n3. The paper fails to discuss and tackle the potential drawback of its proposed solution. As I can see, the multi-view diffusion process will take a long time on every image, which will be much slower than some other 3D object classification models. The paper should analyze the tradeoff between performance and efficiency compared to more typical 3D object classification models. Does the performance boost worth the increasing inference time? \n\n4. The claim that this method is robust is also not sufficiently supported by the experiment. The experiment does not compare to any other baseline at all to show the proposed method is more robust."
            },
            "questions": {
                "value": "Please see the weakness session.\n\nI think the paper needs serious revision to include more experimentations and to reduce the inference time overhead."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a diffusion-based 3D object classification approach. Specifically, they adapt the LION (diffusion-based model for point cloud to mesh generation) into a classification model that defines P(x|c) where x is the given 3D geometry, and c is the object class. They conduct an experiment on a small subset of the ShapeNet dataset and evaluate it on both ShapeNet and ModelNet. The proposed approach seems reasonable, however, the experiment setup is not sound enough to demonstration the advantages of the proposed approach."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The method is straightforward and easy to understand.\n2. Exploring the 3D object understanding and classification seems a worth study topic."
            },
            "weaknesses": {
                "value": "1. The experiment setup, especially for the baseline MVCNN is confusing, and the accuracy for the baseline seems problematic. According to Line 253, the classification is defined as a close-set classification problem that uses the class given the largest P(x|c) as the prediction, however, in line 309, the baseline is evaluated as a binary classification problem (whether belongs to category car or not). Also, for both 3-class classification and binary classification problem the accuracy of Chiar in Table 1 is lower than random guess (33.3% or 50%), which seems the baseline is totally not working. Thus, the experiment results seem not meaningful.\n2. The proposed method is incremental. But compared to weakness 1, this is not a significant weakness."
            },
            "questions": {
                "value": "1. For the baseline what is the renderer setup? What texture/illumination is used when rendering the images?\n2. Why do only equations on pages 4 and 8 have equation numbers?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the use of 3D diffusion models for zero-shot 3D object classification. This paper applies the diffusion classifier (Li et al., 2023a) on a point cloud diffusion model (Zeng et al., 2022a). The experiments show that the proposed method outperforms the baseline, which applies the diffusion classifier directly on multi-view renderings, and classifies based on voting."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The writing of the introduction looks fine."
            },
            "weaknesses": {
                "value": "1. The baseline is not well designed. The original diffusion classifier (Li et al., 2023a) is based on StableDiffusion, which was trained on natural images rather than point cloud rendering. It is expectable that directly applying the diffusion classifier on the point cloud rendering gives bad results.\n2. The main experiments are not thorough. The model is only tested on cars and chairs in ShapeNet. Seven years ago, PointNet [A] has already set a good benchmark for point cloud classification.\n3. The out-of-distribution experiments are barely reasonable. Both the in-distribution and out-of-distribution data are just chairs, though from different datasets, ShapeNet VS ModelNet.\n4. Considering the accuracy of classifying chairs is less than 50%, it is not proper to describe the model as \"accurate\" in multiple places in the paper, such as line 190, 433, 485, and 501.\n5. This paper contains useless paragraphs. For example, line 440-443, it says increasing the image size and number of views can slow down the processing time of the multi-view classifider, which is too obvious.\n6. The writing is confusing. In the introduction, it says MVDC is just a baseline and DC3DO is the proposed model. However, the whole ablation study is about how the input image size affects the performance and inference time of MVDC.\n7. Classifying each object takes approximately 20 seconds.\n\n[A] Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\", CVPR 2017."
            },
            "questions": {
                "value": "What if the multi-view diffusion classifier is fine-tuned on point cloud rendering? Will it significantly change the performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}