{
    "id": "DhHIw9Nbl1",
    "title": "Decoupling Layout from Glyph in Online Chinese Handwriting Generation",
    "abstract": "Text plays a crucial role in the transmission of human civilization, and teaching machines to generate online handwritten text in various styles presents an interesting and significant challenge. However, most prior work has concentrated on generating individual Chinese fonts, leaving complete text line generation largely unexplored. In this paper, we identify that text lines can naturally be divided into two components: layout and glyphs. Based on this division, we designed a text line layout generator coupled with a diffusion-based stylized font synthesizer to address this challenge hierarchically. More concretely, the layout generator performs in-context-like learning based on the text content and the provided style references to generate positions for each glyph autoregressively. Meanwhile, the font synthesizer which consists of a character embedding dictionary, a multi-scale calligraphy style encoder and a 1D U-Net based diffusion denoiser will generate each font on its position while imitating the calligraphy style extracted from the given style references. Qualitative and quantitative experiments on the CASIA-OLHWDB demonstrate that our method is capable of generating structurally correct and indistinguishable imitation samples.",
    "keywords": [
        "Online handwriting generation; Layout generation; Calligraphy imitation; Conditional diffusion Model"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "A novel method for Online Chinese Text Line genration.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=DhHIw9Nbl1",
    "pdf_link": "https://openreview.net/pdf?id=DhHIw9Nbl1",
    "comments": [
        {
            "comment": {
                "value": "We truly appreciate the positive feedback and recognition of our work\u2019s novelty, contribution and foundation\uff01In the following, we provide detailed responses to the queries one by one:\n\n---\n\n>Comment1\uff1aDoes text line style only manifest in the relative positions and sizes of individual characters? The reasonableness of the indepent assumption and explain whether the decoupling might limit the method's ability in style learning.\n\n**Answer**: \nThank you for raising such a valuable and thought-provoking question. This issue is indeed worth exploring further and may provides important insights for future improvements to our method.\n\n+ On the manifestation of text line style: We agree that the entire text line writing style is difficult to be fully captured with disentangled styles. However, we believe that the calligraphy style of individual characters, as well as their relative positions and relationships, form the most intuitive and crucial components of the entire style. In fact, these factors are sufficient to describe **the vast majority** of handwriting styles, making them central to our approach.\n\n+ On the reasonableness of the independence assumption: Our independence assumption is based on extensive observations of writing habits and visualizations from the dataset. We believe this assumption holds in most practical scenarios. This is ultimately an empirical question, and the validity of our assumption can be partially supported by the subjective satisfaction observed in the user studies of synthesized samples.\n\n+ On the decoupling and potential limitations: We acknowledge that decoupling the writing process does introduce some limitations. The most powerful solution may indeed lie in end-to-end manner. However, training a high-quality, end-to-end Chinese text line generation model remains a challenging task. As such, our current approach represents a trade-off between simplicity and performance.\n\n>Comment2\uff1aAbout some figure issues.\n\n**Answer**\uff1aThank you for your helpful suggestion and appreciate your attention to these details, and we will make these revisions in the revised version of the paper.\n\n>Question1&2\uff1a1. If the generated bounding box have different shapes with the generated characters, how should this be handled? 2. Why not jointly train the two models end-to-end instead of training them separately?\n\n**Answer**\uff1aThe two issues are interrelated, so I will address them together:\n+  Referring to Appendix 2.1, in the data preprocessing stage, we normalize the overall height of text lines to 1, which results in **significant variance in the actual size of each character**. For instance, in lines with horizontal writing, character heights are close to 1, but in lines with certain tilted writing angles, character heights may be as low as 0.3. As stated in Appendix 2.3 (training details): \u201dIn practical implementation, we found that without normalizing the size of the characters, the model's ability to learn the structural information of the characters would be compromised, leading to consistent errors in the generated structures. Therefore, during the training of the character generator, each character is normalized to the same size and learned independently.\u201c\n+  As described above, the character generator directly produces characters with normalized size. We employed a simple method of scaling the xy-coordinates to fit the bounding box output by the layout generator. Since the layout generator takes into account the types of characters, the bounding boxes it generates are reasonable. Consequently, we observed that this scaling does not significantly affect the shape or aspect ratio of the characters.\n\n>Question3: Whether the method can be applied to other languages?\n\n**Answer**\uff1aDue to the decoupling of layout and glyph properties, our method is especially well-suited for language systems in which characters are relatively independent, such as Chinese, Japanese, Korean, or even mathematical formulas.\n\n>Question4:   What does 'L', 'sequence' represent in line 285?\n\n**Answer**\uff1aRecalling section3.1, our data consists of online **sequential data**. For example, if there are 1000 trajectory points, the raw data dimension would be $\\mathbb{R}^{(1000,3)}$. Our network consist of 1D convolutional layers, for example, after passing through a convolutional layer with a stride of 2 and a kernel num of  D, the feature dimension would be reduced to $\\mathbb{R}^{(500,D)}$.  L represents the length of the feature sequence, which is 500 in this case.\n\n>Question5: In Line 230, is the ground truth the same as the reference input in Figure 3\uff1f\n\n**Answer**\uff1aYes, we use the **teacher-forcing** technique during training, where for each text line, the bounding boxes of the first i-1 characters are used as the prefix (reference) to predict the bounding box of the i-th character.\n\n---\nThank you  again for your insightful suggestions to improve our paper! We hope that our response adequately addresses your concerns."
            }
        },
        {
            "comment": {
                "value": "Thank you for the thoughtful and positive feedback!  We greatly appreciate for the recognition of the innovative aspects of our approach and the thorough evaluation of our model's effectiveness. In the following, we provide detailed responses to the reviewer\u2019s queries one by one:\n\n---\n\n>Comment1: Missing qualitative comparisons with prior methods to prove the advantages in style fidelity and layout accuracy.\n\n**Answer**:  This is a valuable suggestion.\n+ For font generation: we will supplement it with a qualitative comparison of the calligraphy style imitation of individual fonts with existing methods. \n+ When it comes to the full text line generation, as far as I know, we are **the first to complete the generation of handwritten Chinese text lines and the layout**. The only work that considers layout to some extent is in the field of text line recognition, as stated in Section 4.3.1. They model the layout of text lines via Gaussian distribution in a model-free manner. We have reproduced this previous method and demonstrate the effectiveness and necessity of our layout generation approach in Sections 4.3 and 4.4. In particular, we visually demonstrate in Figure 7 that overly simplistic model-free methods fail to generate layouts with distinct personal characteristics, making them easily recognizable at a glance.\n\n>Comment2:  The contributions over previous approaches could be articulated more clearly, especially regarding the effectiveness of the layout-glyph separation. \n\n**Answer**:  Thank you for your suggestion! Here, I will provide more details on the motivation behind layout-glyph separation: \nMost existing related work focuses only on generating individual characters. However, when extending from single characters to text lines, a key challenge lies in **how to represent the content information of the text line**. In the framework of our 1D U-Net character generator, we conducted end-to-end string generation experiments by concatenating the embeddings of individual characters to form the embedding of a text line. However, without further improvements, we found that the model was capable of generating short sequences but **encountered difficulties with longer sequences**. We attribute this issue to the complexity of training a single diffusion model to simultaneously learn both the structure of the characters and their relative positions. To reduce the learning complexity of the diffusion model, we decomposed the full probabilistic model and decoupled the layout component from the glyphs.\n\nWe will strive to present this aspect in a clearer and more detailed manner.\n\n\n>Comment3: The organization could be refined for readability.\n\n**Answer**:  Thank you for pointing out the writing issues. We will carefully revise and supplement the content based on your feedback to improve the readability and quality of our paper.\n\n>Question1:  Could more details be provided on how the layout-glyph separation specifically enhances performance in comparison to prior models?\n\n**Answer**:  This is an important issue in our approach, and I believe the discussion in Comment 1 and 2 regarding the motivation for layout and the comparison with existing model-free methods should address your questions. We will make every effort to clarify this in more detail in the revised version.\n\n>Question2:  Would additional experiments on style consistency across diverse text lines clarify the benefits of this approach?\n\n**Answer**: This suggestion is highly insightful! We have **improved the subjective experiments** in Section 4.4 considering this factor. Specifically, we now construct each test sample by combining a real handwritten text line from a particular author with **more than one** synthetic text lines. The participants are tasked with determining whether the lines were written by the same person. If there are inconsistencies in style between the synthetic sample and the real sample, or between different synthetic lines, the testers are likely to notice. We believe this improvement makes our experiment more complete. \n\n>Question3:  Could this method can be adapted to non-Chinese scripts or connected handwriting styles?\n\n**Answer**:  \n+ Our method is particularly suited for language systems where characters are relatively independent, such as Chinese, Japanese, Korean or even mathematic formula. \n+ As mentioned in Section 5, the main limitation of our approach lies in its difficulty in replicating writing styles or symbol systems where characters are connected by more intricate strokes or ligatures. \n\nHow to extend our approach to a broader range of handwriting data and overcome the current limitations, we leave these challenges as directions for future work.\n\n---\nThank you again for your valuable suggestions for improving our paper\uff01I hope our response can effectively addresse your concerns."
            }
        },
        {
            "comment": {
                "value": "We are grateful for the positive feedback and valuable questions!  We are truly grateful that the reviewer acknowledges the novelty, clarity, and flexibility of our proposed method. In the following, we provide detailed responses to the reviewer\u2019s queries one by one:\n\n---\n\n>Comment1:  Consideration about the model's complexity, training and inference efficiency.\n\n**Answer**:  This is a very important consideration, in this response, we will first clarify more about the motivation behind decoupling and then provide a detailed analysis of the efficiency aspects, particularly in relation to training and sampling.\n+ Motivation: We actually have also experimented based on our 1D U-Net generator to generate strings end-to-end. However, without further improvements, we found that the model can generate short sequences (e.g., two to five consecutive characters) but encounters difficulties with longer sequences. We attribute this issue to the complexity of having a single diffusion model simultaneously learn both the structure of the characters and their relative positions. To **reduce the learning complexity** of the diffusion model, we decompose the full probabilistic model and decouple the layout component from glyphs.\n+ Training and inference efficiency: 1) During the training phase, as described, the diffusion model only needs to learn the generation of individual characters, while the layout generator is responsible for planning the size and position of each character. This effectively reduces the complexity of training diffusion model.   2) In the sampling phase, since the generation processes of the two components are decoupled, as shown in Figure 3, **they can be fully parallelized**. The character generator can simultaneously generate all characters in a string within a batch, while the layout generator has already planned their positions. Additionally, as detailed in the appendix, the task is not computationally intensive, therfore our layout generator is lightweight (a 2-layer LSTM with a hidden size of 128).\n\n>Comment2:  Analyze the application scenarios for this task.\n\n**Answer**:  We currently have three considerations for potential application directions:\n+ We can provide **personalized writing services**. As is widely known, Chinese comprises thousands of commonly used characters. Users can submit a short passage (e.g., a dozen characters) of any content as a stylistic reference sample. We can then mimic their writing habits to generate handwritten samples of any length and content.\n+ It can be used **in the field of education**. Since the online data we generate includes dynamic information about the writing process, it can teach the stroke structure and order of different Chinese characters.\n+ Used for **data augmentation**: In today's Chinese text recognition field, the training data available is extremely limited (commonly only CASIA OLHWDB). We have made initial progress in this area. We use all real-world data (about 60,000 text lines) as training data, train the text line recognizer using LSTM+CTC Loss, achieving 85.5 AR 85.7 CR on the Icdar2013 test set. After adding 25,000 synthetic samples, we can achieve 88.3 AR 88.7 CR. Related experiments are still ongoing.\n\nOne advantage of our approach is that the generated data inherently includes strong positional labels for characters, which makes it suitable for data augmentation in recognition tasks that **require strongly labeled data** for training, such as character segmentation.  \n\n\n>Comment3:  Limitations in handling certain calligraphic styles.\n\n**Answer**:  The hierarchical generation method do have a weakness in not being able to generate inter-character connections. A potential solution is to make a trade-off by training an end-to-end generation model for a limited number of characters, and then combining it with the layout generation model. We will strive to make up for the shortcomings of our methods in our future work.\n\n---\nHope my response effectively addresses your concerns, if you have any remaining questions or need further information about our study, please feel free to let us know!"
            }
        },
        {
            "comment": {
                "value": "> Comment 3:  Section 4.3.2 lacks quantitative experiments.\n\n**Answer**: Actually, our calligraphy classifier **can also achieves a classification accuracy of 91%** for the entire generated text line. The reason for this is not explicitly included in the paper is that, in Chinese, calligraphy style can be predominantly reflected at the level of individual characters. Since our method generates each character independently, the quantitative evaluation of calligraphy style of the entire line **largely overlaps with** the character-level experiments presented in Section 4.2.\n\n> Comment 4:  The generated layouts show significant absences in Figure 7. \n\n**Answer**: Recalling that our layout generation method requires a few characters bounding boxes as a prefix. In Figure 7, we use the first ten characters as the prefix, so the bounding boxes for these characters are the same as the real ones rather than being missing.\n\n> Comment 5:  It is recommended to compare the proposed method with style transfer-based approaches in Table 3.\n\n**Answer**:  Thanks for your insightful suggestion. We conducted a supplementary experiment for Table 3. by combining the layout generation module with the SDT method\uff1a\n|   | AR   | CR   |\n| ------- | ------- | ------- |\n| In-context SDT | 0.871  | 0.868 |\n\nAs mentioned before, our method consists of two parts: layout generation and character generation. The hierarchical framework makes our approach highly flexible. In the character generation component, we can use either a data-driven or style transfer approach, which is completely **decoupled from the layout generation part**. Thus, we believe that the comparison between these methods is also largely overlaps with the experiments in Section 4.2.  Therefore, in the text line generation experiments, we primarily focus more on evaluating the **effectiveness of the layout generator**, via both quantitative evaluation through binary geometric features and qualitative evaluation through visualization.\n\n> Comment 6: About the applicability and what will happen if some simple layout extraction methods are used to extract the pseudo-layouts of style references.\n\n**Answer**:  1) For customized handwritten text generation, the user needs to provide a few reference characters. In practical applications, we only require the user to write a small piece of text line (e.g 10 characters). The layout generator will mimic the layout characteristics (e.g., font size, letter spacing) of these reference characters when generating the layout for subsequent characters. Additionally, these 10 reference characters will serve as style references for the character generation model.\n2\uff09Performance of simple layout style extraction methods tends to be **overly dependent on** carefully designed features, such as the binary geometric features I used in Table 2. In my own experiments, I found that model-free approaches that are too simplistic often generate layouts with noticeable differences compared to real samples, such as failing to properly handle the relative positions of punctuation marks and text. Furthermore, these methods exhibit poor generalization and are **only limited to text line generation**, whereas model-based approaches can be transferred to other even 2-Dimension handwritten data, such as handwritten math equations.\n\n> Comment 7:  Few generated visual results and lacks visual comparisons with the baseline.\n\n**Answer**: Thank you for your suggestion. We conduct visulization and subjective experiments in Figure 1,8,9  and we will provide more additional visual results as well as visual comparisons with previous font generation methods in the revised version to make our paper more convincing. However, in the domain of text line generation, this task remains largely unexplored, and as such, there is a lack of established baselines. Our approach represents a novel attempt at addressing this task.\n\n---\nWe sincerely appreciate your detailed and thoughtful feedback on our manuscript. We have carefully addressed each of your comments and have made the necessary revisions and additions in the official version of the manuscript.  We hope that our responces meet your expectations and would be grateful if you could consider revising the rating in light of the improvements made. We welcome any further questions or discussions you may have, and we will be happy to provide more elaborate responses as needed\uff01"
            }
        },
        {
            "title": {
                "value": "Response to Concerns Regarding the Novelty and the Effectiveness of the Proposed Method."
            },
            "comment": {
                "value": "Thank you very much for your comments and questions, which are of great significance for us to improve our article and work. Next, I will respond in detail.\n\n### **Regarding the novelty and contribution** :\nFirstly, we would like to emphasize that the primary novelty of our work lies in the proposal of a hierarchical approach to **solving the challenging task of handwritten Chinese text line generation**, a problem that has been **rarely explored**. This decoupling strategy can also be effectively extended to other complex handwriting generation tasks. Our contributions within this framework are twofold: 1) A novel method for explicit layout modeling, and 2) A purely data-driven character generation approach based on a 1D U-Net. \n\n\nFor 1)\uff1a I would like to highlight that we cleverly adapt the in-context generation paradigm from **next-token prediction** in LLM to the task of generating layouts. This simple yet effective approach forms the core of our method. To the best of our knowledge, our work is one of the earliest explorations into handwritten Chinese text line generation, and it is the **first to explicitly generate the layout for text line**. Additionally, an extra benefit of our approach is that the generated data naturally contains strong positional label of characters, which makes it highly convenient for data augmentation in tasks such as character segmentation and recognition.\n\nFor 2\uff09: We design a 1D convolutional network capable of extracting multi-scale features specifically for **online sequential data**. In contrast, previous approaches for sequential handwriting data typically use LSTM or Transformer models, which do not explicitly consider multi-scale features. Furthermore, our approach is purely data-driven, distinguishing it from the style transfer paradigm commonly used in the state-of-the-art methods. These two approaches are not mutually exclusive and can complement each other in different application scenarios.\n\nBelow, we address the reviewer\u2019s questions one by one:\n\n---\n\n### **Response to Specific Comments** :\n> Comment 1: About the novelty of the multi-scale style encoder and multi-scale contrastive loss.\n\n**Answer** : Thank you for pointing out the relevant literature. We will ensure that additional references are incorporated and elaborate more on the differences and complementarities between previous methods including [a],[b] and our own in the official version. It is important to note that the work referenced in [a] deals with offline handwritten data, specifically images. In contrast, all the data used in our work is online data, which is sequential in nature. Networks designed for processing **online handwritten data** typically **do not explicitly** model multi-scale features in the previous related work. In this paper, we introduce a model based on 1D-convolutional networks, marking the first instance of explicitly modeling multi-scale features in online Chinese handwritten data generation field. Additionally, the contrastive loss function we design is tightly integrated with this multi-scale network to enhance its ability to distinguish calligraphy styles from different writers at different scales. While in paper[b], the proposed writer-wise and character-wise contrastive learning is applied **only at a single feature scale**. From this perspective, our contributions are not identical, but they could even **complement each other**. \n\n> Comment 2:  It is not clear : 1) How the prefix guide the generation in layout generator.  2) The modality of style reference data.  3) The task setting.\n\n**Answer** :  1) A more intuitive explanation can be drawn from the **next-token-prediction paradigm** in language models. When a partial sequence of text is input as a context, the subsequent generated content tends to be coherent with the prefix. Similarly, in our task, when the layout information for the first few characters is input as a context, the layout of subsequent characters is naturally consistent with the prefix. For example, if the initial layout exhibits a general skew, there is a higher probability that this characteristic will be maintained in the generated text, as we demonstrate in the experiment section (Figure 7).  This is what we call **\u201cin-context-like layout generation\u201d** .  2) As described in Section 3.1, all the data we used in this paper is online sequential data. Therefore, the novelty of our approach lies, to some extent, in its focus on designing a network specifically tailored for online handwritten data compared with previous work. 3) For fairness in comparison, we have kept the experimental setup consistent with previous methods, specifically using a few-shot setting, where 10 reference characters are used for style reference.\n\n\n[a] Wang H, Wang Y, Wei H. Affganwriting: a handwriting image generation method based on multi-feature fusion, ICDAR, 2023.\n\n[b] Dai G, Zhang Y, et al. Disentangling writer and character styles for handwriting generation, CVPR, 2023."
            }
        },
        {
            "summary": {
                "value": "The paper introduces a novel approach for generating online handwritten Chinese text with specific styles. The authors naturally divide a text line into two components: layout and glyphs, and design a text line layout generator coupled with a diffusion-based stylized font synthesizer to address this challenge hierarchically. The layout generator autoregressively generates the positions for each glyph based on text content and provided style references, while the font synthesizer generates each font at its position while imitating the calligraphy style extracted from the given style references. Experiments on the CASIAOLHWDB demonstrate the method's capability to generate structurally correct and indistinguishable imitation samples."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The study proposes a hierarchical method to address the under-explored task of online handwritten Chinese text line generation.\n2. By decoupling layout generation from glyph generation, the method offers more flexibility in handling the generation of text lines, which is particularly useful when dealing with complex Chinese characters.\n3.  The experiments conducted on the CASIA-OLHWDB database indicate high performance in imitation sample generation, demonstrating the effectiveness of the method."
            },
            "weaknesses": {
                "value": "1. While decoupling layout and glyph generation increases flexibility, it may also add to the model's complexity, potentially affecting training and inference efficiency.\n2. Are there any application scenarios for this task? The author could analyze its practicality.\n3. The paper mentions difficulties in imitating styles with extensive cursive connections between characters due to the independent generation of each character, indicating potential limitations in handling certain calligraphic styles."
            },
            "questions": {
                "value": "Please see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper focuses on the generation of online Chinese handwriting text lines. It proposes a hierarchical approach that decouples layout generation from glyph generation. The text line layout generator arranges character positions based on text content and writing style references, while the font synthesizer generates characters with specific styles. The contributions include a novel layout generator, a 1D U-Net network for font generation, and a multi-scale style encoder. Experiments demonstrate the effectiveness of the method in generating structurally correct and stylistically similar samples."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) The hierarchical decomposition into layout and glyph generation is an innovative approach, particularly suited for complex scripts like Chinese. This framework successfully addresses challenges specific to the language, such as the diversity of character structures.\n\n(2) The model is thoroughly tested on both character and line generation, with metrics tailored to layout and stylistic fidelity. The model's success across multiple metrics shows a well-rounded, effective design.\n\n(3) Despite the technical depth, the paper provides a good level of explanation for each module, with helpful visualizations that demonstrate layout and glyph generation separately.\n\n(4) The method has potential applications in handwriting synthesis, digital personalization, and document augmentation, contributing a valuable approach for future research in multilingual handwriting generation."
            },
            "weaknesses": {
                "value": "(1) Missing qualitative comparisons with prior methods, limiting insights into this model\u2019s advantages in style fidelity and layout accuracy.\n\n(2) The contributions over previous approaches could be articulated more clearly, especially regarding the effectiveness of the layout-glyph separation.\n\n(3) The organization could be refined for readability, as the methods section contains complex explanations that could benefit from clearer structuring."
            },
            "questions": {
                "value": "(1) Could more details be provided on how the layout-glyph separation specifically enhances performance in comparison to prior models?\n\n(2) Would additional experiments on style consistency across diverse text lines clarify the benefits of this approach?\n\n(3) Could this method can be adapted to non-Chinese scripts or connected handwriting styles?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper focuses on the generation of online Chinese handwritten text lines. The core of this method lies in decomposing text line generation into layout generation and character generation, and fill characters into the generated layouts to form complete text lines. Experiments evaluate the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) This paper proposes a hierarchical online Chinese handwritten text line generation method. The proposed method utilizes a layout generator and a font synthesizer to produce the layouts and characters independently, then arranges the characters within the layouts to create complete text lines.\n\n2) The proposed method achieves the best performance in purely data-driven font generation task."
            },
            "weaknesses": {
                "value": "1) The multi-scale style encoder is not a new design in handwriting generation area, as a similar idea has been proposed in [a]. Besides, the proposed style contrastive learning loss is somewhat similar to the style learning loss in [b].\n\n2) The method description is not clear: (1) In lines 233-237, it is mentioned that style reference samples are used as context prefixes, but how they guide the subsequent layout generation is unclear. (2) The paper does not specify the modality of the style references used, online data, or offline images. (3) The paper does not specify the number of style reference samples used, one-shot or few-shot.\n\n3) Section 4.3.2 lacks quantitative experiments in terms of calligraphy styles, raising doubts about whether the proposed Multi-Scale Style Encoder can accurately extract calligraphy styles from entire text lines.\n\n4) In the 'Conditional' row of Figure 7, the generated layouts (red boxes) show significant absences at the beginning of the text line, which raises concerns about the effectiveness of the layout generator.\n\n5) It is recommended to compare the proposed method with style transfer-based approaches, as it can be relatively straightforward to extend this method to a style transfer setting by replacing character embedding with a CNN-based content encoder.\n\n6) The layout generator requires real layouts of style references, which is not directly available in the application, does this limitation affect its applicability? If some simple layout extraction methods are used to extract the pseudo-layouts of style references, what impact would this have on generation performance?\n\n7) The paper provides very few generated visual results and lacks visual comparisons with the baseline.\n\n[a] Wang H, Wang Y, Wei H. Affganwriting: a handwriting image generation method based on multi-feature fusion, ICDAR, 2023.\n\n[b] Dai G, Zhang Y, Wang Q, et al. Disentangling writer and character styles for handwriting generation, CVPR, 2023."
            },
            "questions": {
                "value": "My main concerns are the novelty of the proposed multi-scale style encoder and style contrastive learning loss, and the effectiveness of the proposed layout generator. For details, please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the task of generating online handwritten Chinese text lines condition on the content and style. It identifies that text lines can be divided into two components: layout and characters. The authors propose a hierarchical approach that includes a text line layout generator and a stylized font synthesizer. The layout generator uses in-context-like learning to determine the positions of each character, while the font synthesizer generates characters that imitate the calligraphic style of the provided references. The method is evaluated using the CASIA-OLHWDB dataset, demonstrating its effectiveness in producing structurally correct and indistinguishable imitation samples."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1.While some work on English handwritten text line generation exists, as far as I know, no such work has been published for online Chinese text lines. Compared to English characters, Chinese characters have more complex structures and a larger number of categories, making English generation methods unsuitable for direct application to Chinese. This work proposes a method to address this task, representing a noticable contribution.\n\n2.The method decouples text line generation into two steps\u2014layout generation and character generation\u2014under a unified probabilistic framework, providing a good theoretical foundation and considerable novelty.\n\n3.The experimental section includes comprehensive comparative and visualization experiments for both layout generation and character generation, yielding convincing results.\n\n4.The paper is well-organized and clearly written."
            },
            "weaknesses": {
                "value": "1. The assumption that character generation is independent given their positions seems too strong. Does text line style only manifest in the relative positions and sizes of individual characters? I hope the authors can give discussion on the reasonableness of this assumption and explain whether it might limit the method's ability in style learning. \n\n2. It is better to add sub-figure index for figure 8 and 9. It seems each of figure 8 and 9 has three sub-figures, but now their boundaries are not clear. In Figure 7, it is also suggested to identify which one is the proposed method in the paper. Of course, this is not a big issue."
            },
            "questions": {
                "value": "1. If the bounding box generated by the layout model and the bounding box generated by the character model have different shapes, how should this be handled?\n\n2. Since the method can be described as a unified probability distribution according to Equation 1, why not jointly train the two models end-to-end instead of training them separately?\n\n3. The paper does not discuss whether the method can be applied to handwriting generation of other languages.\n\n4. in Line 285, what does L represent? Although the authors write this is the length of the feature sequence, it is not clear what does this sequence represent? \n\n5. In Line 230, is the ground truth the same as the reference input in Figure 3\uff1f"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}