{
    "id": "sl4hOq9wm9",
    "title": "Knowledge Augmentation: In-context or In-parameter?",
    "abstract": "Generative language models rely on knowledge augmentation to enhance their ability to complete a variety of tasks by incorporating relevant external information. The most common approach is in-context knowledge injection, where the relevant information is appended directly to the model\u2019s input. While straightforward and easy to implement, this approach is limited for complex reasoning tasks due to input length constraints and shallow integration of external and internal knowledge in language models. \nTo overcome these limitations, we introduce an in-parameter knowledge injection method, which temporarily embeds external knowledge into the model's parameters. By injecting knowledge in this way, the language models can access and reason over the information more flexibly, bringing enhanced performance on tasks requiring sophisticated reasoning. \nWe conduct deep explorations of both in-context and in-parameter knowledge injection, highlighting their respective advantages and limitations. Through comprehensive experiments across tasks of varying complexity, we demonstrate that in-parameter knowledge injection is particularly advantageous for complex tasks requiring deep reasoning, while in-context injection remains effective for simpler tasks where the answer can be directly extracted. Our findings provide practical guidance for selecting appropriate knowledge augmentation strategies based on the complexity of the task. \n\nWe have open-sourced all the code, data, and models in the following anonymous GitHub link: https://anonymous.4open.science/r/In-parameter-Knowledge-Injection/",
    "keywords": [
        "Representation Learning",
        "In-Parameter Knowledge Injection",
        "Parametric Knowledge Representation",
        "Large Language Models"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "This paper propose a novel in-parameter knowledge injection method and  compare both in-context and in-parameter knowledge injection method for generative language models across a wide range of tasks.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=sl4hOq9wm9",
    "pdf_link": "https://openreview.net/pdf?id=sl4hOq9wm9",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a method named In-Parameter Knowledge Injection to integrate external knowledge into the large language models. Different from the in-context learning methods that adopt natural language to represent external knowledge, the in-parameter method represents knowledge through parameters, thus avoiding length constraints and becoming more compatible with the foundation LLM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The experimental results show the effectiveness of In-Parameter Knowledge Injection method on 1B, 3B, and 8B LLMs. \n\nThe idea is novel. Embedding knowledge through model parameters will ideally represent how a LLM \u201cunderstand\u201d certain external knowledge."
            },
            "weaknesses": {
                "value": "1. As shown in Figure 3, knowledge can be effectively represented and understood through either natural language or parameters. So, which kind of knowledge should be integrated through parameters? More explorations and investigations are recommended here. \n\n2. The method demands additional pre-training or post-training costs. I suggest incorporating an additional baseline method where a copy of the LLM is adopted to represent the knowledge. The baseline will also demonstrate the contribution of knowledge encoding phrase.\n\n3. Will the In-Parameter Knowledge Injection method generalize to LLMs with a larger scale (e.g., Llama 3.1 70B Instruct, Llama 3.2 11B instruct, etc.)? It\u2019s unclear about the exact contribution of the method, since the model scale is relatively small."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper investigates two methods of knowledge augmentation in language models: in-context knowledge injection and in-parameter knowledge injection. In-context augmentation involves adding external information directly to the model\u2019s input prompts, while in-parameter augmentation temporarily embeds this knowledge into the model\u2019s parameters. Through a series of tasks with increasing complexity\u2014ranging from fact extraction to comparative and multi-step reasoning\u2014the study evaluates the effectiveness of both methods. The findings indicate that in-parameter injection performs better on complex reasoning tasks, whereas in-context methods are more effective for simpler fact extraction. The authors provide insights into the advantages of each approach based on task complexity and computational efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "\u2022 Systematic Comparison: The paper offers a clear and structured comparison between in-context and in-parameter knowledge injection methods, elucidating the trade-offs in different scenarios.\n\n\u2022 Experimental Design: The progression from simple to complex tasks effectively demonstrates how each method scales, offering insights into their applicability across various task demands."
            },
            "weaknesses": {
                "value": "\u2022 Limited Novelty: The in-parameter knowledge injection method is essentially LoRA with additionally synthetic augmentation. The paper does not sufficiently acknowledge this overlap or explain how its approach differs from or improves upon existing parameter-efficient fine-tuning methods.\n\n\u2022 Insufficient Differentiation from LoRA: Given the similarities to LoRA, the paper should have provided a detailed comparison, highlighting any unique contributions or advantages. \n\n\u2022 Scope of Evaluation: The experiments focus on a limited range of tasks. Expanding the evaluation to include more diverse or real-world applications could enhance the robustness and generalizability of the conclusions. \n\n\u2022 Lack of Theoretical Advancement: The paper does not offer new theoretical insights into knowledge augmentation or parameter adaptation in language models, limiting its contribution to an empirical comparison that may already be addressed in existing literature."
            },
            "questions": {
                "value": "1. How might in-parameter knowledge injection perform in tasks beyond fact-based reasoning, such as creative writing or dialogue generation?\n\n2. Can the authors elaborate on how their work differentiates from previous studies on knowledge augmentation and knowledge editing in language models?\n\n3. What challenges might arise when scaling in-parameter knowledge injection to larger models or datasets, and how could these be addressed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies different ways of injecting new knowledge into the LLMs. Specifically, it proposes a new way of first extracting QA pairs from contexts and then training the model with LORA using the QA pairs as a new in-parametric knowledge injection solution. Following that, this paper compares the proposed solution with the widely used in-context solution on different tasks. Experiment results show that on simpler tasks, the in-context solution is still stronger, but on more complex tasks that require complex reasoning of the updated knowledge, the proposed in-parameter solution might be helpful."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The proposed method is sound, and the introduction is clear.\n2. The experiment setting is comprehensive."
            },
            "weaknesses": {
                "value": "The proposed solution has several bottlenecks: (1) the quality of extracted QA pairs is crucial for the effectiveness of the knowledge injection. For example, the context might contain many details, and it is unlikely that the generated QA pairs could cover all of them, so the proposed solution will lose those details. (2) LORA is a way for efficient tuning. There is no guarantee that the model learns all the knowledge in the extracted QA pairs; (3) since LORA directly changes all the parameters, this might hurt the model's performance on other tasks."
            },
            "questions": {
                "value": "1. How will the proposed solution hurt the model's general performance?\n2. Can you present a more detailed analysis of the QA extraction quality? Especially when we do not have a strong external model, can we use the same model to do that, and how will that influence the final performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper discusses the differences in two kinds of ways to augment language models with external knowledge: in-context learning or in-parameter augmentation. The authors propose to use LoRA parameters tuned from QAs that are synthetically generated by language models to augment the models. Experiments on 1B-sized models show good performance on various knowledge-intensive tasks such as fact extraction and comparative reasoning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe topic is important and interesting. There is indeed a limitation with in-context fixed language-based knowledge. \n2.\tThe experiments are comprehensive, with an evaluation of various models and settings. A good number of details of the decisions and prompts are provided in the appendix. The test set suite is also good. All the tasks included are indeed relevant and require external knowledge.\n3.\tThis paper is well-written, the paragraphs and figures are clear and easy to follow."
            },
            "weaknesses": {
                "value": "1.\tMore work in the literature can be discussed in Section 2. The discussion on in-context/in-parameter knowledge injection can be improved with more details in the literature, e.g., a similar setting of parameter updates with knowledge updates is defined in the paper Fast Model Editing at Scale (Mitchell, et al., 2022). Also, much previous work on parameter-efficient fine-tuning (PEFT) is relevant but not discussed, e.g., Adapter.\n2.\tFrom my understanding of the paper, the LoRA weights are tuned from QAs from the whole knowledge base. If so, what is the difference between the proposed in-parameter method and LLM-based data augmentation? This seems to limit the novelty of the method part. Also, it may influence the fairness of comparing with in-context learning. How are the exemplars chosen? Given the current framework, it can be extended to a novel method if, for each test example, you consider different LoRA weights associated with different data points, groups, and external knowledge source K. This paper may provide further intuition along this direction: https://arxiv.org/pdf/2110.04366.\n3.\tIt is quite surprising to me that in-context learning yields such bad performance on comparative tasks. It is possible that the model sizes might limit the reasoning capability. It would be good if the authors could provide the ICL performance of larger models (e.g., 70/405B Llama) as a reference or extend the IP experiments on these models."
            },
            "questions": {
                "value": "1.\tWhat is the difference between in-parameter knowledge injection and knowledge editing?\n2.\tWhat is the difference between IP and LLM-based data augmentation + LoRA? If IP is not an online method where each test example is augmented with different LoRA weights?\n3.\tIn Section 3.3, the authors mention the comparison of the complexity. Is there any comparison of IC and IP on efficiency, e.g, with FLOPs or time?\n\n\nTypos:\n1.\tLine 50, no year in the citation; Line 516-517, wrong citation formats"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}