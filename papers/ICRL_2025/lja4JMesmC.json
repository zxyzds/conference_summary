{
    "id": "lja4JMesmC",
    "title": "From Generalist to Specialist: Adapting Vision Language Models via Task-Specific Visual Instruction Tuning",
    "abstract": "Large vision language models (VLMs) combine large language models with vision encoders, demonstrating promise across various tasks. However, they often underperform in task-specific applications due to domain gaps between pre-training and fine-tuning. We introduce VITask, a novel framework that enhances task-specific adaptability of VLMs by integrating task-specific models (TSMs). VITask employs three key strategies: exemplar prompting (EP), response distribution alignment (RDA), and contrastive response tuning (CRT) to improve the task-specific performance of VLMs by adjusting their response distributions. EP allows TSM features to guide VLMs, while RDA enables VLMs to adapt without TSMs during inference by learning from exemplar-prompted models. CRT further optimizes the ranking of correct image-response pairs, thereby reducing the risk of generating undesired responses. Experiments on 12 medical diagnosis datasets across 9 imaging modalities show that VITask outperforms both vanilla instruction-tuned VLMs and TSMs, showcasing its ability to integrate complementary features from both models effectively. Additionally, VITask offers practical advantages such as flexible TSM integration and robustness to incomplete instructions, making it a versatile and efficient solution for task-specific VLM tuning.",
    "keywords": [
        "Vison Language Models",
        "Task Specific Models",
        "Visual Instruction Tuning"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "We proposed a task-specific visual instruction framework to adapt VLMs for specific tasks with task-specific model-level performance.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=lja4JMesmC",
    "pdf_link": "https://openreview.net/pdf?id=lja4JMesmC",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a VITask framework that enhances the adaptability of Vision Language Models (VLMs) for specific tasks by integrating Task-Specific Models (TSMs). It employs strategies like guiding VLMs with TSM features, enabling adaptation without TSMs during inference, and optimizing the ranking of correct image-response pairs. Experiments on medical diagnosis datasets demonstrate that VITask outperforms standard VLMs and TSMs, providing flexible integration and robustness to incomplete instructions."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe overall writing is relatively smooth and easy to understand. \n2.\tThe paper has made a detailed design in the method of constructing the dataset. \n3.\tThe paper has conducted detailed experiments on existing medical datasets."
            },
            "weaknesses": {
                "value": "1.\tThe overall motivation is to finetune existing VLM for downstream tasks. After fine-tuning, the model can only be used for a specific task, which may hinder the original generalizability of VLM. The authors seem do not consider this issue.\n2.\tFrom the experiment, it can be observed EP is most useful, while other modules bring marginal improvements. Whether the other two modules are necessary requires to be further explored.\n3.\tLisa [1] also adopts similar prompt tuning techniques like EP, and what\u2019s the difference between these methods, and what is the technical advantage of EP?\n4.\tThe comparison lacks comprehensiveness, as numerous medical VLMs exist in the field.\n5.\tThe effectiveness of the proposed method is only demonstrated in the medical field, therefore the title is kind of over claimed. If the method is general, more experiments on other datasets are required.\n\n[1] Xin Lai, Zhuotao Tian, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, and Jiaya Jia. Lisa: Reasoning segmentation via large language model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9579\u20139589, 2024."
            },
            "questions": {
                "value": "See the comments"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a combination of strategies, exemplar prompting (EP), response distribution alignment (RDA), and contrastive response tuning (CRT), to adapt general-purpose generative VLMs for specialized medical classification tasks. Through experiments, the authors show that their method VITask , leveraging these three algorithmic components, can outperform task-specific models (TSMs), which are essentially fine-tuned ViTs, on a variety of medical classification tasks. In ablation experiments, the authors demonstrate that EP contributes the most performance boost while RDA and CRT are also complementary."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper states the problem it aims to solve clearly. The proposed method is validated on a wide range of medical datasets."
            },
            "weaknesses": {
                "value": "The biggest issue of the paper is the lack of depth. While it ablates the impact of each of the algorithmic components, they authors spent little effort trying to understand why each of them work and to compare them against existing methods.\n\n1. It\u2019s not clear what makes EP successful. \n    - I strongly suspect the performance gain is mostly due to the fine-tuning of the connector module. The critical experiment of simply having both the connector and the LLM (LoRA params) trainable is missing.\n    - Additionally, an experiment comparing EP with prefixing tuning [1] will tell whether it\u2019s necessary to condition the prefix (additional tokens to the LLM\u2019s embedding space) on the image at all to get good performance. Essentially, I need to see experiments showing me EP > fine-tuning the original VLM\u2019s connector + prefix tuning to be convinced it\u2019s novel. \n    - I also don\u2019t buy the claim that fine-tuning the Vision model in VLM will distort vision language alignment at all. If fine-tuning the Vision model is harmful, wouldn\u2019t the trained LoRA weights be more harmful as well? A controlled experiment where the vision encode is also trained is needed. I am confident this will make EP perform even better. \n    - Finally, other works with the same core methodology should be discussed. For example, Graph Neural Prompting [2] builds a knowledge graph based on the prompt and multiple choice candidates and generates a conditional prefix to prompt the LLM. I think the idea is extremely similar to EP. \n2. Regarding RDA: this is essentially a fancy way of saying knowledge distillation but no relevant papers are cited. Regarding implementation, the author mentions gradient detachment. If I understood it correctly, this just means the TSM, or the \u201cteacher\u201d, is not trained while the goal is to train the student. Shouldn\u2019t this be the default setting anyway? \n3. Contrastive Response Tuning: as part of the core methodology, the paper should compare its effectiveness against existing methods, such as contrastive decoding [3][4]. \n\nIssues mentioned above should be addressed. Otherwise this work should aim for a more application-oriented venue. \n\nThe notations issues. \n\n- In equations (1), (2), (3), (5), (6), why is there a min() operator on the left hand side? The author seems to mix it up with the argmin notation. I think the author should remove the min() and avoid argmin() like notation since not all parameters are trained. \n\nMinor grammar issues\n- For example, Takeaway #1: TSM features can prompts (prompt) VLMs to generate desired responses.\n\nReferences:\n\n[1] Li, Xiang Lisa, and Percy Liang. \"Prefix-Tuning: Optimizing Continuous Prompts for Generation.\"\u00a0Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.\n[2] Tian, Yijun, et al. \"Graph neural prompting with large language models.\"\u00a0Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 17. 2024.\n[3] Leng, Sicong, et al. \"Mitigating object hallucinations in large vision-language models through visual contrastive decoding.\"\u00a0Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.\n[4] Favero, Alessandro, et al. \"Multi-modal hallucination control by visual information grounding.\"\u00a0Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024."
            },
            "questions": {
                "value": "1. For TSM, does it use the same encoder as the one used by the target VLM? How about the connector?\n2. What parameters are tuned in RDA exactly? I also don\u2019t get how is it really different from tuning from the ground truth labels, which are used anyway. In other words, isn\u2019t p_theta(response | exemplar) just an approximation of the ground truth label? In fact, this pseudo-label is worse since it can be wrong? Also for classification tasks, if the model only decodes a single label, does it really matter to learn the whole distribution instead of an one-hot label? If we look at table 2, RDA indeed improves upon vanilla, but what does vanilla mean? Is it just the base VLM that\u2019s not fine-tuned at all for those medical tasks? I need to see an experiment where you just fine-tune with the ground truth labels in the training set to really understand the role of RDA. Now I tend to think you can totally get rid of it. \n3. For both RDA and CRT, what did you do to deal with the situation when the label consists of more than 1 token due to tokenization?\n4. I want to know the implementation detail of how you extract the answer from the generated output from the VLM. Apparently since it\u2019s free-form generation the format might be slightly off. Are there any instances where the model outputs a semantically equivalent label that\u2019s not an exact match? What\u2019s the percentage of such instances before and after your fine-tuning?\n5. I wonder if the authors can explain more on the motivation of adapting the VLM for classification tasks. I think this task is only meaningful if either 1) the original generative capabilities can be preserved, or 2) the fine-tuned VLM is actually better than SoTA vision models, otherwise we might as well use a predictive classifier that\u2019s smaller and easier to fine-tune. Thus, I think the authors should either 1) present evaluations on non-medical tasks to show there\u2019s very little degradation, or 2) compare against the SoTA vision model, which is probably not a ViT pretrained in 2020."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Although VLMs have excelled in understanding generic images, they fall apart for out-of-distribution task-specific applications. This paper claims that this could be due to the lack of comprehensive image representation and indirect tuning objective VLMs used to optimize. This paper proposes a framework that leverages representation from task-specific models as complementary information and optimizes the VLMs. Additionally, it explores how the inference can be done without task-specific models using two proposed methods RDA and CRT.\nConsidering the high costs of fine-tuning and inference with LLMs, along with the minimal performance gains, why should a user prefer using VITask over enhancing TSMs?\n\nThe paper is well-written but could be improved for better readability."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The motivation of the paper is clear and the authors provided adequate evidence to show why the proposed method can be useful in task-specific applications.\n\nThe task-specific instruction tuning section is quite interesting and the papers validate how each proposed component improves the performance of VLMs.\n\nThe paper has a detailed section providing intuition and empirical evidence to support the claims."
            },
            "weaknesses": {
                "value": "As mentioned in the limitations section, exploration of the method is highly limited to classification tasks. Additional tasks would be more interesting using an LLM, which has rich information embeddings.\n\nGiven the high computation budget and a marginal improvement in performance compared to TSMs, I would try to improve the TSMs which are cost-effective for training and inference. ( I consider the results as marginal improvement, the considered dataset is comparably simpler than the actual applications.) For example, optimize the model architecture, focused hyperparameter selection, Select and Fuse futures, and an ensemble of smaller models.\n\nThe paper is comprised of a lot of detailed text, which also seems to be a weakness of the paper. Authors could provide more visualization to interpret the results and behaviour of each module. Overall, the interpretation of results could be improved for better readability. You may provide more visualization to explain the benefits of the proposed modules or interpretation analysis how the proposed module benefits  compared to TSMs or vanilla VLMs.\n\nThe paper presents a few concerns :\n\n1. The figure related to the RDA analysis referenced in Lines 264-266 is missing. As it stands, the current figure appears to be a bar chart of the EP results. Could please provide the figure?\n\n2. The authors should consider using different formatting styles for equations (3-6). When the terms in the equations are presented in the same style as the surrounding text, it can be confusing (Line 280). Differentiating the formatting will enhance readability.\n\n3. There are spelling errors in Figure 1 (d).\n\n4. The word \"often\" is repeated in Line 041."
            },
            "questions": {
                "value": "1. Authors should explain why using Vision-Language Models (VLMs) with a high computational budget is more beneficial than improving Task-Specific Models (TSMs). I would recommend an empirical analysis of the cost and performance benefits of VITask versus TSMs to.\n\n2. TSMs provide better task-specific representations than general vision encoders. Could you clarify why the results decline significantly when embeddings are completely replaced by task-specific representations? Did you utilize the CLS token from Vision Transformers (ViT) or the entire patch embeddings?\n\n3. Why do we need to optimize Stage 2 with the same loss functions used in Stage 1 without scaling them? After optimizing the Stage 1 model to minimize the Stage 1 loss, using it in Stage 2 could potentially harm the fine-tuning process. Have you considered applying a scale to the Stage 1 loss functions?\n\n4. In line 423, it is mentioned that a novel vision-language connector is introduced in the paper, but no details about this connector are provided in the text. Could you please include more information about it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper first investigate why fine-tuned (VLMs) often lag behind TSMs in performance (use image classification as a case study) and then propose a new framework that can enhance the performance of VLMs on task-specific applications. They conduct it through integrating task-specific models (TSM) into VLMs in fine-tuning with 3 strategies, exemplar prompting (EP), response distribution alignment (RDA), and contrastive response tuning (CRT). EP allow TSM features to guide VLMs while RDA enables VLMs to adapt without TSMs during inference by learning from exemplar-prompted models. CRT further optimizes the ranking of correct image-response pairs by maximizing likelihood of correct image-response pairs while minimizing that of  incorrect pairs. They conduct two-stages training. The first stage is fine-tuning VLMs using vanilla visual instruction tuning in conjunction with EP and RDA. The second stage is fine-tuning VLMs using all strategies. The experiments focus on classification tasks on medical domain."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The idea and strategies used to combine TSMs to VLMs to boost performance of VLMs (without using TSMs to VLMs on inference stage based on RDA mechanism) on task-specific applications are interesting. It helps to remove the limitation of VLMs when fine-tuning on task-specific applications.\n- The performance of experiments on medical image classification are good.\n- The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "- The current experiment results are good, but the number of experiments and baseline models are insufficient, only 4 baseline models (including task-specific model). Can you compare your method with more other baselines, including some works you have mentioned in related works section which attempt to integrate VLMs with task-specific models and more VLMs such as InstructBLIP, BLIP-2, and Qwen-VL-Chat? \n- Because you did classification experiments on medical domain and there are currently many VLMs pre-trained on medical datasets, why you chose to test on the particular VLMs used in the study. In my opinion, it is important to test this approach on more VLMs which were pre-trained on medical datasets such as LLaVA-Med, Biomed GPT, etc. to make sure applying this method on these VLMs give significant improvement results.\n- I am concerned about the time used to fine-tune a VLM using your method, because you need to fine-tune a task-specific model on the dataset first before combining it with VLMs and then fine-tune the VLMs. Can you give me more detail about the resource you use to fine-tune VLMs and the total time for the training process to finish using your method and vanilla methods (comparisons between your method and baseline approaches) ?"
            },
            "questions": {
                "value": "As you have mentioned in the paper, testing this approach only on medical domain is not enough to make sure your method is good. I hope that you can give more experiment results on other non-medical domains such as natural images."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}