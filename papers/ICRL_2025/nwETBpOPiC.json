{
    "id": "nwETBpOPiC",
    "title": "Overcoming label shift in targeted federated learning",
    "abstract": "Federated learning enables multiple actors to collaboratively train models without sharing private data. This unlocks the potential for scaling machine learning to diverse applications. Existing algorithms for this task are well-justified when clients and the intended target domain share the same distribution of features and labels, but this assumption is often violated in real-world scenarios. One common violation is label shift, where the label distributions differ across clients or between clients and the target domain, which can significantly degrade model performance. To address this problem, we propose FedPALS, a novel model aggregation scheme that adapts to label shifts by leveraging knowledge of the target label distribution at the central server. Our approach ensures unbiased updates under stochastic gradient descent, ensuring robust generalization across clients with diverse, label-shifted data. Extensive experiments on image classification demonstrate that FedPALS consistently outperforms standard baselines by aligning model aggregation with the target domain. Our findings reveal that conventional federated learning methods suffer severely in cases of extreme client sparsity, highlighting the critical need for target-aware aggregation. FedPALS offers a principled and practical solution to mitigate label distribution mismatch, ensuring models trained in federated settings can generalize effectively to label-shifted target domains.",
    "keywords": [
        "Federated learning",
        "Label shift",
        "distribution shift",
        "non-iid"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=nwETBpOPiC",
    "pdf_link": "https://openreview.net/pdf?id=nwETBpOPiC",
    "comments": [
        {
            "summary": {
                "value": "This work addresses the realistic scenario of generating a global model for an arbitrary target distribution that may differ from the distribution of the aggregated client training datasets. To tackle this challenge, the authors assume that the central server has knowledge of the different label distributions of the clients and target domains, while this information remains unknown to the clients. They introduce FedPALS, a method that effectively balances the trade-off between bias (related to the target distribution relative to the aggregated training dataset) and variance stemming from the number of each client dataset."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper is the first to tackle the realistic federated learning scenario of generating a global model for an arbitrary target distribution that may differ from the aggregated client training datasets."
            },
            "weaknesses": {
                "value": "**Weaknesses**\n\nThe presentation of this paper is notably poor, as it contains numerous inaccuracies and unclear statements throughout. For instance:\n\n1. (L87-88 and L136)  \"A common assumption in federated learning is that all client distributions are identical.\" \n-> This is not right. Federated learning generally allows for differences in client distributions, with data heterogeneity being one of the main challenges.\n\n2. (L 97-98)-> the phrase \"Given a set of clients S_1, ..., S_M\" -> these are the set of client's marginal distribution.\n\n3. (L98)There is a lack of clarity regarding the loss function; the specific loss being used is not mentioned.\n\n4. (L108) \"While the server has access to all marginal label distributions,\" reflects an assumption made in the paper. Given the emphasis on data privacy in federated learning, this assumption requires a much deeper justification. The authors only reference a single paper (Ramakrishna & Dan, 2022) in (L113-115) to support this assumption, which is insufficient. More extensive discussion is needed to validate this critical assumption.\n\n5. (L161) The phrase \"As we see in Table 1\"  is unclear, as Table 1 appears several pages later. A more helpful reference would be \"As we see in Table 1 in Section 5.\"\n\n6. Proposition 1 discusses the importance of the aggregated training dataset's distribution being equal to that of the target dataset. However, establishing this equivalence alone does not address the challenges of federated learning. The issue of data heterogeneity among clients must be resolved when the aggregated training dataset's distribution matches the target dataset's distribution, particularly when local iterations are performed only once. In practice, due to communication issues, multiple local iterations are typically needed, and the implications of unbiasedness discussed in Proposition 1 are not sufficiently emphasized until lines 285-289.\n\n7. (L 161) There is no definition provided for vector alpha and S  which creates confusion.\n\n8. (L 300) The validation set's specific dataset type is not defined. If it is identical to the target dataset, this would constitute a dangerous approach that could be seen as cheating.\n\n9. The inclusion of the hyperparameter lambda in (L 302) is a significant weakness, as it necessitates searching for optimal lambda values in arbitrary settings, which may vary across different settings.\n\n10. The term \"this benchmark\" in (L 359) lacks clarity. It should specify what is being referred to. Additionally, the experimental setup appears weak, as modern federated learning research typically uses at least CIFAR-100, with ImageNet or Tiny ImageNet as benchmarks. This study seems to rely on a dataset with fewer than 10 classes, which lacks challenge. Moreover, with only 10 clients and an alpha value of 0.1 for data heterogeneity, it is unclear how performance will change as data heterogeneity increases.\n\n11. In (L 444-445), the phrase \"varying the number of clients C across 10 clients\" is confusing, as C does not accurately convey the number of clients."
            },
            "questions": {
                "value": "I am curious about the performance comparison of the proposed method with baseline federated learning algorithms (such as SCAFFOLD) in scenarios where the label distribution of the aggregated training dataset matches that of the target domain."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studied a new FL problem under label shifts where the server knows the different label distributions of clients and target domains are known to the central server but unknown to the clients. To solve this problem, this paper optimized the aggregation weights using the label distributions. Experimental results demonstrated the effectiveness of the proposed methods over several baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(S1) A novel FL problem with label shifts is formulated by assuming that the server knows the different label distributions of clients and target domains are known to the central server but unknown to the clients\n\n(S2) A novel parameter aggregation strategy is proposed based on the label distributions. It also balances the effective sample size and the alignment with the target label distribution.\n\n(S3) Experimental results on several data sets demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "(1) The training procedures of the proposed FedPALS method based on equation (7) are confusing. The parameter $\\lambda$ largely affects the model performance in the experiments. Though section 3.2 provides several options, it is unclear how $\\lambda$ is selected in the experiments, e.g., Figure 3(a)(b).\n\n(2) The assumption of this paper is strong. \n- It assumes that the target label distribution $T (Y )$ is known to the server, but no training examples are available for the target client. It would be better to provide more realistic FL scenarios to illustrate the importance of this special problem settings.\n- It assumes that the server knows the different label distributions of clients. This can also result in the privacy concern.\n\n(3) The prior information regarding $T (Y )$ is only available for the proposed FedPALS approach. It might be unfair for performance comparison between FedPALS and baselines."
            },
            "questions": {
                "value": "(1) The proof of Proposition 2 is confusing. When $\\mu = 2\\sum_i \\frac{\\alpha_i^*}{n_i}$, how can it derive $\\mu = \\frac{2}{sum_i n_i}$ using the the primal feasibility condition?\n\n(2) How is the parameter $\\lambda$ selected in Figure 3(a)(b)?\n\n(3) It seems that the approaches in Figure 3(b) do not converge yet after 80 communication rounds, as their target F1-scores keep increasing.\n\n(4) The paper [c1] also studied the FL problem under unknown target client. It can assume no prior information regarding the target client. Thus, the developed AFL can be one of the strong baselines for FedPALS in the experiments.\n\n[c1] Mohri, Mehryar, Gary Sivek, and Ananda Theertha Suresh. \"Agnostic federated learning.\" In International conference on machine learning, pp. 4615-4625. PMLR, 2019."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses label shift in federated learning, a challenge where label distributions vary across clients and differ from the target domain, potentially leading to degraded model performance. The authors propose FedPALS, a novel model aggregation approach that aligns client updates with the target label distribution, enabling better generalization under label shift. The method incorporates a weighting strategy that balances the need to match target distribution closely while minimizing variance in updates. Experimental results on datasets with label sparsity demonstrate FedPALS\u2019s effectiveness over baseline federated learning methods, showing improved model accuracy in label-shifted target domains."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. FedPALS introduces a well-justified aggregation technique that adjusts model updates for label shifts, making it highly applicable in non-i.i.d. data settings commonly found in real-world federated learning applications.\n\n2. The paper includes extensive experiments on multiple datasets with varying degrees of label sparsity, demonstrating FedPALS\u2019s superiority over standard methods like FedAvg, FedProx, and SCAFFOLD, thus validating its effectiveness in handling label shifts."
            },
            "weaknesses": {
                "value": "FedPALS lacks novelty, largely building on existing federated aggregation methods without introducing a fundamentally new approach. It uses outdated baselines; incorporating recent models (2023-2024) would provide better comparisons. The experiments with a limited number of clients (e.g., 3 for PACS, 10 for CIFAR-10) restrict evaluation of FedPALS\u2019s scalability in larger federated settings. Additionally, its optimization for client aggregation weights could become computationally expensive with more clients or labels. The method focuses on label shift alone, though real-world federated learning often involves covariate shifts. Lastly, FedPALS relies on a critical hyperparameter, \u03bb, without clear guidance on selection, which may limit practical deployment."
            },
            "questions": {
                "value": "1. The novelty of the proposed method (FedPALS) is not strongly highlighted, as it builds upon existing model aggregation schemes in federated learning without introducing a fundamentally new approach. Although it adapts the aggregation scheme to account for label shift, similar issues have been addressed with methods like FedAvg and FedProx, making it essential to clarify the unique contributions FedPALS offers beyond these.\n\n2. The baseline used in this paper is too old. Please use some new baselines from 2023 or 2024 for comparison.\n\n3. The experiments are conducted with a limited number of clients (e.g., 3 clients in PACS and 10 in CIFAR-10 and Fashion-MNIST), which is not representative of typical large-scale federated learning environments. This small client network size limits the evaluation of FedPALS's scalability and robustness, especially under diverse, high-client scenarios that federated learning is intended for.\n\n4. FedPALS introduces an optimization process to determine client aggregation weights, which may become computationally expensive as the number of clients or labels increases. The paper does not address the potential scalability issues of this approach, raising concerns about its applicability in large federated learning settings with numerous heterogeneous clients or labels.\n\n5. The method focuses on label shift, assuming that the input distributions remain consistent across clients and the target domain. However, in real-world federated learning, covariate shift often occurs alongside label shift. Expanding FedPALS to handle both types of shifts would enhance its comprehensiveness and applicability.\n\n6. The method\u2019s performance relies on a crucial hyperparameter, \u03bb, which balances bias and variance in the model. The paper does not offer a clear, practical method for choosing \u03bb, which may pose challenges for real-world deployment where fine-tuning may not be feasible. This lack of guidance could hinder the ease of implementation and generalization of FedPALS."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the problem of label shift in federated learning, where client data distributions differ from a target domain with a known label distribution, but no target samples are available. The authors propose a novel aggregation scheme called FedPALS that optimizes a convex combination of client models to align with the target label distribution, ensuring that the aggregated model minimizes the target risk. The paper provides theoretical justification for the proposed method and demonstrates its effectiveness through extensive empirical evaluation, showing that it outperforms traditional approaches like FedAvg, FedProx, and SCAFFOLD in scenarios with significant distributional shifts."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed FedPALS method is novel and addresses a specific yet significant problem in federated learning, i.e., label shift. The approach of optimizing a convex combination of client models to align with the target label distribution is well-justified.\n- The paper is technically sound, with theoretical analysis and extensive empirical evaluation. The experiments cover a variety of scenarios and datasets, demonstrating the robustness and effectiveness of the proposed method.\n- The writing is clear and the presentation is well-organized."
            },
            "weaknesses": {
                "value": "- The paper lacks a reference to the work \"Agnostic Federated Learning\" by Mohri et al., presented at ICML 2019. This work also addresses federated learning with unknown target distributions and shares some theoretical similarities with the proposed method in this paper. The authors should include this reference in the related work section and provide a more detailed comparison in both the theoretical and experimental sections to highlight the differences and similarities between the two approaches.\n- The paper could be improved by providing a more detailed discussion on the limitations of the proposed method. For example, how does FedPALS perform in scenarios where the label shift assumption does not hold? Are there any cases where FedPALS might fail or underperform?\n- The paper discusses the choice of the hyperparameter $\\lambda$ but could provide more guidance on how to select this parameter in practice. A more detailed analysis of the impact of $\\lambda$ on the performance and robustness of the method would be valuable."
            },
            "questions": {
                "value": "- Could the authors provide a more detailed comparison with existing methods, particularly those that address distributional shifts in federated learning? How does FedPALS differ from and improve upon these methods?\n- Does the proposed method generalize to other types of distributional shifts, such as covariate shift? If so, could the authors provide some initial results or discussion on this topic?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces FedPALS, a method to deal with label shift in federated learning. Label shift happens when label distributions change across clients or between clients and target. The authors propose a novel aggregation scheme to optimize a convex combination of client models to ensure that the aggregated model is better suited for the label distribution of the target domain."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1: The problem of label skews is interesting and well positioned.\n\nS2: The paper gives good theoretical proofs on the algorithm."
            },
            "weaknesses": {
                "value": "W1: The compared baselines are too old. The authors only compare algorithms before 2020 (FedAvg, FedProx, SCAFFOLD). There are several recent works on label shifts in federated learning (e.g., [1, 2, 3]). Lack of these recent baselines cannot convince that the proposed algorithm is SOTA.\n\nW2: The authors work with C=2,3 and beta=0.1 partitions. How about C=1, the most extreme label shift?\n\nW3: Assumes target label distribution known is often not practical. No examples of how to get this info without privacy risk.\n\n[1] Li, Xin-Chun, and De-Chuan Zhan. \"Fedrs: Federated learning with restricted softmax for label distribution non-iid data.\" Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining. 2021.\n\n[2] Zhang, Jie, et al. \"Federated learning with label distribution skew via logits calibration.\" International Conference on Machine Learning. PMLR, 2022.\n\n[3] Diao, Yiqun, Qinbin Li, and Bingsheng He. \"Exploiting Label Skews in Federated Learning with Model Concatenation.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 10. 2024."
            },
            "questions": {
                "value": "See weaknesses. Given the very weak baselines, it is not convincing that the proposed solution is SOTA to reach the bar of acceptance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}