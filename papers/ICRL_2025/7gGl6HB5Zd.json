{
    "id": "7gGl6HB5Zd",
    "title": "Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images",
    "abstract": "Distinguishing between real and AI-generated images presents a timely and significant challenge. Despite extensive research in the (semi-)supervised regime, only recently, zero-shot and few-shot solutions have emerged as promising approaches to this task: They alleviate the ongoing data maintenance, which quickly becomes outdated due to advances in generative technologies. We identify two main gaps: (1) a lack of theoretical grounding for the methods, and (2) significant room for performance improvements in zero-shot and few-shot regimes. Our approach is founded on understanding and quantifying the biases inherent in generated content, where we use these quantities as criteria for characterizing generated images. Specifically, we explore the biases induced by the implicitly learned manifold of a pre-trained diffusion model: Through score-function analysis, curvature and gradient of the probability manifold are approximated in the zero-shot setting - yielding a scalar criterion for classification. We further extend our contribution to the few-shot setting by employing a mixture-of-experts methodology. Empirical results across 20 generative models demonstrate that our method outperforms current approaches in both zero-shot and few-shot settings. This work advances the theoretical understanding and practical usage of generated content biases through the lens of manifold analysis.",
    "keywords": [
        "zero-shot",
        "few-shot",
        "generated image detection",
        "total-variation",
        "curvature",
        "score function",
        "diffusion models"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=7gGl6HB5Zd",
    "pdf_link": "https://openreview.net/pdf?id=7gGl6HB5Zd",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a zero/few-shot framework for detecting AI-generated images by analyzing the inherent biases of a pre-trained diffusion model. The authors hypothesize that generated images are more likely to occupy stable local maxima on this learned manifold, characterized by specific curvature and gradient properties. By approximating these properties, they create a criterion to distinguish between real and generated images without requiring large datasets or retraining. Empirical results show their method outperforms other detection approaches across multiple generative models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Zero-shot and few-shot capability makes the method practical.\n- The theoretical perspective is interesting.\n- Empirical results seem promising."
            },
            "weaknesses": {
                "value": "1. Some theoretical assertions, such as the assumption that generated samples are more likely to be stable local maxima on the learned manifold, are not fully justified. This assumption underpins the detection criterion, but the paper does not offer a thorough mathematical or empirical rationale to support it.\n2. The paper relies heavily on approximations in score-function and curvature estimations (e.g., Eq.5, 16-18). However, there is limited discussion or analysis of the tightness of these approximations. This could lead to questions about the reliability of the approximations, especially when they form the foundation of the theoretical claims. It would be beneficial if the authors provided error bounds analysis or empirical justifications for these approximations.\n3. In line 122, the authors argue that previous methods still rely on access to generative methods during training, leading to biases towards those generation techniques. However, the proposed approach also relies on a pre-trained SD1.4. How does the proposed approach avoid the bias from it? For example, a realistic sample generated from a more recent model may not sit on a stable local maximum in the learnt log probability manifold of SD1.4.\n4. The presentation can be improved. The mathematical analysis can benefit from illustrative examples, while the detailed proof can be moved to appendix."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper explores a novel method to detect AI-generated images, focusing on zero-shot and few-shot regimes. It identifies key challenges in the field, such as the need for data upkeep with traditional supervised learning methods and limited theoretical grounding for current approaches. The authors propose a framework based on the implicit biases within the manifold of a pre-trained diffusion model, leveraging score-function analysis to approximate manifold curvature and gradient in the zero-shot setting. They extend the method for few-shot scenarios by incorporating a mixture-of-experts strategy. The proposed method demonstrates enhanced performance across 20 generative models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The idea of leveraging manifold-induced biases from pre-trained diffusion models to detect generated images is novel and interesting.\n- The methodology, essential theoretical formulations, and results are well-articulated, with equations and definitions supporting the approach.\n- Experimental results are promising, and Figures 1 and 2 are intuitive and easy to understand."
            },
            "weaknesses": {
                "value": "The primary concern is the robustness; please see the Questions below."
            },
            "questions": {
                "value": "1. The proposed method relies on pre-trained diffusion models and manifold analysis, which are implemented in high-dimensional space, potentially increasing computational costs. Could the authors provide an analysis of inference time and memory requirements?\n\n2. The method depends on certain hyperparameters, such as perturbation strength and the number of spherical noises. How robust is the method to these parameters across different models, and what guidelines can be provided for selecting these parameters?\n\n3. The authors tested the impact of JPEG compression on the method and reported a slight performance decrease. How does the method perform with other types of image post-processing, such as augmentation, denoising, and flipping?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work addresses the challenge of distinguishing between real and AI-generated images by analyzing biases on the probability manifold of pre-trained diffusion models. The authors develop a method that offers a scalar criterion for classification in zero-shot settings, and experiments demonstrate its effectiveness against current methods."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The theoretical analysis of current diffusion models\u2019 score functions is comprehensive and novel, potentially inspiring further research in this area.\n\nThe proposed method generalizes well to unseen generative techniques and achieves superior performance over existing approaches in both zero-shot and few-shot settings."
            },
            "weaknesses": {
                "value": "The implementation details in Section 4.3 should be elaborated further to enhance readability and reproducibility.\n\n\nTypo errors:\n- L153 and L149, inconsistent use of $\\mathcal N$ and $N$.\n- L146 and L170, inconsistent use of $\\mathbb{R}$ and $R$\n- L157, better use latex log $\\log$ for clarity.\n- L191, use latex \\` for upper quotas.\n- inconsistent use of Sec. and Section\n- L298-L299, unexpected equation."
            },
            "questions": {
                "value": "The author choose SD-1.4 to implement the proposed method, have the author tried other diffusion models, especially recently more advanced methods, such as SDXL and SD3. Does this helps improve the performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel approach to detecting AI-generated images using a zero-shot and few-shot framework. By analyzing biases inherent in the manifold of pre-trained diffusion models, the authors introduce a new mathematical criterion based on score functions, curvature, and gradient analysis. This approach generalizes well to unseen generative techniques and outperforms existing methods in both zero-shot and few-shot scenarios. Extensive experiments across a diverse set of generative models further validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper provides a sound theoretical foundation by integrating manifold analysis with diffusion models, advancing the field of generated image detection.\n\nThe empirical results show strong performance, with the proposed method outperforming current state-of-the-art approaches.\n\nThe authors conducted experiments across various datasets and generative techniques, including GANs, diffusion models, and commercial tools, providing strong evidence for the robustness of the method."
            },
            "weaknesses": {
                "value": "According to the article, the proposed curvature and gradient based metric for detecting generated images is closely related to the score function. However, it is unclear why this method also performs well with models where score functions are not inherently applicable, such as CycleGAN. The authors are encouraged to clarify this connection and explain why the proposed metric shows strong performance even in such cases where score function analysis is not directly relevant.\n\nThere are citation issues on page 7 of the article, where footnotes and page numbers are not correctly referenced. The authors should revise the citation formatting to ensure all references are accurate and properly aligned with the content.\n\nThe proposed method appears to fit naturally within a zero-shot framework, relying solely on input samples and corresponding perturbations. It is unclear why the few-shot setting was introduced, given that zero-shot scenarios are typically more challenging and often reflect real-world situations. The authors are encouraged to clarify the need for a few-shot setting and explain why zero-shot alone would not suffice as a more compelling and realistic approach."
            },
            "questions": {
                "value": "Please see weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}