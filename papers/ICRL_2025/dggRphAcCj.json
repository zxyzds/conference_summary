{
    "id": "dggRphAcCj",
    "title": "GeoCon: Compositional Generalization Through Geometric Constraints on Representation Structure",
    "abstract": "Compositional generalization, referring to the capacity to generalize novel combinations of fundamental and essential concepts, is thought to be the mechanism underlying a human\u2019s remarkable ability of rapid generalization to new knowledge and tasks. Recent research on brain neural activation space has found that the geometric structure of neural representations is highly related to human compositional generalization capability. In this paper, we extend the above observations from neuroscience to deep neural networks to validate the potential relationship between the geometric structure of representations and compositional generalization capability. In particular, we first construct a new compositional generalization benchmark, which aims to discriminate multiple concepts simultaneously through a powerful representation. Meanwhile, for the aforementioned geometric constraint, the parallelism score is formally defined for deep neural networks. Subsequently, we decompose the deep neural network into two parts: the featurizer and the classifier, to investigate the relationship between compositional generalization capability and parallelism score separately. Our proposed method, Geometric Constraint (GeoCon), involves distance variance minimization regularization on the classifier and parallelism score maximization on the featurizer. Experiments on synthetic and real-world datasets demonstrate significant improvement of our approach, verifying the effectiveness of our neuroscience-inspired GeoCon approach towards human-like superior generalization ability.",
    "keywords": [
        "Represention Learning",
        "Compositional Generalization."
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=dggRphAcCj",
    "pdf_link": "https://openreview.net/pdf?id=dggRphAcCj",
    "comments": [
        {
            "summary": {
                "value": "The paper provides a mathematical formulation of parallelism score (PS) from neuroscience, and how it contributes to out-of-combination compositional generalization (CG) in deep neural networks consisting of a featurizer and classifier for classification tasks. Initial experiments on synthetic datasets reveal a strong positive correlation between PS and CG ability, but also high variance with low CG ability even for high PS. The authors propose minimum distance variance (DV) regularization to reduce such failure cases which encourages similar distance of all samples from the decision boundary. The authors also evaluate multiple pretrained models on real world datasets like PACS, NICO, and Office-Home consisting of class and domain labels, and found that the compositional generalization and parallelism score for each class is strongly correlated. However, there is a negative correlation between compositional generalization for class and domain. Self-supervised DINO and multimodal CLIP models demonstrate good compositional generalization capability for class and domain. The authors finally propose the geometric constraint (GeoCon) method maximizing PS for the featurizer and minimizing DV for the classifier to further improve CG ability across both class and domain."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow.\n\n2. A formal description of the parallelism score from neuroscience is provided.\n\n3. The authors propose GeoCon method which consists of two regularization techniques, one for distance variance minimization and the other for parallelism score maximization to improve the compositional generalization ability of deep neural networks.\n\n4. The authors demonstrate the effectiveness of their method on multiple real world datasets, and the importance of both regularization techniques through ablation studies."
            },
            "weaknesses": {
                "value": "1. The GeoCon method seems to require a similar number of classes for each concept. \n\n2. The experiments are limited to datasets with only two concepts.\n\n3. It is not clear how the method would scale to more realistic tasks, like visual question answering."
            },
            "questions": {
                "value": "1. How does the GeoCon method generalize when there are more than two concepts?\n\n2. Can the authors share more details about the linear probing and finetuning baselines?\n\n3. In Figure 8, shouldn\u2019t the values of the parallelism score and distance variance for the models be similar at epoch=0, which is just after initialization?\n\n4. Is the method only limited to classification problems or more generally applicable to other domains like compositional visual reasoning (e.g. COLA [1] benchmark)?\n\n5. How many samples are required to compute the parallelism score?\n\n[1] - Ray, A., Radenovic, F., Dubey, A., Plummer, B., Krishna, R. and Saenko, K., 2024. Cola: A benchmark for compositional text-to-image retrieval. Advances in Neural Information Processing Systems, 36."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this submission, the authors proposed a neuroscience-inspired method to tackle the problem of generalization of deep neural networks. Specifically, the authors borrow the idea of abstract representation in Ito NeurIPS 2022 to improve the compositional generalization in deep neural networks by applying geometric constraints to the representation structure, including maximizing the parallelism score of representations in the featurizer and minimizing the distance variance between sample points and decision boundary in the classifier. Results are reported on several benchmark dataset, which shows the effectiveness of the proposed method compared with linear probeing and variants of fine-tuning methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea of introducing the concept from neuroscience to the generalization problem of deep neural networks is interesting."
            },
            "weaknesses": {
                "value": "- The idea is coming from Ito, NeurIPS 2022, which is also based on compositional generalization for neural networks. To me, the main idea is quite similar, except that the authors introduce more regularization terms (also introduced in the Ito paper) in the loss function, which is quite incremental. Can you please elaborate more on how the proposed method advances Ito, NeurIPS 2022, in case I miss something? Moreover, is it possible also to use Ito 2022 as a baseline, where the generalization capability of neural networks has been discussed (see Ito Sec 3.5)?\n\n- While the method's evaluation focuses on class and style, and draws motivation from neuroscience, it's unclear how it advances the state-of-the-art compared to existing statistical approaches to invariant feature learning that achieve similar results. \n\n- While the proposed method is neuroscience-based, the results discussion is only limited to accuracy on domain generalization, which is not satisfactory. How does it benefit other generalization tasks, such as zero-shot? explainable AI?\n\n-  I'd also like to suggest the authors consider the dataset in Ito, NeurIPS 2022, which can better help the reader to have a deeper understanding of the deep relationship between generalization and neural science (which is the main claim of the submission)."
            },
            "questions": {
                "value": "please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Discusses parallelism score (PS), from neuroscience, as a proxy measure of compositional generalization (CG) in artificial NNs. \n\nShows that their measure of PS correlates with CG across multiple datasets and models. \n\nShows that minimizing an approximation to PS, as well as an additional loss term that aims to keep points a constant distance from the classifier's decision boundary, improves CG."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Compositional generalization is an interesting problem.\n\nParallelism score seems to make sense theoretically and is generally well-explained. It is nice that it can be optimized directly, as opposed to most measures of disentanglement.\n\nVery convincing experimental results, both in the correlation of PS and CG, and in the improvement in CG from the additional loss terms."
            },
            "weaknesses": {
                "value": "When introducing PS score, it's not clear to me how exactly it relates to the neuroscience measure of Bernardi et al. (2020). Presumably the latter was not able to calculate cosine similarity of different activation vectors.\n\nCould you give more details about the datasets? what types of objects are they classifying? what are some examples of values for \u2018domain\u2019 and \u2018class\u2019? \n\nIf I understand correctly, the experiments in Section 3.2 form a test set of points that have a novel combination of class and domain, and then \u2018CG class\u2019 is the fraction of these points for which the class is predicted correctly, and the same for \u2018CG domain\u2019. In that case, I wonder how getting both correct correlates with PS score, especially in light of the fact that CG class and CG domain are negatively correlated. This is included in Tables 1 and 2, but I\u2019d recommend saying something about it in discussing Figure 6 too. Short of putting this in as another row, \u2018CG both\u2019, in the plots of Figure 6, it would still be helpful just to mention this alternative in the text.\n\nSection 3.2, point (iv) is confusing to me. There are only two concepts here, class and domain, what would it mean to have CG across multiple concepts?\n\nline 364: \u201cwe can also employ an exponential smoothing method\u201d--does that mean you do employ it?\n\nThe approximation to PS seems to require a certain amount of diversity in the batch, what batch size do you use?\n\nThe way you measure CG is very similar to Xu et al. (2022) and Mahon et al. (2024). \n\nLine 050: \u201cthere is currently no evidence that explicitly decoupling input compositional factors substantially improves the learning efficiency or generalization capacity\u201d--this is too strong a statement in my view. On whether there is a connection between disentanglement and CG, there are papers on both sides: those you cite claim there is not, while Higgins et al. (2016) and Esmaeli et al (2019) both claim that their methods for disentanglement show evidence of facilitating CG, and Mahon et al. (2024) claims to find a correlation between disentanglement and CG across various models and datasets. If you are to take a side on that issue, you could measure disentanglement on the embeddings you take from the frozen models in Section 3.2, and see if it correlates with CG and maybe also PS. That would be an interesting addition to your work.\n\n**Refs**\n\nHiggins et al. (2016) \"beta-vae: Learning basic visual concepts with a constrained variational framework.\"\n\nEsmaeli et al. (2019) \"Structured Disentangled Representations\"\n\nMahon et al. (2024) \"Correcting Flaws in Common Disentanglement Metrics\"\n\n\n**Minor points**\n\n103: \u201cFeaturizer\" --> \"The featurizer\u201d\n\n134: \"the linear function\" --> \u201ca linear function\u201d\n\nif g and D are on the LHS of Eq (8), shouldn\u2019t they also be on the LHS of (7) and (6)? i.e. $PS(a)$, should be $PS(a;g,D)$, or you could just remove g and D from (8) taking them to be implicit everywhere\n\nWhat are $L_a$ and $L_B$ in Eq (10)? (stated earlier that they\u2019re CE, but helpful to repeat especially before the them.)\n\nDoes 'accuracy' in Thm. 1 refer to train set accuracy?"
            },
            "questions": {
                "value": "Could you please reply to the points I mentioned in 'weaknesses' above? (most are more questions that weaknesses) Thanks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}