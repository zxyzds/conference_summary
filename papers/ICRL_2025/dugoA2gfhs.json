{
    "id": "dugoA2gfhs",
    "title": "Just Select Twice: Leveraging Low Quality Data to Improve Data Selection",
    "abstract": "Data valuation is crucial for assessing the impact and quality of individual data points, enabling the ranking of data by importance for efficient data collection, storage, and training. Many data valuation methods are sensitive to outliers and require a certain level of noise to effectively distinguish low-quality data from high-quality data, making them particularly useful for data removal tasks. In particular, optimal transport-based methods exhibit notable performance in outlier detection but show only moderate effectiveness in high-quality data selection, due to their sensitivity to outliers and insensitivity to small variations. To mitigate the issue of insensitivity to high-quality data and facilitate effective data selection, in this paper, we propose a straightforward two-stage approach, JST, that initially does data valuation as usual, but then performs a second-round data selection where the identified low-quality data points are designated as the validation set to perform data valuation again. In this way, high-quality data become outliers with respect to the new validation set and can be naturally identified. We empirically evaluate an instantiation of our framework based on optimal transport method for data selection and data pruning on several standard datasets and our framework demonstrates superior performance compared to pure data valuation, especially under small noise conditions. Additionally, we show the general applicability of our framework to influence function based and reinforcement learning based data valuation methods.",
    "keywords": [
        "data selection",
        "data valuation",
        "data-centric AI",
        "optimal transport",
        "robust statistics"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "We propose JST, a novel framework to augment existing data valuation methods for high-quality data selection.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=dugoA2gfhs",
    "pdf_link": "https://openreview.net/pdf?id=dugoA2gfhs",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a two-stage framework, JST, to assist existing data valuation methods in selecting high-quality data points. These data valuation methods are sensitive to outliers but fall short in recognizing in-distribution data points. This framework uses outliers as a validation set and again leverages the sensitivity of these methods to outliers to identify high-quality data points. The experiments show that JST significantly improves over baselines, verifying the effectiveness of the framework. However, it is not adaptable for marginal contribution-based data valuation methods due to a lack of the property of higher sensitivity to outliers."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The narrative of this paper is clear and easy to understand, and the illustrations are vivid and illustrative.\n\n2. The framework is experimentally effective on tested tasks."
            },
            "weaknesses": {
                "value": "1. The lack of theoretical analysis makes the article seem incomplete.\n\n2. The results of Figure 4 seem inconsistent with the analysis of Figure 1.\n\n3. Some experimental phenomena can be further explained.\n\n4. I recommend that the authors add experiments about time cost to demonstrate their applicability in reality.\n\n5. Some symbols are not clear and a bit confusing."
            },
            "questions": {
                "value": "The authors discovered a phenomenon that existing data valuation methods are not sensitive to in-distribution data points and used this property to design a two-stage framework. However, they did not explain this phenomenon mathematically.\n\nIn round 1 of Figure 4, I see that outliers are mixed with in-distribution data points at low data values. Wouldn\u2019t this cause the NDRoutlier to be poor as well? How does JST work in this case?\n\nIn Figure 5, the three curves are very close. I think \"our framework achieves much higher accuracy compared to the pure data valuation method\" is overclaimed. Also, I hope the author can explain why random selection has such good results. In Figure 3, the curve of random is a horizontal line.\n\n\nAdding a stage seems to more than double the time, but the improvement of the new framework in Figure 5 is not significant, which may not be a good thing in real applications. Therefore, the author can add experiments on time cost trade-offs to show that the improvement in performance is reasonable for the increase in time cost.\n\n \u201c-\u201d in the subtitles on the left and right sides of the three figures in Figure 1 is very close to \u201cNoise Level - Std. Dev\u201d and \u201cNDRoutlier-NDRin-distribution\u201d. This is a bit confusing for me to understand the whole figure."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose an interesting and novel way of computing data values, specifically aimed at ensuring high sensitivity to high-quality data and low-quality data (outliers), crucial for the data selection use case."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The authors clearly state the problem, and Figure 1 helps show the noise sensitivity levels for the different methods.\n- The suggested solution is novel and well-illustrated. \n- It was good to see authors assess JST with semi-value approaches like data Banzhaf and show where JST may not do so well.\n- The figures (both in the results and methodology section) that the authors use are very descriptive, nicely drawn, and intuitive.\n- The authors run experiments on various image datasets: MNIST, CIFAR, SVHN, and Food-101."
            },
            "weaknesses": {
                "value": "**Questions and weaknesses**\n- The authors could improve the figures and captioning, especially in the main text. The captions are not sufficiently descriptive. For example, in Figure 3, the authors don't clearly state the base data valuation method used.  In Figure 6, when using the random data valuation, it's unclear what the selection criteria for the images is. And what's the base data valuation method used?\n- Could authors provide the rationale for selecting varied noise levels for different experiments (different base methods) on the same dataset? For example, why is noise level 10 in Figure 8 but 6/9 in Figure 7, and so on?\n- I wonder if the initial utility function that uses the \u201cgeneral clean validation\u201d set might in principle be \u201csignificantly\u201d different from the one that uses the \u201clow-quality-noisy validation\u201d set. Consequently, I am curious if and by how much the value of a datum changes in the initial setup versus the second setup. If the value of datum A > the value of datum B in the initial setup is that still the case?\n- What\u2019s the stability of JST across runs?\n- In case of issues like replication, wouldn\u2019t that \u201cpoison\u201d the level-two training/validation sets?\n- Without \u201csynthetic\u201d noise injection, how well does JST work or compare to marginal-contribution methods on \u201cnatural\u201d data with likely outliers, for example, low representation of samples from a given class, sensitive group, etc? \n\n**Miscellaneous and minor**\n- Minor: The text font size on the figures could be made larger to improve readability.\n- How well does the framework scale to tabular datasets?\n- Are there differences in class balance when using JST versus the base/pure data valuation method? Is it likely to make things worse/better?\n- Given the costly nature of level-one data valuation, how scalable is two-level data valuation (JST)?\n- Given that JST doesn\u2019t improve things in methods like Banzhaf values, where these methods have additional favorable characteristics like replication robustness and consistency across runs, what\u2019s the incentive for one to use JST over them?"
            },
            "questions": {
                "value": "Questions are contextually embedded in the weakness section. Authors should please address questions added in the sub-section \"questions and weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies data valuation, specifically using data values to perform data selection. The authors proposed to exploit a property of optimal transport-based data valuation methods, namely their sensitivity to outliers (and insensitivity to inliers), and describe a two stage algorithm. The proposed algorithm first selects outliers, and then in the second stage use the selected outliers as validation dataset to again select outliers. Due to the statistical difference, the outliers selected in the second stage are high quality data points. Empirical results on image datasets are provided."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The studied problem is relevant and important.\n- The method is described clearly.\n- Some empirical validation is provided."
            },
            "weaknesses": {
                "value": "- There does not seem to be theoretical justification or characterization of the effectiveness of this method. In comparison, the optimal transport based method (Just et al., 2023) or the influence based method (Koh et al., 2017) both provide theoretical justifications.\n\n- The empirical performance can be made more extensive. There are quite a few existing data valuation methods, such as those described in (Sim et al, 2022). While it is understood the proposed method is motivated by the property of optimal transport-based method, the authors indeed investigate other methods such as reinforcement learning based method (Yoon et al., 2020). Thus, it makes sense to compare with these existing methods.\n\n- The key property of this method requires that low-quality and high-quality data to be \"outliers\" to each other. But in practice, this relationship is not so crisp. For a specific task, the characterization of ideal high-quality data is fairly narrow (i.e., there is only one kind of data which is high quality), while there are (possibly infinitely) many characterizations of low-quality data/outliers. While it is true that outliers (say outlier distribution A) would be statistically different from high quality data (outliers to high quality data), but another type of outlier (say outlier distribution B) would also be outlers to outlier distribution A, but this does not make it high quality. In other words, high quality is the outlier to outliers, but the reverse need not be true (an outlier to an outlier is a high quality data point)."
            },
            "questions": {
                "value": "In abstract, \n\n`Many data valuation methods are sensitive to outliers and require a certain level of noise to effectively distinguish low-quality data from high-quality data,`\n\nWhat is meant by \"require a certain level of noise... \"?\n\n\nIn Figure 1, how are the rates computed? and why do they show a higher sensitivity of data valuation methods to outliers?\n\nInstead of ResNet-18 and ResNet-18 pretrained on Image1K, what do you propose as a principled and general way to perform feature extraction for a dataset to use your method?\n\nWhat would be the empirical results if there are different types of outliers present? For instance two differnt types of noise."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes to enhance data selection by performing a second round of data valuation. The first round of data valuation is done using a validation set. The proposed algorithm would identify $k$ points with the lowest valuation (i.e., performance on the validation set). The second round would value the remaining points based on how poorly they perform on this low value set. Points that perform poorly are high quality data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "It is important to study how data valuation can be better adapted to select high quality data (instead of only filtering out low quality data). The experiments consider various datasets and data valuation methods."
            },
            "weaknesses": {
                "value": "1. The clarity of the paper can be improved. The paper repeatedly use the word \"outlier\" but does not define or use the word precisely. How do we distinguish between outliers and in-distribution data? How do outliers differ from noisy data? Does the classification depend on the data valuation method? Without clear examples or definition, the significance of Figure 1 is unclear.  The definition of outlier seems to change in line 79 \"allows high-quality data to be identified as outliers in the new context\". The authors can provide a clear definition or example at the start of the paper and use it consistently.\n2. The experiments only consider corrupted images. Would the JST algorithm perform well for other scenarios such as corrupted labels? For example, the first round of data valuation might select some data with wrong label A. In the second round, any data with different label (e.g., true label B and wrong label C) would have the same low score. The revision should. include more experiments to prove the method is useful for other data corruption.\n\nMinor comments: Citations should be in the form of (author, year) instead of author (year)."
            },
            "questions": {
                "value": "1. Explain how the normalised outlier detection and in-distribution data detection rate is computed in Fig 1. Is there some ground truth to classify whether data is an outlier or in-distribution? \nIdeally, how should Fig 1 look like for a good data valuation method? Is that achieved by your method?\n2. What is a more precise definition for sensitivity to outliers and sensitivity to high quality data?\n3. Would the JST algorithm work for tabular data and other form of errors such as corrupted labels?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}