{
    "id": "Af7CsWMUNI",
    "title": "In-Context Learning at Representation Level via Unlabeled Texts",
    "abstract": "Large language models (LLMs) have exhibited impressive capability of In-Context\nLearning (ICL), where LLMs perform relatively complicated tasks beyond the\npre-training objective by conditioning on the given demonstrations. Nevertheless,\nICL introduces two gaps between pre-training and inference: label appearance\n(presence of inserted labels in the demonstrations) and weak semantic relevance\n(independently sampled demonstrations exhibit less semantic coherence compared\nto consecutive text segments in pretraining corpora). We propose a new inference\nmethod that only use unlabeled inputs from the test set and label space. In this\nmethod, we extract the representations of the demonstrations inputs independently\nand fuse them to reshape the representation of the test input for inference. Inter-\nestingly, without access to labels, our method outperforms traditional ICL with\nextra information of gold labels. Furthermore, our method allows small models\nto outperform the zero-shot performance of models that are twice their size (e.g.,\nGPT-Neo-2.7B surpasses Llama2-7B, and Llama2-7B outperforms Llama2-13B).\nOur code will be available at this.",
    "keywords": [
        "In-context Learning",
        "Language models",
        "Zero-shot",
        "Representation Learning"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Af7CsWMUNI",
    "pdf_link": "https://openreview.net/pdf?id=Af7CsWMUNI",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a novel in-context learning (ICL) method at the representation level, leveraging (unlabeled) sentences from the test set.\n\nThe proposed method is motivated by two existing gaps between pre-training and ICL:\n1. **Label appearance**: During pre-training, the text lacks task-specific signals, while in ICL, the input-label mapping introduces explicit task information.\n2. **Weak semantic relevance**: Text used in pre-training tends to be more coherent, whereas ICL demonstrations are often relatively unrelated to each other.\n\nTo address these issues, the proposed approach builds on **unlabeled ICL**. \nSpecifically, representations of different test sentences are first pre-computed using an LLM.\nThe new test input is then encoded with the same model, and this representation is used as a query in the attention mechanism, with $k$ relevant representations from the previous stage functioning as keys and values. \nFinally, the attention mechanism\u2019s output vectors for the $k$ different samples are averaged and combined with the original test input feature vector. \nThis final vector serves as input for the target language model\u2019s lm_head, where the likelihood of each option is computed, and the option with the highest likelihood is selected as the final answer.\n\nIn the experiments, the proposed method is compared with zero-shot and few-shot ICL. Results indicate that it generally outperforms zero-shot and is comparable to other demonstration selection-based few-shot baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed method does not rely on label information from demonstrations, making it applicable in cases where only relevant context is available without gold-standard labels.\n- Interestingly, the proposed method can be interpreted as representing the vector of the target input within the space spanned by vectors of other samples.\n- An analysis was conducted to examine the inner workings of ICL from the authors\u2019 own perspectives, providing insights into the paradigm."
            },
            "weaknesses": {
                "value": "- While assumptions like label appearance and weak semantic relevance are intriguing, I am somewhat doubtful, especially regarding weak semantic relevance. In pre-training, language models are exposed to a substantial variety of cases, some of which might closely resemble in-context learning scenarios. For instance, if multi-choice QA datasets were included in pre-training, the answer choices could introduce sequences that appear relatively unrelated. Thus, it may not be easy to guarantee that LMs are unfamiliar with inputs seen in in-context learning scenarios.\n- I\u2019m also unsure whether comparison with only zero-shot ICL is entirely fair. Although the proposed method does not utilize label information from the test set, it does use textual information from it. Could we add more reliable baselines, such as performing few-shot ICL with random labels (distinct from a random few-shot retrieval-based baseline) or using self-generated labels?\n- Equation 11 seems somewhat arbitrary, with no explanation provided for why those specific hyperparameters (e.g., 0.4 and 0.6) are applied in the weighted sum. Could you elaborate on this process?\n- It would be helpful if the paper included an analysis of the proposed method\u2019s efficiency. While accuracy is critical for evaluating performance, the method\u2019s efficiency is also a key factor in understanding its practical implications."
            },
            "questions": {
                "value": "- I am curious why sentences from the test set are used to construct representations for the method\u2019s computation. What would happen if we relied on sentences from the training set instead? Although the proposed method does not rely on label information from the test set, avoiding the use of any hints or information extractable from the test set, if possible, would help ensure a fair evaluation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposes a new in-context learning paradigm. It is mainly motivated by the identified issue of weak semantic relevance in traditional ICL: ICL demonstrations exhibit weaker semantic dependence than the pretraining corpora. Therefore, the authors propose to process ICL examples independently for better coherence within each example. It then use the attention mechanism to integrate these independent representations of examples into the test input's representation. In addition, this method does not require labels for ICL examples. Experiments are conducted on four LLMs and eight datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This work highlights a discrepancy  between ICL and LLM pretraining - unlike coherent text used in pretraining, ICL demonstrations exhibit weaker semantic dependence\n- The proposed paradigm of conducting ICL at the representation level is new."
            },
            "weaknesses": {
                "value": "- The first concern is the absence of empirical evidence to support the theoretical claims about the weak semantic relevance's impact on ICL performance. Without quantitative evaluation, it is unknown whether the impact of this discrepancy is significant, making the main motivation of this work not well-supported. Additional experiments could be conducted to compare conventional ICL demonstrations with modified ones that include semantically coherent transitions.\n- The proposed ICL paradigm simplifies the interaction between examples and the test input into a single step, potentially losing vital information that could be obtained in multi-layer interactions of conventional ICL.\n- The proposed method is likely to increase computational and storage demands in computing independent representations of each example and reconstructing the representation of the test sample. However, there is a lack of analysis on the efficiency of the proposed method.\n- There is a lack of experimental details. For example, the prompts used in Section 2 and the main experiments are not provided, and the methodology for selecting hyperparameters in Equation 11 is not introduced, and the references of the baselines used in the main experiment are missing.\n- Some discrepancies in ICL performance of baselines are observed between this paper and the literature. For example, the 16-shot ICL performance using random examples for Llama2-7B on SST-2, RTE, and CoLA is reported as 93.16, 77.02, and 70.20, respectively in [1], which is 20-30 points higher than that reported in this study.\n\n---\n[1] Van, Minh-Hao, and Xintao Wu. \"In-Context Learning Demonstration Selection via Influence Analysis.\" arXiv preprint arXiv:2402.11750 (2024)."
            },
            "questions": {
                "value": "- Why does the proposed method achieve the same accuracy across four different LLMs on MRPC and CoLA datasets?\n- Why there is a decrease in performance when upgrading from Llama2-7B to Llama2-13B on SST-2 and Phrase datasets using the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new representation-based in-context learning (ICL) paradigm, which utilizes unlabeled text in the test set for learning, without relying on annotated examples. The authors find that the presence of labels has a greater positive impact than negative impact on domain-specific datasets, but the opposite is true for general-domain datasets. Furthermore, the authors' proposed method performs inference by independently processing the representation of the example input, which is superior to the traditional ICL based on annotated examples, and allows smaller models to outperform larger models in zero-shot performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "It proposes a new representation-based in-context learning (ICL) paradigm that utilizes the unlabeled text in the test set for learning, without relying on annotated examples.\n\nIt finds that the presence of labels has a greater positive impact than negative impact on specific domain datasets, but the opposite is true for general domain datasets.\n\nThe proposed method performs reasoning by independently processing the representations of the example inputs, which is superior to the traditional ICL based on annotated examples, and allows smaller models to outperform larger models in zero-shot performance."
            },
            "weaknesses": {
                "value": "- The paper requires some additional comparation to some in-context vector methods like [1][2], which also create a hidden state offset by in-context example.\n\n- Required some additional ablation study to prove why use the unlabeled texts from test set rather than labelled.For example, if you use labelled data in your framework in Figure 2, how will the performance be?\n\n- The improvement form increasing numbers of the retrieved hidden states is limited.\n\n\n[1]Liu, S., Ye, H., Xing, L., & Zou, J.Y. (2023). In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering. ArXiv, abs/2311.06668.\n[2]Hendel, R., Geva, M., & Globerson, A. (2023). In-Context Learning Creates Task Vectors. ArXiv, abs/2310.15916."
            },
            "questions": {
                "value": "- The link of the codes is invalid.\n\n- Besides MRPC, the difference between labelled and unlabelled data for ICL is limited. Is there any more dataset can be used for prove the conclusion about un-labelled ICL in General-Domain.\n\n- Could you share the prompts or give some analysis about the effect of the prompt use to get the presentation of the in-context examples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper firstly proposes two gaps between current ICL paradigm and pre-training, label appearance and weak semantic relevance. Sometimes ICL benefits from the gap but sometimes it does not. Then it conducts corresponding experiments and observe different conclusions on specific-domain and general domain datasets, based on which it proposes its method -- fusing unlabeled samples to reshape the representation of the test input for inference. This method outperforms traditional ICL on models of varying sizes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* This paper is well-written. The motivation demonstrated by preliminary experiments is very clear. \n* By viewing specific and general domain datasets separately, the observation is interesting.\n* The experimental results show the method is effective."
            },
            "weaknesses": {
                "value": "* Though this method performs well on some NLU tasks, I'm curious about other diverse tasks like generation, reasoning and more difficult tasks in LLM era, since ICL can be used in many scenarios. \n* I'm curious that whether getting hidden states bring extra time cost, compared with top-k example selection in traditional ICL.\n* The performance on specific domain datasets is sometimes worse than the baseline. (maybe trying whether to use gold labels can be further explored)"
            },
            "questions": {
                "value": "* More analysis on time cost and latency brought by this method can be investigated.\n* What about the performance on other diverse tasks in LLM era, like reasoning, etc."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}