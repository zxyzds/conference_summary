{
    "id": "gInIbukM0R",
    "title": "Quantifying Emergence in Neural Networks: Insights from Pruning and Training Dynamics",
    "abstract": "Emergence, where complex behaviors develop from the interactions of simpler components within a network, plays a crucial role in enhancing neural network capabilities. We introduce a quantitative framework to measure emergence as structural nonlinearity, study the dynamics of this measure during the training process, and examine its impact on network performance, particularly in relation to pruning and training dynamics. Our hypothesis posits that the degree of emergence\u2014evaluated from the distribution and connectivity of active nodes\u2014can predict the development of emergent behaviors in the network. We demonstrate that higher emergence correlates with improved trianing performance. We further explore the relationship between network complexity and the loss landscape, suggesting that higher emergence indicates a greater concentration of local minima and a more rugged loss landscape. We show that this framework can be applied to explain the impact of pruning on the training dynamics. These findings provide new insights into the interplay between emergence, complexity, and performance in neural networks, offering implications for designing and optimizing architectures.",
    "keywords": [
        "Emergence",
        "training dynamics",
        "pruning",
        "landscape"
    ],
    "primary_area": "learning theory",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=gInIbukM0R",
    "pdf_link": "https://openreview.net/pdf?id=gInIbukM0R",
    "comments": [
        {
            "summary": {
                "value": "The authors use the framework of emergence as defined in Li et al 2023a to experimentally study the role of emergence during training. Emergence is varied by pruning the network or initializing it with high vs low emergence. Then variations in the training curves of these networks is attempted to be explained by absolute or relative emergence."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The authors attempt to show practical uses of Emergence as defined in Li et al 2023a, Li et al 2024 to explain the loss landscape and training curves in neural networks."
            },
            "weaknesses": {
                "value": "Since no new theory is developed, the authors should at least compare this framework to others that explain training behaviour, e.g. double descent or the lottery ticket hypothesis (see e.g. proofs in Malach et al 2020), if they want to position Emergence as a useful metric.\n\nFigure 2 seems just an illustration of what the authors imagine the energy landscape would look like. Why \"relative emergence can be conceptualized as reflecting the density of local minima within a given region of the loss landscape\" is not substantiated by the authors.\n\nFigures 3-8 appear to have been run without multiple seeds as I see no standard deviations around the plots? Various arguments are made about minor differences in training accuracy and emergence evolution when all these seem within the margin of noise around these curves."
            },
            "questions": {
                "value": "All the weakness above need to be addressed satisfactorily. I think this would require a lot more simulations and ( experimental or theoretical) justifications of the claims, along with comparisons to other frameworks that explain learning behavior of neural networks.\n\nLine 339: Rather than maintaining the learning rate constant, might be better to tune the learning rate as a hyperparameter across also 4 models. Because after pruning, depending on LayerNorm or otherwise, the fraction of total input to a neuron due any one parameter changes, and so the max learning rate without losing stability will also change and so learning rate should be tuned for each model separately. Or just use Adam.\n\nMinor:\nline 319: paramters -> parameters\nFigure 3/4: Please use colors that are not so similar. Like red, blue, etc. Currently all 4 lines are different shades of red, which are very difficult to distinguish."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this manuscript, the authors analyzed the learning dynamics of deep neural networks in image recognition tasks from the perspective of \u201cemergence.\u201d They defined \u201cemergence\u201d as the total number of pathways from an inactive node to active node in the neural network. The authors numerically compared \u201cemergence\u201d with training performance across various image recognition tasks, concluding that the \u201cemergence\u201d measure correlates with performance improvement."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The manuscript is clearly written. The emergence of functionality that the authors aimed to address is an important topic in deep learning that we have yet to understand well."
            },
            "weaknesses": {
                "value": "I'm afraid that this manuscript falls below the standard in several aspects.\n\nThe definition of \u201cemergence\u201d: The definition of \u201cemergence\u201d does not seem to capture the emergent phenomena discussed in the introduction and related work. The authors define \u201cemergence\u201d based on the number of active units in each layer, effectively making it a measure of hidden layer activity sparsity. Specifically, according to the definition provided in lines 200\u2013201, maximizing \"emergence\" would require all units in the first layer to be inactive ($a_1=0$) and all units in the last layer to be active ($a_N = n_N$). It suggests that the measure may not be meaningful in the context of emergent phenomena. \n\nRelationship between the loss landscape and the \u201cemergence\u201d measure: The discussion of this relationship lacks substance. The authors included only a schematic figure without providing analytical or numerical support.\n\nImpact of pruning on performance: It is well-established that neural networks can retain learning performance even with up to 99% pruning (e.g., Lee, Ajanthan & Torr, ICLR 2019). Thus, the observed high performance in a model pruned by 70% is not surprising.\n\nCorrelation between \u201cemergence\u201d and task performance: The presented figures do not clearly show a correlation between \u201cemergence\u201d and task performance, except in the 0% pruning scenario. Additionally, it is unclear what insight this correlation offers, given that activity sparsity naturally changes during training.\n\nLack of essential details in numerical experiments: Key details are missing. For instance, how is a hidden unit determined to be active? Does a unit need to exceed an activity threshold of 0.05 across all samples, or is it sufficient for the average activity over samples to exceed 0.05? What learning algorithm was used for training? What are the width and depth of the network?"
            },
            "questions": {
                "value": "Could you clarify the key details of the numerical experiments, especially the points above?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors tackle the concept of emergence, and specifically its relationship with training performance. The authors build recent work to define their chosen metric of emergence. The relationship with training is first studied empirically in experiments on (fashion)-MNIST and CIFAR-10. In parallel, the authors explore how the emergence relates to the loss landscape, and probe the concept of tuning under this light. Finally, the authors open up the discussion on how such an emergence metric can help understand training, pruning, and provide a tool for training convergence and consequently early training-termination."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is original, approaching the relevant question of quantifying the wide-spread phenomenon of emergence, which lacked rigorous treatment in the past. \n- The paper is well motivated. L35 for instance is a perfect example of a well-posed objective. \n- The paper builds on previous work on defining emergence, and applies it to the extremely well-studied setting of training in NNs performing classification tasks, thus making the results approachable to a wide audience. \n- The authors identify some covariates that could bias their estimates and correct for it, such as the number of parameters changing during pruning. \n- Some results are quite clear. For instance, relative emergence being correlated with pruning (Figure 4 and 8) is well supported. \n- The implications of an emergence metric for training termination are interesting."
            },
            "weaknesses": {
                "value": "Major:\n\n- Conclusions are made before results are presented (L62, L256, L266), and sometimes some claims are made with no supporting results at all (L242, L302). Furthermore, many results are presented as \"validating our hypothesis\". I would suggest removing this hypothesis-based presentation, and focus on an analysis of your results. This could be done by presenting the results of section 4 first, *then* dive into the analyses of the latter half of section 3.3(.0) and section 3.3.1. \n\n- Mathematical definitions lack support and introduction. The definitions rely on (Li et al, 2023), which \"provides rigorous mathematical foundation for understanding emergence in network structures\" (L77). The authors would benefit from integrating in their manuscript a more thorough summary and introduction to the definitions. For instance, it is highly unclear to me how one goes from equation on L166 to the main definition of emergence in L175, and how the latter can be derived from Eq. (8) in Appendix. Appendix A does not provide clarification unfortunately, only copy-pasting (exact replica with unproperly formatted references, see L648 and L669) from (Li et al., 2024). \n\n- Lack of surrounding literature. At a superficial level, the reference list is quite small, with more than half of the papers being preprints/non-peer-reviewed work. More concretely, the authors would benefit from including more literature on emergence in LLMs and neural scaling laws (see e.g. (Nam et al., 2024, NeurIPS) for recently published work that surveyed some of these topics).\n\n- Circular reasoning arguments are employed many times, starting with the abstract \"Our hypothesis posits that the degree of emergence [...] can predict the development of emergent behaviors in the network\", then further in L381 \"as the value of Emergence decreased, training accuracy change decrease, thereby supporting our hypothesis that emergence functions as a measure of prediction of emergent traits within a neural network.\", and again on L438 \"[...], supporting the idea that the emergence value is a predictor of emergent traits.\" . These are logical fallacies unfortunately and should be removed, in a favor of exposition in line with my first point above. \n\n- Repeated sentences and content, for instance L44-L47 and Paragraph beginning with L71 both makes similar comments on the loss landscape and its relationship with emergence, and see a further example in the circular reasoning point above. \n\n- Claims of significance should be backed by statistical tests.\n\nMinor \n- Repeated reference for (Li et al, 2023)\n- Remove \"intuitively\" in L251 if no intuition is provided. \n- Many typos, too many to list unfortunately. A thorough re-read is advised."
            },
            "questions": {
                "value": "- What are baselines for your metric of emergence? \n- How is the threshold of 0.05 chosen? How do your results vary as a function of that threshold? Weight values are related to performance in a very complex, non-trivial manner (for instance as highlighted in the rich v.s. lazy literature on learning dynamics), and while you do touch this aspect in section 4.2., the paper would benefit from more justification of the chosen bounds generally. \n- To provide some intuition, how does the metric behave under alternative transformations $\\Phi$ not representative of training, for instance, additive Gaussian noise on the weights? Why does it decrease over training? (Figure 4, 8)\n- What is Figure 2 showing? If it corresponds to scalar E over a parameter state space, what are these parameters, and how are the (un)pruned networks plotted against it?\n- I think the results on emergence and end of training are interesting: could you explore further the possible advantages, for instance by comparing how many epochs earlier you can predict the end of training than traditional measures of convergence?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors suggest a measure of sparseness they term emergence as a key property of neural networks. The measure is the number of paths between active and inactive nodes over training. There are several experiments in which networks are trained and emergence is measured. In some of these experiments, there is a relationship between the two."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Understanding how representations form while a neural network is training is an important open problem. The authors suggest a new measure to this end."
            },
            "weaknesses": {
                "value": "Overall, this seems like an initial exploration that is not yet ready for publication. \nMajor points are:\n1.\tThe paper uses many vague terms such as \u201cintricate patterns\u201d, \u201cemergence\u201d that are not properly defined.\n2.\tThe actual definition of emergence is a form of sparseness. But the paper does not discuss any work on sparseness in machine learning. Perhaps LASSO is a good place to start.\n3.\tThe main claim is a relation between emergence (or relative emergence) and performance. But there are no plots directly comparing the two.\n4.\tThe experiments are without any repetitions (different seeds, etc.), and thus it is hard to draw conclusions.\n5.\tThe figures are all without captions.\n6.\tThe work is based on the framework of Li et al 2023, which is an arxiv preprint. Because it is an unreviewed preprint, the current paper should contain the essential elements rather than refer to the previous work."
            },
            "questions": {
                "value": "7.\tVague wording: \u201d Higher emergence values in larger, more complex networks indicate a stronger potential to develop sophisticated behaviors and patterns during training\u201d\n8.\tREF Lei et al 2019 \u2013 no bibliographic information\n9.\tDefinition of emergence is given without intuition. Why the set x\\in G\\H? Using H as a trained network suggests that nodes x do not disappear over training. The next paragraph defines active nodes, but the order can be confusing.\n10.\tLine 216 has the definition of emergence. It would be helpful to introduce this earlier, as it would help the reader to follow the equations.\n11.\tLine 234: suddenly emergence can also be measured by weight change.\n12.\tFigure 2: There in no caption to describe what exactly is plotted here. What do the colors mean? What do the shadings mean? Is this based on some simulations? Is this an hypothesis?\n13.\tPruning is mentioned several times, but the exact process is not described.\n14.\tResults: change in accuracy is not defined (derivative over epochs?). Are there any statistics on accuracy? The differences in figure 5 between curves seem very noisy, and perhaps due to random seeds and not to pruning level. The numbers given in line 383 are without any error estimates.\n15.\tFigure 9,10. Emergence decreases with training \u2013 so it is negatively correlated with performance. But it\u2019s higher for the pre-trained networks \u2013 so it is positively correlated with performance. \n16.\tLine 466 further describes \u201cThe direct relationship between the change in training accuracy and the emergence value validates the the value being a predictor of the networks performance.\u201d. But the blue lower curve jumps in emergence at epoch 17 while the change in performance is around epoch 25. The purple curve (which is not color matched) has a non-trivial performance curve, but nothing corresponding in emergence."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}