{
    "id": "ZjvUcCAEK8",
    "title": "UMVMap: Improving Vectorized Map Construction via Multi-vehicle Perspectives",
    "abstract": "Prevalent vectorized map construction pipelines predominantly follow an end-to-end DETR-based paradigm. While these methods have achieved significant advancements, they are limited by their reliance on data from a single ego vehicle, which restricts their effectiveness and can lead to perceptual uncertainty in handling complex environmental scenarios. To address this limitation, we introduce a novel framework: Uncertainty-aware Multi-Vehicle Vectorized Map Construction (UMVMap). This framework effectively mitigates uncertainties by leveraging relevant non-ego information. UMVMap comprises two essential components: the Uncertainty-aware Multi-Vehicle Vectorized Map Construction Network (UMVMap-Net), which optimally integrates data from multiple vehicles, and the Uncertainty-aware Non-ego Vehicle Selection (UNVS) strategy, which identifies and incorporates the most informative non-ego data to minimize uncertainty. Comprehensive evaluations on the nuScenes dataset demonstrate that UMVMap significantly outperforms the single-vehicle MapTRv2 baseline by a margin of 9.1\\% and 9.9\\% respectively on the full and partial validation sets, with each of its components proving to be both effective and robust.",
    "keywords": [
        "multi-vehicle",
        "autonomous driving",
        "vectorized map construction"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "UMVMap: Improving Vectorized Map Construction via Multi-vehicle Perspectives",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ZjvUcCAEK8",
    "pdf_link": "https://openreview.net/pdf?id=ZjvUcCAEK8",
    "comments": [
        {
            "summary": {
                "value": "In this article, the authors present a novel online mapping framework called Uncertainty-aware Multi-Vehicle Vectorized Map Construction (UMVMap). This framework addresses the uncertainty in ego-vehicle HD map construction by integrating information from surrounding traffic participants.\n\nAccording to the description provided in the paper, UMVMap comprises two components:\n\nAn uncertainty-aware multi-vehicle vectorized map construction network (UMVMap-Net) consists of two sub-modules: the Uncertainty-guided Multi-Vehicle Information Integrator (UMVII), which integrates data from multiple vehicles, and the Segmentation Prior Guided Map Decoder (SPMDec), which decodes the integrated information. As noted by the authors in the paper, this structure enables UMVMap-Net to select data from various vehicles using an optimal strategy.\n\nIn addition, they utilize a Segmentation Prior Guided Map Decoder (UNVS) strategy to aid the model in identifying other traffic participants in regions where the ego-vehicle's perception results are highly uncertain.\n\nTheir comprehensive evaluation on the nuScenes dataset indicates that UMVMap has achieved what appears to be acceptable performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors propose a Vehicle-to-Vehicle (V2V) perception paradigm for the task of online mapping."
            },
            "weaknesses": {
                "value": "From my perspective, there are several concerns regarding this article.\n\nFirstly, I believe that the Vehicle-to-Vehicle (V2V) mapping approach lacks practical value. The deployment costs associated with this type of perception are prohibitively high, and it requires stable communication. Furthermore, this method would introduce significant latency, a critical issue that the authors have not addressed anywhere in the paper.\n\nSecondly, regarding the dataset selected by the authors, to the best of my knowledge, the nuScenes dataset is inadequate for supporting vehicle-to-vehicle (V2V) online mapping tasks. Additionally, the authors have not included specific details in the dataset section of the paper about how they processed the nuScenes dataset, which is typically utilized for single-vehicle perception tasks, to adapt it for multi-vehicle perception tasks.\n\nIn addition, in the StreamMapNet work, the authors implemented a more rational division of the online mapping dataset. However, it seems that they are still utilizing the previous dataset division, which may result in unfairness in the evaluation of the results.\n\nMoreover, the authors' experiments lack comprehensive comparisons with the latest works, such as HIMap, MapTracker, and HRMapNet.\n\nLastly, there are several unclear points and errors in the authors' writing. For instance, in Figure 2, I cannot understand how the number of ego vehicles can exceed 10,000."
            },
            "questions": {
                "value": "1. Please explain in detail how the authors used the nuScenes dataset to complete V2V online mapping.\n\n2. Why didn't the authors conduct more experiments on Argoverse2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores a new task: multi-vehicle cooperative vectorized map construction, aiming to leverage information from non-ego vehicles to mitigate perceptual uncertainty in complex scenarios. The paper introduces a framework called Uncertainty-aware Multi-vehicle Vectorized Map Construction (UMVMap) for this task. UMVMap comprises two components: the Uncertainty-aware Multi-vehicle Vectorized Map Construction Network (UMVMap-Net) and the Uncertainty-aware Non-ego Vehicle Selection (UNVS) strategy to optimally leverage information from multiple vehicles. Experimental results demonstrate that UMVMap outperforms state-of-the-art single-vehicle methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper presents UMVMap, a pioneering work exploring vehicle-to-vehicle collaborative perception in vectorized map construction. Experimental results demonstrate that UMVMap outperforms state-of-the-art single-vehicle methods.\n\n2. UMVMap consists of several key components: the Uncertainty-guided Multi-Vehicle Information Integrator (UMVII), the Segmentation-guided Query Initialization Mechanism (SQI), and the Uncertainty-aware Non-ego Vehicle Selection Strategy (UNVS). Ablations demonstrate the effectiveness of each component."
            },
            "weaknesses": {
                "value": "1. The proposed UMVMap lacks significant novelty. It incorporates the idea of confidence-aware communication from existing collaborative perception methods, such as Where2comm [1], to integrate intermediate features from the single-vehicle method MapTR [2] for the cooperative task. Please answer the following questions in the rebuttal with details: (1) What are the challenges of the cooperative vectorized map construction task? (2) What are the key contributions of the proposed UMVMap compared to existing collaborative perception and map construction methods? (3) How have these contributions addressed the aforementioned challenges?\n\n2. Limited discussion is provided on real-world implementation. Communication efficiency is essential in the cooperative autonomous driving community. In this work, raw sensor data from non-ego vehicles is transmitted to the ego vehicle, leading to significant communication costs and transmission delays.\n\n3. There are several errors in the paper, such as the incorrect citation of StreamMapNet and duplicate citations of MapVR.\n\n[1] Hu et al. Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps. NeurIPS 2022. \\\n[2] Liao et al. MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction. ICLR 2023."
            },
            "questions": {
                "value": "1. Please address the weaknesses. \n\n2. What is the communication volume of the proposed UMVMap, and how does the method handle communication delays in real-time applications?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposed a novel framework to extend the previous single-agent map construction framework into a multi-agent scenario where they could leverage other cameras from the collaborative vehicles to handle the long-range and occlusion issues limited by the single-agent viewpoint. They proposed a uncertainty-aware method to fuse the multi-vehicle information."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is novel in the field of multi-agent collaborative map construction task since there is no much literature discussing on map construction with the help of multi-agent collaboration. The paper is overall well-written and easy to follow, and the enhancement is significant as described by the authors."
            },
            "weaknesses": {
                "value": "Overall, the contribution is limited at the aspect that, it is not surprising to know if we leverage multiple cameras at different view points the results will improve. In fact, the paper seems focusing less on the problem of multi-agent collaboration, i.e., the communication volume, localization error, perturbations that are essential to the collaboration of different agents. We could regard that the problem becomes easier with the help of multi-agent, but the paper does not address much on the issues inherent of multi-agent scenario, which limits the scope of the contribution."
            },
            "questions": {
                "value": "Some specific questions:\n1. The paper lacks of generalizability on the proposed methods (only show in one baseline and one dataset), and it feels necessary to augment their experiments by leveraging the recent advancement of cooperative datasets (i.e., DAIR-V2X) and apply for more baselines.\n2. The paper lacks of discussion on why having more than 2 agents result in performance drop, which is counter-intuitive. This could be a place where the method could be further enhanced (only selecting the closest vehicle, which is probably vanilla). \n3. As mentioned above, the paper should have some more discussions on the viability when applying the framework to real-world online inference scenario (where it's the core of multi-agent problem, what/where/how to communicate with each other)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel framework, Uncertainty-aware Multi-Vehicle Vectorized Map Construction (UMVMap), aimed at enhancing vectorized map construction for autonomous driving by integrating data from multiple vehicles. The authors highlight the limitations of existing DETR-based methods that rely solely on data from a single ego vehicle, leading to perceptual uncertainty in complex environments. UMVMap addresses these issues by employing two main components: the Uncertainty-aware Multi-Vehicle Vectorized Map Construction Network (UMVMap-Net) and the Uncertainty-aware Non-ego Vehicle Selection (UNVS) strategy. The proposed framework shows significant performance improvements over the single-vehicle baseline (MapTRv2), with experimental results indicating enhancements of 9.1% and 9.9% on the full and partial validation sets of the nuScenes dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "\u2022\tNovel Framework: The introduction of UMVMap, which utilizes multi-vehicle data for vectorized map construction, is a significant contribution to the field. Emphasizing the importance of effectively aggregating information from diverse views.\n\u2022\tUNVS Strategy: The development of the UNVS strategy allows for the identification and selection of non-ego vehicles that provide complementary information, particularly in areas with high uncertainty.\n\u2022\tComprehensive Evaluations: The thorough evaluation of UMVMap against a robust dataset establishes its superiority over existing single-vehicle methods and highlights the effectiveness of its components through ablation studies."
            },
            "weaknesses": {
                "value": "\u2022\tLimited Scope of Evaluation: While the framework performs well on the nuScenes dataset, additional evaluations on diverse datasets or real-world scenarios would strengthen the claims of generalizability.\n\u2022\tComplexity of Implementation: The proposed framework may involve a more complex implementation compared to simpler methods, which could deter practical adoption.\n\u2022\tScalability Concerns: The paper does not adequately address the scalability of the system in scenarios with a significantly higher number of vehicles, which could impact performance and computational resources.\n\u2022\tReproduce concern: code and datasets were not provided in this paper, and making it unclear whether the experimental results can be reproduced."
            },
            "questions": {
                "value": "\u2022\tExpanded Evaluation: Consider incorporating additional datasets to demonstrate the robustness and versatility of UMVMap in various environments. Show more information on the computational cost of the method, particularly in larger datasets or more complex domains.\n\u2022\tSimplification of Framework: Explore opportunities to simplify the implementation process or provide more detailed guidelines for practical deployment. \n\u2022\tAddress Scalability: Discuss potential strategies or modifications to handle scalability issues as the number of vehicles increases in real-world applications.\n\u2022\tEnsure reproducibility: Access to project dataset source and code is expected to make sure results are reproducable."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}