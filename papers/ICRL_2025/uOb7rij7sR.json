{
    "id": "uOb7rij7sR",
    "title": "CryoGEN: Cryogenic Electron Tomography Reconstruction via Generative Energy Nets",
    "abstract": "Cryogenic electron tomography (Cryo-ET) is a powerful method for visualizing cellular structures in their native state, but its effectiveness is limited by anisotropic resolution caused by the missing-wedge problem, complicating the interpretation of tomograms. IsoNet, a deep learning method, addresses these challenges by iteratively reconstructing missing-wedge information and improving the signal-to-noise ratio of tomograms. However, IsoNet relies on recursively updating the predictions, which can lead to training instability and model collapse. In this study, we present CryoGEN, an improved energy-based method that effectively mitigates resolution anisotropy. Our approach eliminates the need for recursive subtomogram generation, offering a more stable and consistent methodology. Applying CryoGEN to various datasets\u2014including immature HIV particles and neuronal synapses\u2014demonstrates its capability to enhance structural interpretability. Moreover, CryoGEN holds significant potential for improving the functional interpretation of cellular tomograms in future high-resolution (Cryo-ET) studies, thereby providing substantial value and advancing progress in biological research.",
    "keywords": [
        "CryoET",
        "Cryogenic Electron Tomography",
        "Generative Model",
        "Energy Model"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=uOb7rij7sR",
    "pdf_link": "https://openreview.net/pdf?id=uOb7rij7sR",
    "comments": [
        {
            "title": {
                "value": "To Reviewer dAoL - Part 2"
            },
            "comment": {
                "value": "3. **Constructing The Distribution $p_x$**\n   \n    One of the key challenges\u2014and a main contribution of our work\u2014is constructing the distribution $p_x$ from a distribution $p_y$. We outline this process step-by-step:\n\n    * 1. Defining the Energy Function $E(y)$: Our objective is to define an energy function such that points near any data point in $\\mathcal{Y} = \\{y_i\\}$ have low energy, while points distant from all data points have high energy. For this, contrastive learning presents itself as an effective choice. This method assigns lower $E$ values to regions with high data density and higher $E$ values elsewhere, which naturally leads us to use GANs as a tool (refer to [2] for more details).\n\n\n    * 2. Constructing $p_y$: The next question is how to construct $p_y$ given a trained energy model $E$. We address this by representing the distribution using energy-based models as $p_y(y) \\propto \\exp(-E(y))$, in line with a Boltzmann distribution.\n    \n    * 3. Constructing $p_x$: Leveraging the isotropy property of CryoET, we define $\\log p_x(x) \\propto \\frac{1}{|\\mathcal{R}|} \\sum_{R \\in \\mathcal{R}} \\log p_y(\\mathcal{T}_M \\circ R \\circ x)$, where $R$ denotes the rotation operation.\n\n    By integrating all these steps, we arrive at the final algorithm.\n\n4. **Streak-like Artifacts** \n   \n   For the experimental results presented in Figure 9, there is indeed no ground truth for comparison. However, we argue that the original results shown in IsoNet exhibit strong streaking artifacts. Streaking in imaging and signal processing refers to unwanted lines or artifacts in images, often caused by incomplete data. In CryoET, these artifacts arise due to the missing wedge problem, where limited angles are used for capturing images, resulting in elongated, streak-like artifacts in the reconstruction. In contrast, our method does not exhibit these streaking artifacts at all compared to IsoNet.\n\n5. **IsoNet\u2019s Instability**\n\n   We apologize for not explicitly addressing IsoNet\u2019s instability. This is a general observation we have made, as IsoNet requires careful fine-tuning at each iteration. An intuitive explanation is that IsoNet\u2019s recursive training approach can lead to error accumulation, which in turn causes instability. Specifically, in IsoNet, training $g_{\\theta_t}$ depends on the predictions generated by $g_{\\theta_{t-1}}$ (see our previous response - *Intuition Behind Consistency Loss*). As a result, any intermediate failure in model $g_\\theta$ can propagate through subsequent cycles, ultimately compromising the entire training process. This is similar to an open-loop control system, where errors accumulate due to the lack of feedback. In contrast, our algorithm does not rely on recursive updates, resulting in faster training and greater stability.\n\n6. **Addressing Mode Collapse in GANs**\n\n    The original GANs are known to encounter both *mode collapse* and *training instability* issues, but we address these as follows:\n\n    * Mode Collapse:\n    Mode collapse is less problematic for reconstruction in CryoET, as our goal is to find a single solution or a set of solutions $\\tilde{x}$ that maximize $p(x|y)$ given the observation. While mode collapse may reduce diversity, it does not compromise quality.\n\n    * Training Instability:\n    By introducing noise $\\epsilon$, our method aligns with the theoretical framework in [3] (the foundational paper on Wasserstein GANs), effectively addressing our specific one-to-many mapping problem illustrated in motivation section while significantly improving training stability.\n\n7. **Incorporation of Rotations**\n\n   The incorporation of rotations is used to derive $p_x$ from $p_y$ by leveraging the isotropy property of CryoET.\n\n8. **Experimental Results**\n\n   We have tested our model and IsoNet on noisy synthetic data of Vipp1 assembly. Our method provides a better reconstruction of the missing wedge with reduced noise. Additional results will be included in the supplementary file shortly.\n\n\n---\n\n**References:**\n\n[1] Chen, Wenlin, et al. \"Diffusive Gibbs Sampling.\" *International Conference on Machine Learning*, 2024.\n\n[2] Murphy, Kevin P. \"Probabilistic machine learning: Advanced topics - Chapters 24 and 26.\" MIT press, 2023. \n\n[3] Arjovsky, Martin, and L\u00e9on Bottou. \"Towards principled methods for training generative adversarial networks.\" *International Conference on Learning Representations*, 2017."
            }
        },
        {
            "title": {
                "value": "To Reviewer dAoL - Part 1"
            },
            "comment": {
                "value": "We thank the reviewer for the detailed comments and instructive feedback. We also appreciate the recognition of our contribution. We will address your remarks one by one and hope to clarify your concerns. We apologize for any lack of clarity in our current version.\n\n1. **Motivation Clarification**:\n\n    * Gaussian Mixture Prior\n\n        * The key observation here is that for each observation $y$ (incomplete data with missing wedge), there may be multiple solutions that align the observed outcome. By \"align\", we mean that for a given $y$, $X|y = \\arg\\max p(x|y)$ can represent a set of solutions rather than a single one. In such cases, the log posterior distribution $\\log p(x|y)$ can exhibit multiple maxima\u2014a fairly common scenario.\n\n        * Our goal is to determine a parameterized function $g_\\theta$ (usually a neural network) that maximizes $\\log p(g_\\theta(y)|y)$, which is the primary objective of this paper. In contrast, IsoNet\u2019s objective is to directly minimize $\\sum_{x_i \\in X|y} ||g_\\theta(y) - x_i||^2_2$, where each $x_i$ is a maximum of $\\log p(x|y)$.\n\n        * The distribution $p(x|y)$ is not necessarily a Gaussian mixture; rather, it is generally assumed to be non-convex. Since the exact form of $\\log p(x|y)$ is unknown, we adopt the Gaussian mixture prior as a general assumption\u2014an approach that has proven effective in current generative tasks within deep learning (For example, diffusion models approximate the data distribution as a Gaussian mixture by convolving the discrete data with Gaussian distributions at different levels of variance, which has demonstrated strong performance).\n\n    * Lack of Ground Truth for $\\log p_x(x)$\n\n        In CryoET reconstruction tasks, there is no ground truth for $\\log p_x(x)$, so we approach this as an *unsupervised* learning task, unlike the concurrent work, where $p(x)$ is assumed to be known. However, we propose a way to express $p_x(x)$ by first approximating the distribution $p_y$ based on observations of the incomplete data $\\{y_i\\}$ and then defining $\\log p_x(x) \\propto \\frac{1}{|\\mathcal{R}|} \\sum_{R \\in \\mathcal{R}} \\log p_y(\\mathcal{T}_M \\circ R \\circ x)$. This formulation leverages the isotropy and rotational symmetry properties of CryoET, representing a key contribution of our work.\n\n    * Addressing One-to-Many Mapping\n\n        As mentioned earlier, if the cardinality of $X|y = \\arg\\min p(x|y)$ is greater than one, it is impossible to find a parameterized function $g_\\theta$ that can map a single observation to all possible values of $x$, as this creates a one-to-many mapping. To address this, we use $y + \\epsilon$, where $\\epsilon$ has full support over the real domain, giving it infinite cardinality and effectively converting the problem into a many-to-fewer mapping.\n\n2. **Intuition Behind Consistency Loss**\n\n    This is the original objective function used in IsoNet. Although we lack reference or ground truth for the missing wedge, we do have it for other parts, enabling us to proceed with a pseudo-supervised approach. The steps of IsoNet can be outlined as follows:\n\n    * Step 1: First, we fill in the missing wedge for the incomplete data using the prediction model $g_\\theta$ to generate $\\tilde{x}$.\n\n    * Step 2: Next, we rotate the sample and apply a different missing wedge via $\\mathcal{T}_M$ to produce $\\tilde{y}$.\n\n    * Step 3: Since we have the label for the artificially created missing wedge, we can train $g_\\theta$ in a supervised manner by minimizing $||\\tilde{x} - g_\\theta(\\tilde{y})||_2^2$.\n\n    At the start of training, we incorporate this objective into our algorithm as well. The reasoning is that, when sampling from a distribution $p(x)$ using MCMC, a reasonable starting point for the Markov chain is $\\int_x x p(x) \\, dx$, even though this is not a minimum (see [1] for example). In our case, rather than sampling, we directly learn the mapping from $p_y$ to $p_x$ via $g_\\theta$, but the intuition remains similar. Nonetheless, including this objective function still aids in improving the convergence of training $g_\\theta$."
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel deep learning based method to solve the missing wedge problem, which is an inverse problem that arises in cryogenic electron tomography (cryo-ET). \n\nIn cryo-ET, the goal is to reconstruct the 3D density of a biological sample (e.g. a cell) from a set of 2D projections of the density. Due to limitations during acquisition, there is a wedge-shaped region of viewing directions where no projections can be recorded. As a result, the set of projections does not uniquely determine the 3D density of the sample. \n\nThe authors propose a method called CryoGEN that aims to fill in the missing data of the missing wedge. The method is self-supervised (does not require clean ground truth for training) and fits a missing wedge reconstruction network directly to the tomogram(s) whose missing wedge is to be filled. The fitting of this reconstruction network is regularized by an energy function, represented as another neural network, which is learned together with the reconstruction network in an adversarial manner.\n\nBased on a theoretical motivation, and experiments on synthetic data and two real-world tomograms, the authors argue that the energy function yields improved missing wedge reconstruction performance over two closely related state-of-the-art missing wedge methods (IsoNet and DeepDeWedge). \n\n\n**Recommendation:** I do not recommend publishing the paper at ICLR *in its current form*. This is mainly because I found parts of the paper (especially the motivation and training of the energy function and the construction of the losses) unclear. However, since the missing wedge problem is important, and since CryoGEN performs better than state-of-the-art baselines in some cases. \nI recognize the potential of the method and am willing to raise my score if the authors better explain their method and why it outperforms the baselines (IsoNet and DeepDeWedge)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- CryoGEN outperforms IsoNet on the clean synthetic data (Section 5.2) and gives a cleaner reconstruction of the (real) HIV capsids (Figure 10).\n- The missing wedge problem addressed in the paper is important and challenging.\n- The authors applied CryoGEN to two real-world tomograms, demonstrating the practical applicability of the method."
            },
            "weaknesses": {
                "value": "- I cannot really follow the motivation in Section 3, where the authors argue that IsoNet produces an average of two 3D densities $x_1$ and $x_2$ that produce the same measurement $y_0$ under the forward map $\\mathcal{T}_M$. The following is unclear to me:\n\t- Why do the authors \"choose\" a Gaussian mixture prior for IsoNet (lines 170 - 171)? If I understand correctly, IsoNet does not use a prior for regularization.\n\t- What is the concrete energy function ($E(x) = - \\log p(x)$) that gives a better solution?\n\t- Why does adding noise to the measurements $y$ solve the problem that there are many $x$ that map to the same $y$ (lines 194 - 199)?\n\n- I do not understand the motivation and intuition behind the consistency loss (equation (7)). Why is the reconstruction mesh $g_\\theta$ applied to y and then again after $\\mathcal{T}_M$?\n\n- The authors give no intuition as to why the energy function (which looks like a prior to me) can be learned directly on the data one wants to reconstruct. I would also appreciate more explanation as to why the energy function is learned in an adversarial manner (equation (9)).\n\n- The authors argue that CryoGEN outperforms IsoNet on the purified ribosome tomogram (Figure 9), but I find the CryoGEN tomogram visually much less appealing. It seems to contain less detail and the contrast of the ribosomes looks too strong to me. (Since there is no ground truth, it is impossible to measure which reconstruction is actually better). \n\n- The experiments on synthetic data (Section 5.2) are done on noiseless data. However, the low signal-to-noise ratio (as low as <10%) is one of the main challenges in cryo-ET. Therefore, it would be good to include an experiment that demonstrates how CryoGEN handles strong noise. Synthetic data is suitable for such an experiment because clean ground truth is available.\n\n- In the abstract, the authors state that IsoNet suffers from model collapse as it updates its own training data. This aspect is not discussed in the paper."
            },
            "questions": {
                "value": "- Why is the energy function learned in an adverserial way (Equation (9))?\n- Does the adverserial training of the energy function lead to any instabilities during training?\n- Why does the \"Posterior\" loss (Equation 8) involve random rotations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a new method for reconstructing 3D structures from cryo-electron tomography (Cryo-ET) data. It aims to address a common issue in Cryo-ET reconstruction known as the missing wedge problem. The proposed algorithm, CryoGEN, tackles this by using an energy-based model that learns to generate realistic 3D structures from incomplete information. The model includes two main components: an energy model, which scores how realistic a structure is, and a prediction model, which reconstructs the missing regions. CryoGEN also adds noise to the input data during training to handle the challenges posed by the one-to-many mapping issue. This approach enables the model to create accurate and clear reconstructions by filling in missing areas based on learned patterns from data. The paper uses four datasets to evaluate the effectiveness of CryoGEN, particularly in comparison to the baseline solution, IsoNet. Results show that CryoGEN produces clearer and more complete reconstructions with better preservation of structural details. On three of the datasets, quantitative evaluation is performed, demonstrating that CryoGEN surpasses IsoNet."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper addresses the missing wedge problem, a major issue in Cryo-ET that causes incomplete and blurred 3D reconstructions.\n\n2. The paper proposes a novel deep learning solution for Cryo-ET reconstruction. Using GANs and energy models is a reasonable approach.\n\n3. Diverse datasets are considered for evaluation, including both simulated and real tomograms."
            },
            "weaknesses": {
                "value": "1. The techniques used in CryoGEN are fairly standard in general computer vision. There doesn\u2019t appear to be any part of the algorithm specifically motivated by the unique characteristics of Cryo-ET data, such as the missing wedge. For example, the motivation discussed in Section 3 is very common in general generative models like VAE and EBM. Also, EBM and GAN models have been widely used in general inpainting problems but not discussed as related work.\u00a0\n\n2. It's unclear why Equation (8) represents the posterior distribution. Is Equation (8) an implementation of Equation (3)?\n\n3. This paper improves upon IsoNet by incorporating the energy model and noise perturbation on the input. Which of these additions is more essential to the strong performance of CryoGEN?\n\n4. Regarding computational complexity, the paper provides inconsistent information. Section 5.3 reports that CryoGEN is much faster than IsoNet. However, CryoGEN is clearly more complex than IsoNet in terms of architecture. The authors also mention that the energy model converges more slowly in Section 4.1.\n\n5. As mentioned in related work, DeepDeWedge can be used to address denoising and missing wedges simultaneously. Why is DeepDeWedge not included in the quantitative evaluation?"
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the limitations of\u00a0Cryogenic Electron Tomography (Cryo-ET)\u00a0in reconstructing 3D structures of cellular components due to the\u00a0missing wedge problem, which creates anisotropic resolution in tomograms. The authors introduce\u00a0CryoGEN, a generative energy-based model designed to tackle the missing wedge problem more effectively and stably, without requiring recursive prediction."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The use of energy-based models for addressing the missing wedge problem is novel and shows promise in improving reconstruction quality.\n2. CryoGenic is computationally efficient, achieving significant runtime reductions compared to IsoNet, which would be valuable in large-scale biological studies\n3. The paper is well-written and easy to follow"
            },
            "weaknesses": {
                "value": "1. Couldn't find big technical issues.\n2. A more detailed discussion would be needed (e.g., limitations, what would be the future work).\n3. Typo: Page 1, line 32 \u2013 Repeated phrase \"insights insights into.\""
            },
            "questions": {
                "value": "1. What is the SNR of the data shown in Figure 7? I\u2019m curious to see 3D reconstruction results (comparison with IsoNet) with higher noise (SNR 0.01 or 0.001) levels.\n2. On page 6: \"At the inference stage, we begin by cropping the complete tomogram into multiple overlapping subtomograms\" \u2013 Could you specify the number of crops used?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concerns"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "CryoGEN's author(s) proposed a new method called CryoGEN, aimed at addressing the \"missing wedge\" problem and the challenge of low signal-to-noise ratio in cryo-electron tomography (Cryo-ET). CryoGEN combines generative adversarial networks (GANs) with energy-based models to produce more consistent and high-quality 3D reconstructions. Compared to traditional weighted back-projection (WBP) and existing deep learning methods like IsoNet, CryoGEN effectively fills in missing information and reduces blurring artifacts.\n\nKey contributions :\n\n1. The introduction of CryoGEN, which uses energy-based models to handle multiple possible solutions, avoiding the blurring effect caused by simple averaging.\n\n2. The inclusion of consistency loss and noise injection to ensure that generated images maintain fidelity to the original data while preserving diversity in the results.\n\n3. Experimental validation on multiple datasets, such as HIV viral particles and neural synapses, where CryoGEN outperforms existing baseline methods in metrics like peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and Fourier shell correlation (FSC).\n\nIn all, the authors announces a more effective solution for reconstruction in Cryo-ET, showing significant improvements in quality and stability. Future work includes improving training efficiency, automating parameter adjustments, and extending its applications to other cryo-electron microscopy domains."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality: The originality of the paper lies in its attempt to improve and combine existing methods by using generative adversarial networks (GANs) and energy-based models to address the missing wedge problem in cryo-electron tomography (Cryo-ET). \n\nQuality: The quality of the research is validated through experiments on multiple datasets, including synthetic samples and real biological samples (e.g., HIV viral particles and neural synapses). However, the experimental design lacks in-depth comparison with other state-of-the-art methods, especially the absence of sufficient ablation studies to demonstrate the importance of each model component.\n\nClarity: The paper is generally well-written with a logical flow, but some parts are explained too briefly, particularly the mathematical description and implementation details of the energy model, which might make it difficult for non-expert readers to fully understand the working principles.\n\nSignificance: The potential impact of CryoGEN in the field of cryo-electron tomography is limited. Although the method improves reconstruction quality to some extent, the degree of improvement is relatively modest, and challenges may arise when applied to more complex datasets."
            },
            "weaknesses": {
                "value": "Lack of Novelty: Although CryoGEN combined GANs and energy-based models, this architecture still relies on existing methods and lacks truly groundbreaking innovation. For instance, the combination of GANs and energy-based models has already been widely applied in other fields, and the paper does not sufficiently demonstrate the unique contribution of this combination in Cryo-ET. We recommend citing some recent literature, such as \"Your GAN is Secretly an Energy-based Model and You Should Use It\" by Tong Che et al. (2020), which discusses the connection between GANs and energy-based models and their effectiveness in data reconstruction. Furthermore, it is suggested to elaborate on the specific aspects where this combination lacks novelty in Cryo-ET applications, such as similarities in loss functions, model architecture redundancy, or training strategy limitations, and clarify how CryoGEN distinguishes itself from existing methods to enhance the contribution statement of the paper.\n\nIncomplete Theoretical Explanation: The mathematical description and implementation details of the energy model are overly simplified. It is recommended to provide a more detailed description of the energy model's training process, including key equations and their roles in optimizing the model. Adding intuitive examples or visual aids, such as diagrams illustrating the training dynamics of the energy model, would make the content more accessible to non-expert readers. Specifically, expanding on equations (3) and (4) would help clarify how the energy model interacts with the GAN during training. These additional details would help address potential confusion and make the feedback more actionable.\n\nLack of In-Depth Result Analysis: Although the experimental results show performance improvement, the authors do not provide in-depth discussion on the reasons behind these key performance improvements. It is recommended to provide a more detailed analysis of why CryoGEN performs better on specific datasets compared to other methods, which would better support the validity of its contributions."
            },
            "questions": {
                "value": "1. Lack of Comparative Experiments: It is suggested to add comparisons with other recent methods, particularly with more challenging and complex models, to better validate the advantages of CryoGEN.\n\n2. Supplemental Theoretical Explanation: Could the authors provide more detailed explanations regarding the implementation details of the energy model? Adding intuitive examples and diagrams would help readers understand its complexity."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}