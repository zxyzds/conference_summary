{
    "id": "mHkbi3XM58",
    "title": "Conditional density estimation for video prediction with score-based models",
    "abstract": "Temporal prediction is inherently uncertain, and representing the ambiguity in natural image sequences is a challenging high-dimensional probabilistic inference problem. For natural scenes, the curse of dimensionality renders explicit density estimation, let alone integration, statistically and computationally intractable. We describe an implicit regression-based framework for learning and sampling the conditional density of the next frame in a video given the past few observed frames. We show that sequence-to-image deep networks trained on a simple resilience-to-noise objective function extract adaptive representations for temporal prediction. Synthetic experiments demonstrate that this score-based framework handles occlusion boundaries:  unlike classical methods that average bifurcating temporal trajectories, it chooses among likely trajectories, selecting more probable options with higher frequency. Furthermore, local linear analysis of networks trained on natural image sequences reveals that the representation automatically weights predictive evidence by reliability, which is a hallmark of probabilistic inference.",
    "keywords": [
        "temporal prediction",
        "diffusion models",
        "denoising",
        "conditioning",
        "occlusion boundaries",
        "cue combination"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "Probabilistic video prediction with conditional denoiser networks relies on representations that automatically adapt to the signal.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=mHkbi3XM58",
    "pdf_link": "https://openreview.net/pdf?id=mHkbi3XM58",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a simplified diffusion-based framework for modeling conditional density, with demonstrations in video prediction. The key idea, derived from the empirical Bayes formulation of score-based models, involves learning a denoising function that implicitly infers noise levels and removes noises of arbitrary magnitude from an input. This denoiser yields an estimation of a family of score functions across noise levels. This framework thus removes the time axis in a standard diffusion model, and pursues a direct regression approach, allowing easy analysis of the learned representations. This framework is evaluated on synthetic videos, as well as natural image sequences."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "The main contribution of this paper is mostly conceptual. The key ideas of (1) employing a direct regression approach for learning score-based models and (2) the sampling strategy from the learned denoising function are both intriguing. It is perhaps a bit surprising to see how they can work even on some toy data. \n\nThe proposed framework presents an interesting and significantly simplified alternative to existing diffusion models.\n\nThe paper is well-written overall. The results, including a detailed analysis of the learned representations, are elaborated."
            },
            "weaknesses": {
                "value": "Despite the conceptual novelty, the practicality of the proposed framework is somewhat questionable. Considering the problem of video prediction, it is probably fair to say that the proposed framework provides at best an alternative solution to diffusion models. While diffusion models have demonstrated impressive results for video generation and prediction, the proposed framework is solely demonstrated on \u201ctoy\u201d data (small scale, low resolution synthetic and real videos). It is not clear if the proposed framework can scale up to larger datasets or higher resolution videos."
            },
            "questions": {
                "value": "It will be very helpful to include a discussion that draws the boundary between the proposed framework and well-known diffusion models.\n\nA demonstration of the proposed framework on high resolution videos will help to strengthen the experiments. If this is not possible, a discussion about the scalability might be beneficial."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The manuscript formulates probabilistic forecasting of the next video frame as a generative modeling task. The proposed method allows to recover plausible instances of the next frame by iteratively sampling a denoising deep generative model through Tweedie's formula. In the experiments, the denoising model is a U-Net with up to \\tau=2 conditioning frames. The model optimizes the L2 reconstruction loss which corresponds to log p(x|y,c). The experiments have been performed on a synthetic dataset (moving leaves) and DAVIS32."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- forecasting future frames in video is an important problem\n- generative modelling is an appropriate tool for the task at hand due to ability to account for multimodal future"
            },
            "weaknesses": {
                "value": "- the proposed method appears quite straight-forward and in line with previous recent work in the field\n[a] Gabriel Loaiza-Ganem, Brendan Leigh Ross, Luhuan Wu, John P. Cunningham, Jesse C. Cresswell, Anthony L. Caterini. Denoising Deep Generative Models. ICBINB 2022\n\n- the manuscript does not report quantitative comparison with related work in the field; for instance, it would be insightful to report MS-SSIM and LPIPS on Cityscapes and KITTI, as in [b] and references therein.\n[b] Yue Wu, Qiang Wen, Qifeng Chen. Optimizing Video Prediction via Video Frame Interpolation. CVPR 2022: 17793-17802."
            },
            "questions": {
                "value": "- equation (1) is not clear due to index s having two distinct roles (also, it would be helpful to clarify whether s>t is feasible)\n- it would be good to clarify whether f(y,c) is E[x|y,c] as in (2) or f(y,c) is E[x|y,c] - y as in (7)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper describes a probabilistic formulation for next-frame-prediction.  The paper develops statistical machinery based on learned denoising functions in what appears to be a sampling approach, although the details are vague and hard to follow.  The method is tested on a synthetic, procedural dataset and a small natural image sequence dataset."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The paper motivates a strong problem about the lack of transparency in next-frame generation (or general video generation) papers.\n- The base formulation for the next prediction is sound."
            },
            "weaknesses": {
                "value": "- The development of the technical ideas in the paper are difficult to follow, moving from an initial problem formulation to denoising without any reasonable discussion.   Then the discussion jumps around with relatively basic statistical machinery without giving any details of the actual method.   Better description of what the novelty in the method would be helpful.  More concrete relationship between the current work and the related art is very important to help the reader understand the current method and its contributions.\n\n- The overall approach seems similar to other probabilistic generative methods, even those noted in the paper.\n\n- The evaluation approach is not well described or convincing.  There are not comparisons to component methods or baselines.  It would improve the paper if comparative baselines were included.  The notion of occlusion, which may be useful is introduced seemingly out of nowhere.  It would improve the paper if there is more discussion motivating this evaluation.  However, evaluation should also describe general generation techniques.  The natural image sequences tested are few.  It would improve the paper to demonstrate capability on establish video generation benchmarks with established video generation evaluation protocols, beyond PSNR.  The details of the networks used are unclear.  It would improve the paper to have a thorough network description, even if in the appendix.\n\n- (Minor) Typos exist in the paper; e.g., line 89 focuese"
            },
            "questions": {
                "value": "- The temporal sampling of an image sequence is an artifact of the technology; how does this impact the modeling proposed.  The basic technical premise is disarming: \"The next frame in an image sequence is a single event with several possible outcomes...\"  The next frame in an image sequence has very very many possible outcomes; it's also not clear what \"an event\" means (in the context of the earlier part of this bullet).  It would be helpful if the paper included a discussion of the impact of this discrete sampling of continuous time along with a discussion of the potential impact this has on the method's performance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a score-based model for conditional density estimation tailored to video prediction. The authors demonstrate that single-step denoising results in blurred predictions, highlighting the necessity of iterative denoising\u2014a standard approach in score matching, diffusion, and flow matching models\u2014to capture sharper, more plausible outcomes. Through a straightforward dataset and network, they further illustrate the distinct contributions of past frames and the current noisy frame in shaping accurate predictions."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper defines score matching formulation for video prediction in a really accurate way. They also show how adding noise is helpful both in training and inference."
            },
            "weaknesses": {
                "value": "It\u2019s challenging to identify the novel contribution of this paper, as it seems to be positioned somewhat independently, with limited engagement with prior work on video prediction, particularly with diffusion models. More explicit connections to existing approaches and an analysis of what this model uniquely offers in comparison would strengthen the work."
            },
            "questions": {
                "value": "Could the authors clarify how their approach to conditional density estimation for video prediction differs from existing score-based or diffusion models?\n\nWhat specific insights or improvements does this work offer over current state-of-the-art methods in video prediction?\n\nHow does the analysis of the network's adaptive behavior contribute to our understanding of video prediction models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}