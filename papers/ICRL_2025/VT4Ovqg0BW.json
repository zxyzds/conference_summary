{
    "id": "VT4Ovqg0BW",
    "title": "Functional-level Uncertainty Quantification for Calibrated Fine-tuning on LLMs",
    "abstract": "From common-sense reasoning to domain-specific tasks, parameter-efficient fine tuning (PEFT) methods for large language models (LLMs) have showcased significant performance improvements on downstream tasks.  However, fine-tuned LLMs often struggle with overconfidence in uncertain predictions, particularly due to sparse training data. This overconfidence reflects poor epistemic uncertainty calibration, which arises from limitations in the model's ability to generalize with limited data. Existing PEFT uncertainty quantification methods for LLMs focus on the post fine-tuning stage and thus have limited capability in calibrating epistemic uncertainty. To address these limitations, we propose Functional-Level Uncertainty Quantification for Calibrated Fine-Tuning (UQ4CT), which captures and calibrates functional-level epistemic uncertainty during the fine-tuning stage via a mixture-of-expert framework. We show that UQ4CT reduces Expected Calibration Error (ECE) by more than 25% while maintaining high accuracy across 5 benchmarks. Furthermore, UQ4CT maintains superior ECE performance with high accuracy under distribution shift, showcasing improved generalizability.",
    "keywords": [
        "Uncertainty Quantification",
        "Large Language Models",
        "Mixture of Experts",
        "Parameter Efficient Fine Tuning"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "A method to quantify and calibrate epistemic uncertainty in LLMs with Mixture of Experts.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=VT4Ovqg0BW",
    "pdf_link": "https://openreview.net/pdf?id=VT4Ovqg0BW",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a novel method called Functional-Level Uncertainty Quantification for Calibrated Fine-Tuning (UQ4CT), aimed at addressing overconfidence in large language models (LLMs) during fine-tuning, especially in scenarios with limited or sparse data. Traditional parameter-efficient fine-tuning (PEFT) approaches often fail to accurately calibrate epistemic (model-related) uncertainty, leading to overly confident predictions. To overcome this, UQ4CT incorporates a Mixture-of-Experts (MoE) framework with LoRA (Low-Rank Adaptation), enabling dynamic, prompt-dependent expert selection that captures and calibrates functional-level uncertainty throughout the fine-tuning process. The paper\u2019s main contributions are:\n1. A new approach to quantify epistemic uncertainty at the functional level during fine-tuning, using MoE to dynamically adjust uncertainty based on input.\n2. A calibration loss function that aligns uncertainty with predictive correctness, encouraging expert exploration for incorrect predictions and reinforcing correct predictions.\n3. Empirical results showing that UQ4CT reduces Expected Calibration Error (ECE) by over 25% across multiple benchmarks while maintaining high accuracy, demonstrating robustness both within distribution and under distribution shifts."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper introduces a novel approach by integrating functional-level epistemic uncertainty directly into the fine-tuning process of LLMs, departing from conventional post hoc calibration. The unique combination of MoE with LoRA enables dynamic, prompt-dependent uncertainty modeling, addressing both parameter efficiency and overconfidence in fine-tuned models. The proposed calibration loss function further aligns model confidence with predictive accuracy, reducing overconfidence in a novel, functional manner.\nThe paper is validated with comprehensive experiments across multiple benchmarks, supported by baseline comparisons and ablation studies.\nThe paper is well-structured and accessible, with clear explanations and effective use of visual aids, making complex concepts understandable.\nUQ4CT addresses a critical need for reliable uncertainty estimation in high-stakes applications by enhancing calibration and robustness under distribution shifts. This advancement strengthens the foundation for trustworthy AI, especially in domains where reliable predictions are essential despite sparse data."
            },
            "weaknesses": {
                "value": "UQ4CT\u2019s calibration loss relies on clear correctness metrics, limiting its applicability to tasks with definitive right or wrong answers. This restricts its use in open-ended tasks, such as generative dialogue or summarization. To broaden applicability, future work could explore calibration methods based on human feedback scores or soft accuracy measures instead of binary correctness.\nThe use of MoE for dynamic expert selection, while effective, could lead to scalability issues with larger models or multi-task scenarios due to increased computational demands. Optimizing expert selection with pruning or adaptive sparsity methods could help make UQ4CT more efficient and feasible for resource-limited applications."
            },
            "questions": {
                "value": "1. Since UQ4CT\u2019s calibration relies on binary correctness, how might this approach be adapted for tasks where \u201ccorrectness\u201d is less definitive, such as open-ended text generation or summarization? \n2. Could the authors elaborate on any experiments or initial explorations in applying UQ4CT to such tasks? \n3. Exploring approaches that rely on alternative correctness signals, such as soft scoring or feedback-based calibration, might broaden the applicability."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new approach called Functional-Level Uncertainty Quantification for Calibrated Fine-Tuning (UQ4CT) to calibrate the functional-level epistemic uncertainty via the LoRA MoE architecture."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper introduces a unique uncertainty quantification (UQ) method for fine-tuning large language models (LLMs) using a Mixture-of-Experts (MoE) approach\n2. In this paper, UQ4CT reportedly achieves a 25% reduction in Expected Calibration Error (ECE) across multiple benchmarks, which is a substantial improvement."
            },
            "weaknesses": {
                "value": "1. The novel calibration loss function is mentioned as one of the contributions. However, the paper lacks detailed theoretical analysis to illustrate why this specific design especially the loss is effective for uncertainty calibration.\n2. Although the paper compares UQ4CT with other PEFT-based uncertainty quantification techniques, a more comprehensive comparison with non-PEFT-based methods might provide a clearer view of its advantages and limitations. \n3. The whole framework is built on LoRA, and can it be applied to more general settings?\n4. There are a lot of hyper-parameters, such as the number of top gate routers (why use 2 in this paper), and N, s, L. How to set them in practice and is there any theoretical insight for these choices?"
            },
            "questions": {
                "value": "Please refer to the weakness part. \nFor example: \n1. Can the authors add some theoretical analysis?\n2. Can more baseline methods be compared?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a novel calibration method for LLMs that is applicable already during the fine-tuning stage of the model. This is achieved by leveraging the specific nature of the LoRA MoE architecture, using the weights of the Top-K router layers to quantify the functional epistemic uncertainty. The epistemic uncertainty calculated this way is used with the predictive accuracy in a specific loss function (as one part of a triple loss function for the overall loss). The authors claim to reduce ECE substantially while not impairing the predictive performance, but even resulting in better predictive performance and making it more robust to e.g. distribution shift. These findings are backed by two experiments: First, they show ECE decrease across 5 MCQA benchmarks while maintaining better (or at least on par) accuracy compared to the baselines. Second, they use a subset of the benchmarks to create distribution shift scenarios to prove the robustness of their approach."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The experiments are outlined very clearly and explained and motivated comprehensively. This makes the paper easy to follow and understandable to the reader. The additional experiments (distribution shift and ablation) are well-motivated and contribute to the overall experimental setup.\n- The problem tackled in this research is widely known and highly problematic, yet there is no definite and generally applicable solution to it. Hence this work, tackling it effectively for LoRA MoE architectures is an important contribution to the field in general.\n- Not only do the authors introduce a method that can substantially improve the model calibration, but it also shows strong model performance in terms of accuracy."
            },
            "weaknesses": {
                "value": "- The ablation study/studies could be more elaborated, i.e. e.g. examining what the influence of the different terms in the loss is, or how sensitive performance is to the hyperparameters alpha and beta in the loss. I think such examinations are important to understand what\u2019s going on and how brittle such triple losses are.\n- The approach is specifically tailored to the nature of the LoRA MoE architecture as it critically depends on leveraging the weights of the Top-K Routing layers of the MoE. While this seems to work pretty well here, one might also consider this a limitation of the approach in general since it is not generally applicable."
            },
            "questions": {
                "value": "- In Equation (5): What exactly do M\u2019 and a\u2019 refer to? I believe this is not explicitly specified anywhere\n- Why did you place the \u201cRelated work\u201d section after your methodology? I think it introduces important concepts to the reader who would thus benefit from reading this before your explanations in the \u201cMethodology\u201d section.\n- L. 326: I personally think it\u2019s not optimal to call something \u201csignificant\u201d that you actually did not formally test with a statistical test. Maybe it\u2019s better to use a formulation like \u201cnotable\u201d or \u201csubstantial\u201d?\n- L 359: Just to be sure, what do you mean by \u201cbin size of 15\u201d? I think it is more common to communicate this in terms of \u201cnumber of bins (of equal size usually\u201d? \n- L. 447 More of a comment than a question, but I think a sole subsubsection (5.4.1) does not really make sense, probably you should rather just add this subsubheading to the heading of subsection 5.4."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a method for epistemic uncertainty quantification in the context of LoRA fine-tuning, which is also compatible with a mixture-of-experts setup. The authors introduce a specialized training loss, designed to capture the difference between predictive accuracy and functional-level epistemic uncertainty. When applied to the Llama2 model, the proposed method shows improvements across a variety of datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The pipeline and method developed in this paper appear well-founded, and the paper is generally well-written."
            },
            "weaknesses": {
                "value": "The biggest weakness of this paper is the limited experimental effort. Specifically, the experiments are conducted on only one LLM, and there is very little ablation or other study to investigate the additional properties of this UQ method. While I don\u2019t consider the number of pages a deterministic measure of effort, the brevity of the experimental section does suggest a lack of thoroughness in the design of experiments.\n\nAdditionally, beyond the lack of comprehensiveness, the paper offers very little empirical or theoretical insight into why this approach is effective. I also find that the paper lacks depth overall."
            },
            "questions": {
                "value": "1. In equation (9), what is the term $\\mathcal{L}_b$? I don't think this is a good practice to put it in the reference. It should be at least written in the appendix.\n\n2. In table 1 and 2, what is the numeric values in the subscript?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}