{
    "id": "vwOq7twk7L",
    "title": "Image-level memorization detection via inversion-based inference perturbation",
    "abstract": "Recent studies have discovered that widely used text-to-image diffusion models can replicate training samples during image generation, a phenomenon known as memorization. This raises significant concerns regarding data privacy and copyright infringement. Existing detection methods primarily focus on identifying memorized prompts, but a critical challenge remains: directly detecting whether a given image is memorized by the model without access to the original prompts. We refer to this challenge as image-level memorization detection, where current methods fall short. In this work, we first uncover two key characteristics of memorized images under perturbed inference: a notable similarity discrepancy and a large magnitude of text-conditional noise prediction. Building on these insights, we propose Inversion-based Inference Perturbation (IIP), a novel framework for image-level memorization detection. Our approach uses unconditional DDIM inversion to derive latent codes that contain core semantic information of original images and optimizes non-memorized prompt embeddings for effective perturbation. The resulting metrics show distinct characteristics of memorized images compared to non-memorized ones, offering a robust basis for detection. We construct a comprehensive setup for the image-level memorization detection task, carefully curating datasets to simulate realistic memorization scenarios. With this setup, we evaluate our IIP framework across three different memorization settings, demonstrating its state-of-the-art performance in identifying both training and generated memorized images, even in the presence of augmentation defenses.",
    "keywords": [
        "Text-to-image diffusion model",
        "data memorization detection",
        "DDIM Inversion"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "we propose a simple yet effective image-level memorization detection method, namely Inversion-based Inference Perturbation (IIP).",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vwOq7twk7L",
    "pdf_link": "https://openreview.net/pdf?id=vwOq7twk7L",
    "comments": [
        {
            "summary": {
                "value": "This paper investigates the memorization limitation of the Stable Diffusion model to help protect the training data\u2019s privacy. The paper proposes a new task: image-level memorization detection, which is different from existing works that detect memorization during inference. Then, based on two insights that memorized images under perturbed inference have a notable similarity discrepancy and a large magnitude of text-conditional noise prediction, the paper proposes IIP framework that uses unconditional DDIM inversion to derive latent noises for the images and conducting perturbations. The paper also construct a setup for this new task and demonstrated better performance than baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This work tackles an important and practical problem: diffusion models can memorize their training data, potentially leading to privacy concerns. These issues are thoroughly discussed and effectively motivated in the paper.\n2. The paper is well-presented, clearly structured, and easy to follow. \n3. This paper further proposes a new task of image-level memorization detection and a correspondingly designed method for this new task."
            },
            "weaknesses": {
                "value": "1. The motivation for the proposed new image-level memorization detection task is based on a misunderstanding of the related work. Specifically, in lines 46-47, the paper claims that \u201cHowever, these approaches rely heavily on access to the original prompts, which is often impractical.\u201d Since all baselines and this paper experiment on the text-to-image Stable Diffusion model, using text prompts is practical. Also, the baseline methods do not need an organized prompt list that contains triggering prompts since they can obtain detection signals (such as TCNP in [1]) during the inference process. They can then detect the potential memorized images being generated within only one inference step and with good accuracy. Such lines of method are actually more practical than the proposed image-level memorization detection task, as the memorization is detected and halted from the source (way before the image is even generated). Thus, the proposed task is of limited practical significance. I would suggest the authors consider investigating unconditional diffusion models (where there is no text prompt) and see if the proposed method works.\n2. The finding that large TCNP correlates with memorization is not novel. I understand that the paper differs in performing DDIM inversion to the clean image, however, it is actually the identical finding of [1] that a noise can present large TCNP even after the first step of DDIM denoising.\n\n[1] Detecting, Explaining, and Mitigating Memorization in Diffusion Models."
            },
            "questions": {
                "value": "Please see the weaknesses regarding motivation and novelty."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a new method for identifying whether an image was part of the diffusion model training set, without access to the prompt used for generation. As far as the authors know, they are the first to identify this task. To this end - inference under prompt perturbations is examined for memorized / not memorized samples, with the aid of DDIM's inversion capabilities (specifically unconditional inversion to avoid dependency on the prompt). Under this process, they find two key properties that differentiate between memorized and non-memorized samples. Building on their insights, they propose a Inversion-based Inference Perturbation (IIP) -  a novel method for the task at hand and out-perform the competitors on an extensive test suite."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The results present SOTA performance with respect to the defined task and the evaluated existing methods.\n\n2. The experiments are extensive: Evaluate both success, sensitivity, and soundness.\n\n3. The writing is good and articulate.\n\n4. Novelty of the method: The authors propose for the first time to experiment with inference with perturbed prompts for the task at hand."
            },
            "weaknesses": {
                "value": "1. Novelty of the task: Please have a look at [1], [2] - these work engage in membership inference without using prompts, as far as I know. Could the authors clarify how their proposed task of image-level memorization detection differs from membership inference, particularly in light of the cited works that perform membership inference without prompts?\n\n[1] Matsumoto, T., Miura, T., & Yanai, N. (2023, May). Membership inference attacks against diffusion models. In 2023 IEEE Security and Privacy Workshops (SPW) (pp. 77-83). IEEE.\n\u200f\n\n[2] Hu, H., & Pang, J. (2023, November). Loss and Likelihood Based Membership Inference of Diffusion Models. In International Conference on Information Security (pp. 121-141). Cham: Springer Nature Switzerland.\n\n2. Comparison to other methods: Could the authors add comparisons to relevant methods that do not require prompt access (e.g. the methods mentioned above)?\n\n3. Additional experiments with a different stable diffusion model would substantiate the proposed method's advantage.\n\n4. Requiring inversion of the model is quite restrictive, considering how quickly generative technology changes, and how rare it is for generative models to enable such inversions. Can the authors think of ways adapt their findings to non-invertible scenarios?\n\n5. Minor Weaknesses: \na. In all related figures - change \"ori\" to the full word \"original\".\nb. The expression \" images exhibit greater similarity discrepancy \" in the introduction is rather confusing"
            },
            "questions": {
                "value": "Please refer to Weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose an algorithm named IIP to detect memorized images generated by LDMs. The algorithm features two observations during DDIM generation with perturbed prompts (1) a notable similarity discrepancy (2) a large magnitude of text-conditional noise prediction."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(1) The observed phenomenon seems to be universal and statistically notable.\n\n(2) Within the experiment setup of this paper, the algorithm shows promising performance.\n\n(3) The presented figures are illustrative and depictive."
            },
            "weaknesses": {
                "value": "**Major**\n\n(1) The biggest concern I have about this paper is its high overlap with existing work [1], making its technical and empirical contribution weak. I shall support my claim with the following facts: (a) The metric TCNP/MTCNP is proposed by [1], which also applies the metric to memorization detection. (b) Perturbing the textual embedding during DDIM generation is already used by [1] to mitigate memorization. (c) minimizing the magnitude of text-conditional prediction is already used by [1] to achieve the perturbed prompt embedding. It wasn't until I carefully re-read [1] that I noticed so much overlap between the proposed algorithm and an existing work. I believe the authors fail to give enough credit to the existing work, as all this necessary information is not shown in the submitted manuscript.\n\n(2) The authors tend to use big words like \"SOTA\" and \"pioneer\". However, I am not fully convinced by the importance of the \"image-level detection\" setting proposed by the authors. If we can detect memorization as early as in the generation phase like [1], why would we bother doing the \"image-level detection\"?\n\n[1] IMAGE-LEVEL MEMORIZATION DETECTION VIA INVERSION-BASED INFERENCE PERTURBATION; https://openreview.net/pdf?id=84n3UwkH7b\n\n**Minor**\n\n(1) Only SD v1.4 is considered, which is not enough because the performance of the proposed algorithm might be highly affected by the architecture, the training data, and the sampling configuration of the LDMs.\n\n(2) Missing period in line 181 \"during the subsequent generation process [period here] Interestingly...\""
            },
            "questions": {
                "value": "Please see the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a method for image-level memorization detection. It is motivated by an analysis showing two key characteristics of memorized images under perturbed inference: similarity discrepancy and a large magnitude of text-conditional noise prediction. The key idea of the method seems to be using an unconditional DDIM inversion to derive latent codes and optimizing non-memorized prompt embeddings for effective perturbation. The method is evaluated on a number of datasets, showing strong ability to detect memorized images."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The results are strong and the method seems reliable in detecting memorized images\n* There is an analysis section to motivate the approach and explain why it may work\n* The paper is generally well-written and easy to read"
            },
            "weaknesses": {
                "value": "* The prompts appear to be an input to the optimization procedure that generates the optimized prompt embedding, so even if the prompts are not directly paired with the images, we may not be able to say the method does not rely on prompts (as may seem from some parts of the paper). This can be discussed more to explain to what extent we do not need access to the original prompts.\n* All settings are based on Stable Diffusion v1.4: while this is a common model for image generation, one would like to see if the same method works across different models. There are currently various image generation models available, so it would be good to try the method on more - e.g. two more - to see if this method generalizes more broadly.\n\nMinor:\n* Ori prompt would be easier to understand if it was written as original prompt or orig. prompt"
            },
            "questions": {
                "value": "* To what extent are the perturbed prompts related to the original prompts? Can we really say we do not use the original prompts in any way? E.g. if we use something derived from them\n* How expensive is it to run the method for an image to test if it is memorized?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}