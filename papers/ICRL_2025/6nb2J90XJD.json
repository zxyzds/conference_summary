{
    "id": "6nb2J90XJD",
    "title": "Unsupervised Multiple Kernel Learning for Graphs via Ordinality Preservation",
    "abstract": "Learning effective graph similarities is crucial for tasks like clustering, yet selecting the optimal kernel to evaluate such similarities in unsupervised settings remains a major challenge. Despite the development of various graph kernels, determining the most appropriate one for a specific task is particularly difficult in the absence of labeled data. Existing methods often struggle to handle the complex structure of graph data and rely on heuristic approaches that fail to adequately capture the global relationships between graphs. To overcome these limitations, we propose Unsupervised Multiple Kernel Learning for Graphs (UMKL-G), a model that combines multiple graph kernels without requiring labels or predefined local neighbors. Our approach preserves the topology of the data by maintaining ordinal relationships among graphs through a probability simplex, allowing for a unified and adaptive kernel learning process. We provide theoretical guarantees on the stability, robustness, and generalization of our method. Empirical results demonstrate that UMKL-G outperforms individual kernels and other state-of-the-art methods, offering a robust solution for unsupervised graph analysis.",
    "keywords": [
        "Graph Kernel; Unsupervised Learning; Multiple Kernel Learning"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "UMKL-G combines multiple graph kernels in an unsupervised way, preserving the ordinal relationships between graphs.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=6nb2J90XJD",
    "pdf_link": "https://openreview.net/pdf?id=6nb2J90XJD",
    "comments": [
        {
            "summary": {
                "value": "The authors propose an unsupervised multiple kernel learning method that produces a weighted sum of kernels given a set of kernels and a dataset."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Multiple kernel learning is a relevant topic. In particular, the unsupervised creation of a suitable kernel from a set of kernels given a dataset is a nontrivial problem."
            },
            "weaknesses": {
                "value": "- the basic definition (Def. 1) is imprecise and I could not follow the paper, as it remains unclear (to me) which ordinal relationship is supposed to be maintained"
            },
            "questions": {
                "value": "I have severe problems understanding\n> Definition 1:\n> Consider the graph $G_i$ where its similarities to $G_j$ and $G_r$ are respectively given by the learned kernel values $k_{ij}$ and $k_{ir}$. \n> The ordinal relationship between $G_j$ and $G_r$ with respect to $G_i$ are preserved if, for any weights $w$: $k_{ij} > k_{ir}$. \n\nIt seems that this definition is self-referential, as only the learned kernel values $k$ are mentioned. Is there another similarity that should be preserved? If $k$ is to be learned, then it probably should retain the ordinal relationship of another similarity (or similarities?). Or am I missing something? I am sorry, but this does not make sense to me right now and I have to recommend to reject this paper at the current point in time."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The article introduces a novel approach for unsupervised multiple kernel learning on graphs. The task is to combine several weak kernels for unsupervised learning scenarios by learning a set of weights. The main idea is to preserve the data topology by maintaining ordinal relationships, i.e., the order of similarities between graphs. This is achieved through a designed probability simplex. The authors provide comprehensive theoretical results, addressing aspects such as robustness to kernel perturbations and generalization capabilities. Finally, the approach is experimentally evaluated by performing graph clustering tasks on standard molecular datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The approach offers a novel solution to an understudied problem.\n- The technical quality of the theoretical part of the work is high.\n- The theoretical analysis is comprehensive, featuring a range of results on properties and detailed proofs. \n- While the authors present their work in the realm of graph kernels, their approach can be applied to arbitrary kernels."
            },
            "weaknesses": {
                "value": "- While most parts of the article are well described, some central intuitions that motivate the approach are not sufficiently addressed. For instance, why is P a more accurate representation of the data's inherent geometry'? \n- The evaluation is fairly limited, relying solely on the clustering task. I understand that due to space limitations, the authors focused on the theoretical parts. However, a more comprehensive evaluation (even if it's on synthetic data) should have been done. Particularly, none of the theorems of section 4.6 are evaluated in the experiments. \n- Some details on the baseline methods, UMKL, and sparse-UMKL, are unclear. For instance, the statement that the authors \"experimented with an approach that learns graph representations and kernel weights simultaneously\" requires further elaboration.\nMinor weaknesses:\n- Some of the numbers in Table 1 do not coincide with the numbers in the supplementary. (E.g., ACC for BZR and MUTAG.)\n- It would be helpful if the authors could include the definitions of the clustering metrics in the appendix."
            },
            "questions": {
                "value": "1. I would appreciate it if the authors could comment on the limited experimental evaluation (see weaknesses). \n2. Can you explain why any parameter o>1 results in exactly the same performance for the selected clustering metrics? Can this be generalized or is it only the case in the considered experiments?\n3. What ground truth was used e.g. for the clustering accuracy metric (ACC)? \n4. Did the authors consider the simple baseline where each weight is set to 1/M?\n5. It is mentioned in section 4.5 that the learned composite kernel can directly be applied in supervised tasks. Have the authors tested this on graph classification tasks using the molecular benchmark graph datasets? \n6. Can the authors elaborate on the choice of representing graphs using a GCN for the baseline methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces Unsupervised Multiple Kernel Learning for Graphs (UMKL-G), a method that combines multiple graph kernels without the need for labeled data. By preserving ordinal relationships among graphs through a probability simplex, UMKL-G aims to provide a unified, adaptive kernel learning approach for unsupervised graph-level clustering."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper presents an interesting concept by preserving ordinal relationships among graphs in an unsupervised setting, addressing a unique aspect of unsupervised kernel learning.\n2. The authors provide proofs for stability, robustness, and generalization, which strengthen the theoretical foundation of the method.\n3. The empirical validation across eight datasets provides a reasonable breadth of testing for the proposed approach."
            },
            "weaknesses": {
                "value": "1. Although the paper claims novelty in ordinal preservation, the methodology heavily relies on established techniques in probability simplex construction and multiple kernel learning. The main contribution appears to be an incremental adaptation rather than a breakthrough.\n2. The method does not convincingly outperform modern baselines or recent self-supervised clustering methods, especially given that existing techniques like sparse-UMKL and GCN-based methods already achieve comparable results in unsupervised scenarios. This raises questions about the practical impact and added value of UMKL-G.\n3. While the paper proposes potential extensions to broader data types (referred to as UMKL-X), there is no experimental evidence or conceptual framework supporting its effectiveness beyond graph-specific tasks. This reduces confidence in the generalizability and adaptability of the approach across different types of structured data."
            },
            "questions": {
                "value": "1. How does UMKL-G handle datasets with minimal ordinal relationships, or where graph similarities are uniform across samples?\n2. Could the authors clarify the method\u2019s sensitivity to the initial weight settings and the power hyperparameter o in the kernel concentration step?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a new way to combine multiple graph kernels into a unified kernel value. The algorithm preserves topology through ordinal relations. This is mainly achieved by capturing important neighborhood structures by boosting the stronger similarities between graphs towards a set of target probabilities."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Theoretical results are provided that guarantee stability and robustness of the method (e.g. Lipschitz continuity, robustness to kernel perturbations).\n- UMKL-G outperforms existing methods on graph clustering benchmarks, demonstrating robust performance in unsupervised contexts on real and synthetic datasets.\n- The method is applicable to a variety of datasets, making it versatile and potentially useful for many applications."
            },
            "weaknesses": {
                "value": "- It is not entirely clear to me how this work differs significantly from existing MKL approaches, apart from the focus on ordinal relations. That is, the methodology, although well executed, seems to me an incremental extension of existing techniques. \n- Some parts of the paper are technical and dense, which although I appreciate very much, makes the text particularly complicated to follow.\n- Comparisons with other techniques, in particular more recent methods based on Graph Neural Networks (GNN), are limited. This reduces the perception of how competitive UMKL-G is compared to emerging technologies.\n- Perhaps some focus on scalability is lacking, as testing on large datasets limits the evaluation of the method's effectiveness in real, large-scale scenarios.\n- Large parts of the introduction and Section 2 are redundant. \nThe writing is dense and the explanation of concepts complex. Greater clarity could make the work more accessible to a wider range of readers."
            },
            "questions": {
                "value": "- How does UMKL-G really stack up against GNN-based methods for clustering graphs? A more in-depth comparison could be useful to estimate the applicability despite methodological differences.\n- What is the impact of the scalability of the method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}