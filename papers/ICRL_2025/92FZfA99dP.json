{
    "id": "92FZfA99dP",
    "title": "Learning to Teach: Improving Mean Teacher in Semi-supervised Medical Image Segmentation with Dynamic Decay  Modulation",
    "abstract": "Medical image segmentation is essential in medical diagnostics but is hindered by the scarcity of labeled three-dimensional imaging data, which requires costly expert annotations. Semi-supervised learning (SSL) addresses this limitation by utilizing large amounts of unlabeled data alongside limited labeled samples. The Mean Teacher model, a prominent SSL method, enhances performance by employing an Exponential Moving Average (EMA) of the student model to form a teacher model, where the EMA decay coefficient is critical. However, using a fixed coefficient fails to adapt to the evolving training dynamics, potentially restricting the model's effectiveness. In this paper,\nwe propose Meta MeanTeacher, a novel framework that integrates meta-learning to dynamically adjust the EMA decay coefficient during training. We approach proposed Dynamic Decay Modulation (DDM) module in our Meta MeanTeacher framework, which captures the representational capacities of both student and teacher models. DDM heuristically learns the optimal EMA decay coefficient by taking the losses of the student and teacher networks as inputs and updating it through pseudo-gradient descent on a meta-objective. This dynamic adjustment allows the teacher model to more effectively guide the student as training progresses.\nExperiments on two datasets with different modalities, i.e., CT and MRI, show that Meta MeanTeacher consistently outperforms traditional Mean Teacher methods with fixed EMA coefficients. Furthermore, integrating Meta MeanTeacher into state-of-the-art frameworks like UA-MT, AD-MT, and PMT leads to significant performance enhancements, achieving new state-of-the-art results in semi-supervised medical image segmentation.",
    "keywords": [
        "Meta learning",
        "Medical image segmentation",
        "semi-supervised learning"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "Apply meta learning to mean teacher framework as a plug and play module.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=92FZfA99dP",
    "pdf_link": "https://openreview.net/pdf?id=92FZfA99dP",
    "comments": [
        {
            "summary": {
                "value": "This paper presents the 'Meta Mean Teacher', an approach for semi-supervised medical image segmentation. Building on the Mean Teacher model, which leverages exponential moving average (EMA) to create a stable teacher model from a student model, this framework introduces the Dynamic Decay Modulation (DDM) module. DDM dynamically adjusts the EMA decay coefficient based on both the student and teacher losses, improving the model's adaptability during training."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper addresses semi-supervised learning in medical image segmentation with a novel meta-learning approach, introducing the Dynamic Decay Modulation (DDM) module to adjust the EMA decay coefficient dynamically. \n\nThe paper strengthens its empirical evaluation by testing on three datasets, covering different imaging modalities."
            },
            "weaknesses": {
                "value": "While the paper builds on the Mean Teacher model, which is well-established in semi-supervised learning, it may lack substantial novelty as the framework mainly modifies an existing approach. Although the Dynamic Decay Modulation (DDM) module adds a new layer of adaptability, many similar extensions to Mean Teacher already exist, potentially limiting the paper's contribution to novel methodology.\n\n\nThe experimental scope appears limited as it only includes limited number of baseline methods, i.e. Mean Teacher variations like UAMT with UNet and VNet, models that have already been well-explored in this context. The paper\u2019s experiments may be restricted by a limited range of labeled-to-unlabeled data ratios, which does not fully capture the model\u2019s performance across different semi-supervised settings. Testing with a wider variety of label-scarcity scenarios would offer more robust insights into the framework's adaptability and practical applicability in real-world cases where data availability varies."
            },
            "questions": {
                "value": "(1) How do you ensure that comparisons are fair in semi-supervised learning scenarios? For example, I understand that in some cases, we can control the percentage of labeled and unlabeled data, such as using 5% or 10% labeled data. However, the feature distribution of labeled and unlabeled data cannot be guaranteed to be the same.\n\n\n(2) The exclusive use of VNet as the backbone may limit the generalizability of the results, as it does not reflect performance across more commonly used architectures like UNet or newer ViT-based UNets.\n\n(3) In Table 2, I observe that VNet\u2019s performance is significantly lower than others when only 5% of data is labeled, but it is only slightly lower when 10% is labeled. Could you explain why this discrepancy occurs? Additionally, could you provide more results for cases with 20%, 50%, 80%, and 90% labeled data, if available?\n\n(4) In table 3, why VNet outperforms UA-MT when 20% are labeled."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces the Meta Mean Teacher framework, a novel approach to improve semi-supervised medical image segmentation. Traditional Mean Teacher models use a fixed Exponential Moving Average (EMA) decay coefficient to update the teacher model, but this fixed value often limits model effectiveness. Meta Mean Teacher addresses this limitation by introducing a Dynamic Decay Modulation (DDM) module that adaptively adjusts the EMA decay coefficient based on training dynamics. This dynamic adjustment optimizes the student-teacher learning process, enabling better performance in tasks with limited labeled data.\n\nKey contributions of this work include:\n\n1. Adaptive EMA Decay: The DDM module optimizes the EMA decay coefficient, enhancing the model's adaptability and enabling it to capture richer training representations.\n2. Plug-and-Play Architecture: Meta Mean Teacher is designed to integrate seamlessly into existing models, improving performance across various Mean Teacher-based methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Dynamic Adaptability: By incorporating the Dynamic Decay Modulation (DDM) module, the framework dynamically adjusts the EMA decay coefficient (\u03b1) during training. This adaptability ensures that the teacher model evolves effectively with the student model, allowing more precise guidance as training progresses. This approach addresses a common limitation in fixed-coefficient Mean Teacher models, which often fail to account for varying training dynamics.\n\n2. Plug-and-Play Module: The Meta Mean Teacher framework is designed as a modular system, making it highly compatible with existing models based on the Mean Teacher architecture. This modularity allows easy integration into various semi-supervised frameworks like UA-MT, AD-MT, and PMT.\n\n3. Enhanced Stability and Robustness: The framework benefits from the Mean Teacher method\u2019s inherent stability due to EMA but improves upon it by learning an optimal decay coefficient through meta-learning techniques."
            },
            "weaknesses": {
                "value": "1. High Computational Overhead: The adaptive EMA adjustment via DDM introduces complexity and requires more computational resources. The dynamic adjustment process, which includes cloning and iterative updates of both teacher and student models, may not be feasible for real-time or resource-limited applications, especially when processing large 3D medical imaging data.\n\n2. Limited Exploration of Other Adaptive Techniques: While the paper focuses on dynamically adjusting the EMA decay coefficient, other hyperparameters (like learning rates or loss weight factors) could also impact model performance in semi-supervised learning. The focus on only one parameter might restrict the overall optimization potential, as additional adjustments could further enhance the segmentation quality."
            },
            "questions": {
                "value": "1. On the impact of \u03b1=0.01: Why does the model show improvement when \u03b1 is set to 0.01? This result seems to contradict the explanation provided in Section 3.1.\n\n2. The use of fixed \u03b1 in the ablation experiments in Section 4.3: In Section 4.3, why was the average fixed \u03b1 method chosen for comparison? From Figure 1, we can see that lower \u03b1 values \u200b\u200b(such as 0.03, 0.05, and 0.1) significantly degrade the performance. In contrast, \u03b1 of 0.97 achieves performance higher than 0.84. Doesn't this general average comparison seem a bit biased?\n\n3. The impact of \u03b1 greater than 0.5: From Table 1, we can see that when \u03b1 is greater than 0.5, its impact on performance becomes less significant. Test whether randomly selected \u03b1 values \u200b\u200bgreater than 0.5 are beneficial, thereby potentially improving the results?\n\n4. Suspicion about the data in Section 4.4 compared with other methods: Why is your experimental setting different from that in \"Alternative Diversified Teaching of Semi-Supervised Medical Image Segmentation\", but most of the state-of-the-art data (including LA and Pancreas-NIH datasets) are the same as the data in that paper? Does this indicate that the data is directly borrowed?\n\n5. The m symbol in Figure 2: What does \"m\" mean in Figure 2? Is this symbol redundant?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the EMA decay coefficient within the MT semi-supervised framework, fully tapping into the potential of the MT framework. Additionally, it introduces a novel meta-learning strategy to dynamically find the optimal EMA decay coefficient during the training process. Experiments conducted on two medical image datasets demonstrate that this method achieves superior performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper introduces a novel meta-learning strategy to adjust the EMA decay coefficient, fully tapping into the potential of the MT semi-supervised framework.\n2. This paper introduces a strategy to adjust the EMA decay coefficient to improve semi-supervised segmentation performance, which could be a meaningful contribution to this field.\n3. The extensive experimental results show the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. I have not observed many innovative aspects in the application of meta-learning to the field of semi-supervised medical image segmentation. Part of the reason for this is the clarity of the writing; it is currently unclear what significant differences exist between the proposed DDM and previous meta-learning strategies. If there are no substantial differences, then the methodological contribution of this approach appears to be quite limited.\n2. Could the authors explain what potential drawbacks a fixed EMA decay coefficient might have on the MT framework, particularly in the context of medical image processing?\n3. The motivation is unclear. I do not understand why a dynamic change in $\\alpha$ would have a greater advantage compared to a fixed value. $\\alpha$ can be understood as the weight distribution between the teacher model\u2019s parameters and the student model\u2019s parameters during the iterative update process, with the teacher model\u2019s weight being overwhelmingly dominant. I question the assumption that dynamically varying $\\alpha$ between 0.95 and 0.99 is necessarily better than a fixed value of 0.97. Could you provide a plot showing how $\\alpha$ changes dynamically over training iterations in the experiments?\n4. In Equation 2, what criteria does DDM use to derive \u03b1m? Is there a relationship between $\\alpha_m$ and these two losses? For example, if the teacher model has a lower loss, should $\\alpha_m$ be larger? Please explain.\n5. The notation in the paper is somewhat confusing. In Equation 1, what are the differences between $\\Theta_s^*$ and $\\Theta_s$, and between $\\Theta_s$ and $\\theta_s$? Additionally, what is meant by meta data $\\mathcal{D}_m$, and how does it differ from labeled data and unlabeled data? Furthermore, the $\\mathcal{L}_m$ formula is missing; I suggest adding it.\n6. What is the initial value of $\\alpha$? Has an ablation study been conducted to verify the impact of $\\alpha$?\n7. The authors mention that DDM can be promoted as a plug-and-play component for different models. However, I think DDM has limitations. For instance, how would DDM be applied to commonly used pseudo-labeling methods based on CPS (Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision)?"
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}