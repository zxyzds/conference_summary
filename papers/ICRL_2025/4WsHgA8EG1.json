{
    "id": "4WsHgA8EG1",
    "title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing",
    "abstract": "Large multi-modal models inevitably decay over time as facts change and previously learned information becomes outdated. Traditional approaches such as fine-tuning are often impractical for updating these models due to their size and complexity. Instead, direct knowledge editing within the models presents a more viable solution. Current model editing techniques, however, typically overlook the unique influence ranges of different facts, leading to compromised model performance in terms of both generality and locality. To address this issue, we introduce the concept of the generality-locality trade-off in multi-modal model editing. We develop a new model editing dataset named OKEDIT, specifically designed to effectively evaluate this trade-off. Building on this foundation, we propose \\textbf{BalancEdit}, a novel method for balanced model editing that dynamically achieves an optimal balance between generality and locality. BalancEdit utilizes a unique mechanism that generates both positive and negative samples for each fact to accurately determine its influence scope and incorporates these insights into the model's latent space using a discrete, localized codebook of edits, without modifying the underlying model weights. To our knowledge, this is the first approach explicitly addressing the generality-locality trade-off in multi-modal model editing. Our comprehensive results confirm the effectiveness of BalancEdit, demonstrating minimal trade-offs while maintaining robust editing capabilities. Our code and dataset will be available.",
    "keywords": [
        "Multi-modal learning",
        "Model editing"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=4WsHgA8EG1",
    "pdf_link": "https://openreview.net/pdf?id=4WsHgA8EG1",
    "comments": [
        {
            "summary": {
                "value": "Existing knowledge editing methods often overlook the influence scope of a knowledge edit, leading to limited generality and locality about samples similar to the edited ones. This paper proposes a novel method, BalancEdit, to optimize the trade-off between generality and locality. To assess this trade-off, this paper constructed a new dataset, OKEDIT. Experimental results demonstrate that BalancEdit outperforms existing methods in both single and sequential editing settings."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The issues addressed in this paper are of considerable significance. Existing editing methods affect the performance of the edited model on samples related to the edited ones. This paper proposed a new method to adjust the influence radius dynamically. The innovative approach of using positive and negative samples to estimate the influence radius of each knowledge edit is particularly commendable. Additionally, the paper clearly articulates the above issues and presents corresponding solutions."
            },
            "weaknesses": {
                "value": "1. The proposed method builds upon Grace [1], with the key differences being using positive and negative samples to estimate the influence radius and the fine-tuning of the transformation layer. However, the paper does not include an ablation study to evaluate the contributions of these two modules.\n2. The proposed dataset OKEDIT employs GPT-4 and a diffusion model to generate rephrased images for assessing image generality. However, previous studies have noted that generated images may shift in content, leading to inconsistencies with the original images [2]. \n3. The use of the harmonic mean (HM) is questionable, as the presence of a minimum can result in a lower harmonic mean. In Table 3, the FT method applied to BLIP2-OPT shows a performance of less than 1% on the locality.\n\n[1] Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors\n[2] VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark"
            },
            "questions": {
                "value": "1.Why is the accuracy for the Base model in Table 3 not 0? In my humble opinion, the Acc and Loc should be 0 and 100 respectively, similar to the results presented in [1]. \n2. Why were sequential editing experiments conducted on OKVQA instead of MMEdit and OKEDIT, as proposed in this paper?\n3. Previous studies have indicated that the MEND method can produce NaN values [2] during sequential editing; however, this issue does not appear in Table 4. Are there differences in the sequential editing settings between this study and [2]?\n4. IMHO, if the weights in the language module are edited, it is essential to measure text locality and compare it with other methods.\n5. The paper states that black images are used as negative samples across various visual recognition tasks. It would be beneficial to include citations to support this approach.\n6. Some proprietary terms, such as MiniGPT-4 and BLIP-2 OPT, are used inconsistently throughout the text.\n\n[1] Can We Edit Multimodal Large Language Models\uff1f\n[2] VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "BalancEdit introduces a new model editing approach, addressing the limitations of traditional model editing techniques. Unlike existing methods, which often ignore the distinct influence of different facts, BalancEdit strikes an optimal balance between generality and locality. By using a codebook of localized edits and generating both positive and negative samples, it accurately assesses each fact's impact without altering the model's core structure. Tested on the newly developed OKEDIT dataset, BalancEdit demonstrates robust editing performance with minimal trade-offs, marking a significant advance in multi-modal model editing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The motivation is good, particularly the attention to balancing generality and locality in model edits. \nThe approach for setting the influence radius is straightforward, requiring no additional training, which enhances usability. \nAdditionally, the model demonstrates good efficiency in terms of both time and data requirements."
            },
            "weaknesses": {
                "value": "The method\u2019s visual reasoning goal is limited, offering little differentiation from MMEdit, especially as the test data format remains similar and is based on question answering. \n\nUsing a black image as a negative sample is simplistic and may fall short in defining an \"optimal balance between generality and locality.\" Consequently, the hyperparameter alpha is fixed, potentially limiting flexibility.\n\nImages in the generality and locality tests are generated by a diffusion model, which offers limited advancement over MMEdit due to inconsistent image quality.\n\nThe study uses Blip2-OPT and MiniGPT-4 as baseline models, which are somewhat outdated and limited. Architectures like LLaVA and related models may yield different results.\n\nWriting issue:\nThere is a major issue on page 10, lines 489-514, where two paragraphs convey the same information, likely due to an unintentional oversight.\nTypo: Line 723: \u201clabelis\u201d\nLine 862: missing reference\nTable 3: some bold texts are not best results\nThe example in figure 4 is confusing, because the first image and the rest two has significant difference, and the main subject is two people rather than a church."
            },
            "questions": {
                "value": "As those mentioned in weakness:\n\nDoes the visual reasoning goal in this approach offer substantial differentiation from MMEdit, given the test data's similarity in the form of QA? \n\nCould a more sophisticated method replace black images as negative samples to better define the balance between generality and locality?\n\nHow significant is the impact of using diffusion model-generated images for testing generality and locality, considering their variable quality? Do you verify the image quality by any means (especially human verification), check if the generated images could be used for test?\n\nWould using more recent model architectures, like those in the LLaVA series, yield different results in these experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "BalancEdit presents a new solution for updating large multi-modal models by achieving a balance between generality and locality in model edits. By introducing the OKEDIT dataset, this approach evaluates and addresses the generality-locality trade-off, a challenge overlooked by other methods. BalancEdit showcases minimal compromise in model performance, offering a robust and efficient approach to knowledge editing without altering the model's core weights."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The motivation of balancing generality and specificity in model editing is good. \n\nThe method for determining the influence radius is simple and requires no extra training, which improves usability. \n\nMoreover, the model shows good efficiency in terms of both time and data usage.\n\nIntroducing more generality test for each editing case is beneficial."
            },
            "weaknesses": {
                "value": "Using a black or white image as a negative sample is straightforward but may not achieve an optimal balance between generality and locality.\n\nThe editing method involves finetuning a layer, which may be simplistic. Additionally, the experimental results lack comparison with the SERAC method.\n\nAbout image quality, I have some doubts on diffusion generated images, which are used as tests. From fig 4, the second image is totally different from the first image. From fig 6, the first and third examples of generality test are entirely different from the editing sample, making the test results questionable.\n\nThe experiments involve Blip2-OPT and MiniGPT-4. However, considering the fast development of MLLMs, the newer models like LLaVA series, which are widely recognized, should be tested."
            },
            "questions": {
                "value": "As those mentioned in weakness.\n\nAdditions:\n\nHow many locality test image for each editing case? If only one image, this can be imbalanced because generality test has 10 images for each.\n\nDo you verify the quality of generated images? How do you verify them?\n\nWhy don\u2019t you present the results of SERAC method?\n\nWriting issue:\n\nTable 3: Misuse bold texts, some are not best results.\n\nA critical issue exists on lines 489-514, where two paragraphs redundantly convey the same information. This appears to be a significant oversight of the content.\n\nMissing reference in ine 862"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No Ethics Concerns"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}