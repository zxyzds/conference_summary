{
    "id": "ToveGL9vRN",
    "title": "Since Faithfulness Fails: The Performance Limits of Neural Causal Discovery",
    "abstract": "Neural causal discovery methods have recently improved in terms of scalability and computational efficiency.\nHowever, there are still opportunities for improving their accuracy in uncovering causal structures.\nWe argue that the key obstacle in unlocking this potential is the faithfulness assumption, commonly used by contemporary neural approaches. We show that this assumption, which is often not satisfied in real-world or synthetic datasets, limits the effectiveness of existing methods. We evaluate\nthe impact of\nfaithfulness violations both qualitatively and quantitatively and provide a unified evaluation framework to facilitate further research.",
    "keywords": [
        "causal discovery",
        "faithfulness assumption",
        "neural networks"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "We show that the faithfulness assumption limits the structure discovery accuracy of  neural causal discovery method on standard benchmarks.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ToveGL9vRN",
    "pdf_link": "https://openreview.net/pdf?id=ToveGL9vRN",
    "comments": [
        {
            "summary": {
                "value": "This paper posits that the primary obstacle in neural causal discovery is the faithfulness assumption frequently used by modern neural approaches. It examines the impact of violations of this assumption both qualitatively and quantitatively, and provides a unified evaluation framework to facilitate further research."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The main claim of this work is that progress in causal discovery requires moving beyond the faithfulness assumption, which is a reasonable standpoint. The key experimental findings are:\n >- despite advancements in causal discovery over the past few years, $ESHD_{CPDAG}$ and $F1-Score_{CPDAG}$ metrics do not improve significantly. \n>-  structure discovery accuracy does not scale with the amount of data. \n>-  variations in MLP architecture have minimal impact on performance.\n\n-  develop techniques to measure how faithfulness violations degrade performance (Figure 4 is particularly interesting) and set an\nupper bound for current benchmarks.\n\n-  The paper is well-written."
            },
            "weaknesses": {
                "value": "- Line 71 : $U_{i}$ is assumed to be 1-dimensional.  Justify.\n- Please justify the additive noise assumption. \n- > Faithfulness assumption can be violated, for example, in a situation when paths cancel each other effects out, leading to statistical independence despite an existing causal relationship. \n\n**Give concrete example**\n - Expected SHD between CPDAGs has been discussed; there is no discussion about $F1-Score_{CPDAG}$\n -  Why do Table 1 and Section 3.2  miss the result on ER(5, 1)? \n - why do you exclude *DIFFUSION MODELS FOR CAUSAL DISCOVERY\nVIA TOPOLOGICAL ORDERING* in your analysis? \n\n- > To provide a comprehensive evaluation, we explored architectures with 1, 2, and 3 layers, configured\nwith 4, 8, and 16 hidden units.\n\n**why do you think this is sufficient to conclude *variations in MLP architecture have minimal impact on performance* ?**\n\n- The faithfulness metric, denoted DeFaith needs more detailed discussion. For example, \n>  To address this, we introduce a degree of faithfulness metric, denoted DeFaith, to measure how well statistical dependencies correspond to the true graph\u2019s d-separation properties. Inspired by Zhang & Spirtes (2003), we use Spearman\u2019s rank correlation coefficient to quantify the conditional dependencies in the dataset. We define a predictor of d-separation based on the coefficient.\n\n**Please clearly state what is the predictor here.**\n**More discussion is needed around the quality of this predictor itself**.\n\n- The paper does not address how to design neural causal discovery methods without the faithfulness assumption."
            },
            "questions": {
                "value": "Please see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper experimentally demonstrates that violating the faithfulness assumption is the key obstacle in improving the performance of existing neural causal discovery methods. In this paper, the authors introduce a metric to measure the degree of faithfulness violation, and also proposed a method to compute an experimental bound on the causal discovery performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- I totally agree with the authors on the assertion that faithfulness violations might be the key reason why the performance within the current causal discovery paradigm is limited to a large extent. I am happy to see the experimental support presented in this work.\n    \n- The proposed metric of faithfulness violations also makes sense\n    \n- The paper is well organized in a logical manner, and is easy to follow."
            },
            "weaknesses": {
                "value": "- The analyses presented in the paper are only experimental, lacking a theoretical foundation. Although they provide some insights, it might be not convincing enough to generalize to other scenarios.\n    \n- The proposed method to compute experimental upper bound is highly unlikely to scale up."
            },
            "questions": {
                "value": "- Why assuming additive noise SCMs in the paper?\n    \n- How general is the proposed faithfulness metric? At what conditions does it work?\n    \n- Why not choosing NOTEARS or its variants as baselines? I think NOTEARS might be one of the most well-known neural causal discovery methods?\n    \n- Since MLPs have universally strong fitting abilities, the loss easily converges to zero or a very small value when training a network for each parent set. In this case, it is possible that the log-likelihood losses of many DAGs lead to zero or a very small value or have very similar value. If so, how to identify the true DAG?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper has claimed that progress in causal discovery requires moving beyond the faithfulness assumption. The experiments shows that the violation of faithfulness would degrade performance. To clearly quantify this phenomenon, a metric called DeFaith has been proposed. Also, as the increase of sample size, the performance of different methods, including DCDI, BayseDAG, DiBS, SCCD, don\u2019t show improvement or even show degraded performance. To investigate the limits of different socre-based neural causal discovery methods, an algorithm called NN-opt has been proposed which consists two step. Through NN-opt, the upper bound of the neural method could be estimated."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper touches some important theoretical aspects of neural causal discovery.\n2. Several ordinary causal approaches are compared."
            },
            "weaknesses": {
                "value": "1. The theoretical analysis can be built more in depth to justify the arguements of the paper."
            },
            "questions": {
                "value": "Q1:In the structure evaluation, Expected SHD between CPDAGs and Expected F1-Score between CPDAGs have been defined. Compared to other metrics such as SHD and SID, is there any strength or reason to use them?\n\nQ2:DeFaith is proposed to evaluated the faithfulness, but could this metric accurately describe the change of the faithfulness? Could you give more theoretical analysis about the reality between the faithfulness and DeFaith? It is better if this quantification can be justified to be more theoretically \"close\" to the faithfulness.\n\nQ3:As mentioned before, NN-opt could compute the upper bound of specific methods. In step 2, which is exhaustive graph search, it is not feasible in practice. Is there any way to improve the method to make it practiced?\n\nQ4:In this paper, several methods have been evaluated to search the upper bound of these methods using different sample size and neural structures. From the aspect of experiments, the methods evaluated in the paper may only include some typical ones among all methods and it\u2019s more persuasive to compare more socre-based neural causal discovery methods. Could you give some reason of the selection of the four methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents the idea that the ''faithfulness assumption\" is holding back the improvements in the neural causal discovery research. The work starts with empirically demonstrating the strenghts and limitations of neural causal discovery. To this end, a benchmark is proposed where several of the discovery algorithms are evaluated.  Then a degree of faithfulness metric is proposed that is helpful to estimate to what degree does faithfulness effect the discovery algorithms."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The premise is really interesting. Identifying the faithfulness assumption as the main culprit is an important hypothesis that can have wide ranging impact.\n\n2. The paper is relatively well written."
            },
            "weaknesses": {
                "value": "There are several issues with the paper that forces me to go with a lower rating.\n\n1. Although the premise is interesting, the overall work does not justify the premise. For example, using a AUC-ROC curve to measure faithfulness is not very well justified. Also quantifying the conditional dependecies by a correlation coefficient is not very innovative/interesting. \n\n2. The works talks about why such assumptions are a problem for real world datasets, but the experimental evaluations are on synthetic data sets. This kind of defeats the message.\n\n3. The NN-opt method seems to pretty expensive since all possible DAG's are being evaluated.\n\n4. In Fig 2, SDCD and Bayes DAF do show a downward trend so maybe more evaluations are required before claiming that there is no improvement in the ESHD metric.\n\n5. Spell check required. Eg: Masuring -> Measuring in heading of Section 4."
            },
            "questions": {
                "value": "Please look at the weaknesses section. Furthermore,\n\n1. Were there any ablation studies conducted for the neural networks as functional aprroximators?\n\n2. I do not see the point of Fig 1 to be honest. It gives no specific information."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}