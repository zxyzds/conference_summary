{
    "id": "LxkgScfHKf",
    "title": "Conformal Training with Reduced Variance",
    "abstract": "Conformal prediction (CP) is a distribution-free framework for achieving probabilistic guarantees on black-box models. {CP} is generally applied to a model post-training. Conformal training is an approach that aims to optimize the CP efficiency during training. In this direction, ConfTr (Stutz et al, 2022) is a technique that seeks to minimize the expected prediction set size of a model by simulating {CP} in-between training updates. Despite its potential, we identify a strong source of sample inefficiency in ConfTr that leads to overly noisy estimated gradients, introducing training instability and limiting practical use. To address this challenge, we propose variance-reduced conformal training (VR-ConfTr), a method that incorporates a variance reduction technique in the gradient estimation of the ConfTr objective function. Through extensive experiments on various benchmark datasets, we demonstrate that VR-ConfTr consistently achieves faster convergence and smaller prediction sets compared to baselines.",
    "keywords": [
        "Conformal Training",
        "Conformal Prediction",
        "Optimization",
        "Quantile",
        "Deep Learning",
        "Uncertainty Quantification"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We improve performance of conformal training by tackling optimization challenges.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=LxkgScfHKf",
    "pdf_link": "https://openreview.net/pdf?id=LxkgScfHKf",
    "comments": [
        {
            "summary": {
                "value": "In this work, authors studies conformal training and proposes variance-reduced conformal training which incorporates a variance reduction technique in the gradient estimation of the ConfTr objective function. In particular, it proposes an $\\epsilon$ estimator to estimate quantile gradient. Authors also provide the theoretical results of the variance and bias of the proposed estimator, and some numerical studies on synthetic datasets and MNIST dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Authors state the problem clearly and then propose a solution, finally provide numerical studies.\n2. The discussion is accompanied with sufficient background introduction\n3. Authors tackle the high-variance issue in conformal training  and reduce the variance of quantile estimator relaxing the definition of the gradient and using more available samples in estimation."
            },
            "weaknesses": {
                "value": "1. Some of the formulas are not clearly explained. In particular, what does the set ${E_{\\theta}(X,Y) =\\tau_{\\tau}}$ represent? It seems $E_{\\theta}(X,Y)$ is a random variable, $\\tau_{\\tau}$ is a scaler, but how to interpret it in ${E_{\\theta}(X,Y) =\\tau_{\\tau}}$? Furthermore, what expectation you take with respect to in equation 11 and 12?\n2. How do you the value of $\\epsilon$? Can you include some ablation studies to this hyper-parameter?\n3. What is the per-step computational cost of your algorithm compared to the ConfTr?\n4. Can you test your method over larger scale datasets beyond the toy dataset of MNIST?"
            },
            "questions": {
                "value": "Please see the weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The submission proposes VR-ConfTr, a variance-reduced conformal training method that enhances the stability and efficiency of conformal prediction by reducing the variance in gradient estimates, which is a key limitation in previous [1]. VR-ConfTr introduces a novel gradient estimator that achieves faster convergence and smaller prediction sets.\n\n---\n\n[1] Stutz, David, et al. \"Learning Optimal Conformal Classifiers.\" International Conference on Learning Representations."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The length efficiency in conformal prediction is an important research problem. The proposed novel approach addresses significant sample inefficiency issues present in prior methods and stabilizes gradient estimation.\n\n- This is a plug-in algorithm hence the proposed variance reduction technique could enjoy a broad applicability.\n\n- VR-ConfTr demonstrates superior performance across multiple datasets, including MNIST, Fashion-MNIST, Kuzushiji-MNIST, and OrganAMNIST."
            },
            "weaknesses": {
                "value": "- The proposed VR-ConfTr gradient estimation method uses sample splitting, where batch data are divided into calibration and prediction subsets. This approach might introduce sampling instability, particularly with smaller datasets or non-i.i.d. data. This limitation is not sufficiently analyzed in the paper, nor do the authors consider alternative sampling strategies that might enhance stability.\n\n- Although the paper claims innovation in integrating variance reduction into conformal training, similar variance reduction techniques have already been proposed in gradient estimation contexts (e.g. well-known SVRG in optimization community). The authors fail to convincingly differentiate their work from these established methods, nor do they address why VR-ConfTr is distinct beyond the context of conformal prediction.\n\n- The empirical results, while presented across multiple datasets, appear selective and limited to low-complexity, classical datasets (e.g., MNIST variants). Conformal prediction applications span far more complex domains, yet there is no evidence here that VR-ConfTr scales or performs effectively on realistic, large-scale datasets.\n\n\n- The theoretical section of this paper appears hastily constructed (see Questions), which risks undermining the reader's confidence in the proposed methodology and suggests that this submission is not yet ready for formal publication."
            },
            "questions": {
                "value": "- The mathematical notation in Theorem 3.1 lacks standardization. Are you intending to use $q_{\\epsilon}(\\theta)^n$ from (i) and $\n[q\\_{\\epsilon}(\\theta)]^n$ from (ii) to both represent the $n$-th power of $q(\\cdot)$?\n\n- line 323: the definition of $K(t)$ lacks a right parenthesis\n\n- line 716, the asymptotic equivalence is defined by $a_n \\asymp b_n: \\lim_{n \\to \\infty} \\frac{a_n}{b_n} = 1$ (in your sense), so we should have $b_n \\neq 0$, which is in contrast to your usage like line 719, 745. Besides, \"Let\"\n\n- line 852: missing a proper definition\n\n- if you let $a_n=nf_n$, shouldn't your (45) turns into $a_{n+1}=(n+1)q f_n+(1-q^n)$ instead of your (46)?\n\n- In my view, the notation in the second line of (50) should begin with $ \\preceq$. Also the = in the final line seems unclear to me. While I understand your intention to retain the $\\frac{2 - p}{pn} \\Sigma_\\epsilon$, the remaining terms are somehow ambiguous\u2014how exactly does it equate to your final conclusion?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a new training objective for optimizing for conformal predictive set size, based on the work of (Stutz et al., 2022). By focusing on the computation of the gradients of the loss rather than the loss itself, the authors identify an alternative estimator of the conformal threshold to be incorporated in the loss that is more sample efficient, leading to less noisy gradients, and thus more stable training, faster convergence and better models."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The problem of building models that optimize for conformal predictive set size is a natural one, and yet often left to the sides. Indeed, there are still few works that tackle this problem, and more work on the topic is certainly welcome. The proposed solution is novel and can be of use to a wide audience."
            },
            "weaknesses": {
                "value": "I have two major issues with the paper:\n1. The mathematical reasoning in the paper does not seem sound\n2. Even if they were, the theoretical analysis seems lacking.\nGiven these two points, the paper could still be held up by a comprehensive empirical analysis. However, while there is some empirical analysis, it is hardly comprehensive, and could be improved on (especially if it is needed in order to compensate for (1.) and (2.)).\n\nOn the soundness of the mathematical reasoning:\n- The derivatives in equation (5) do not exist. As currently written, the chain rule cannot be applied. Perhaps it can be salvaged with subgradients, though.\n- I was unable to understand why (8) holds, or where it comes from.\n\nLacking theoretical analysis: the authors only prove their reduced variance with one particular estimator, which does not even match the estimator used in the experiments; moreover, this was done under significant simplifying assumptions. If these assumptions were so light as the authors imply, then it should be easy to prove a relaxed version of the theorem that incorporates them. (Change-of-measure inequalities may be useful here.)\nThis is to the point that I barely consider the paper to have any theoretical analysis.\n\nOn the experiments:\n- The current visualizations are almost exclusively learning curves. While their presence is welcome, there are probably better ways to visualize, e.g., the variance of the gradients over the course of the training, which the authors claim to have reduced. From the learning curves, it is not entirely clear that these have really been reduced.\n- It would be nice to also investigate the conditional coverage of the models. Does using your training objective lead to better conditional coverage? (Even if the answer is 'no', it would still be nice to have this in the supplementary material, and would not count negatively, in my view.)\n- The authors should consider more datasets and models -- currently only CNNs on MNIST-like datasets. I suggest the authors also consider:\n  - ViTs, still on image data\n  - Transformers (e.g., BERT-style) on text classification tasks\n  - GNNs for graph-based tasks, e.g., node prediction\n  Since the paper proposes a new training objective, in the absence of a better theoretical understanding of it (possibly including on its interactions with gradient descent methods), it is important to test it on a wider variety of architectures.\n\nThere are also some minor issues:\n- The use of $\\min\\_{\\theta \\in \\Theta} L(\\theta) := [\\cdots]$ can be a bit confusing, as it seems at a first glance that the equality is claimed with regards to the minimum. A better way to write this is $\\min\\_{\\theta \\in \\Theta} L(\\theta) \\quad \\text{where}\\ L(\\theta) := [\\cdots]$.\n- In line 317, I suggest avoiding the use of the term 'gradient-boosting estimators'; gradient boosting estimators are an established class of ML models (e.g., XGBoost, LightGBM, etc.). These have little to do with the estimators being constructed in the paper, and caused a fair amount of head-scratching on my end. How about just calling these 'estimators for $\\eta(\\theta)$'?\n- The writing in the proof of lemma 3.1 is rather unorthodox in the context of a paper. Consider avoiding long chains of {in,}equalities, especially, when you feel the need to follow it up with explanations for why the steps of the chain hold (e.g., line 682).\n- On tables 1, 2 and 5, use the standard $\\mu \\pm \\sigma$ notation in a single column for average and standard deviation, rather than separating into multiple columns.\n- The notation is overall very heavy, probably unnecessarily so. This makes the paper a bit hard to parse.\n\nFinally, it is worth noting that over half of the paper is spent effectively describing the work of (Stutz et al., 2022). Perhaps this can be trimmed somewhat, or better streamlined."
            },
            "questions": {
                "value": "My main questions:\n\n- Some clarification on (8) would be appreciated. Why does it hold? The text claims that it comes from differentiating $\\ell$, but that does not make sense. Is there a typo?\n- How does the derivation of the loss fare in the face of the non-existant derivatives in (5)? (Or do they actually exist and I've missed something?)\n- How does the proposed method fare when using the estimator in equation (13) rather than the ranking estimator?\n\n**Score:** the weaknesses (particularly those relating to soundness and the theoretical analysis) seem rather significant to me, making me lean towards rejection. Given their severity, I do not think the rejection is borderline, even if the experimental results seem somewhat positive. Should the reviewers improve their presentation and soundness of their theoretical results, I would be willing to increase my score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new approach, Variance-Reduced Conformal Training, which adds a variance reduction in the estimation of gradients to improve the efficiency of conformal prediction during training. It is an attempt to sort out the inefficiency problems that appear with other methods like ConfTr, for which the estimation of gradients is problematic because of noise in the data batches. These improvements in the proposal have brought both an increase in the speed of convergence and the efficiency in the size of the sets of predictions, as confirmed by experiments using different benchmark datasets. This effectively preserves probabilistic guarantees to obtain much more compact and reliable prediction sets when compared to baseline models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. VR-ConfTr consistently generates smaller prediction sets with better length efficiency than its predecessor, ConfTr, and baseline models.\n\n2. The paper provides a solid theoretical analysis to support the variance reduction claims, offering insights into the bias-variance trade-off involved.\n\n3. The paper is well-written and clearly structured."
            },
            "weaknesses": {
                "value": "1. VR-ConfTr relies on a large calibration set to accurately estimate the quantile estimator $\\hat{\\tau}$ and its gradient $\\hat{\\frac{\\partial \\tau}{\\partial \\theta}}$, which are critical for variance reduction.\n\n2. While VR-ConfTr improves prediction set efficiency, it introduces additional computational steps, which may slow down training in scenarios with limited computational resources."
            },
            "questions": {
                "value": "1. How does VR-ConfTr handle situations with limited/imbalanced calibration data, and how does this affect coverage guarantees?\n\n2. The paper mainly focuses on MNIST-type datasets, which restricts the demonstration of generality and robustness. How would VR-ConfTr perform on high-resolution images?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}