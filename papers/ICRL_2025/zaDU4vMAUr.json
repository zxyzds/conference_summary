{
    "id": "zaDU4vMAUr",
    "title": "Bilevel Reinforcement Learning for Stock Data with A Conservative TD Ensemble",
    "abstract": "Reinforcement learning (RL) has shown significant promise in stock trading. A typical solution involves optimizing cumulative returns using historical offline data. However, it may produce less generalizable policies that merely \"memorize\" optimal buying and selling actions from the offline data while neglecting the non-stationary nature of the financial market. We frame stock trading as a specific type of offline RL problem. Our method, MetaTrader, presents two key contributions. First, it introduces a novel bilevel actor-critic method that spans both the original stock data and its transformations. The fundamental idea is that an effective policy should be generalizable across out-of-distribution data. Second, we propose a novel variant of conservative TD learning, utilizing an ensemble-based TD target to mitigate value overestimation, particularly in scenarios with limited offline data. Our empirical findings across two publicly available datasets demonstrate the superior performance of MetaTrader over existing methods, including both RL-based approaches and stock prediction models.",
    "keywords": [
        "Reinforcement learning",
        "stock markets",
        "portfolio optimization"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=zaDU4vMAUr",
    "pdf_link": "https://openreview.net/pdf?id=zaDU4vMAUr",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces \"MetaTrader,\" a reinforcement learning (RL) approach for stock trading that aims to overcome challenges of overfitting to offline data and lacking generalizability in non-stationary financial markets. MetaTrader trains policies to perform well on transformed out-of-distribution (OOD) data, with a conservative temporal difference (TD) ensemble, designed to mitigate value overestimation in offline RL. Through bilevel actor-critic training on both original and transformed stock data, MetaTrader builds robustness to OOD scenarios. Empirical results on two stock datasets indicate MetaTrader's superiority over existing RL and stock prediction methods, with improved performance in portfolio returns and risk-adjusted metrics like Sharpe ratio, demonstrating its potential for robust and adaptable trading strategies."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper addresses an interesting and important problem: stock trading in the offline RL setting. The bilevel optimization approach combined with conservative TD learning directly addresses practical challenges in offline RL for trading, particularly the out-of-distribution (OOD) generalization problem.\n\nThe paper effectively positions stock trading as a unique offline RL problem, underscoring the potential for dataset expansion through their decoupled MDP framework.\n\n The empirical results demonstrate a comparison with other existing models, including SARL, FinRL-SAC, FinRL-DDPG, and StockFormer. Real-world data sets, specifically the CSI-300 Index and NASDAQ-100, are used."
            },
            "weaknesses": {
                "value": "The notations are not clearly explained and are sometimes used inconsistently, which makes them hard to follow. Some points related to clarity are outlined below.\n\n1. Observation space on page 2: \u201c$K$ technical indicators that reflect the temporal trends of stock prices\u201d. There is no explanation of what technical indicators are or how they reflect the temporal trends.\n\n2. State space on page 2: \u201cThe action-free market state $h_t$ is composed three types of latent states $s_t^{\\text relat}$, $s_t^{\\text long}$, $s_t^{\\text short}$ generated from the observation $o_t^{\\text price}$, $o_t^{\\text stat}$, $o_t^{\\text conv}$\u201d. There is no explanation about how $s_t$ is generated by $o_t$. Instead, the authors refer to Eq (1) on page 3, however, Eq (1) does not include $s_t$. \n\n3. Dimension of $h_t$ on page 3: The dimension of $h_t$ is stated as the number of stocks times $D$, but there is no explanation of what the notation $D$ represents.\n\n4. Daily prices in Appendix A: The input data for daily prices are denoted by $p_t$. This should be written as $o_t^{\\text close}$. The notations are used inconsistently.\n\n5. Metrics in Appendix C: The evaluation metrics for the experiments are defined in Equations (4), (5), and (6). The definitions are very vague and the notations are not clearly explained, lacking connection to $o_t$, $h_t$, $z_t$, $a_t$ defined in Section 2. \n\n\nThe authors manipulate the input data using the three transformation methods. While the paper notes that data transformations are used to create diverse subsets, it does not provide a clear rationale for the chosen transformations. These transformations can substantially impact the underlying factors driving stock prices and alter correlations between stocks, so an explanation of their selection and intended effects would strengthen the work. Appendix A explains their methods; however, there is no justification or theoretical background provided. Although the empirical studies demonstrate that the proposed algorithm outperforms the existing methods using two real-world data sets, the benefits of using the proposed algorithm are not clear to me, because it functions like a black-box solution.\n\n\nUsing an ensemble-based conservative TD target to mitigate overestimation in offline RL, though effective, lacks novelty, as this technique has been explored extensively in previous research.\n\n\nSince this work primarily emphasizes empirical results over theoretical contributions, the experimental section should be more robust. For instance, the significance of the findings in Tables 3, 4, and 5 cannot be interpreted without standard deviations. To provide a clearer picture of the proposed algorithm\u2019s stability, the authors could use a rolling training/test set and report both the mean and standard deviation of performance metrics. This would offer a more comprehensive view of the algorithm\u2019s consistency and reliability."
            },
            "questions": {
                "value": "Please see the weaknesses listed above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper applies RL to portfolio management, focusing on generalization in dynamic financial markets. Traditional RL models often overfit offline data, leading to rigid policies. To address this, the authors propose MetaTrader, introducing a bilevel actor-critic approach and a conservative TD learning variant with an ensemble-based target to reduce value overestimation. Experiments on two public datasets indicate that MetaTrader achieves improvements over existing RL and stock prediction models, suggesting enhanced adaptability in changing markets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "\u2022\tOOD (out-of-distribution) issues are prevalent in the stock market. This paper focuses on augmenting offline data to train a policy with stronger generalization capabilities to handle distribution shifts in online stock data. This is a crucial and interesting topic.\n\n\u2022\tThe writing is logically structured and easy to follow, making the content clear and accessible to readers. The arguments are presented in a straightforward manner, allowing readers to grasp the key points without difficulty.\n\n\u2022\tThe paper includes appropriate experiments and ablation studies to support its findings. These experiments provide evidence for the proposed method\u2019s effectiveness, though certain aspects of the experimental setup could be further improved for a more comprehensive evaluation."
            },
            "weaknesses": {
                "value": "\u2022\tRelying on training the policy with real and augmented data, followed by fine-tuning on real data to address the OOD problem in the stock market, is not an ideal approach. This can be observed in the following two aspects:\n\n1) The augmentation methods have limitations. For instance, do the F2 and F3 methods mentioned in the paper potentially introduce data leakage? Additionally, is the choice of the top 10% in F1 (why specifically 10%?) reasonable?\n\n2) The effectiveness of fine-tuning is questionable. Based on findings in the application of RL to finance, the performance of fine-tuning RL can be similar to or even weaker than training RL from scratch. The experiments in the paper do not include a comparison between fine-tuning RL and training RL from scratch to validate its effectiveness.\n\nNote: To clarify, \u201ctraining from scratch\u201d here refers to directly using the original data for portfolio management without involving data transformations in training.\n\n\u2022\tThe experimental setup has some flaws, detailed as follows:\n\n1) Data Validity: The experimental data only goes up to 2022, without including more recent data (e.g., up to 2024), which makes the findings less convincing. Websites like Yahoo Finance (https://finnhub.io/), Alpaca (https://docs.alpaca.markets/), and FMP (https://site.financialmodelingprep.com/developer/docs#chart-intraday) provide easy access to the latest data, which would strengthen the study\u2019s confidence.\n\n2) Stock Selection and Market Representation: While the CSI300 index theoretically consists of 300 stocks, only 88 were selected in this study. Additionally, both chosen stock markets consist of only around 80 stocks, without distinguishing between different market scales. This limited selection makes the results less persuasive, and it would be beneficial to include stock markets of varying scales for a more comprehensive analysis.\n\n3) Evaluation Metrics: The choice of metrics is somewhat limited. The study only focuses on return-related metrics (even though the Sharpe Ratio accounts for risk-adjusted returns, it still primarily measures profitability). Including risk metrics such as VOL and MDD would provide a more balanced evaluation of performance.\n\nNote: I noticed that this paper follows the experimental setup of StockFormer. However, using data from two years ago is not ideal and updating the data could significantly improve the credibility of the experiments. Furthermore, StockFormer included MDD as a risk metric, so it\u2019s unclear why this study chose not to incorporate it in its evaluation criteria.\n\n\u2022\tBenchmark Selection**.** Many financial companies still use machine learning and deep learning methods based on prediction, such as LightGBM, LSTM, and Transformer models. Including these in the experiments would provide a more convincing comparison. Qlib (https://github.com/microsoft/qlib) can be a helpful reference for implementing these methods."
            },
            "questions": {
                "value": "\u2022\tAs described in the weaknesses section, is there a potential issue of data leakage with the three types of data transformations mentioned? Additionally, why is it set to the top 10%? It would be helpful if the authors could clarify these points.\n\n\u2022\tIn Figure 3, the augmented data is labeled from 1 to M, while the finetuning data is labeled as M+1 to M'. If I understand correctly, should it actually be M+1 to M+M'? If this is not a typo, please disregard this comment. If this is indeed a writing error, it would be helpful for the authors to adjust any other relevant parts of the paper accordingly.\n\n\u2022\tLines 87\u201394 mention that the state data consists of action-free and action-dependent components. I would like to know more about the data processing methods used. For example, variables like price, cash holdings, and position can exhibit significant differences over extended trading periods. For instance, Apple\u2019s (AAPL) price on the NASDAQ was around $12 in 2011, but by 2022, it had exceeded $130. This shift in stock prices can lead to substantial differences in cash, position, and price scales. Without normalization, how is RL training stability maintained? It would be helpful if the authors could explain this in detail."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies a way to train an RL policy for stock trading using past transaction data. To deal with the non-stationary and out-of-distribution data in the deployment phase, the paper proposes to perform (i) data transformation (augmentation), (ii) updating the Q function via pessimistic ensemble among multiple subsets of (augmented) data, and (iii) fine-tuning the data collected in the most recent time period. The experiment results demonstrate that the proposed method works better than existing online and offline RL approaches in the real stock transaction data."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- **Data transformation (augmentation) makes most of the application-specific features of finance.**\n\nAs a key component of the proposed approach, the paper proposed to perform data augmentation to enhance the generalizability of the model to out-of-distribution (OOD) data. In many RL settings, this is usually not a promising approach due to the difficulty of predicting/obtaining rewards for the OOD (state, action) pairs. \n\nHowever, in the finance application, this is not the case because we can assume individual actions do not make a huge impact on the market dynamics, and what depends on the actions (selling or buying) is only the individual reward they get from these transactions. This paper nicely exploits this structure and does data augmentation.\n\n- **Approaches, including bi-level optimization and fine-tuning, sounds reasonable and the components are harmoniously combined.**\n\nThe paper combines the aforementioned components in a sound way, and there are no components that seem redundant or unnecessary. The motivations behind why the proposed method needs each component are also well explained. While each component itself (e.g., fine-tuning and conservative learning) is not very novel, yet, I think this idea is worth sharing. \n\n- **Well done ablations and experiments.**\n\nThe baselines are picked from representative algorithms of approaches in predictions, online and offline RL. Also, ablations on w/ and w/o data transformation, w/ and w/o fine-tuning, and runtime comparison are all informative for readers.\n\n- **Clarity of the paper.**\n\nOverall, the paper is clearly written and easy to follow."
            },
            "weaknesses": {
                "value": "To be honest, there is not much to point out for weakness. However, the following might have room for improvement.\n\n- **Related work on offline RL and offline-to-online RL**\n\nThe current related work focuses on the existing approaches for learning a stock-trading policy. Adding discussion on why the conventional offline RL does not work and why the proposed method works might be helpful for readers who are not very familiar with offline RL. Also, there is some work on offline-to-online RL, which does online fine-tuning after performing offline RL. This approach is relevant to the proposed method, and can be worth mentioning in the related work section.\n\n- **Description about the proposed method in Introduction**\n\nWhile the paper was in general very well written, the description of the proposed method in the introduction may have some room for improvement. It was difficult for me to imagine what the proposed method looks like only from the introduction (in particular, it was not clear to me what \"in-domain profits\" refer to and what the outer-loop optimization does), while It became clear after reading Section 3."
            },
            "questions": {
                "value": "- How does the proposed method (and other baseline) determine the trajectory length? Are there any guidelines to pick a reasonable trajectory length if there are some tradeoffs between short and long trajectories?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper seeks to enhance classical reinforcement learning through the introduction of two techniques: bilevel learning and conservative TD ensemble. The effectiveness of these improvements is evaluated using experiments on two stock datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well-structured, and the ablation studies are conducted thoroughly."
            },
            "weaknesses": {
                "value": "### Major Issues:\n\n1. **Lack of Discussion on Non-Stationarity**: There is insufficient discussion on how the paper addresses the issue of non-stationarity. As I understand it, the paper attempts to mitigate non-stationarity through specific data transformations. However, the rationale behind the choice of these three particular transformations is unclear. For instance, in F1, why is only the top 10% considered and not the bottom 10% as well? The action space allows for both long and short positions. Regarding F2, how does disrupting the order of observations in time help overcome non-stationarity? If time observations are treated as completely independent, the sequence would be unpredictable. For F3, as explained in Appendix A, future data is compressed into the present to create a non-empty input. Applying this approach in the out-of-sample leads to the future information issue. These questions raise concerns about the experimental validity.\n  \n2. **Input Construction and Covariance Matrix**: A critical component of the model input is the sample covariance matrix between stocks. How exactly is this matrix computed? According to random matrix theory, when the number of assets is close to the number of time observations, the sample covariance matrix becomes singular and provides a biased estimate of the true covariance matrix. Although this method may still be applicable to the two datasets in the paper (with 300 and 100 stocks, respectively), it raises concerns about the scalability of this approach to larger datasets.\n  \n3. **Experimental Shortcomings**:\n  \n  - First, lines 401-412 involve the calculation of true values, and there appear to be issues with this in the paper. To compute the true value theoretically, a globally optimal policy is required. I may have missed some details, but I hope the authors can clarify this in their rebuttal.\n  - Second, regarding the performance metrics, the portfolio return aligns with the annual return. It would strengthen the results if the maximum drawdown (MDD) were also reported alongside the annual return.\n  - Finally, the stock prediction strategy\u2014buying only the single stock with the highest predicted value\u2014is problematic, as it introduces excessive randomness into the strategy. A more convincing approach would be to purchase the top 10% of stocks based on cross-sectional prediction values, with equal weighting across them.\n\n### Minor Issues:\n\n1. Some of the terminology used in the paper is unconventional. For instance, \"portfolio return\" in Table 1 is more commonly referred to as \"cumulative return,\" and \"annual return\" should be labeled as \"annualized return.\" Additionally, the risk-free rate used in the analysis is not specified.\n  \n2. Several references on ensembled Q-learning have been published, but this paper lacks a rigorous discussion of these existing works."
            },
            "questions": {
                "value": "1. Please carefully reconsider how you structure your network inputs.\n2. Please ensure that the comparison between the proposed method and classical methods is conducted fairly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}