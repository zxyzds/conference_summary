{
    "id": "N2wPtFVK6o",
    "title": "MOUCHI: Mitigating Over-forgetting in Unlearning Copyrighted Information",
    "abstract": "Large language models are trained on massive internet datasets, which may inadvertently memorize illegal copyrighted content, making its inclusion unavoidable. Unlearning is a potential solution to remove such content. However, existing unlearning methods often suffer from **over-forgetting**, where the process unintentionally erases knowledge similar to the copyrighted content that falls under fair use and should be preserved. To address this issue, we propose **MOUCHI**, a novel unlearning framework that introduces the concept of **derivative knowledge**, a subset of information derived from copyrighted content that must be retained during unlearning. MOUCHI first generates derivative knowledge and then incorporates a derivative loss function into the unlearning process to mitigate over-forgetting in unlearning copyrighted content. Due to its plug-and-play nature, MOUCHI can be effortlessly integrated into existing unlearning methods. Experimental results show that MOUCHI reduces unintended knowledge loss, improving performance by **up to 145%** compared to baseline methods when evaluated on the derivative set.",
    "keywords": [
        "machine unlearning",
        "LLM unlearning",
        "derivative knowledge"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "Propose a novel LLM unlearning framework based on derivative knowledge to avoid over-forgetting",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=N2wPtFVK6o",
    "pdf_link": "https://openreview.net/pdf?id=N2wPtFVK6o",
    "comments": [
        {
            "summary": {
                "value": "This paper tackles the problem of over-forgetting during the unlearning process of LLMs, i.e., unintentionally removing similar content which should be preserved. The authors propose a concept of derivative knowledge, which is a subset of information derived from the copyrighted content and should be retained during unlearning. In particular, 1) the set derivative knowledge will be generated and 2) a derivative loss function is included. Different unlearning approaches can incorporate their proposed method and obtain various performance improvements in terms of model utility and forget quality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* Propose an interesting and effective approach to tackle the over-forgetting issue of LLMs' unlearning process\n* The approach can be integrated into existing unlearning methods to achieve various performance improvements\n* Detailed analysis of the experiment results"
            },
            "weaknesses": {
                "value": "* Lack of manual analysis of the derivative knowledge: the authors also mention that experts/lawmakers need to be involved to check the boundary, otherwise it is difficult to judge how good (enough) the KL-based semantic similarity is in this context. I would suggest the authors to incorporate human judgements in this process.\n* Experiments are restricted to one dataset, also one scenario/domain. Maybe the authors could comment on how easy/difficult for the approach to be adapted to other types of copyrighted information."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper titled \"MOUCHI: Mitigating Over-Forgetting in Unlearning Copyrighted Information\" addresses the critical issue of copyright infringement within large language models (LLMs). Due to the extensive and often indiscriminate data used in their training, LLMs can inadvertently memorize and reproduce copyrighted content, posing a significant legal and ethical challenge. The proposed MOUCHI framework introduces \"derivative knowledge\" as a subset of information derived from copyrighted content but intended for retention during unlearning to maintain fair-use knowledge. MOUCHI integrates a derivative loss function to differentiate and preserve derivative knowledge, allowing the model to continue answering general questions related to copyrighted material while removing infringing content. The framework is designed to work seamlessly with existing unlearning methods, providing a plug-and-play solution. Experimental results show that MOUCHI successfully reduces unintended knowledge loss by up to 145% over baseline methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well-written, with a clear explanation of the problem and the proposed solution. \n\nThe concept of over-forgetting and derivative knowledge is effectively introduced and explained, making the paper accessible to a broad audience.\n\nCopyright concerns in LLMs are increasingly pressing, particularly as these models become more widely deployed. The focus on balancing copyright compliance with preserving relevant knowledge is timely and important. MOUCHI attempts to address the complex need to avoid copyright infringement while retaining content that may fall under fair use."
            },
            "weaknesses": {
                "value": "The MOUCHI framework, while straightforward, maybe too simplistic to fully address the nuanced requirements of copyright compliance. \n\nMOUCHI may still risk indirect copyright violations by retaining derivative knowledge that could closely resemble the copyrighted content \"CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation\"\n\nUtility evaluation is limited, which weakens the claim of solving overforgetting problems. The authors may need to run common benchmarks such as MMLU to ensure the utility of LLM is not sabotaged. \n\nThe paper does not compare MOUCHI with some recent and relevant unlearning baselines, such as Goldfish Loss \"Be like a goldfish, don\u2019t memorize!\" and \"Avoiding Copyright Infringement via Machine Unlearning\"\n\nCode is not given.\n\nAlthough the authors reference several key studies, the paper could be strengthened by discussing additional recent works that are pertinent to the topic of copyright compliance in LLMs. Listed below:\n\n- Foundation Models and Fair Use\n- Rethinking LLM Memorization through the Lens of Adversarial Compression\n- Llms and memorization: On quality and specificity of copyright compliance\n- SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation\n- Digger: Detecting copyright content misusage in large language model training\n- Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4"
            },
            "questions": {
                "value": "KL Divergence value is constrained by ChatGPT? Is this possible without an iterative approach?\n\nHow to know whether the generated dataset is correct and does not include hallucinations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To address the over-forgetting in LLM unlearning, this paper proposes MOUCHI, a new unlearning framework that generates a set of derivative knowledge to enrich the retain set. The derivative knowledge lies between the forget set and the retain set, which helps to better specify the boundaries of the knowledge to be removed. Experimental results demonstrate that MOUCHI can provide better control over over-forgetting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.This paper is well motivated as it focuses on the over-forgetting issue in unlearning.\n\n2.This paper proposes a simple method to expand the retain set in the form of data synthesis."
            },
            "weaknesses": {
                "value": "1.The proposed method lacks novelty as it simply prompts the model to generate derivative knowledge and uses KL divergence for filtering. And there is no improvement in the loss function for the derivative set, which can be regarded as an expansion of the retain set. Is there a generation-free way to induce derivative knowledge?\n\n2.This paper only conducts experiments on TOFU and needs to verify the effectiveness on more unlearning datasets, such as scenarios where the range of unlearning knowledge is particularly extensive.\n\n3.Some implementation details are lacking. For example, the forget set in TOFU consists of 200 fictional authors and has no connection with real-world knowledge. Then what is the derivative knowledge of these fictional authors? Some generated results need to be provided."
            },
            "questions": {
                "value": "Please see the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Copyright concerns in large language models (LLMs) have become especially prominent due to the widespread use of these models, making them more vulnerable to misuse. Unlearning is a potential solution for removing such content. However, existing unlearning methods often suffer from over-forgetting, where the process unintentionally erases knowledge that is similar to copyrighted content falling under fair use and should be preserved. There is a trade-off between unlearning and over-forgetting.\n\nThis paper analyzes and identifies the over-forgetting problem in current LLM unlearning methods, then introduces the concept of derivative knowledge, and applies it to the MOUCHI framework by proposing the $L_{drv}$ loss. Experimental results show that this method achieves better performance than previous unlearning methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper investigates the issue of over-forgetting in unlearning methods. Its strengths include:\n\n1. Analyzing and identifying the over-forgetting problem in current LLM unlearning methods.\n2. Proposing the concept of derivative knowledge, which can be viewed as a buffer zone between the knowledge to be forgotten and the knowledge that needs to be retained.\n3. Carefully designing a derivative generation module, with experimental results surpassing those of previous unlearning methods."
            },
            "weaknesses": {
                "value": "1. There are inconsistencies in the paper's wording. For example, in line 17, it states, \"...the concept of derivative knowledge, a subset of information derived from copyrighted content that must be retained during unlearning.\" However, in line 76, it says, \"the concept of derivative knowledge\u2014a subset derived from the target copyrighted information that needs to be removed.\"\n\n2. More experiments are needed to validate the effectiveness of the method. Currently, the paper is based on only one language model and a relatively small dataset (TOFU), where each author has only 20 QA questions. Such results may have certain limitations. There are many existing, more comprehensive unlearning datasets available, and broader testing is required to assess the method's generalizability.\n\n[1] Muse: Machine unlearning six-way evaluation for language models. arXiv preprint arXiv:2407.06460, 2024.\n\n[2] The wmdp benchmark: Measuring and reducing malicious use with unlearning. arXiv preprint arXiv:2403.03218, 2024.\n\n[3] RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models. arXiv preprint arXiv:2406.10890, 2024."
            },
            "questions": {
                "value": "1. Since the TOFU dataset is relatively small, this paper divides it into four subsets (by augmenting part of the data). Could you provide a detailed distribution of these subsets?\n\n2. Regarding the evaluation metric \"Derivative,\" if MOUCHI is not included, will the model not be trained on $D_{drv}$ ? Or is $D_{drv}$ integrated into other subsets for training?\n\n3. Given the diversity of ChatGPT's generated content, has the determination of \u03b4min and \u03b4max undergone multiple validations to ensure its accuracy?\n\n4. In the example on the right side of Figure 6, is the given \"A\" the knowledge that the model needs to retain? If so, what specifically needs to be forgotten? For clarity, it would be helpful to include related Q&A from both the Forget set and the Derivative set for the same author in the presentation, illustrating what should be retained versus what should be forgotten."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Privacy, security and safety"
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}