{
    "id": "Dc6dgTq2UZ",
    "title": "Towards Distributed Backdoor Attacks with Network Detection in Decentralized Federated Learning",
    "abstract": "Distributed backdoor attacks (DBA) have shown a higher attack success rate than centralized attacks in centralized federated learning (FL). However, it has not been investigated in the decentralized FL. In this paper, we experimentally demonstrate that, while directly applying DBA to decentralized FL, the attack success rate depends on the distribution of attackers in the network architecture. Considering that the attackers can not decide their location, this paper aims to achieve a high attack success rate regardless of the attackers' location distribution. Specifically, we first design a method to detect the network by predicting the distance between any two attackers on the network. Then, based on the distance, we organize the attackers in different clusters. Lastly, we propose an algorithm to \\textit{dynamically} embed local patterns decomposed from a global pattern into the different attackers in each cluster. We conduct a thorough empirical investigation and find that our method can, in benchmark datasets,\noutperform both centralized attacks and naive DBA in different decentralized frameworks.",
    "keywords": [
        "Decentralized Federated Learning",
        "Distributed Backdoor Attacks"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Dc6dgTq2UZ",
    "pdf_link": "https://openreview.net/pdf?id=Dc6dgTq2UZ",
    "comments": [
        {
            "summary": {
                "value": "In this paper, the authors propose a distributed backdoor attack method. The core of the work is based on the insight that the attack success rate depends on the distribution of attackers in the network architecture. The authors design a topology detection method to detect the network by the distance of the attackers, and then organize the subsequent attacks based on the distance to improve the attack success rate. Experimental results show that the proposed method outperforms traditional centralized attacks and the naive distributed backdoor attack."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed work is the first to investigate the distributed backdoor attack method on decentralized federated learning tasks.\n- Experimental results show that the proposed method achieves a higher attack success rate than traditional methods."
            },
            "weaknesses": {
                "value": "- The work lacks discussion on the key parameters of the proposed method in the experiment, such as the number of clusters.\n- The authors should add more ablation studies to evaluate the contribution of each module to the attack success rate."
            },
            "questions": {
                "value": "Please refer to the weaknesses for rebuttal. I will check the related content carefully."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors examine distributed backdoor attacks in decentralized FL, introducing a method to detect attackers by estimating distances between them, clustering attackers accordingly, and proposing an algorithm to dynamically embed local patterns from a global pattern into each cluster."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. It is interesting to consider the topology of decentralized FL and LSTM seems like a reasonable way to predict the distance. \n2. The authors consider dynamically embed the backdoor trigger instead of using fixed patterns."
            },
            "weaknesses": {
                "value": "1. DBA takes into account factors like location and size, resulting in potentially infinite combinations of triggers. Even with a dynamic selection method, there's no guarantee that the chosen combination will be optimal or near optimal. A more fundamental approach might involve using a generative model to implant invisible/stealthy triggers (as pixels), such as [1], to optimize the trigger more effectively.\n2.  Considering the clustering method as a major contribution to this paper, ablation studies are needed to assess the improvement gained from introducing clustering (and the number of clusters, threshold distance to dividing clusters) compared to not using clustering in a fair comparison.\n3. To showcase the effectiveness of proposed attack, performance under defense mechanisms is needed.\n\n[1] Doan, Khoa, et al. \"Lira: Learnable, imperceptible and robust backdoor attacks.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021."
            },
            "questions": {
                "value": "1. Have the authors considered other methods to enhance backdoor attacks durability like [1]\n2. Since MNIST and CIFAR-10 each have only 10 classes, does the number of classes matter?\n3. Can the current method effectively handle more complex real-world topologies in terms of scalability and performance guarantees?\n\n[1] Zhang, Zhengming, et al. \"Neurotoxin: Durable backdoors in federated learning.\" International Conference on Machine Learning. PMLR, 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper investigates distributed backdoor attacks (DBA) in the context of decentralized federated learning (DFL), where there is no central server. Traditional DBA methods, which work effectively in centralized settings, often experience reduced success rates in decentralized systems due to the varying influence of adversarial clients based on their network location. To address this, the authors propose a two-step approach: first, a method to estimate distances between adversarial clients in the network, and second, a clustering-based algorithm to maximize attack success by dynamically organizing the distributed backdoor attacks based on network topology. Through experiments on various DFL frameworks, the authors demonstrate that their method achieves higher attack success rates than standard DBA and centralized backdoor approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper presents an innovative approach by introducing distributed backdoor attacks (DBA) specifically tailored for decentralized federated learning (DFL), an area that has seen limited exploration."
            },
            "weaknesses": {
                "value": "Although the proposed attack method is shown to be effective, the paper does not sufficiently explore potential defensive strategies against this enhanced DBA approach.\n\nThe success of the proposed approach heavily relies on the accuracy of topology detection and clustering. However, there is limited discussion on the potential impact of inaccuracies in clustering or topology estimation on the overall attack success rate.\n\n\nThe clustering and trigger decomposition steps involve hyperparameters, such as cluster size and trigger distribution patterns. However, the paper does not provide sufficient insight into how sensitive the method\u2019s performance is to these parameters.\n\nThe method relies heavily on accurate distance estimation between adversarial clients. The paper does not discuss how inaccuracies in these estimates might affect the attack's effectiveness, especially in dynamic or less predictable network environments where client distances may vary."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates Distributed Backdoor Attacks (DBA) within a decentralized Federated Learning (FL) framework. The authors demonstrate that the attack success rate of DBA in decentralized settings is impacted by the distribution of attackers across the network. To address this, the paper introduces a two-step strategy: (1) a method to detect network topology by predicting distances between attackers, allowing them to cluster, and (2) an enhanced DBA method where attack patterns are distributed dynamically within clusters to optimize the attack\u2019s impact across various network topologies. Experimental results show that the proposed approach improves attack success rates over traditional DBA and centralized attacks on standard datasets (CIFAR-10 and MNIST)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Overall, the structure of this paper is easy to follow. \n- The problem studied is sound and important.\n- The dynamic cluster-based trigger distribution is interesting."
            },
            "weaknesses": {
                "value": "- This paper\u2019s contribution is somehow limited as it only focuses on DBA. While DBA in decentralized FL is a novel attack, the study does not discuss possible defense mechanisms, which could provide a more balanced perspective.\n- The clustering and dynamic distribution of triggers may become computationally expensive with a larger number of attackers and clients. \n- The approach assumes attackers can communicate to coordinate poisoned images and agree on target labels, which may not be practical in a real-world adversarial setting."
            },
            "questions": {
                "value": "- How would the clustering algorithm handle larger networks with significantly more clients and attackers? \n- How practical is it for attackers to synchronize their attacks across clusters in real-world decentralized FL applications with limited communication? \n- Have any potential defense mechanisms been considered that could mitigate the effectiveness of the proposed DBA in decentralized FL? \n- How sensitive is the method\u2019s effectiveness to inaccuracies in distance prediction? Is there a tolerance threshold?\n- Could this method be extended to other types of adversarial attacks in decentralized FL, such as data poisoning or model inversion attacks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}