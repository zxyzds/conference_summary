{
    "id": "Bc15z5RrLo",
    "title": "MixNAM: Advancing Neural Additive Models with Mixture of Experts",
    "abstract": "Additive models, such as Neural Additive Models (NAMs), are recognized for their transparency, providing clear insights into the impact of individual features on outcomes. However, they traditionally rely on point estimations and are constrained by their additive nature, limiting their ability to capture the complexity and variability inherent in real-world data. This variability often presents as different influences from the same feature value in various samples, adding complexity to prediction models. To address these limitations, we introduce MixNAM, an innovative framework that enriches NAMs by integrating a mixture of experts, where each expert encodes a different aspect of this variability in predictions from each feature. This integration allows MixNAM to capture the variability in feature contributions through comprehensive distribution estimations and to include feature interactions during expert routing, thus significantly boosting performance. Our empirical evaluation demonstrates that MixNAM surpasses traditional additive models in performance and is comparable to complex black-box approaches. Additionally, it improves the depth and comprehensiveness of feature attribution, setting a new benchmark for balancing interpretability with performance in machine learning. Moreover, the flexibility in MixNAM configuration facilitates the navigation of its trade-offs between accuracy and interpretability, enhancing adaptability to various data scenarios.",
    "keywords": [
        "Interpretable Machine Learning",
        "Neural Additive Model",
        "Explainable Artificial Intelligence"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Bc15z5RrLo",
    "pdf_link": "https://openreview.net/pdf?id=Bc15z5RrLo",
    "comments": [
        {
            "summary": {
                "value": "Additive models like Neural Additive Models (NAMs) are valued for their transparency, clearly showing how individual features impact outcomes. However, their reliance on point estimates and additive structure limits their ability to capture complex, variable feature influences in real-world data. To address these limitations, MixNAM is introduced as a framework that enriches NAMs through a mixture of experts, each capturing different aspects of feature variability. This approach allows MixNAM to model diverse feature contributions, and interactions, and allow distribution estimations. Empirical results show that MixNAM not only outperforms traditional additive models but also approaches the performance of complex black-box methods while providing detailed feature attributions. Its flexible configuration further allows for balancing accuracy and interpretability, adapting to various data scenarios effectively."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Overall, the paper is clear and well-written.\n- The paper attempts to contribute to the important and relevant topic of uncertainty quantification in neural additive models with mixtures of experts\n- The proposed method is evaluated on both simulated and real-world data, using multiple criteria, including model additivity, bound tightness, and prediction accuracy."
            },
            "weaknesses": {
                "value": "* The discussion on related work lacks clarity. For instance, the authors state that \"these approaches are still limited by their inevitable assumptions of prior distributions and the additive nature of the entire models, which restrict their ability to accurately reflect complex underlying distributions and interactions.\" However, it is unclear what is meant by \"prior distributions.\" Why can\u2019t these models capture interactions effectively? Why are they considered less flexible? Additionally, the authors mention that \"these models generally rely on a simplistic assumption about output distributions.\" More specific details are needed to understand the limitations that the proposed approach aims to address.\n\n* The type of uncertainty or variability captured by the proposed method is not clearly defined. The authors use various terms, such as \"different aspect of the variability,\" \"more comprehensive insight into the output distribution,\" \"captures a broad range of possible outcomes,\" \"detailed variance,\" and \"more comprehensive insight into the output distribution.\" However, this language lacks rigor and does not clearly communicate the specific type of uncertainty intended to be captured. Furthermore, in a regression context where \\(L\\) represents the MSE, it is unclear how the proposed method would capture \"uncertainty\" by minimizing MSE (instead of proper scoring rules).\n\n* Although the authors consider different values for \\(K\\) and \\(C\\) in Table 8 in the appendix, the roles of these hyperparameters are not well explained. The results appear relatively consistent, and the impact of using a single expert is missing from the analysis. Additionally, there is no study of the values for \\(\\gamma\\) and \\(\\lambda\\) in equation (8), particularly with extreme values (gamma = 0).\n\n* As demonstrated by the authors in Appendix E, the proposed method can essentially be viewed as a generalized additive model with specific normalization. The added complexity in the approach is not well justified when compared to existing methods.\n\n* Only six relatively \"old\" datasets are used in this study. A broader selection of available tabular datasets would provide a stronger and more comprehensive evaluation. Refer to L\u00e9o Grinsztajn et al. \u201cWhy do tree-based models still outperform deep learning on tabular data?\u201d (July 2022) and Pieter Gijsbers et al. \u201cAn Open Source AutoML Benchmark\u201d (July 2019) for relevant data sources.\n\n* The authors write, \"The bounds represent the maximum and minimum potential outputs for a feature.\" It would be helpful to clarify what is meant by \"possible\" in this context. Possible according to what criteria? These bounds are directly affected by the number of experts. How is that important?\n\n\nAdditional Comments\n\n* In expression (12), the denominator equals zero.\n* In Figure 4, why is NAM unable to capture multimodality? Were proper hyperparameters used?\n* Please clearly indicate what the values after the +/- symbol represent (standard errors?).\n* Label the y-axis in Figure 3 for clarity."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces MixNAM, an extension of Neural Additive Models (NAMs) designed to enhance both accuracy and interpretability. MixNAM incorporates a mixture of experts, each capturing different aspects of feature variability, to address the limitations of traditional NAMs, which struggle to represent complex data patterns. Experiments show that MixNAM improves accuracy over traditional additive models while achieving performance comparable to black-box models, achieving a balance between interpretability and predictive power."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper introduce MoE within the NAM framework to overcoming the limitations of traditional additive models. This architecture allows MixNAM to capture data complexity more effectively than NAMs.\n- The paper includes experiments across various datasets, including both real-world and simulation data, to demonstrate MixNAM's improved accuracy and interpretability compared to both traditional additive models and more complex black-box approaches."
            },
            "weaknesses": {
                "value": "- Although MixNAM achieves interpretability with improved accuracy, it relies on a dynamic routing mechanism and multiple experts, which might increase computational requirements.  It would be better to include analysis of computational cost and assess the tradeoff of the computational cost and the increased accuracy.\n- The paper primarily focuses on tabular data, which raises questions about the generalizability of the framework\u2019s effectiveness to other domains, such as image or text data."
            },
            "questions": {
                "value": "- For datasets with highly sparse features, does the routing mechanism maintain its efficiency, or does it introduce sparsity issues that affect performance?\n- The simulation study includes only two random variables. Could the study include more experiments on high dimensional variables to better demonstrate MixNAM's effectiveness?\n- How does MixNAM handle extreme cases of feature variability, where the impact of a feature varies widely across different samples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces MixNAM which improves neural additive model (NAMs) by combining with a mixture of experts (MoE) to capture the feature variability due to its interaction with other features. MixNAM uses multiple experts for each feature and uses a dynamic routing mechanism to assess and combine the relevance of different experts. This improves the prediction performance and gives the upper and lower bound of the feature attribution. The empirical evaluation demonstrates that MixNAM outperforms traditional additive models that ignore interactions and achieves comparable performance to complex black-box models while providing feature attributions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The idea of combining MoE with NAM is novel and can improve the flexibility of NAM to capture feature interactions and maintain interpretability. The claim is supported by extensive experiments and benchmarks against various baselines, in terms of prediction performance and interpretability.\n\n2. MixNAM provides a point estimator of feature attribution but a range of it, which reflects the feature interaction."
            },
            "weaknesses": {
                "value": "1. If we look at Table 1, MixNAM is only significantly better than other interpretable methods (with FA) on the Housing and Year dataset by taking the standard error into consideration. \n\n2. The model is benchmarked only on tabular datasets due to the limited flexibility of NAM on structured datasets, even though it's still beneficial to discuss its potential usage on structured datasets, as they are the primary use cases of neural networks.\n\n3. The performance and interoperability of MixNAM are sensitive to the penalty parameter \\lambda. The paper would benefit from a more in-depth discussion on how to choose it."
            },
            "questions": {
                "value": "1. How was the hyper-parameter \\lambda selected? Was it cross-validated against prediction accuracy? It would be great to provide some heuristics to select it to balance the accuracy and interpretability.\n\n2. It would be great to compare the interpretation of MixNAM with any post-hoc feature attribution (e.g., SHAP) on XGBoost, which is a popular choice to gain interpretability on tabular data. What is the difference between these two options? A practitioner may like to know when they should use an interpretable MixNAM and when they should use XGBoost with post-hoc interpretation methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concerns of ethics."
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces an enhancement to Neural Additive Models (NAMs) by incorporating a Mixture of Experts (MoE) framework, enabling the model to capture feature variability and complex feature interactions. This approach allows each feature to be modeled through multiple expert predictions, which are dynamically selected based on relevance, thus addressing traditional NAM limitations in handling real-world data complexity. This new framework enhances additive models' utility, offering advanced predictive accuracy and transparency."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper combines NAMs\u2019 interpretability with MoE\u2019s capacity for multi-aspect feature representation, contributing a new approach to interpretable machine learning.\n\n2. MixNAM\u2019s ability to capture variability in feature impacts is highly relevant for real-world applications that require transparent models with high predictive power. The proposed method also allows users to balance accuracy with interpretability."
            },
            "weaknesses": {
                "value": "1. As described in line 164, each expert $E_{ik}$ is implemented as a linear layer, but normally, MLPs are used as base models for experts, the authors should justify why choosing linear model as experts.\n\n2. The novelty of this paper is quite limited, as they just apply regular MoE architecture on top of each feature's embedding and weighted combine them to obtain the outputs, even so, the authors did not provide a detailed rationale for choosing such a method. \n\n3. In line 336, it seems that the uncertainty intervals are formulated by a group of expert predictions, this is not a natural way of producing prediction intervals, as the uncertainty should come from the model parameters or the data itself.\n\n4. The multimodal experiments are all based on small-scale simulated datasets, the authors should benchmark its method on larger-scale multimodal benchmarks."
            },
            "questions": {
                "value": "How does the proposed method handle load imbalance when training MoE models? Is the expert variation penalty similar to the load imbalance loss function?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}