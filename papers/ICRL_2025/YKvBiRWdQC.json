{
    "id": "YKvBiRWdQC",
    "title": "The Overcooked Generalisation Challenge",
    "abstract": "We introduce the Overcooked Generalisation Challenge (OGC) \u2013 the first bench-mark to study reinforcement learning agents\u2019 zero-shot cooperation abilities when faced with novel partners and levels in the Overcooked-AI environment.\nThis perspective starkly contrasts a large body of previous work that has evaluated cooperating agents only on the same level or with the same partner, thus failing to capture generalisation abilities essential for real-world human-AI cooperation.\nOur challenge interfaces with state-of-the-art dual curriculum design (DCD) methods to generate auto-curricula for training general agents in Overcooked.\nIt is the first cooperative multi-agent environment specially designed for DCD methods and, consequently, the first evaluated with state-of-the-art methods. \nIt is fully GPU-accelerated, built on the DCD benchmark suite minimax, and freely available under an open-source license: http://anonymised.edu. \nWe show that state-of-the-art DCD algorithms fail to produce useful policies on this novel challenge, even if combined with recent network architectures specifically designed for scalability and generalisability. \nAs such, the OGC pushes the boundaries of real-world human-AI cooperation by enabling research on the impact of generalisation on cooperating agents.",
    "keywords": [
        "Human-AI Cooperation",
        "Unsupervised Environment Design",
        "Multi-Agent Reinforcement Learning"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "We introduce the Overcooked Generalisation Challenge (OGC) \u2013 the first bench-mark to study reinforcement learning agents\u2019 zero-shot cooperation abilities when faced with novel partners and levels in the Overcooked-AI environment.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=YKvBiRWdQC",
    "pdf_link": "https://openreview.net/pdf?id=YKvBiRWdQC",
    "comments": [
        {
            "summary": {
                "value": "MARL research has focused on studying how to generalize across novel partners on the same task. However, there is little work on generalizing to novel partners across novel tasks in the Overcooked-AI environment. This work introduces a new challenge for using DCD methods on fully cooperative tasks in Overcooked. They show how SOTA DCD methods cannot build agents that learn to coordinate with novel partners across novel problems, even with recent advances in neural networks, making this an open challenge for the MARL community."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper was a compelling first stab at building agents capable of generalizing across partners and problems. The authors did their due diligence with showing the speed of their environment, the performance of difference SOTA algorithms for UED across a variety of network architectures, and justifying the distinction between this work and prior methods for enabling ZSC, such as population based approaches. Overall, the implementation and evaluation details seem well thought through and justified, and the results point towards a clear gap in the multi-agent UED literature."
            },
            "weaknesses": {
                "value": "While most of the paper was well written, Section 6 on benchmarking the challenge was a little confusing. Specifically, the difference between generalization performance and zero-shot cooperation performance could've been written with more clarity. It was not obvious if the authors were referring to generalization with partners during training across novel layouts, generalization to partners not seen during training for a single layout within distribution of the generator, and generalization in to novel partners across novel layouts.\n\nAlso, Figure 7 is a little unclear. While it is explained in the error analysis section, for someone quickly looking at it it is not obvious what the takeaway should be, or how the number of visits should relate to the return. (as a nitpick, the colors for the number of visits could be in a different pallet to be more obvious, not super necessary but may be helpful). In general, while benchmarking and understanding the limits of the challenges of existing UED approaches is very important and will lead to a high quality paper, the methods for analysis could use more than a few sentences of justification if possible. I.e. if the authors think state-coverage is a useful metric for ability to cooperate and that is why they choose to analyze the frequency of cells visited, then this motivation should be spelled out."
            },
            "questions": {
                "value": "For the error analysis, it is interesting that the models perform well in layouts like asymmetric advantages and cramped room. Both of those layouts are capable of being solved by a single agent to get a high cross-play reward. Can you draw any conclusions about how existing UED objectives might be biasing agents towards solving single agent problems even though the reward scheme technically makes it cooperative?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper connects the Overcooked-AI implementation from `JaxMARL` [1] with the `minimax` [2] library for Unsupervised Environment Design (UED) to create a new benchmark, the Overcooked Generalization Challenge (OGC). \n\nOGC is meant to assess the generalization and coordination ability of agents when faced with novel partners in levels unseen during train time, where each level is a specific instantiation of the overarching Dec-UPOMDP.\n\nThe authors then evaluate four popular UED methods combined with three different policy architectures by looking at the mean episode return in self-play on held-out layouts (Table 3) and mean episode return when paired with fictitious co-play (FCP) policies in held-out layouts (Figure 5). In both cases, the held-out layouts are the 5 original layouts introduced in Overcooked-AI [3]. \n\nFinally, authors perform some analysis in an attempt to explain the low performance of DCD methods in the benchmark. \n\n[1] https://github.com/FLAIROx/JaxMARL/tree/main/jaxmarl/environments/overcooked\n\n[2] https://github.com/facebookresearch/minimax\n\n[3] https://github.com/HumanCompatibleAI/overcooked_ai"
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "As the authors have pointed out, the vast majority of the coordination literature studies the coordination challenges that arise when paired with novel partners in the same environment as seen as train time (though with possible variations, such as different deck orderings in Hanabi [1].)  \n\nAs a result, there is indeed a significant gap in the coordination literature regarding test-time generalization to scenarios unseen during training, including to new layouts, different number of agents, new dynamics or new reward functions. A benchmark that allows to jointly evaluate the coordination and generalization ability of AI agents is a welcome contribution, and could drive significant algorithmic innovations. However, for the reasons explained below, I do not believe this paper fulfills this role. \n\nOther strengths include the writing, which I found clear and easy to follow, the commitment to open-sourcing the benchmark, and the thorough reporting of hyperparameters in the appendix. Finally, adopting the Dec-UPOMDP formalism allows to more rigorously define the extent of generalization the model should reach. \n\n[1] The Hanabi Challenge (https://arxiv.org/abs/1902.00506)"
            },
            "weaknesses": {
                "value": "**1. Limited Scope**\n\nWhile authors adopt the Dec-UPOMDP formalism, their proposed challenge only evaluates generalization to new layouts. This means they only assess generalization to new states, but not to new observation functions, reward functions or dynamics. As such, the whole benchmark is in fact simpler than the formalism suggests, and is equivalent to simply augmenting the set of initial states in Overcooked.\n\nThis problem is exacerbated by the environment being fully observable and deterministic, which in many layouts means that agents can simply react to what their partner is doing for a good, if not optimal, policy. See Section 7 of [1] for a discussion of partial observability and what that implies for limitations of Overcooked as a coordination challenge.\n\n**2. Unclear Contributions**\n\nThe authors claim to introduce a new environment, OvercookedUED, and it is listed as one of their 3 main contributions of the paper on page 2. That said, from the description in section 5.1, OvercookedUED is simply a wrapper of the JaxMARL implementation of Overcooked-AI (i.e. Overcooked-JAX) that connects it to the `minimax` library. Since Overcooked-JAX already comes with a way of easily creating new layouts by providing an ASCII string [2], OvercookedUED appears to be only a minor contribution. \n\nRelatedly, Table 2 seems to report the steps-per-second achieved by running Overcooked-JAX, and it is unclear what information it carries that is specific to the authors' contribution.\n\n**3. Different design space for different UED methods**\n\nThe description of OvercookedUED in Section 5.1 lacks key details on how the layout generation is performed for each UED method. Furthermore, there appear to be significant differences in the design space for each method, which can in turn affect performance. Based on the paper:\n\n- For PAIRED, new layouts are generated by the teacher placing objects \"sequentially and in a deterministic order\". Since the teacher conditions only on the unfinished layout, does that mean that the number of objects of each type is fixed for all layouts generated by PAIRED?\n\n- PLR can select 1 or 2 piles of onions, bowls, pots and serving locations, so the number of objects of each type is clearly variable. The authors do not specify the sampling procedure for the walls, which can greatly influence the layout.\n\n- ACCEL can remove/add walls and move all other objects in the layout, but *not* remove them. There's also no mention on whether it can move agent starting positions.\n\nBecause the design space for each method can greatly influence its performance, the authors should clearly detail how each method operates, and also eliminate any discrepancy. In other words, *all layouts theoretically obtainable by one method should also be obtainable by the other ones*. The descriptions in the paper indicate that this is not the case.\n\n**4. No assessment of policy learning ability**\n\nThe authors evaluate three different policy architectures. In Table 11, they show that one unspecified architecture can learn to overfit to a single layout. However, they provide no evidence that any of those architectures can learn a policy over multiple layouts. At a minimum, the authors should train each of the architectures on the 5 held-out layouts and show that they can indeed learn a general policy. They could then evaluate the performance gap between those expert agents and those trained in UED.\n\nWithout that experiment, it is impossible to conclude whether the poor performance in Section 6 is due to the UED methods failing to provide a suitable curriculum or to the policy networks being unable to learn a general policy.\n\n**5. No assessment of robustness of FCP policies**\n\nCoordination is evaluated in the ad-hoc teamplay [3] framework (despite the authors never using that term and failing to cite Stone et al. 2010), where the final policy is paired with a pool of test-time partners. In the case of the paper, the pool is obtained by Fictitious Co-play (FCP), but the authors do not evaluate whether those policies are themselves robust to new partners. This poses two problems. \n\nFirst, this evaluation pool is limited and likely not very diverse. Authors claim that \"*There is currently no algorithm to train a population of diverse agents over a distribution of levels.*\", but given that each level simply corresponds to a different initial state, algorithms such as TrajeDi [4] or ComeDi [5] could apply out of the box.\n\nSecond, there is no evaluation in the paper showing that FCP policies are robust to unseen partners. As such, poor returns in cross-play could be the fault of the trained policy or of the FCP policies themselves. See [6] for an extreme example of this. \n\n**6. Other minor issues**\n\n- The authors misuse \"Zero-Shot Coordination\"; it is a specific setting introduced in [7] and requiring that test time partners be trained with the same algorithm used to train the policy being evaluated.\n- The authors misuse \"Other-play\"; it is a method introduced in [7], not an evaluation setting. Instead, the authors should use the term \"cross-play\".\n- \"*Notice that the training levels in which our model performs well in are similar to Asymmetric Advantages and Cramped Room, while the worst levels are similar to the other 3 evaluation levels*\". This statement is not substantiated by Figure 7. \n- Most figures use the visuals from Overcooked-AI but figure 7 uses the visuals form OvercookedJAX, without explanation. This can be confusing to authors which are not familiar with both works.\n\n[1] Who Needs to Know?, https://arxiv.org/pdf/2306.09309\n\n[2] Overcooked-JAX, https://github.com/FLAIROx/JaxMARL/tree/main/jaxmarl/environments/overcooked\n\n[3] Stone et al., https://ojs.aaai.org/index.php/AAAI/article/view/7529\n\n[4] TrajeDi, https://proceedings.mlr.press/v139/lupu21a/lupu21a.pdf\n\n[5] ComeDi, https://arxiv.org/pdf/2310.15414\n\n[6] ADVERSITY, https://openreview.net/pdf?id=uLE3WF3-H_5\n\n[7] Other-Play, https://arxiv.org/abs/2003.02979"
            },
            "questions": {
                "value": "1. Can the authors please clarify the sampling procedure for each of the UED methods?\n2. Can authors clarify what OvercookedUED provides on top of OvercookedJAX and minimax, from an implementation perspective?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This works proposes OvercookedUED, an GPU-based cooperative multi-agent environment that is compatible with UED methods. The proposed environment is more complex than existing UED-compatible environments. It also aims to connect UED with ad-hoc teamwork literature by allowing agents to be tested with unseen partners under unseen game levels. Empirically, existing UED methods struggle to produce strong agents in OvercookedUED. Further, UED-produced agents tend to cooperate better when they are more generally capable."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is well written and easy to understand.\n- I really like that the authors aim to connect the UED and ad-hoc teamwork literature through this benchmark. The paper highlights clearly what is the gap of existing UED-compatible environments, i.e., environment and partner generalization, and thus is well motivated and novel.\n- The evaluation seems to be thorough with many baselines and evaluation scenarios\n- The project will be open-source"
            },
            "weaknesses": {
                "value": "Though I really like the paper at a high-level, there are quite a few significant improvements that can make the paper more mature:\n\n- The environment assumes a single recipe in the game and thus missing an important aspect of the game. There are variants of Overcooked that use multiple recipes that make the game more interesting and require more complex coordination [1,2,3]. I believe including more possible recipes improves the depth of the environment significantly, arguably adding another important layer of generalization.\n- line 288: the observation space is not explained in details, it is especially hard for readers without prior Overcooked knowledge.\n- It is not clear if the UED agents were just undertrained or the UED algorithms themselves struggle to generate complex layout. I wish the authors include training curves showing the performance on seen and unseen layouts of UED agents.\n- The result of per layout generalization performance is missing from the main paper. I believe Table 13 shows this result but is not included in the main paper. I compare Table 13 and Table 14 (which is the raw results of Fig 5) and see that the self-play performance is actually lower than *test cross-play* performance, hinting that the agents are being *carried* by the FCP test partners. I believe that this observation is important and should be included and discussed in the main text.\n- FCP does not explicitly generate diverse agents, which might not be a robust method for generating test partners.\n\n\nMinor comments:\n- Random and Stay baselines (Fig 5) are never introduced\n- Fig 4 sentence 2: I find the sentence to not be consistent with the figure. Some of the generated layouts are definitely solvable.\n- line 54: empty space on the right\n- last line of page 2: the citation should not have parentheses as it is a part of a sentence\n\n\n[1] Wu, Sarah A., et al. \"Too many cooks: Bayesian inference for coordinating multi\u2010agent collaboration.\" Topics in Cognitive Science 13.2 (2021): 414-432.\n\n[2] Yu, Chao, et al. \"Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased.\" The Eleventh International Conference on Learning Representations.\n\n[3] Charakorn, Rujikorn, Poramate Manoonpong, and Nat Dilokthanakul. \"Generating diverse cooperative agents by learning incompatible policies.\" The Eleventh International Conference on Learning Representations. 2023."
            },
            "questions": {
                "value": "- Is it possible to **only** test partner generalization under the proposed environment (e.g., something similar to Fig. 5 but under seen layouts)? This would allow user to isolate between two types of generalization, diagnose, and develop better UED+ZSC algorithms."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Overcooked Generalisation Challenge (OGC), which is a benchmark for testing RL agents' ability to cooperate with new partners in unseen environments. It focuses on zero-shot coordination to improve human-AI collaboration in complex scenarios. The study shows that current algorithms struggle with this challenge, highlighting the need for more adaptable cooperative agents."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Originality: The paper introduces a new benchmark, the Overcooked Generalisation Challenge (OGC), which evaluates RL agents' zero-shot cooperation abilities with new partners in previously unseen layouts, addressing gaps in existing cooperative AI research.\n\n- Quality: The study provides extensive empirical results, and includes detailed error analysis, showcasing both successful and challenging areas for current algorithms.\n\n- Clarity: The paper is well-structured, clearly presenting the motivations, methodology, and findings. It is easy for readers to follow the research and apply its insights.\n\n- Significance: The OGC fills the gap in cooperative AI research by focusing on zero-shot coordination, which is essential for real-world applications of AI in dynamic and unpredictable environments."
            },
            "weaknesses": {
                "value": "- The challenge restricts layout sizes to ensure observability and compatibility with CNN-based encoders, which may limit the exploration of more natural and scalable representations for complex environments.\n\n- The OGC environment, with its emphasis on running parallel layouts and complex training, may demand substantial computational resources. This could limit accessibility for researchers without high-performance computing capabilities and restrict broader experimentation and adoption of the benchmark."
            },
            "questions": {
                "value": "How do you plan to address the constraints on layout size in future iterations of the OGC to explore more scalable or natural scene representations? Would methods like graph-based representations or item embeddings be a viable approach?\n\nWhat are the specific computational requirements for running the OGC, and have you established any benchmarks or guidelines to help researchers estimate the necessary resources for effective experimentation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}