{
    "id": "SfNmgDqeEa",
    "title": "Looking Beyond the Top-1: Transformers Determine Top Tokens in Order",
    "abstract": "Understanding the inner workings of Transformers is crucial for achieving more\naccurate and efficient predictions. In this work, we analyze the computation performed\nby Transformers in the layers after the top-1 prediction has become fixed, which has been\npreviously referred to as the \u201csaturation event\u201d. We expand the concept of saturation events\nfor top-k tokens, demonstrating that similar saturation events occur across language, vision, \nand speech models. We find that these saturation events happen in order of the \ncorresponding tokens\u2019 ranking, i.e., the model first decides on the top ranking token, then \nthe second highest ranking token, and so on. This phenomenon seems intrinsic to the \nTransformer architecture, occurring across different architectural variants (decoder-only, \nencoder-only, and to a lesser extent full-Transformer), and even in untrained Transformers.\nWe propose an underlying mechanism of task transition for this sequential saturation, where \ntask k corresponds to predicting the k-th most probable token, and the saturation events are \nin fact discrete transitions between the tasks. In support of this we show that it is possible to \npredict the current task from hidden layer embedding. Furthermore, using an intervention \nmethod we demonstrate that we can cause the model to switch from one task to the next. \nFinally, leveraging our findings, we introduce a novel token-level early-exit strategy, which \nsurpasses existing methods in balancing performance and efficiency.",
    "keywords": [
        "mechanistic interpretability",
        "transformer",
        "large language model",
        "efficient inference"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=SfNmgDqeEa",
    "pdf_link": "https://openreview.net/pdf?id=SfNmgDqeEa",
    "comments": [
        {
            "comment": {
                "value": "We\u2019re glad that you found our concept novel and see the potential of our proposed practical applications. \n\nPer your suggestion we re-ran our order saturation and task transition probing experiments using Llama3-8B model on 1K randomly chosen samples from MMLU and Hellaswag benchmarks. We show that Llama3\u2019s top-k tokens reach saturation in order of their ranking up to (and including) the 4th ranking token, and that we\u2019re able to predict the task number from layer embeddings with 88% accuracy. Please see Section B.2 in the appendix for more details, \nAnd let us know if you feel that more samples or additional datasets are needed.\n\nRegarding your questions:\n1. We appreciate your suggestion, and acknowledge that in the NLP field the word \u201ctask\u201d has other more downstream connotations. Yet we feel that the word \u201cprocess\u201d here  would be misleading, and that \u201ctask\u201d better encapsulates the discrete nature of the proposed mechanism, where the model determines each token in sequence.\n\n2. We recognize that our practical applications sections apply only to language models, but we feel that the main focus of our paper is the discovery of the ordered saturation phenomenon and the proposed task transition mechanism, which as we argue are inherent to Transformer architecture regardless of modality. For this reason we think that focusing only on language models would be doing a disservice to the generality of our findings.\n\n3. To address the question of which tokens undergo saturation we\u2019ve added a section to the Appendix (B.1) where we show  that in GPT2 saturation events are common for top-k tokens, with over 80% of samples reaching top-1 saturation. Additionally, these samples belong to different parts of speech (POS), and are not just function words for example, with over 27% of them being nouns. \nOur findings do not apply to samples which do not reach top-1 saturation, but our results in Section 5.2 suggest that these predictions night be less accurate in terms of language modeling.\n\nIf there are specific models, benchmarks, or analyses you would like us to explore to strengthen the work further, please do not hesitate to let us know."
            }
        },
        {
            "comment": {
                "value": "We are glad you found our writing and illustrations clear and noted the extensive experiments across different modalities. \n\nAnswers to points raised:\n1. Although the classifiers for vision and speech models achieve lower accuracy than that of the classifier trained on the language model, the results are still statistically significant with p < 0.00001 based on a Binomial Distribution probability test. The difference in accuracy might be due to the different number of layers between the models, where GPT2 has 48 layers, ViT and Whisper have 32. The larger number of layers lends itself to more layers per task and better separation between them. \n\n2. The number 7 was chosen arbitrarily as a hyperparameter; to demonstrate the robustness of the effect, we re-ran the experiment with values in the range 2-10 and indeed observed the same phenomenon, indicating that there\u2019s nothing unique about the number 7: the accuracy of 2nd tokens which reach saturation i layers before output   (with 2 <=i <=10) is significantly higher than of those that are determined only at the last layer. Please see Section B.3 in the Appendix for more details.\n\n3. Thank you for bringing this to our attention. After running an independent samples t-test, we found that the difference in accuracy between our method and each of the alternatives is statistically significant, with p < 0.001 and made note of it in Table 2.\nWe would like to emphasize that the practical applications are not the main focus of our paper, and are meant to showcase how our theoretical insights can be used.\n\nYou mentioned that the proposed method seems heuristic and hand-crafted, and that there is not enough supportive evidence. Can you please expand on what you mean by that? Which method used in the paper are you referring to and what additional supportive evidence could we provide?\n\nIf there are specific models, benchmarks, or analyses you would like us to explore to strengthen the work further, please do not hesitate to let us know."
            }
        },
        {
            "comment": {
                "value": "We are pleased that you appreciated our contributions to advancing the understanding of Transformer models. It is encouraging to see that our efforts to establish generalizability across modalities and provide empirical backing for the task-transition hypothesis were well received. \n\nAlthough we provide a new early-exit strategy as a practical application for our findings, this is not the main focus of our paper. Furthermore, our proposed strategy focuses only on the top-1 as is the standard in most efficiency focused works, but as we argue in the Related Works section, this does not take into account the other top-k tokens which are often used in common generation sampling methods. For this reason, to fundamentally improve inference efficiency as you suggest, future work should consider the trade-off between speedup and top-k accuracy.\n\nIf there are specific models, benchmarks, or analyses you would like us to explore to strengthen the work further, please do not hesitate to let us know"
            }
        },
        {
            "comment": {
                "value": "We're glad you found our paper clear and understandable, with a well-defined approach and practical contributions.\n\nWe do not claim that the ordered saturation phenomenon is unique to Transformers, which, as we mention in the \u201cConclusion and Future Work\u201d section, is a question worth exploring, particularly in RNNs. We argue that it is inherent to the architecture and support our claim by reproducing the findings in an untrained randomly initialized Transformer model (Section 4.1).\n\nFollowing your comments and to demonstrate that this phenomenon appears in recent, state-of-the-art models, we have reproduced our results using Llama3-8B on MMLU and Hellaswag benchmarks. We find that Llama3\u2019s top-k tokens reach saturation in order of their ranking up to (and including) the fourth-ranking token and that we\u2019re able to predict the task number from layer embeddings with 88% accuracy. Please see Figure 7 and Table 5 in Section B.2 of the appendix for more details.\n\nYou noted that the practical applications require further validation to enhance their real-world relevance. Could you please explain what type of validation would be helpful here?\n\nRegarding your questions:\n1. The difference in chance level for each model follows from the different number of tasks used when training the probing classifier for each model. The number of tasks is determined per model to be the maximum number for which, after balancing the data, there are at least 10 embeddings from each layer in each class from at least 4 different layers. To clarify this point, we\u2019ve added the relevant footnote to Section 2.3. \n\n2. In cases where two top-ranked tokens reached saturation as the same layer, they both get the same ranking which works against our claim of ordered saturation. Despite this, we see a statistically significant difference between the average ranks of adjacent top tokens.\n\n3. When creating the data for the task number classifier, if two adjacent top tokens reached saturation at the same layer (for example 3d and 4th) then these would be labeled as belonging to the task of the smaller token between them (in this case 3d task). This adds some noise to the data, but does not prevent the classifier from achieving high accuracy.\n\n4. Classifier accuracy was calculated as the percentage of samples where the predicted label matches exactly that of the true label.\n\n5. Fixed typo.\n\n6. We provided comparison with the only known token level early exit methods known to us based on the cited survey [1] . If you can suggest others, we would be happy to compare our strategy against them as well.\n\nWe will add clarifications to all of these questions in the paper.\n\nIf there are specific models, benchmarks, or analyses you would like us to explore to strengthen the work further, please do not hesitate to let us know.\n\n[1] - A survey on efficient inference for large language models. (https://arxiv.org/abs/2404.14294)"
            }
        },
        {
            "comment": {
                "value": "We\u2019re glad that you find our research question important and interesting.\n\nAlthough, to the best of our knowledge, the existence of \u201csaturation events\u201d is not controversial in the literature [1,2,3], we agree that we should have provided some evidence demonstrating their frequency in the data. For this reason, we\u2019ve added a section (currently in Appendix B.1) showing that in GPT2, saturation events are common for top-k tokens, with over 80% of samples reaching top-1 saturation. Even if we consider only cases where top-1 saturation happens in the first 85% layers of the model, as we do in all of our experiments, we find that this includes 51.5% of all samples.\n\nTo facilitate your evaluation, we have also uploaded a Jupyter notebook to the supplementary materials called \u201csaturation_events.ipynb\u201d. This notebook contains code which allows you to verify the existence of saturation events as described in the paper on Llama3 model.\n\nRegarding the robustness of our findings, we have reproduced our results in different regimes and architecture types and even across modalities - pre-trained and untrained (randomly initialized) GPT2 which is decoder-only, encode-only pre-trained ViT, and encoder-decoder pre-trained Whisper (see Sections 3.2 and 3.3). \n\nTo address your concern of our results generalizing to SOTA models and different NLG tasks, we have reproduced our order saturation and task transition probing experiments using Llama3-8B model on MMLU and Hellaswag benchmarks. We show that Llama3\u2019s top-k tokens reach saturation in order of their ranking up to (and including) the 4th ranking token, and that we\u2019re able to predict the task number from layer embeddings with 88% accuracy. Please see Section B.2 in the appendix for more details.\n\nWe show that the phenomenon of ordered saturation is statistically significant using a stricter version of a well known ranking metric Kendall\u2019s tau. If this is not sufficient, could you please suggest which other statistical rank tests we should run?\n\nThe goal of the intervention experiment is not to demonstrate a practical application for our findings, but rather to show causality and further validate our proposed task transition mechanism. \n\nRegarding Table 2, thank you for bringing this to our attention. After running an independent samples t-test we find that the difference in accuracy between our method and each of the alternatives is statistically significant, with p < 0.001 and make note of it in Section 5.1.\n\nIn Section 5.1 we report the highest accuracy achieved across all tested thresholds for Softmax Response and State Saturation methods, which is calculated for the next-word prediction task as the percent of samples where the predicted top-1 token matches exactly the next token in the text. Please see Section A.7 in the Appendix for further details.\n\nIf there are specific models, benchmarks, or analyses you would like us to explore to strengthen the work further, please do not hesitate to let us know.\n\n1 - Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space. (https://arxiv.org/abs/2203.14680)\n\n2 - Confident adaptive language modeling. (https://proceedings.neurips.cc/paper_files/paper/2022/hash/6fac9e316a4ae75ea244ddcef1982c71-Abstract-Conference.html)\n\n3 - Language Models Implement Simple Word2Vec-style Vector Arithmetic (https://arxiv.org/abs/2305.16130)"
            }
        },
        {
            "comment": {
                "value": "We thank our reviewers for their insightful feedback and helpful suggestions.\n \nIn light of their comments, we\u2019ve run additional experiments, which are presented in Appendix B:\n\n1. To provide evidence establishing how common saturation events are in the data, we\u2019ve added Section B.1 showing that in GPT2 model  over 80% of samples reach top-1 saturation. \n\n2. We have reproduced our results using Llama3-8B on MMLU and Hellaswag benchmarks to demonstrate the ordered saturation phenomenon in recent state-of-the-art models. We find that Llama3\u2019s top-k tokens reach saturation in order of their ranking up to (and including) the fourth-ranking token and that we can predict the task number from layer embeddings with 88% accuracy. Please see Figure 7 and Table 5 in Section B.2 of the appendix for more details.\n\n3. In Section 5.2, the number 7 was chosen randomly as an hyperparameter; to demonstrate the robustness of the effect we re-ran the experiment with values in the range 2-10 and indeed observed the same phenomenon, indicating that there\u2019s nothing unique about the number 7 (see Section B.3).\n\nWe\u2019ve also added some clarifications and statistical significance markers in the paper itself, color-coded in cyan for your convenience. \n\nFinally, we uploaded a Jupyter notebook to supplementary materials called \u201csaturation_events.ipynb\u201d, which allows the reviewers to verify the existence and frequency of the saturation events discussed in the paper on Llama3 model."
            }
        },
        {
            "summary": {
                "value": "This work expands the top-1 saturation event to top-k tokens and finds a significant phenomenon that there is an order law between the saturation events and the corresponding tokens' ranking. Additionally, such phenomenon is rooted in transformer architecture, which happens across all modality and even in untrained models. With the finding of such order law on the saturation events, an efficient decoding method is proposed for early-exit for next-token prediction."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. The concept and research problem in this work is very novel. It significantly extends the range of saturation event to the top-k token level. \n\n2. The findings are very brute-force, which can be easily used for early-exit decoding for next token prediction acceleration without introducing much additional computation. And such decoding strategy is general and easily applied across all transformer based LLMs."
            },
            "weaknesses": {
                "value": "1. The evaluation of this method is limited in its size and targeted models. 60k tokens and 100 texts are a too small evaluation set size for a robust conclusion. GPT2-XL is also not well-trained and the experiments on Llama-3 is more recommended. If the saturation event for top-k tokens only happens at very late layers, then the acceleration ratio is not that ideal compared with GPT2-XL experiments. CNN summarization task is a very basic task for recent LLMs, while the benchmarks of MMLU, Hellaswag are more recommended for study and experiments."
            },
            "questions": {
                "value": "1. I recommend to change the definition of \"task\" to other words like \"process\". The concept of \"task transition\" makes me feel like there is some generality in different tasks like summarization, QA, dialogues, etc.\n\n2. The experiments on vision and speech transformers are great demonstrations to your claim on the generality of your findings but have no contribution to real applications like decoding acceleration. Maybe you can consider to remove them into appendix and enlarge your study on language model part.\n\n3. I am very interested in whether such saturation event happens on all tokens in the context or just a few tokens? If it does not happen on all tokens, how you can deal with the prediction towards these non-saturation tokens?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper is to understand the inner workings of transformers to achieve more accurate and efficient predictions. Authors expand the concept of saturation events for top-k tokens, demonstrating that similar saturation events occur across language, vision, and speech models. The experiments show that it is possible to predict the current task from hidden layer embedding. Furthermore, authors use an intervention method to cause the model to swithc from one task to the next."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is well written with clear illustrations.\n2. There are extensive experiments across different modalities, such as vision, language, and speech.\n3. Compared with two baseline models, the proposed method demonstrates improved performance."
            },
            "weaknesses": {
                "value": "1. Compared with Line 275 and L 276, the proposed method seems to be model-specific. While the results in Table 1 show the layer embeddings contain information about the task number, such information may only work for language, but not vision and speech.\n\n2. in Line 472, why the second token's saturation layer is at least \"7\" layers before the output? The hypothesis seems to be hand-crafted without any supportive evidence.\n\n3. In Table 2, the comparisons of different strategies are a little bit weak to support the claim. Is 40% accuracy a significant improvement compared to the baselines 35.9% and 37.5%? As these numbers are pretty low to have any real applications."
            },
            "questions": {
                "value": "See the above weakness. The main concern is that the proposed method is quite heuristic and hand-crafted without enough supportive evidence. While the authors demonstrate the results across different modalities, it is difficult to evaluate the effectiveness of this method given the relatively low numbers."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates the internal mechanisms of Transformers, particularly focusing on the computation performed after the top-1 prediction has been determined, a phenomenon referred to as the \"saturation event.\" The authors expand the concept of saturation events to top-k tokens and demonstrate that these events occur in a ranked order across various modalities (language, vision, speech) and Transformer architectures. They propose a task-transition mechanism to explain this sequential saturation, where each task corresponds to predicting the k-th most probable token. The paper further shows that it is possible to predict the current task from hidden layer embeddings and to induce task transitions through interventions. Finally, the authors introduce a token-level early-exit strategy that improves performance and efficiency, outperforming existing methods."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. The paper provides a fresh perspective on how Transformers process predictions beyond the top-1 token, which is a significant contribution to the field of model interpretability.\n2. The study's scope extends across multiple modalities, enhancing the generalizability of the findings and demonstrating the robustness of the proposed mechanisms.\n3. The authors back their claims with extensive experiments and provide empirical evidence supporting the task-transition hypothesis.\n4. The paper not only has theoretic analysis but also explores practical applications, such as the early-exit strategy, which has potential implications for improving model efficiency and accuracy."
            },
            "weaknesses": {
                "value": "This is a suggestion rather than a weakness. \n\nIt would be great to discuss whether this is a fundamental solution for early exit problem. After all, it is ridiculous for us to let problems with all level of difficulties to go through all the layers. There must be a solution that significantly improve the inference efficiency of the current LLM through sparsity or early exit. Yet the solution proposed by this paper give only marginal improvement."
            },
            "questions": {
                "value": "Please see the weakness part. Highly appreciate if the author give some feedback."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "1) This study extends the concept of saturation from only the top-1 token to multiple top-ranked tokens, providing deeper insights into the computational processes within Transformer models.\n2) Experiments across diverse domains, including text, vision, and speech, demonstrate the broad applicability of this sequential saturation mechanism.\n3) Beyond observing this phenomenon, the authors propose an early-exit algorithm based on their findings, presenting a practical approach to enhance computational efficiency in Transformer models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is written in a clear and understandable manner, with a well-defined approach and valuable findings that go beyond observation to demonstrate practical benefits. I believe this is an good research, and with a few additional points, it would be well-suited for acceptance at the conference."
            },
            "weaknesses": {
                "value": "If the paper claims that these findings are unique to Transformers (as the title suggests), it should demonstrate that (1) this phenomenon does not occur in other architectures and (2) it consistently appears in recent, state-of-the-art models. Providing this evidence would make the paper much more logically sound and robust.\n\nThe practical applicability of the experiments in Sections 5.1 and 5.2 feels somewhat limited; further validation could enhance their real-world relevance. (For example, as shown in A.5, softmax and state cannot outperform ours even at the minimum speedup, which makes the comparison less compelling.)"
            },
            "questions": {
                "value": "(1) Table 1 shows different chance levels for each model (e.g., 25% for Whisper-large vs. 20% for GPT2-XL and ViT-L/16) Could the authors clarify the reason for these differences?\n\n(2) In Figure 3, how did the authors handle cases where two top-ranked tokens reach saturation at the same layer?\n\n(3) Following up, how were such cases handled during classifier training?\n\n(4) In Table 1, how was accuracy calculated in these scenarios?\n\n(5) typo: 400lines: l1(s1) < l2(s2) => l1(s1) < l1(s2)\n\n(6) Could the authors provide a comparison with other early exit methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper explores hidden states of intermediate layers of transformer-based models by mapping them onto the vocabulary space to extract ranking over tokens and analyzing their changes over the layers. The authors claim to identify sequential saturation events for top-k tokens, a phenomenon observed across language, vision, and speech models. They propose a type of discrete transition occurs during decoding."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Strengths:\nThe paper emphasizes the importance of investigating layer-wise states transition. The study tackles an important and interesting research question."
            },
            "weaknesses": {
                "value": "The hypothesis of \u201csaturation events\u201d is taken as granted without sufficient evidence. The mechanism in producing top-1 tokens in LLMs is influenced by various factors, including LLM architecture, contexts, and how an LLM reacts to an input. Based on practice shared by many colleagues in probing LLMs, transformers often alternate their top-1 token predictions, even in later layers, which undermines the claimed findings by this study. \n\nThe scope of the experiment is limited in terms of both the number and types of LLMs and tasks. This raises concerns about the generality of the findings. It is important to investigate both NLU and NLG tasks on a diverse range of LLMs under different regimes (e.g., pre-trained, post-trained, decoder-only, encoder-decoder) to ensure comprehensive insights. Instead of limiting to a small-scale LLM like GPT2-XL, the authors may consider exploring state-of-the-art (SOTA) LLMs, such as the LLAMA series, to broaden the scope of their research and enhance the robustness of the conclusions.\n\nThe use of ranks and central tendency in Figure 3 is confusing (i.e., why averaging ranks and std in figure 3). There are existing statistic rank tests the authors may leverage. The claimed sequential saturation pattern should be convincingly demonstrated.\n\nThe practical application of intervention is unclear, and the results shown in table 2 are not statistically significant. When you choose \"Highest accuracy\", how do you calculate it? Is it based on EM?"
            },
            "questions": {
                "value": "as above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}