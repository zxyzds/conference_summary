{
    "id": "xriJVaTh4C",
    "title": "Gaussian Loss Smoothing Enables Certified Training with Tight Convex Relaxations",
    "abstract": "Training neural networks with high certified accuracy against adversarial examples remains an open challenge despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods, perhaps surprisingly, can perform worse than looser relaxations. Prior work hypothesized that this phenomenon is caused by the discontinuity, non-smoothness and perturbation sensitivity of the loss surface induced by tighter relaxations. In this work, we theoretically show that Gaussian Loss Smoothing (GLS) can alleviate these issues. We confirm this empirically by instantiating GLS with two variants: a zeroth-order optimization algorithm called PGPE which allows training with non-differentiable relaxations, and a first-order optimization algorithm, called RGS, which requires gradients of the relaxation, but is much more efficient than PGPE. Extensive experiments show that when combined with tight relaxations, these methods surpass state-of-the-art methods when training on the same network architecture for many settings. Our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks and pave a path towards leveraging tighter relaxations for certified training.",
    "keywords": [
        "Certified Robustness",
        "Adversarial Robustness",
        "Certified Training",
        "Convex Relaxation",
        "Neural Network Verification"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We show that Gaussian Loss Smoothing allows us to overcome the Paradox of Certified Training and yields better networks when training with tighter bounds.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=xriJVaTh4C",
    "pdf_link": "https://openreview.net/pdf?id=xriJVaTh4C",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes to use a method (Gaussian Loss Smoothing) to address the paradox of certified training which is caused by the discontinuity/non-smoothness/sensitivity issues of certifiable training with tighter convex relaxations. Moreover, the authors also use a gradient-based method called Randomized Gradient Smoothing (RGS) to scale GLS to larger models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "I think the following strength itself is enough for accept.\n- The paradox of certified training is an important subject to study.\n- The proposed method (GLS) is well-motivated and backed up by theoretical results.\n- The empirical results on small perturbation settings in Table 3 are quite impressive."
            },
            "weaknesses": {
                "value": "This paper is well-motivated, but has a minor weakness in the performance (on large perturbation) detailed as follows:\n- Table 3 (Table 5 in Appendix) shows the results for small (large) perturbation settings. The results for large perturbation is not significant. IBP performs well for large perturbations and other tighter methods does well for small perturbations. This is because of the continuity, smoothness and sensitivity of the loss landscape. Thus, to check the effectiveness of GLS, I think it is crucial to check the result of tighter methods on large perturbation settings. However, setups (i) MNIST $\\epsilon=0.3$ and (ii) CIFAR-10 $\\epsilon=8/255$ show that \nGLS (or RGS) (i) does not show a significant performance gain (DP-RGS (IBP) vs MTL-IBP; 88.69 vs 88.68) or (ii) shows a worse performance (29.25 vs 29.62). This should be discussed in the main text (not in Appendix). I don't think the performance itself is a reason for a rejection, but it needs more discussion.\n- In Table 1, \"the more precise DeepPoly bounds now yield the best certified accuracy across all settings, even outperforming accuracy at low perturbation radii'', but not for the large perturbation (IBP vs DeepPoly-PGPE; 77.23 vs 74.28, 25.72 vs 22.19).\n- In GRAD Training, \"IBP dominates the other methods, confirming the paradox of certified training\", but in the original paper of CROWN-IBP, CROWN-IBP outperforms IBP for a larger network (see their Table 2 https://arxiv.org/pdf/1906.06316). \n- (For a larger model,) IBP outperforms the other methods (e.g, CROWN-IBP, CAP) for large perturbation, not for small perturbation (e.g., see Table 1 in Lee et al. (2021)). This implies that the paradox plays more important role for a larger perturbation.\n\n\n\nPlease check the Questions part together. I think unclear presentation is also a weakness."
            },
            "questions": {
                "value": "- There is no comparison with CROWN-IBP in Table 3. Why?\n- \"We remark that scaling to CNN7 used by the SOTA methods is still infeasible due to the high computatinoal cost of evaluating DeepPoly\" How about applying RGS to CROWN-IBP as it is cheaper than DeepPoly?\n- What do the italic numbers mean in Table 3?\n- DP-RGS appears first in L480, but never defined (seems like DP-RGS = DeepPoly-RGS)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper talks about the variation in certified training; though tighter relaxations sometimes reduce performance compared to looser bounds, it shows the authors introducing Gaussian Loss Smoothing as one of the methods for smoothing the loss landscape to reduce discontinuity and sensitivity\u2014the major hurdles in certified training with tight relaxations.\n\nThey provide two ways of realizing the different realizations of GLS: first is PGPE, a gradient-free approach based on policy gradients with parameter-based exploration; second is RGS, which is described as a gradient-based approach using randomized gradient smoothing. Experimental results on several datasets illustrate that indeed the algorithm GLS outperforms current methods relying on tight relaxations; sometimes its performance is tested along with the DEEPPOLY relaxation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "GLS introduces novelty in using Gaussian smoothing across the loss landscapes, strongly problematic in certified training."
            },
            "weaknesses": {
                "value": "## Writing Style\n\n- **Introduction**: In some respects, the introduction could be improved about adversarial certified robustness. It is abrupt and feels more work-related.\n  \n- **Transitions and Structure**: Transitions from one section to another are missing; hence, making the paper hard to follow. Statements such as, \"While CROWN-IBP is not strictly more or less precise than either IBP or DEEPPOLY,\" necessarily need references or explanations.\n\n- **Undefined Terms**: Terms such as \"soundness\" and \"sensitivity\" are undefined.\n\n- **Results of experiments**: These are presented in a very untidy fashion.\n\n\n## Related Work\n\n- **Definitions**: Some more clear definitions can be provided, for instance, adversarial attack and adversarial robustness because the latter is different from certified robustness.\n  \n- **Redundant Subsections**: Sections 2.1 would seem to represent redundant subsections: \"Training for Robustness\" and \"Adversarial Training.\"\n\n\n## Theoretical Findings\n\n- **Lack of Rigor**: Theoretical statements, like Theorem 3.1, are informal and not mathematically precise. References to results, including Stein's Lemma [2], could be good in the proof.\n  \n- **Flaw in Proofs in Lemmas**: \nIn the proof of Lemma B.1 terminology and symbols that are important are not defined (for example, \\(\\delta \\theta\\), \\(P_{\\epsilon_1}\\), \\(P_{\\epsilon_2}\\), \\(P_{\\mathcal{N}(0, \\sigma^2)}\\)). The authors seem to take the limit $\\delta \\theta$ to $0$ but it is never stated anywhere in the proof and the integral of the derivative of the loss  $L^\\prime$  should be a multi dimensional integral as the input space is multi dimensional.\nIn Lemma B.2's proof  the simplifications are excessive,  the structure of the proof is highly defective in many places and it needs a thorough revision. \n\n\n\n## Experimental Results\n\n- **Lack of Detail**: Neither the dataset nor the architecture used in Figure 1 are specified.\n  \n- **Performance Gains**: Although the experimental results are somewhat improved, they are not very significant compared to previous methods; therefore, this added complexity is questionable in value. Presentation of the standard deviations over multiple runs would have given more robust conclusions since apparent gains are marginal.\n\n\n# Major Concerns\n\n1. **Theoretical Rigor**: The proofs are not rigorous; better structure and formalization are required. The use of Stein's Lemma might improve the underlying framework, giving credibility to the theoretical results.\n  \n2. **Marginal Gains and Complexity**: GLS brings in computational complexity especially with PGPE, while performance benefits are marginal.\n\n3. **Readability and Clarity**: The writing style and the structure take away from clarity, making the paper difficult to follow.\n\n\n[2] Stein, \u201cEstimation of the Mean of a Multivariate Normal Distribution,\u201d The Annals of Statistics, 1981."
            },
            "questions": {
                "value": "GLS appears to be related to Sharpness-Aware Minimization (SAM) [1], as both approaches aim to smooth the loss landscape for a more regular surface. It would be beneficial to include a discussion or a related work section to clarify this connection in the paper.\n\n[1] Foret et al., \u201cSharpness-Aware Minimization for Efficiently Improving Generalization,\u201d ICLR, 2021."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes to use Gaussian Loss Smoothing (GLS) with certified training algorithm, such as IBP, CROWN, etc. The motivation is that a previous paper pointed out that methods other than IBP, though having tighter relaxation, suffer from discontinuity, non-smoothness, perturbation sensitivity. The authors argue that GLS can make the loss surface smoother using a theoretical result and some plots as evidence. The method is tested on MNIST, Cifar-10 and TinyImagenet."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The writing is fine. There is little difficulty understanding the paper."
            },
            "weaknesses": {
                "value": "1. Contribution: This paper proposes to apply GLS to existing certified training methods such as IBP and DeepPoly, and one can use PGPE or RGS to compute the GLS. Note that, however, all of IBP, DeepPoly, GLS, PGPE and RGS are existing methods. Theorem 3.1 is a direct application of an existing result. So if I understand correctly, the only novelty of this submission is combining these things together, and thus the contribution is incremental.\n2. Performance: How does the proposed method perform? From Table 1, it seems that the proposed method (PGPE) is not significantly better than the standard method (GRAD), if not worse. It is true that PGPE makes DeepPoly better than IBP, but the way it does that is to make IBP worse, not making DeepPoly better. On MNIST (0.3) and CIFAR-10 (8/255), the best PGPE method is worse than the best GRAD method. On the other two settings, it is only slightly better. For all settings, IBP-PGPE is worse than IBP-GRAD (standard). Thus, this result suggests that one probably should not use PGPE. There is no evidence that the proposed method works in practice.\n3. Experimental results: Tables 1 and 3 seem contracting with each other. In Table 1, standard IBP on CIFAR-10 (2/255) has natural accuracy 48.05% and certified accuracy 37.69%; in Table 3, the two reported numbers are 54.92% and 45.36%. Probably this is because CNN5 is better than CNN3, but then what is the point of Table 1? Why not always use a bigger model (CNN7 seems even better). And why not compare with RGS in Table 1? I don't think there is anything preventing you from comparing with RGS in Table 1. The authors report DP-RGS to be the best method in Table 3, but since there are so many problems with the tables I do not trust this result.\n\nOverall, this submission proposes to combine a bunch of existing methods, but the experiments show that this is even worse than the original methods. Thus, I recommend rejecting this submission."
            },
            "questions": {
                "value": "1. DeepPoly-GRAD achieves 90.04% certified accuracy on MNIST (0.1) in Table 1; in Table 2 this number is only 68.47%. Is this a typo? I don't believe that changing the model size can make such a big difference; plus, only DeepPoly-GRAD has such a huge drop in performance.\n2. Is it correct that you are only changing the loss of training the model, but you are not changing the way of certifying the model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}