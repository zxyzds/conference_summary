{
    "id": "Jg9Ol9aVjx",
    "title": "DICR: Direct Intra-image Constrastive Regularization for Contrastive Learning",
    "abstract": "Typical contrastive self-supervised learning methods apply inter-image contrast to post-projector embeddings, thereby indirectly encouraging the pre-projector representations' invariance to several augmentation operators.\nWhile effective, these methods do not account for the inherent difference between semantics-altering (such as cropping and cutout) and semantics-preserving augmentation operators (such as resizing, flipping and color distortion), and thereby lack an explicit mechanism to encourage distinguishable representations for semantically different contents within the same image.\nWe explain, both in reason and in practice, that these issues can harm the generalizability of the representations in downstream tasks.\nTo address these issues, we propose Direct Intra-image Contrastive Regularization (DICR), a plug-and-play regularization method that directly applies intra-image contrast to pre-projector representations.\nEmpirical results show that DICR can significantly enhance the generalizability of existing methods in downstream tasks, and validate the crucial role of semantic content distinguishability in the generalizable performance of contrastive learning.",
    "keywords": [
        "Contrastive Learning",
        "Representation Learning",
        "Self-Supervised Learning"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-20",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Jg9Ol9aVjx",
    "pdf_link": "https://openreview.net/pdf?id=Jg9Ol9aVjx",
    "comments": [
        {
            "summary": {
                "value": "This paper studies image-based contrastive learning. Observing that existing contrastive learning methods suffer from semantic change in applying croppings, the paper proposes DICR, a PnP regularization method that is explicitly designed to solve this issue. The experiments show that the proposed method has improved in various settings and downstream tasks."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed method is novel, simple yet effective. By only adding a branch of loss after the feature maps, the proposed method can mitigate the issue.\n- The method is described in a clear manner with lots of formulas, making it easy to understand.\n- The proposed method consistently outperforms the w/o baselines in most evaluation cases. Ablation studies are also provided."
            },
            "weaknesses": {
                "value": "- Lack lots of empirical comparisons to extensively verify the effectiveness of the method.\n   - All the pre-training datasets are very small datasets. It is unsure whether the proposed method can work on large-scale datasets like ImageNet.\n   - The only backbone is ResNet18. It is also uncertain whether the proposed method can also work on (1) larger ResNets, or (2) other model architectures like ViTs.\n   - The only downstream task is classification. It is uncertain whether the method can improve the performance in more semantic-aware tasks like segmentation or captioning.\n   - Not all common contrastive learning methods are considered, e.g., MoCo v2 and MoCo v3. Especially MoCo v3, which got rid of the queues and achieved contrastive learning with large batch sizes.\n   - This lack of comparison significantly hurts the soundness of the paper. If the proposed method only works on small datasets with small networks, the conclusion is not very reasonable and cannot be applied on most of the scenarios, and the contribution will be limited.\n- Some abbreviations are not clearly described. The audience needs to make educated guesses to find out what it means. E.g., \"RoI\" - \"region of interests?\"\n- L083 claims that \"which adds no extra parameters and can efficiently regularizes existing methods.\" However, no information about \"efficiency\" was provided as experiment results. I wonder what the actual additional computation cost is."
            },
            "questions": {
                "value": "- Please refer to the weakness to see some additional experiments that can be added to improve the soundnesses.\n- I wonder whether other non-contrastive self-supervised learning, e.g., MAE or DINO, can also benefit from the proposed method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paperintroduces DICR, a new regularization method that improves upon traditional contrastive learning by directly contrasting pre-projector representations within images. DICR enhances the ability of models to generalize to new tasks by distinguishing between semantically different image contents, leading to better performance in downstream applications."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.The paper identifies a significant issue with current contrastive self-supervised learning methods in their indiscriminate treatment of semantic-altering and semantics-preserving augmentations, which can lead to performance degradation in downstream tasks.\n2. The paper provides a detailed theoretical explanation and empirical evidence for the importance of distinguishing between these two types of augmentations.\n3.The paper introduces Direct Intra-image Contrastive Regularization (DICR), a method that aims to ensure the distinguishability of different but co-occurring contents through intra-image contrast, while preserving their correlation through inter-image contrast.\n4. The paper demonstrates DICR's ability to differentiate between various semantic contents within an image and its effectiveness in enhancing the generalizable performance of existing methods in downstream tasks."
            },
            "weaknesses": {
                "value": "1.The paper assumes that distinguishing between semantic-altering and semantics-preserving augmentations will enhance generalizability, but more experiments may be needed to validate this assumption across different datasets and tasks.\n2.Although DICR does not require additional parameters, it may increase the computational cost of training, especially with large datasets.\n3.The introduction of DICR may complicate the model training process, requiring careful tuning to ensure performance."
            },
            "questions": {
                "value": "1.The effectiveness of DICR may rely heavily on the choice of augmentations, and different choices could affect model performance.\n2.DICR's emphasis on distinguishing different contents could lead to overfitting to specific types of datasets, potentially underperforming on unseen distributions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose that  indiscriminately treating semantics-altering and semantics-preserving augmentation operators may be suboptimal for downstream tasks. To address this issue, a intra-image constrastive learning method is designed with no extra parameters, which improves the generalizable downstream performance of existing methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The authors conduct extensive experiments and analytical study, and perform comparisons with explicit and implicit models.\n2. The authors provide implicit empirical demonstration."
            },
            "weaknesses": {
                "value": "1. The motivation for the proposed intra-image contrastive loss is not clear. Why do we attract foreground and background into identical representations? And why do we attract different parts of the same object into the same representations? The Figure.1 and Section 2.1 confuse me."
            },
            "questions": {
                "value": "1. The authors should carefully explain the motivation of their intra-image contrastive loss.\n2. It can be observed in Figure3 that the intra-image contrastive learning divides the image to finer regions and perform attraction and repulsion among n1, n2, o1 and o2. So why does the method still need inter-image constrastive learning?\n3. In the results presented in Table 1, why does Base sometimes show better results, and why does Base sometimes show the results same as DICR?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Existing methods typically employ inter-image contrastive learning, indirectly encouraging the representations to be invariant to augmentation operations. However, they fail to differentiate between semantics-altering augmentations (e.g., cropping, cutout) and semantics-preserving augmentations (e.g., resizing, flipping, color distortion). This work proposes a Direct Intra-image Contrastive Regularization (DICR) method to improve the generalizability of contrastive self-supervised learning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The motivation of this paper is reasonable and clear.\n2. The effectiveness of the proposed regularization was verified on multiple baselines."
            },
            "weaknesses": {
                "value": "1. Although the motivation is clear, it lacks concrete examples to support the finding that prior contrastive learning methods cause confusion in downstream models. This absence of empirical evidence makes the motivation less solid. Moreover, section 2.2 \"Implicit Empirical Demonstration\" lacks clarity and is somewhat difficult to understand. Specifically, for example in Figure 2a, it is unclear what \"Distinguishability\" represents and how this value is derived, as the paper does not provide an explanation for it. \nMost importantly, the two observations mentioned in this section\u2014\"lower layers have more distinguishable representations\" and \"lower layers have more generalizable representations\"\u2014lack a clear conclusion or insight, making it difficult to understand the connection between these observations and the overall motivation. This part is challenging to follow and comprehend.\n2. The proposed Direct Intra-image Contrastive Regularization (DICR)  is somewhat simple and lacks novelty. By simply talking about overlapping parts being close to each other and non-overlapping parts being willing to each other, does this destroy similar feature representations in the non-overlapping parts. As an extreme example given by the authors, if two views of a crop with non-overlapping regions happen to be the left and right ears of a dog, should their representations also be far away from each other in feature space? I think the method is overly simplistic in its design and harder to achieve what the authors are aiming for.\n\n3. Although the performance on image classification tasks was validated, other downstream tasks (such as detection and segmentation) were not tested. It is necessary to further verify the generalizability of DICR on additional downstream tasks."
            },
            "questions": {
                "value": "1.In Figure 2a, it is unclear what \"Distinguishability\" represents and how this value is derived."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}