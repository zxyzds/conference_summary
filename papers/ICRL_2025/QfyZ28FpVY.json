{
    "id": "QfyZ28FpVY",
    "title": "DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries",
    "abstract": "DNA-encoded library (DEL) screening has revolutionized the detection of protein-ligand interactions through read counts, enabling the rapid exploration of vast chemical spaces. However, noise in read counts, stemming from nonspecific interactions, can mislead this exploration process. Neural networks trained on DEL libraries have been employed to discern and capture nuanced, task-specific patterns within chemical landscapes. However, existing methods overlook two critical aspects: (1) the inherent ranking nature of read counts and (2) the potential of true activity labels to correct systematic biases. We present DEL-Ranking, a novel distribution-correction denoising framework that addresses these challenges. Our approach introduces two key innovations: (1) a novel ranking loss that rectifies relative magnitude relationships between read counts enabling the learning of causal features determining activity levels, and (2) an iterative algorithm employing self-training and consistency loss to establish model coherence between activity label and read count predictions. Furthermore, we contribute three new DEL screening datasets, the first to comprehensively include multi-dimensional molecular representations, protein-ligand enrichment values, and their activity labels. These datasets mitigate data scarcity and incomplete data issues in AI-driven DEL screening research, providing novel benchmark datasets for this field. Rigorous evaluation on diverse DEL datasets demonstrates DEL-Ranking's superior performance across multiple correlation metrics, with significant improvements in binding affinity prediction accuracy. Our model exhibits zero-shot generalization ability across different protein targets and successfully identifies potential motifs determining compound binding affinity. Our work not only advances the field of DEL screening analysis but also provides valuable resources for future research in this area.",
    "keywords": [
        "DEL Denoising",
        "Deep Learning",
        "Bioinformatics"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=QfyZ28FpVY",
    "pdf_link": "https://openreview.net/pdf?id=QfyZ28FpVY",
    "comments": [
        {
            "summary": {
                "value": "The authors define a novel objective function for finding hits from a DEL screening campaign. They then compare their approach across a number of different DEL datasets of carbonic anhydrase."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The description of the field is helpful.\n\nI think the deep dive into the biochemical and technical sources of variation are helpful.\n\nThe number of datasets in which evaluation was done is impressive.\n\nThe ablation experiments are very helpful and surely a lot of work, so I appreciate them described in detail here.\n\nGenerally, I think the authors are quite well versed in the field and problem domain."
            },
            "weaknesses": {
                "value": "Generally, I\u2019m a bit confused about the discussion of \u201cDistribution Noise\u201d. Is this variance? Others in the sequencing space has parameterized this as either a negative binomial or a zero-inflated negative binomial\u2013is this what you\u2019re referring to? If so, it\u2019s just the variance of the observations.\n\nAre the acronyms ARDC, AGR, and CDEC necessary? Is there a one-word description of these that you could propose to summarize their function? For example:\n\nARDC - Reference Correction\nAGR - Refinement\nCDEC - Consistency\n\nThis will help the reader follow how each of these components contribute to the model. This is in addition to new acronyms PSR, and LGR.\n\nMore care needs to be given to defining the Pairwise Soft Ranking Loss. There are a number of variables that either aren\u2019t defined or aren\u2019t used consistently. It\u2019d also be great to have more intuition for design decisions on the objective function. What happens when certain components become large or small? Why multiply or subtract things? As a reader that\u2019s worked with DEL data, this isn\u2019t clear.\n\nThe same is true for the Listwise Global Ranking Loss. What is s_i? How does it differ from s_{\\pi(i)}? Then \\sigma is recycled from PSR as the weight for L_con?"
            },
            "questions": {
                "value": "\u201ca novel ranking loss that rectifies relative magnitude relationships between read counts enabling the learning of causal features determining activity levels\u201d. The use of \u2018causal\u2019 is particularly strong here. How do you disentangle correlation from causation? What aspects are explicitly causal?\n\nIn section 3.1, where is the \u201cActivity Label\u201d derived? Is it used in any equation? (This is y_i). The variable y is then also used in line 250\u2013is this the same?\n\nAgain in section 3.3, what is Activity? Also \u201c...where Apred and Atrue denote the predicted and ground-truth activity\u201d: Do you actually ever know \u201cground-truth\u201d activity, or is it just \u2018observed\u2019? Typically there is just some biochemical proxy for \u2018ground-truth\u2019.\n\nWhere are \\Delta G_ij and \\Delta D_ij defined? I see the non \\Delta versions defined in lines 254 and 255.\n\nHow do you know the docked poses described in part 4 are actually real, or correspond to where the molecule is binding? Have these docking poses been shown to correspond to read counts in these molecules?\n\n\u201cTraditional methods based on binding poses and fingerprints inculde[sic]...Benzene Sulfonamide\u2026\u201d What is Benzene Sulfonamide? This is just a carbonic anhydrase-specific thing?\n\nIs the \u201czero-shot\u201d predictions just also on carbonic anhydrase? That seems disingenuous. I would anticipate zero-shot to be on another target entirely, not just a different dataset on the same target.\n\nWere the pyrimidine sulfonamide groups identified by any other method presented here?\n\nWas the pose encoder necessary? It seems superfluous to the other components added here, and quite complex."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "DNA-encoded library (DEL) screening has been an instrumental technique in accelerating the pace of drug development. By attaching a unique DNA \u201cbarcode\u201d to each compound, thousands of compounds can be screened against a protein target in a single experiment. The number of copies of each barcode indicates how many of those compounds are bound to the target protein. However, the barcode count data is noisy, is not directly correlated with the dissociation constant, and contains systematic biases. Therefore, the problem is reduced to generating a ranking of compounds based on observed barcode read counts. The authors address the main issues in DEL screening by proposing a new ranking loss, rectifying some inherent issues in read counts, and implementing a self-training method to align activity labels with barcode read counts."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Unfortunately, I am not able to gauge the strengths of this paper due to presentation issues (see \u201cQuestions\u201d)."
            },
            "weaknesses": {
                "value": "Please refer to \u201cQuestions\u201d for Major Concerns.\n\n**Minor points**\n- In Fig. 1, the middle panel incorrectly depicts DNA barcodes binding to the target protein; it should show \u201cbuilding blocks\u201d instead. A correct version can be found in (Shmilovich et al., 2023).\n- In line 104, ZIP loss has not been defined.\n- In line 147, the statement \u201cWhile existing methods offer improved scalability and the ability to capture complex molecular interactions, they still face challenges in interpretability\u201d is vague and needs further elaboration."
            },
            "questions": {
                "value": "I had difficulty following the problem formulation. Here are some of my questions:\n\n- Why are M_i and R_i \\in \\mathbb R+? Can\u2019t these counts be zeros?\n- M_i\u200b is control counts and R_i is the target counts. But in line 197, it states: \u201cmodeling read counts r_i as (M_i,R_i), where M_i accounts for excess zeros and R_i represents non-zero counts.\u201d I am confused. Is r_i two-dimensional? Moreover, what does the (M_i, R_i) tuple mean?\n- In Eq. (2), why does each compound have a different \\pi (\\pi_i)?\n- Why do control and target counts not have different \\pi values, as in Shmilovich et al. (2023)? These \\pi values should differ by orders of magnitude.\n- In the Problem Definition, y_i\u200b \\in {0,1} is the activity level, but in line 250, \u201c\\hat y_i\u200b represents the predicted read count value for compound i.\u201d Then, what are \\hat M\u200b_i and \\hat R_i introduced in Eq. (1)?\n- In Eq. (4), L_PSR does not seem to be a function of i or j, as the sum goes over all values of i and does not depend on j either.\n- In the same equation, why does it depend on y_i and y_j? Should it have been \\hat y_i and \\hat y_j? Although, the authors also mention in line 254 that G_i = softplus(y_i).\n- What is \u201cK\u201d in Eq. (5)?\n- In Eq. (6), L_GSR, the first term on the right-hand side does not depend on i or j, while the second term depends on both i and j. Should there be a double sum over i and j for the second term?\n- On the same note, what is \u201cs_i\u200b\u201d? Is it the same as r_i\u200b?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the problem of how to build a good machine learning model of ligand binding activity based on DEL screens. The two primary challenges with modeling DEL-based data is the noise in the data and the mismatch between the true log-enrichment of a compound in the DEL assay and the actual binding affinity of the compound. The authors propose a number of new modeling approaches to tackle these issues. First, a new ranking-loss is proposed. In addition the authors introduce an iterative training approach that promotes the matching of read-based predictions to true activity values as well as a consistency loss."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper addresses a number of relevant challenges to an important problem of predicting binding affinity from DEL data."
            },
            "weaknesses": {
                "value": "1) I found it really hard to understand the details of the specific losses and approaches. For example, Equation 4 seems to depict a function that takes in two element, y_i and y_j, but the right-hand side is written using a sum of 'i' and 'j', suggesting it is over the entire dataset?\n\nI was unable to understand at all what the activity-guided refinement is based on the written text. Similarly, there is no clear motivation for the specific choices of many of the loss functions. For example, Equation 8 is just presented but there is no explanation for why the particular terms are included over a simpler loss such as ||A_true - A_pred||_2.\n\n2) The largest weakness for me is that the paper seems reads as a \"bag-of-tricks\". Each individual loss may be reasonably motivated, but each loss term also introduces its own set of hyperparameters. This paper introduces at least 6 new hyperparameters. Importantly, there was no discription of how these hyperparameters were chosen and no demonstration that they can be robustly chosen using a validation set. Thus, I do not believe the authors have demonstrated that they have actually produced a more useful method. So far, they have only shown that with a carefully chosen set of hyperparameters and the introduction of a much much more complicated modeling scheme that they can slightly improve the spearman correlations.\n\n3) Nowhere in this paper is the ZIP loss actually defined. It first shows up in the paper with just the acronym and no description of what ZIP means."
            },
            "questions": {
                "value": "1) How were the hyperparameters chosen?\n\n2) Can they be chosen robustly with a validation set? Please provide experiments demonstrating this, if so.\n\n3) Using molecular docking structures seems potentially problematic as these poses are often wrong and therefore add noise to your model. Please discuss this further.\n\n4) The authors claim that DEL data is inherently ranking in nature, but this is not obvious to me. The relative magnitude of the log-enrichments may provide useful information about the binding affinity. Throwing away this information and only ranking loses information.\n\n5) What is ZIP? \n\n6) Please provide further discussion of the iterative algorithm."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}