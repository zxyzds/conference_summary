{
    "id": "EWQaqDgXgr",
    "title": "Sparse Repellency for Shielded Generation in Text-to-Image Diffusion Models",
    "abstract": "The increased adoption of diffusion models in text-to-image generation has triggered concerns on their reliability. Such models are now closely scrutinized under the lens of various metrics, notably calibration, fairness, or compute efficiency. We focus in this work on two issues that arise when deploying these models: a lack of diversity when prompting images, and a tendency to recreate images from the training set. To solve both problems, we propose a method that coaxes the sampled trajectories of pretrained diffusion models to land on images that fall outside of a reference set. We achieve this by adding a simple repellency term to the diffusion SDE throughout the generation trajectory, that is triggered whenever it is expected to land too closely to an image in the shielded reference set. Our method is sparse in the sense that these repellency terms are mostly zero and inactive, even more so towards the end of the generation trajectory. Our method, named SPELL\nfor sparse repellency, can be used either with a static reference set that contains protected images, or dynamically, by updating the reference set at each timestep with the expected images concurrently generated within a batch. We show that adding SPELL to popular diffusion models improves their diversity while impacting their FID only marginally, and performs comparatively better than other recent training-free diversity methods. Moreover, we demonstrate how SPELL can ensure a shielded generation away from a very large set of protected images by considering all 1.2M images from ImageNet as the protected set.",
    "keywords": [
        "Diffusion Model",
        "Guidance",
        "Repellency",
        "Diversity"
    ],
    "primary_area": "generative models",
    "TLDR": "Guiding text-to-image diffusion trajectories away from protected images.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-11-15",
    "forum_link": "https://openreview.net/forum?id=EWQaqDgXgr",
    "pdf_link": "https://openreview.net/pdf?id=EWQaqDgXgr",
    "comments": [
        {
            "title": {
                "value": "Reviewer H25b: Rebuttal discussion"
            },
            "comment": {
                "value": "Many thanks for your encouraging comments and for praising our presentation with a score of 4. We are grateful for your many questions which we try to answer within the timeline of this rebuttal.\n\n> **The core issue for this paper is the soundness in terms of the superior effectiveness compared to other similar methods. In Fig. 4, there is only comparisons on recall-precision, converage-density, and vendi-clip trade-off, while other concerning metrics in Tab. 1, such as FID, FIDINOv2, are not included. I also failed to find reasoning on why only these three metric-pairs are selected.**\n\nThis is a great point. The reason we have used these metric pairs is that they are popular diversity (y-axis)  vs. quality (x-axis) pairs. But following your request, we have added a fourth plot in Fig.2, with FD_DINOv2 vs CLIP Score. We have also added Table 4, with all metrics, to provide an exhaustive view of all metrics.\n\n\n> **This discussion of the fundamental methodology difference towards Particle Guidance on Page 5 is not convincing, as it seems SPELL can be treated as a special case of Particle Guidance when the energy potential \u03d5t  is simply calculating the difference.**\n\nThanks for this comment. We agree that we were not clear enough in this section, starting with the title _(Intra-batch) SPELL as Particle Guidance_ which was, in retrospect, confusing. We have corrected this section in the paragraph you reference. Given more space we can expand a bit further the discussion. To be more detailed:\n\n- PG was proposed for intra-batch diversity following principles from the literature on interacting particles (_not_ to protect generation away from a reference set). We believe this viewpoint has guided two important choices: casting modifications of the trajectories as gradients of an interaction potential + use of a soft-decaying kernel that considers _exhaustively all_ interactions. This means that intra-batch similarity in PG is _always_ guiding / modifying the sampling of particles, throughout time and w.r.t. samples.\n\n- By contrast, SPELL is not defined as an energy minimizing principle, but follows instead from geometric principles (Fig. 1) which cannot, to our current knowledge, fit into such a \u201cgradient\u201d based perspective (we tried but experimental evidence suggests that SPELL interventions in Eq. 8 are not conservative). By doing away with this \u201cinteraction energy\u201d principle we lose PG\u2019s mathematical interpretation, but we gain efficiency and the ability to simply state our goal of making sure the trajectories almost always flow normally, and are only \u201cbumped\u201d when strictly needed (both w.r.t. batch but also in time, see Fig. 5(b), Fig. 9~16). In our view, that sparsity w.r.t samples _and_ time is crucial to scale in our application to image protection, but also to get unperturbed trajectories, and our experiments validate this intuition.\n\n> **This paper could benefit from more concrete visual evidences.**\n\nThis is a great suggestion. We are getting the computational resources to generate further example images, and will come back to you very soon.\n\n> **As it is difficult to show all possible trade-offs, a better way of giving concrete comparisons would be adding detailed tables for each of the methods. Each table shows all results with rows to be parameters, and columns to be all the metrics. Adding such tables would surely address my core concern, but due to limited time, it is also promising if the reasoning of choosing these trade-offs are persuasive and convincing.**\n\nThanks for the suggestion! We have added Table 4. We hope that this addresses your core concern.\n\n> **I'm generally not quite sure if SPELL could be treated as a special case of Particle Guidance in terms of intra-batch diversity. A brief explanation would be sufficient.**\n\nWe hope our answer above assuages your concerns. \n\nTo recapitulate, the two fundamental differences with PG lie in (i) adding guidance terms that are _not_ grad-potentials (ii) designing specifically very sparse repellence terms, with sparsity in two senses: \n- They act on trajectories rarely over time, and most interventions happen early and then vanish, see Fig. 5b. This is thanks to our focus, from the start, on _expected_ generation and not location at time $x_t$.\n- They only add sparse terms, to the extent that most of them are 0, when comparing to points in the reference set (either self-reference in intra-batch, or external reference for protection). This makes our method scale to 1.2M points as a reference set and leaves dynamics unperturbed *when perturbations are not needed*.\n\n> **This paper would also benefit from providing more diversity results, but it is understandable if this is infeasible considering the limited time for rebuttal.**\n\nThis is a great point. As mentioned above, we are getting access to resources needed to generate these examples. We will get back to you soon.\n\n> **MINOR**\n\nThanks for spotting these! We addressed these points in the revision."
            }
        },
        {
            "title": {
                "value": "Reviewer 94st: Rebuttal discussion"
            },
            "comment": {
                "value": "We are very grateful for your detailed review, your encouragements and your score of *4* for presentation. Here are a few answers to your concerns:\n\n> **While SPELL can be used for any diffusion pipelines, the effectiveness of SPELL for smaller models or domains other than ImageNet is not fully investigated.**\n\nIt was very tempting for us to use text2image as a testing ground for SPELL because this facilitates visual inspection of results and is well suited to the ICLR audience. Additionally, since one of our main claims is that our interventions are sparse (unlike PG) and can scale, considering very large reference sets (e.g. 1.2M images in ImageNet) was crucial. We believe that using our code will run into less challenges on smaller scale problems and other fields.\n\n> **SPELL does not provide a very tight guarantee to avoid generations of similar images to the reference set, which can limit the applicability of SPELL for high-risk cases.**\n\nThanks for this great point. SPELL is already the first method that is close to a perfect guarantee due to its geometric intervention rules (Eq. 5). In the protection experiment in S.4.6, we previously showed a 99.45% protection rate for EDMv2 + SPELL, compared to 92.40% for the bare EDMv2.\n\nIn fact, we can introduce a tradeoff, where the fast-NN search is more accurate (and longer) by increasing the number of searched Voronoi cells. We can reach a 99.84% success rate with a more accurate search (see updated Table 2 in revision). We have not optimized yet the parameters of the fast-NN search (currently this is run, sub-optimally, on CPU). We believe these overheads can be significantly reduced.\n\n| Model     \t| Searched cells | Time per image (s) \u2193 | Generated images far enough from all ImageNet images \u2193 |\n|---------------|----------------|-----------------------|---------------------------------------------------------|\n| EDMv2     \t| -          \t| 2.434             \t| 92.40%                                          \t|\n| + SPELL   \t| 1          \t| 4.633             \t| 98.92%                                          \t|\n| + SPELL   \t| 2          \t| 6.057             \t| 99.45%                                          \t|\n| + SPELL   \t| 3          \t| 7.790             \t| 99.67%                                          \t|\n| + SPELL   \t| 5          \t| 9.949             \t| 99.78%                                          \t|\n| + SPELL   \t| 10         \t| 13.545            \t| 99.84%                                          \t|\n\n\n> **Applying repellency terms based on the current state x_t instead of the expected final output seems applicable for the intra-batch repellency case, providing better diversity to a batch of generated images. Can it be one of the baselines to compare SPELL for the intra-batch case?**\n\nThanks for this great comment.\n\nWhen the repellency terms only depend on the current state $x_t$ (and when the repellency terms are the grad of an interaction potential, and we restrict to intra-batch repellency) what you suggest is exactly particle guidance ([Corso et al. 24]), as detailed in lines 250~265. PG is featured prominently in our experiments (it's one of the baselines in Fig. 4, and added to Table 4 in the revised paper).\n\nNote however that PG interactions are not sparse, and cannot therefore be realistically extended to our large scale protection experiment.\n\n> **It seems like SPELL forces each trajectory to arrive near the boundary of other balls (shields).**\n\nWe will clarify this, but this is not really the case.\n\nWhat you describe would be somewhat our worst-case scenario, in which SPELL would fulfill the shielding requirement only when applied _at the last timestep_.\n\nInstead, as depicted in Fig. 1, when SPELL detects that a generation at time $t$ is _pointing_ towards a shield, it alters the diffusion direction to make it point outside of that shield. Ideally, these modifications happen as early as possible so that the diffusion can explore a different mode instead and perturb as little as possible the later (image-detail defining) stages of the diffusion, to avoid visual artifacts (Fig. 17).\n\nLuckily, following our intuition, SPELL interventions occur mostly in early diffusion timesteps, as shown in the density plot in Fig. 5a, that shows many more interventions early on in diffusion at time $t=1$. This is tightly connected to the radius that is chosen (Fig. 5b) and is indeed confirmed when $r=20$. This is also extensively documents in Figures 9~16. \n\n> **Can further methods (something similar to momentum or just larger overcompensation) improve the diversity of generated images?**\n\nWe have not tried momentum, but this is a great suggestion. A small overcompensation of 1.6 seems to work very well. One combination we explored is to both use a lower CFG weight to increase diversity and add SPELL. In Appendix I, Figures 18 - 24, we find that even when we already increase diversity by decreasing the CFG weight, adding SPELL still boosts further diversity."
            }
        },
        {
            "title": {
                "value": "Reviewer V3e4: Rebuttal discussion"
            },
            "comment": {
                "value": "Many thanks for reading our paper despite this not being your area of expertise. Still, we are very happy to see that despite this mismatch you had a positive impression of our paper overall. ICLR papers should be tailored to reach a wide readership, and we took great efforts to make our paper easy to parse, through e.g. Fig. 1 and other illustrations.\n\n> **I find the issue addressed in this paper to be interesting and important.**\n\nIndeed, we believe these are core issues that appear naturally when letting end-users interact with diffusion models.\n\nIn our first application (intra-batch diversity), we were happy to advance the recent SOTA set in ICLR 2024  (https://arxiv.org/abs/2310.17347 and https://arxiv.org/abs/2310.13102) and NeurIPS 2024 (https://arxiv.org/abs/2404.07724). \n\nAs for our second application (protecting images), we are the first (to our knowledge) to propose a method for this task that works at such a scale, with an impressive reference set of more than 1 million images."
            }
        },
        {
            "title": {
                "value": "Reviewer EnjK: Rebuttal discussion (part 2)"
            },
            "comment": {
                "value": "> **For instance, an analysis of average wall-clock time compared with baseline methods, or testing with larger reference dataset sizes, would be helpful for readers.**\n\n_**When using ImageNet-1k as the reference set (L.983 in our algorithm)**_, this is already detailed in the rightmost column of Table 2, L. 492. In that experiment with a reference set of over 1M images, using the same model, generation time goes from 3.5s to 6s using SPELL. \n\nThe overhead of 2.5s is mostly due to the fast nearest-neighbor (NN) search to the $K=1,281,167$ reference set images at each $t$ during generation. That time grows _at most_ linearly with $K$ when adding more neighbors. \n\nWe have extended **Table 2 with more parameters** (see revision), where we control more accurately the quality of fast-NN search by increasing the number of Voronoi cells that the NN algorithm calculates distances for, which controls both accuracy and compute. As shown below, when going from 1 to 2 cells, runtime increases by ~1.4 seconds, when going from 2 to 3 another 1.7s, from 3 to 5 by 2.2s and from 5 to 10 by 3.6 seconds. Note also that with more inference runtime, we are able to guarantee even better protection rates (0.16% at 10 cells compared to 0.6% in the paper, which used 2 cells). We have not optimized yet the parameters of the fast-NN search (currently this is run, sub-optimally, on CPU). We believe these overheads can be significantly reduced.\n\n\n| Model     \t| Searched cells | Time per image (s) \u2193 | Generated images too close to ImageNet neighbors \u2193 |\n|---------------|----------------|-----------------------|-----------------------------------------------------|\n| EDMv2     \t| -          \t| 2.434             \t| 7.60%                                          \t|\n| + SPELL   \t| 1          \t| 4.633             \t| 1.08%                                          \t|\n| + SPELL   \t| 2          \t| 6.057             \t| 0.55%                                          \t|\n| + SPELL   \t| 3          \t| 7.790             \t| 0.33%                                          \t|\n| + SPELL   \t| 5          \t| 9.949             \t| 0.22%                                          \t|\n| + SPELL   \t| 10         \t| 13.545            \t| 0.16%                                          \t|\n\n\n_**When the reference set is a set of concurrently or previously generated samples (L.991 in our algorithm)**_ to increase diversity, the overhead consists of calculating pairwise distances for up to 128 (expected or realized) images at each diffusion time. That computation is negligible. The runtimes of the base model, SPELL, and also CADS, IG, and PG are equal in this setup. \n\n> **For example, the fourth image is repelled from the third image, and it's unclear why this image is closer to the third image than to the first or second.**\n\nThis is likely due to background similarity between images 3 & 4 (top row). Note that SPELL intervenes *during generation* and not as a post-processing mechanism: To insist (in the spirit of L.425~), SPELL was *not* used because SD3 Image 4 came out as too close to Image 3; SPELL was used before that, during the generation of Image 4, because (L.463) it \u201cwas _expected_ to come out too close to the 3rd image\u201d.\n\n> **Additionally, it would be beneficial if the authors provided examples with multiple image batches, other than a single-image batch.**\n\nThanks for the suggestion! We plan to generate further examples (we are working to get access to compute resources) and will post these examples here very soon.\n\n> **I wonder whether the L2 distance-wise nearest neighbor search was the best choice. This is because many images in the third row (EDM + SPELL) seem more similar to the second row (ImageNet neighbor for EDM) rather than the fourth row (ImageNet neighbor for EDM+SPELL).**\n\nYour question can be parsed in 2 different ways: (i) whether to use the L2 distance, and (ii) whether to use L2 of images in the MDTv2 latent space to guide SPELL. \n\nOn (i), Fast NN search (e.g. FAISS as used here) is designed to work for L2, and we are hence somewhat stuck with it.\n\nOn (ii), indeed, we are not bound to using that representation for SPELL, the user may define any other encoding of interest. In image protection, defining an encoding also defines explicitly the type of protection that is achieved.\n\nFor now, our goal in Fig. 7 was to convey clearly that SPELL avoids obvious copies (e.g. images 2 3 4 5 6 7 8) that using EDMv2 directly would output.\n\n> **However, according to Table 1, isn't this actually the case for 4 out of 6 models? Please correct me if I am wrong.**\n\nWe apologize for not being clear. We write _The third diversity metric, coverage, is also increased in all models except SD3_ (L.323). This is technically correct, because SD3-Medium is considered both in the text2image and class2image tasks. But you are also correct, this is 4/6 _experiments_ in Table 1, we have corrected this entire part in L.358."
            }
        },
        {
            "title": {
                "value": "Reviewer EnjK: Rebuttal discussion (part 1)"
            },
            "comment": {
                "value": "We would like to thank Reviewer **EnjK** for their encouraging comments and constructive review. We did our best within the time constraints to address all of the points that you have raised, and will do our best to answer other concerns.\n\n> **For example, while Table 1 indicates that SPELL has a minor trade-off in precision, the authors do not compare this trade-off with the baselines. Figure 4 is the only comparative result provided, but it lacks an analysis of image quality. Specifically, I would like to know if all models in Figure 4 are capable of similar generation quality, say in terms of FID.**\n\nThis is a great point, thanks for raising it. Our goal (L. 403) was indeed to contrast diversity vs *quality* in 3 different plots, 3 different Pareto fronts, using Precision / Density / Clip scores. Following your request, **we have added a fourth plot in Fig. 4, with FD_DINOv2 vs CLIP Score**, as can be seen in our updated draft. We can add other similar figures if you think they would be relevant.\n\n**We have also added the following table (Table 4, p.21 in draft)**, with all metrics, to provide readers with an exhaustive view. \n\n|Method|Recall|Vendi Score|Coverage|Precision|Density|FID|$FD_\\text{DINOv2}$|CLIP Score|\n|----------------------------------------------------|--------|-------------|----------|-----------|---------|-------|-----------|--------|\n|Base Model|0.237|2.527|0.446|0.558|0.768|9.566|105.967|27.789|\n|Particle Guidance, strength=1024|0.099|1.987|0.249|0.300|0.326|84.115|705.661|24.470|\n|Particle Guidance, strength=512|0.230|2.753|0.378|0.443|0.534|23.106|286.093|26.740|\n|Particle Guidance, strength=256|0.252|2.656|0.429|0.523|0.682|11.934|154.897|27.440|\n|Particle Guidance, strength=128|0.248|2.591|0.447|0.553|0.754|9.442|109.257|27.704|\n|Particle Guidance, strength=64|0.245|2.561|0.449|0.559|0.771|9.072|101.796|27.781|\n|Particle Guidance, strength=32|0.235|2.528|0.445|0.557|0.763|9.724|108.382|27.812|\n|Particle Guidance, strength=16|0.236|2.529|0.446|0.557|0.764|9.596|107.041|27.813|\n|Interval Guidance, [0.1,0.9]|0.372|2.840|0.455|0.537|0.730|8.385|85.871|27.453|\n|Interval Guidance, [0.2,0.9]|0.419|2.994|0.442|0.514|0.689|8.359|85.094|26.813|\n|Interval Guidance, [0.1,0.8]|0.470|3.174|0.448|0.500|0.663|7.507|76.104|27.215|\n|Interval Guidance, [0.3,0.9]|0.471|3.208|0.421|0.483|0.635|8.406|87.971|25.885|\n|Interval Guidance, [0.2,0.8]|0.518|3.340|0.434|0.478|0.624|7.478|75.250|26.544|\n|Interval Guidance, [0.1,0.7]|0.567|3.576|0.432|0.451|0.577|6.804|72.092|26.784|\n|Interval Guidance, [0.4,0.9]|0.525|3.495|0.395|0.442|0.569|8.623|96.611|24.630|\n|Interval Guidance, [0.3,0.8]|0.571|3.575|0.411|0.446|0.570|7.556|78.887|25.549|\n|Interval Guidance, [0.2,0.7]|0.614|3.770|0.417|0.426|0.536|6.771|72.972|25.979|\n|Interval Guidance, [0.1,0.6]|0.673|4.138|0.396|0.385|0.466|6.885|81.643|26.020|\n|CADS, mixture factor=0, tau_1=0.6|0.262|2.598|0.447|0.553|0.753|9.248|105.006|27.746|\n|CADS, mixture factor=0, tau_1=0.7|0.253|2.579|0.448|0.555|0.757|9.288|105.549|27.757|\n|CADS, mixture factor=0, tau_1=0.8|0.245|2.561|0.449|0.557|0.762|9.356|105.856|27.771|\n|CADS, mixture factor=0, tau_1=0.9|0.239|2.545|0.450|0.559|0.767|9.452|106.455|27.790|\n|CADS, mixture factor=0.001, tau_1=0.6|0.325|2.816|0.442|0.531|0.696|8.897|105.081|27.534|\n|CADS, mixture factor=0.001, tau_1=0.7|0.297|2.734|0.446|0.540|0.719|8.963|104.006|27.617|\n|CADS, mixture factor=0.001, tau_1=0.8|0.277|2.660|0.447|0.548|0.739|9.098|103.766|27.697|\n|CADS, mixture factor=0.001, tau_1=0.9|0.256|2.588|0.448|0.554|0.755|9.273|105.268|27.754|\n|CADS, mixture factor=0.002, tau_1=0.6|0.425|3.208|0.417|0.472|0.584|9.870|129.159|26.920|\n|CADS, mixture factor=0.002, tau_1=0.7|0.380|3.028|0.429|0.501|0.637|9.143|114.333|27.242|\n|CADS, mixture factor=0.002, tau_1=0.8|0.330|2.837|0.442|0.529|0.692|8.893|105.511|27.506|\n|CADS, mixture factor=0.002, tau_1=0.9|0.277|2.660|0.446|0.548|0.739|9.098|103.762|27.696|\n|SPELL, shield radius=40|0.370|2.998|0.437|0.500|0.631|13.072|140.841|27.397|\n|SPELL, shield radius=35|0.359|2.935|0.445|0.518|0.665|11.452|120.346|27.556|\n|SPELL, shield radius=30|0.337|2.856|0.451|0.531|0.695|10.349|106.753|27.655|\n|SPELL, shield radius=25|0.312|2.774|0.454|0.542|0.723|9.794|100.123|27.739|\n|SPELL, shield radius=20|0.287|2.691|0.455|0.552|0.746|9.535|98.666|27.781|\n|SPELL, shield radius=15|0.263|2.616|0.454|0.558|0.762|9.558|100.709|27.811|"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel technique called SPELL to address the challenge of shielded generation and improve generation diversity in text-to-image diffusion models. SPELL shields the model from replicating protected images and promotes intra-batch diversity by adding sparse repellency terms to the diffusion process, guiding generated images away from a reference set and the images in the same batch. The authors demonstrate the effectiveness of their methods via experiments on the state-of-the-art diffusion models. Compared to the previous works, SPELL achieves the best trade-off between image diversity and generation quality. Further, the authors empirically show that SPELL is scalable with a large reference set."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper tackles a timely and practically-relevant problem supported by a fair amount of experiments. Shielded generation of text-to-image diffusion models is an area with limited prior research, making this work particularly valuable.\n- Overall, the paper is clearly written and easy to follow."
            },
            "weaknesses": {
                "value": "- One key weakness of this paper is the lack of experiments regarding the main trade-offs against baseline methods. For example, while Table 1 indicates that SPELL has a minor trade-off in precision, the authors do not compare this trade-off with the baselines. Figure 4 is the only comparative result provided, but it lacks an analysis of image quality. Specifically, I would like to know if all models in Figure 4 are capable of similar  generation quality, say in terms of FID.\n- Since SPELL is a training-free sampling method, the authors should also provide a quantitative analysis regarding inference time. For instance, an analysis of average wall-clock time compared with baseline methods, or testing with larger reference dataset sizes, would be helpful for readers.\n- In the main qualitative analysis in Section 4.5, Figure 6 does not convincingly illustrate improved image generation diversity. For example, the fourth image is repelled from the third image, and it's unclear why this image is closer to the third image than to the first or second. Similarly, in the 13th image, the only notable difference is the color of the ball, and yet the blue ball is the most common color in prior images. Additionally, it would be beneficial if the authors provided examples with multiple image batches, other than a single-image batch.\n- Regarding Figure 7, I wonder whether the $L_2$ distance-wise nearest neighbor search was the best choice. This is because many images in the third row (EDM + SPELL) seem more similar to the second row (ImageNet neighbor for EDM) rather than the fourth row (ImageNet neighbor for EDM+SPELL)."
            },
            "questions": {
                "value": "- In line 359, it states that \"precision and density decrease slightly in 5 out of 6 models.\" However, according to Table 1, isn't this actually the case for 4 out of 6 models? Please correct me if I am wrong."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel guidance mechanism called SPELL (Sparse Repellency) aimed at enhancing diversity and protecting certain reference images during the generation process in text-to-image diffusion models. This approach addresses two common challenges with diffusion models: the tendency to produce repetitive images for the same prompt and the potential risk of inadvertently recreating training images, which raises privacy and copyright concerns. In summary, SPELL is a post-training intervention that enhances image diversity and safeguards specific images by selectively adjusting generation paths. This method offers a practical solution for more diverse and privacy-respecting image generation in diffusion models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well written.\n2. The addressed problem is import in diffusion models."
            },
            "weaknesses": {
                "value": "I am not familiar with this field, but I find the issue addressed in this paper to be interesting and important. AC can disregard my opinion and score."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel way to diversify diffusion generations by introducing repellency terms to the diffusion SDE. It achieves the diversity of generated images from one prompt and/or prevention of similar generation to the reference set, which is one of the significant challenges for real users."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This paper tackles a very practical problem of repetitive generations of text-to-image diffusion models to both protective images in the training set and previously generated images.\n- The proposed method, repellency terms, has a concrete background and intuitive to solve the problem.\n- Thorough empirical investigations provide enough understanding of how SPELL can increase the diversity of generated images, and the advantages for real-world applications."
            },
            "weaknesses": {
                "value": "- While SPELL can be used for any diffusion pipelines, the effectiveness of SPELL for smaller models or domains other than ImageNet is not fully investigated.\n- The efficiency of SPELL is validated for ImageNet class or simple text prompts where the diversity within a text prompt is huge. Evaluation for more complex text prompts that align with more practical usage of text-to-image diffusion models would validate the effects of SPELL more.\n- As noted by authors, the proposed SPELL does not provide a very tight guarantee to avoid generations of similar images to the reference set, which can limit the applicability of SPELL for high-risk cases."
            },
            "questions": {
                "value": "- Applying repellency terms based on the current state x_t instead of the expected final output seems applicable for the intra-batch repellency case, providing better diversity to a batch of generated images. Can it be one of the baselines to compare SPELL for the intra-batch case?\n- It seems like SPELL forces each trajectory to arrive near the boundary of other balls (shields). Can further methods (something similar to momentum or just larger overcompensation) improve the diversity of generated images?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel post-training guidance mechanism, SPELL, which primarily addresses the training-set protection issue and the diversity problem of image diffusion models. SPELL is designed to repell the latents away from a trajectory that is close to a protected image set or from other latents within the same inference batch. It dynamically introduce small corrections to the latents in a way that is sparse and only triggered when the predicted trajectory is too closely to a reference domain. The authors evaluate SPELL on multiple state-of-the-art open-sourced diffsion models, showing its effectiveness. They also provide comparisons to other previous approaches that are also aimed at addressing diversity or with protected image set, which show some superior results on selected trading-off plots."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The overall problem that this paper addresses is one of the important issues that current diffusion-based image generation models possess, which adds to the value of motivations for this paper.\n2. This paper is well-written and easy-to-understand. Notations within the background section and the method section are self-contained and clear to follow. Fig. 2 further adds readability.\n3. The method this paper proposed is novel, which provides conceptual insights particularly in the method section (Sec. 4).\n4. Experiments contain both ablation studies and comparisons to other methods. Fig. 3 show the effect of SPELL's only parameter **r**, in which we see effectiveness especially around 10-20."
            },
            "weaknesses": {
                "value": "MAJOR:\n1. The core issue for this paper is the soundness in terms of the superior effectiveness compared to other similar methods. In Fig. 4, there is only comparisons on recall-precision, converage-density, and vendi-clip trade-off, while other concerning metrics in Tab. 1, such as $\\text{FID}$, $\\text{FD}_\\text{DINOv2}$, are not included. I also failed to find reasoning on why only these three metric-pairs are selected.\n2. This discussion of the fundamental methodology difference towards **Particle Guidance** on Page 5 is not convincing, as it seems SPELL can be treated as a special case of Particle Guidance when the energy potential $\\phi_t$ is simply calculating the difference.\n3. This paper provides abundant unconditional results with protected image set being ImageNet-1k in Fig. 17 in the appendix, but it seems that the only qualitative results for diversity is in Fig. 1. This paper could benefit from more concrete visual evidences.\n\nMINOR:\n1. In contributions, bullet point 3, **generated** is misspelled.\n2. In contributions, bullet point 2, explanations on the **future looking** feature is quite not straight-forward to understand, I'd suggest keeping it brief here as a bullet point in contributions, and further explain it in method section with mathematical symbols, such as $x_t, x_0$."
            },
            "questions": {
                "value": "1. As it is difficult to show all possible trade-offs, a better way of giving concrete comparisons would be adding detailed tables for each of the methods. Each table shows all results with rows to be parameters, and columns to be all the metrics. Adding such tables would surely address my core concern, but due to limited time, it is also promising if the reasoning of choosing these trade-offs are persuasive and convincing.\n2. I'm generally not quite sure if SPELL could be treated as a special case of Particle Guidance in terms of intra-batch diversity. A brief explanation would be sufficient.\n3. This paper would also benefit from providing more diversity results, but it is understandable if this is infeasible considering the limited time for rebuttal."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}