{
    "id": "oZdaEiDBpF",
    "title": "On Characterizing and Mitigating Imbalances in Multi-Instance Partial Label Learning",
    "abstract": "\\textit{Multi-Instance Partial Label Learning} (MI-PLL) is a weakly-supervised learning setting encompassing \\textit{partial label learning}, \\textit{latent structural learning}, and \\textit{neurosymbolic learning}. Unlike supervised learning, in MI-PLL, the inputs to the classifiers at training-time are tuples of instances $\\mathbf{x}$. At the same time, the supervision signal is generated by a function $\\sigma$ over the (hidden) gold labels of $\\mathbf{x}$. In this work, we make multiple contributions towards addressing a problem that hasn\u2019t been studied so far in the context of MI-PLL: that of characterizing and mitigating \\textit{learning imbalances}, i.e., major differences in the errors occurring when classifying instances of different classes (aka \\emph{class-specific risks}). In terms of theory, we derive class-specific risk bounds for MI-PLL, while making minimal assumptions. Our theory reveals a unique phenomenon: that $\\sigma$ can greatly impact learning imbalances. This result is in sharp contrast with previous research on supervised and weakly-supervised learning, which only studies learning imbalances under the prism of data imbalances. On the practical side, we introduce a technique for estimating the marginal of the hidden labels using only MI-PLL data. Then, we introduce algorithms that mitigate imbalances at training- and testing-time, by treating the marginal of the hidden labels as a constraint. We demonstrate the effectiveness of our techniques using strong baselines from neurosymbolic and long-tail learning, suggesting performance improvements of up to 14\\%.",
    "keywords": [
        "muliti-instance partial label learning",
        "weakly-supervised learning",
        "neurosymbolic learning",
        "learning theory",
        "long-tailed learning",
        "learning imbalances",
        "class-specific error bounds"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=oZdaEiDBpF",
    "pdf_link": "https://openreview.net/pdf?id=oZdaEiDBpF",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses Multi-Instance Partial Label Learning (MI-PLL). The primary contributions are :  1. a theoretical characterization of class-specific learning imbalances in MI-PLL; 2. practical algorithms for mitigating these imbalances at training and testing stages."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The exploration of class-specific risk in MI-PLL settings is a novel angel. The theory is sound and robust. The proposed algorithms lead to empirical improvements."
            },
            "weaknesses": {
                "value": "I'm a bit concerned on the assumption that the transition $\\sigma$ is instance-independent. I'm not sure how consistent it is with the real-world datasets. I think recent literatures on learning with noise and domain changes assume instance-dependent transitions (e.g. https://www.arxiv.org/pdf/2408.16189)."
            },
            "questions": {
                "value": "How hard is it to generalize the theory to allow transition $\\sigma$ to be instance-dependent and how will that change the analysis? I think the proofs in Patrini et al., 2017 can be naturally adapted to instance-dependent noise by letting noise transitions $T$ depend on $x$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In the multi-Instance partial label learning problem, the authors provide class-specific error bounds and show that the transition function $\\simga$ can significantly impact learning imbalances. On the practical side, we first propose a statistically consistent technique for estimating the marginal of the hidden labels given partial labels. They propose two algorithms that mitigate imbalances at training- and testing-time. The first algorithm assigns pseudo-labels to training data based on a novel linear programming formulation of MI-PLL. The second algorithm uses the hidden label marginals to constrain the model\u2019s prediction on testing data"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. They derive class-specific error bounds that depend on the MI-PLL risk under minimal assumptions.\n2. They introduce an algorithm to estimate the marginal of the hidden labels.\n3. They mitigate learning imbalances at testing-time by modifying the model\u2019s scores to adhere to the estimated ratios."
            },
            "weaknesses": {
                "value": "1. The presentation about the algorithm in Section 4.2 becomes confusing from line 300. I will list my doubts in the questions below.\n2. Can you explain why you enforce the first three constraints in Equ. (6)?\n3. In experiments, for $\\rho = 0$, i.e., the hidden label distribution is unmodified and balanced, the performance of CAROT is even worse than LA under $M=5$.\n4. Figure 1 seems to indicate that within 100 epochs, almost all classes are not well classified. Does the model converge in 100 epochs? If not, can you provide the curve after 100 epochs until the network converges?"
            },
            "questions": {
                "value": "a).\tIn line 301, why is each training sample uniquely associated with a Boolean formula of $R_{\\ell}$ disjuncts of the form $\\Phi_{\\ell} := \\psi_{\\ell, 1} \\vee \\ldots \\vee \\psi_{\\ell, R_n}$? Is each $\\psi_{i, t}$ a bool variable or a function? How to determine $ R_{\\ell}$. \nb).\tIn line 302, why it is that \u201cFormula $\\Phi_{\\ell}$ encodes the valid label assignments for the $\\ell$-th partial training sample subject to $\\simga$ and $s_{\\ell}$?\nc).\tCan you show that \u201cEach disjunct in \u03a6\u2113 is a conjunction of Boolean variables from $\\{q_{\\ell,i,j}\\}_{i,j}$, where $q_{\\ell,i,j}$ is true if and only if $x_{\\ell, i}$ is assigned to the $j$-th label in $\\mathcal{Y}$\u201d.\nd)    The introduction of $\\alpha_{\\ell, t\\}$ is also not easy-to-follow.\ne)    Exact definition of $\\Phi_{\\sigma}$ in Section 4.1 is missing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the problem of learning imbalances in Multi-Instance Partial Label Learning (MI-PLL), where the true labels are hidden and supervision is provided via a transition function. The authors derive theoretical bounds for class-specific risks, and propose methods to estimate hidden label distributions and introduce algorithms to mitigate these imbalances during both training and testing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper provides a theoretical contribution by analyzing learning imbalances in MI-PLL, offering a deeper understanding of the problem.\n\n2. The authors introduce novel algorithms for both training and testing phases, with empirical evidence."
            },
            "weaknesses": {
                "value": "1. The notation used in this paper is quite convoluted and makes it really hard to follow. I spent a lot of time carefully reading Section 2, but I still don\u2019t have a clear understanding of what exactly the MI-PLL setting is or how it\u2019s supposed to be used in practice.I would recommend reconsidering whether certain notations, e.g., $r_y = r_{l_j} = r_j$ , are essential in the manuscript. Additionally, including a notation table may be helpful for readers to quickly reference symbols, which would enhance the overall clarity and accessibility of the paper.\n\n2. I understand that the setup in this paper seems different from previous work called MI-PLL, but the motivation of this pape is that earlier \"MI-PLL\" (which has a different meaning than this paper) methods cannot handling the long-tail issue well. What\u2019s puzzling is that it doesn\u2019t actually compare the proposed approaches to those prior MI-PLL methods in the experiments, which feels really inconsistent.\n\n3. From the algorithmic side, I\u2019m left wondering why the proposed methods should work for long-tail distributions. The explanation for how they handle rare classes is pretty vague, and it\u2019s not easy to see how the approach directly addresses the long-tail problem. And the assumption that transition function is known to the learner is too strong. As far as I know, in weakly supervised learning people generally don't make such strong assumption, but it is crucial to learn the function\u3002"
            },
            "questions": {
                "value": "Please see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores a weakly-supervised learning framework that integrates aspects of partial label learning and partial label learning. It presents theoretical contributions by establishing class-specific risk bounds under minimal assumptions and demonstrating the significant impact of transition functions on learning imbalances. Additionally, the paper introduces practical algorithms for estimating hidden label distributions and mitigating learning imbalances at both training and testing phases, achieving performance improvements of up to 14% over strong baselines."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This is an theoritically-solid paper - the proofs and theorems appears to be correct and sound.\n\n2. This paper have proposes several notable and interesting theoritical properties, which could be benefical for the future development of MI-PLL.\n\n3. This paper introduces two new algorithms to mitigate imbalances at training and inference time.\n\n4. The proposed method obtained competitive performances comparing with its closest counterparts."
            },
            "weaknesses": {
                "value": "1. This paper becomes challenging to comprehend as the authors have not provided clear definitions of a partial label. Specifically, by examining Example 1.1 alone, the authors' characterization of partial labeling seems to differ from existing work [1].\n\n2. It appears that the authors' proposed method is somewhat orthogonal to their theoretical results, suggesting a divergence between practice and theory.\n\n3. While it is reasonable to assume that imbalances in Multi-Instance Partial Label Learning (MI-PLL) arise not only from label distribution but also from the partial labeling process, the theoretical results of this paper seem to only consider the imbalances caused by partial labeling. This limitation potentially restricts the flexibility and applicability of the theoretical findings.\n\n[1] Learning from Partial Labels, JMLR 2011."
            },
            "questions": {
                "value": "1. Is Equation 1 introduced by the authors or derived from previous works? I find the mathematical connections a bit challenging to grasp, particularly as it doesn\u2019t seem to directly correspond to the definition of partial risk outlined by Cour et al. If this is an original contribution from your team, shouldn\u2019t Equation 1 be presented as a lemma with accompanying proofs to substantiate its validity?\n\n2. I'm not completely certain, but it appears that Proposition 3.3 suggests the dependency of the empirical partial risk on the imbalance of partial labels, while your measure of complexity (e.g., the Natarajan dimension) remains unaffected by the level of imbalance. If this interpretation is accurate, does this imply that minimizing the partial risk is invariably advantageous in imbalanced MI-PLL scenarios, regardless of the extent of imbalance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}