{
    "id": "C2uViDZmNp",
    "title": "Information Subtraction: Learning Representations for Conditional Entropy",
    "abstract": "The representations of conditional entropy and conditional mutual information are significant in explaining the unique effects among variables. The previous works based on conditional contrastive sampling have successfully eliminated information about discrete sensitive variables, but have not yet addressed continuous cases. This paper introduces a framework of Information Subtraction capable of representing arbitrary information components between continuous variables. We implement a generative-based architecture that outputs such representations by simultaneously maximizing an information term and minimizing another. The results highlight the representations' ability to provide semantic features of conditional entropy. By subtracting sensitive and domain-specific information, our framework effectively enhances fair learning and domain generalization.",
    "keywords": [
        "conditional entropy",
        "conditional representation learning",
        "self-supervised learning"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=C2uViDZmNp",
    "pdf_link": "https://openreview.net/pdf?id=C2uViDZmNp",
    "comments": [
        {
            "summary": {
                "value": "The authors introduce a framework for learning representations, aimed at applications in fair learning and domain generalization. \nThe authors use powerful MINE-based estimators to learn representations that share minimal MI with given conditional variables.\nPrevious methods focused on discrete sensitive variables, while here the authors extend these approaches to continuous cases."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "* The choice of MINE-based MI estimator to maximize/minimize MI terms is an excellent choice which allows the proposed method to scale to high-dimensional data.\n* Extending previous work to include continuous variables is an important contribution.\n* The proposed method might have potential for broad application due to the above points, and the fact that it is independent of the choice of architecture."
            },
            "weaknesses": {
                "value": "* Line 168: \u201cBased on our previous work (?)\u201d - this is a strong hint to the identity of the authors which breaks the double-blind regime of the reviewing process.\n* The novelty might be very limited here. Specifically, the use of MINE-based methods might be the major novelty here.\n* There is no discussion about the failing points of the proposed method. What happened when the condition variable X and the target Y are entangled in more complex ways? How will the learned representation Z be affected? \n* The formulation and the presented Algorithm are not clear."
            },
            "questions": {
                "value": "* Did you try adding a hyper-parameter to one of the terms in the loss? Could that allow for finer control by the user on the learned representation?\n* Did you have issues in training stability?\n* Did you test the effectiveness of the proposed method on high dimensional data? How did the computational cost scale?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a framework called \"Information Subtraction\" for learning representation Z that maximizes conditional entropy H(Y|X) or, put in another way, maximizes the conditional mutual information (CMI) I(Z;Y|X). The method applies for continuous variables, which is harder than discrete variables. The proposed framework utilizes an approach similar to generative adversarial training where discriminators are used to maximize or minimize information terms. The authors evaluate the framework's performance on synthetic and real-world datasets, demonstrating its effectiveness in fair learning and domain generalization tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The framework tackles a relatively under-explored and challenging problem of selectively maximizing and minimizing specific information components during representation learning. Previous works in the topic of CMI are more focusing on getting a good estimation, while this work is interested in leveraging CMI for representation learning."
            },
            "weaknesses": {
                "value": "**Lack of background of CMI estimators**: Previous works on estimating (conditional) mutual information are not discussed. In particular, [1] proposes similar framework where discriminators are used for the estimation. It's also unclear to me how the proposed method differs from the existing approaches for estimating conditional mutual information, e.g. MI-Diff+f-MINE in [1]. Are there any significant technical difficulties for turning an estimator into a representation learner? Would the classifier-based approach advocated by [1] results in better representation?\n\n**Lack of baselines and ablation studies**: the experiments, synthetic or real, don't compare to any other methods. It's, therefore, not obvious how the experimental result should be interpreted. The experimental section would also benefit from ablation studies to analyze the contribution of different components of the architecture and the impact of hyperparameter choices.\n\n[1] Mukherjee et al. CCMI : Classifier based Conditional Mutual Information Estimation."
            },
            "questions": {
                "value": "1. Are there any difficulties or details that need to pay attention to make the training scheme work? MINE has been proved to be difficult to tune.\n2. In the paper, the generator takes Y as the input, could X also be given in the input? Would that change the result?\n3. Line 168, reference missing. Why is it called an expanded architecture?\n4. For the synthetic experiments, does the proposed method learns a better representation than the baselines such as contrastive-based approach?\n5. Does the proposed method perform better in the downstream task than other approaches for the fairness and domain invariant learning setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce a framework for representing arbitrary information components between continuous variables using Information Subtraction. Essentially a generator network is trained to generate a latent representation $Z$ which captures the mutual entropy of target viable $Y$ and conditional variable $X$, without carrying information about $X$ itself. \nTo achieve this, they use two discriminator networks $A$ and $B$. While $A$ estimates $I(Z,X;Y)$, $B$ estimates $I(Z;X)$. The Objective $I(Z,X;Y) - I(Z;X)$ is back propagated to the generator network.\n\nThe authors test their method on two synthetic scenarios and on fair learning and domain generalisation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well written in general. The challenge being tackled is of interest for part of ICLR's audience. While maybe not novel \u2013 I am not an expert on the related work \u2013 the approach of using two discriminator networks to estimate $I(Z,X;Y)$ and $I(Z;X)$ seems reasonable to me."
            },
            "weaknesses": {
                "value": "**Related Work Section**:\n\nThe authors write: \"While we share similar architectures with these works, their structures are not designed for conditional representations.\"\nIt is unclear to me how large the contribution of this paper is. Is the proposed architecture only a slight modification of existing work? Or would a slight modification of existing work suffice to reach the same goal as the authors propose? If so, why is there no comparison to those in the experimental section?\n\n**Experimental Section**:\n\nThe section lacks comparability to prior work. As I understand it, it stands very much isolated and it's hard for me to estimate the significance of  the contribution the authors have made. If existing models cannot be applied for comparison, I'd still expect the authors to come up with other, simpler, baseline architectures against which to compare. \n\nIt is unclear to me whether the reported values come from train, validation or test splits. The lack of standard deviation (suggesting no cross validation was used) makes it hard to estimate the significance of the results. Additionally, the chosen \"real-world\" datasets seem very simple to me. \n\nOverall, unfortunately, the experimental section does not convince me."
            },
            "questions": {
                "value": "The *Weaknesses* section outlines the questions and concerns I have."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Information Subtraction framework, which addresses conditional representation learning for continuous variables. It employs a generative architecture with a generator neural network and two discriminators to stabilize information term estimations. The generator's objective is to maximize information from one discriminator while minimizing it from the other, effectively capturing semantic features of conditional entropy and enhancing fair learning by removing sensitive information.\nThe authors highlight the significance of conditional representation learning and demonstrate the framework's capacity to decompose signals and produce unbiased representations. Experimental results show that the proposed approach improves fairness in both synthetic and real-world contexts and enhances domain generalization by combining domain-specific factors with universal representations."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper effectively outlines the problem from a methodological standpoint, framing it as a well-defined optimization issue that is clear from a mathematical perspective. It provides a comprehensive overview of related work and their limitations, emphasizing the necessity for a representation learning method that can eliminate information pertaining to continuous sensitive variables. The primary objective is to elucidate the unique effects among variables. Additionally, the inclusion of real-world experiments highlights the paper's contributions to the current research landscape in fair learning and domain generalization applications."
            },
            "weaknesses": {
                "value": "The article presents challenges in terms of readability, as the mathematical loss functions being minimized in practice are not adequately described. The discussion of the quantities to be optimized tends to remain at a high level. Additionally, the architecture description is introduced late in the paper and lacks detail; a more concrete schematic representation with specific input types (e.g., images, tabular data) and detailed analytical loss expressions would be beneficial.\n\nMoreover, the existing literature on debiasing appears to be quite extensive regarding the elimination of sensitive information from continuous variables [A], [B]. I found it difficult to discern how this work connects to those prior studies.\n\nFinally, the experimental section seems relatively weak in terms of the number of experiments and datasets utilized. Including a straightforward debiasing or fair learning experiment in a real-world context, such as healthcare applications or scenarios involving ethnic biases, along with qualitative visual explanations, would enhance the overall quality of the article.\n\n[A] Unbiased Supervised Contrastive Learning, C.A. Barbano et al. ICLR 2023. https://arxiv.org/abs/2211.05568\n[B] CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information, P. Cheng et al, ICML 2020. https://arxiv.org/abs/2006.12013"
            },
            "questions": {
                "value": "Is it necessary to assume that your inputs or latent representations follow a specific distribution (e.g., Gaussian, von Mises-Fisher) to derive your loss functions?\n\nAdditionally, the authors mention \"Based on our previous work (?)\" at one point. It is important to note that ICLR requires authors to cite their own work as they would cite others'. In this case, the authors should state: \"Based on the previous work [x].\" This would allow readers to locate and review the referenced paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}