{
    "id": "63KdWsaYhb",
    "title": "Modeling Asynchronous Time Series with Large Language Models",
    "abstract": "We propose a novel prompt design for using Large Language Models (LLMs) with Asynchronous Time Series data (LASTS), where the series is represented as pairs of events described in natural language and timestamps expressed as inter-arrival times. Unlike existing models restricted to fixed event categories, our model operates in an open-world setting, processing new events without retraining by leveraging LLMs\u2019 world knowledge for better reasoning across domains and tasks. We further introduce Stochastic Soft Prompting (StoP), a novel prompt tuning mechanism that we use to adapt LLMs to LASTS representation and various downstream tasks, including forecasting, data imputation, and anomaly detection. Extensive experiments on real-world datasets demonstrate our model\u2019s versatility across tasks, achieving state-of-the-art results. Additionally, we observe that StoP prompts are interpretable and contain meaningful information.",
    "keywords": [
        "Large Language Models",
        "Asynchronous Time Series",
        "Time Series modeling",
        "Deep Learning"
    ],
    "primary_area": "learning on time series and dynamical systems",
    "TLDR": "Asynchronous Time Series modeling using Large Language Models",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=63KdWsaYhb",
    "pdf_link": "https://openreview.net/pdf?id=63KdWsaYhb",
    "comments": [
        {
            "summary": {
                "value": "This paper leverages the LLM\u2019s world knowledge for forecasting, imputation, and anomaly detection, using a unique Stochastic Soft Prompting (StoP) approach. Through experiments across datasets, the authors claim state-of-the-art results and present the interpretability and efficiency of StoP prompts in handling ATS tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The LASTS framework is innovative in utilizing LLMs to handle asynchronous time series by encoding events with natural language descriptions, bypassing the need for domain-specific retraining.\n- StoP is presented as a promising technique that enhances robustness and interpretability. The probabilistic truncation of soft prompts during training is an interesting mechanism for learning adaptable representations.\n- The paper conducts evaluations across multiple tasks (forecasting, imputation, anomaly detection) and datasets, demonstrating the generalizability of LASTS and StoP."
            },
            "weaknesses": {
                "value": "- The paper mentions that LASTS underperforms in time prediction compared to TPP models for some datasets but lacks sufficient analysis to explain this. Additionally, the model architecture Figure 2b only shows \"Cross Entropy loss\" and how the RMSE calculated.\n- While the interpretability of StoP prompts is highlighted, the methods used to assess this (like task descriptions generated by the LLM itself) may not effectively capture the full extent of interpretability, especially for more complex tasks. More case studies needed.\n- LASTS represents ATS data using natural language, which could inadvertently introduce data leakage if events are semantically similar across training and test data. This risk is not adequately discussed."
            },
            "questions": {
                "value": "1. Given the zero-shot claims, to what extent could LASTS be applied to tasks outside the experimental dataset types (e.g., non-linguistic event sequences)?\n2. Did the authors consider testing the LASTS framework with smaller LLM backbones or non-LLM transformers? Would the results hold similarly across these variations?\n3. How is the risk of data leakage mitigated given the use of natural language prompts, especially in cases where events may share semantic overlaps across the dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the use of LLMs to perform tasks related to asynchronous time series data. Unlike common time series data, asynchronous time series data does not necessarily have a time pattern. This paper Stochastic Soft Prompt (StoP) a soft prompting strategy to adapt an LLM to an asynchronous time series. Experiments show that StoP outperforms the baselines in zero-shot and common evaluation settings."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper studies an interesting problem of adapting LLMs with soft prompting.\n2. The proposed method outperforms the zero-shot baselines and shows competitive results as some methods designed for asynchronous time series.\n3. Experiments present comprehensive analysis."
            },
            "weaknesses": {
                "value": "1. It is not very clear what makes asynchronous time series more difficult than normal time series for LLMs. It seems that many existing methods of LLMs for time series can be easily adapted to asynchronous time series as well. It is recommended that some baselines of the existing LLMs be added for the time series.\n2. Although StoP is designed for asynchronous time series, it could also be applied to normal time series. I am curious how it performs. In particular, StoP is only evaluated on three datasets. More datasets of normal time series can strengthen the evaluation."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper considers the problem of asynchronous time series modeling (specifically--the three tasks of forecasting, anomaly detection, and imputation). They take an in-context-learning approach to solving this task. Their main contributions:\n1. They propose \"LASTS\" (Large Language models with Asynchronous Time Series data), a prompt-engineering based method which allows LLMs to solve the asynchronous time series modeling problems in a zero-shot manner.\n2. They propose \"StoP\" (STOchastic soft Prompting), an interpretable adaptation of soft prompting, as part of their prompt engineering strategy. This method involves randomly truncating the soft prompts, which lets the model learn more diverse representations."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. At a meta level, this paper's strongest feature is how well it was written. I wish that more AI papers were written with this much clarity and intention. Overall, I would say the paper is structured in such a clear way that it is easy to evaluate the quality of the underlying research, because as a reader I didn't need to get bogged down in trying to understand what was written.\n\n    * Example 1: , the related works section was truly a delight to read, and I felt like it was very thorough (modulo one missing class of works, see Weakness #2). I especially liked all the different hierarchically-organized categories.\n    * Example 2: the background section does a very clear job explaining, in precise mathematical terminology, what the problems being solved are, with minimal notations being introduced (and I know this isn't always easy). \n    * Example 3: section 4.2, which explains the background on low-rank adaptation and how it's used in the paper, then soft prompting, then how the paper uses Stochastic soft prompting, is a master class in clearly explaining the background methodology, and how it's used in the present work. This makes this paper very self-contained and clear.\n\n2. Previous works on asynchronous time series typically modeled events as categories, but this paper models them using natural language descriptions (c.f. Section 4.1). This is a clear improvement in flexibility, especially given that the downstream performance improves as well. As a result, it is clear that the authors have proposed a superior framework. Furthermore, the use of ICL with LLMs means that this technique will continue to improve as LLMs improve, and as ICL techniques improve. \n\n3. The results in Table 1 provide a very clear ablation, showing that the proposed ICL-based strategy of LASTS + StoP consistently enough outperforms \"random\" and the other prompting settings.\n\n4. The results in Table 2 demonstrate that LASTS + StoP beats the other prior works consistently enough as well (see my Question 3 for clarification on this). This demonstrates the clear superiority of this method."
            },
            "weaknesses": {
                "value": "1. A minor suggestion: in the introduction, perhaps the paper could contain a concrete example of an asynchronous time series, if the authors want this paper to be optimally self-contained. One way to accomplish this would be to move Figure 1 onto the first page, right between the abstract and the introduction. This would make it very clear to the reader what \"asynchronous time series\" are, because I was confused until I got to that image.\n\n2. There is a line of research (see e.g. AntGPT, https://arxiv.org/abs/2307.16368 from ICLR 2024) which does text-based next action prediction using in-context learning. Perhaps the authors could add more citations to other papers that use a similar ICL strategy to process sequences of actions, because right now the article makes it seem as though this idea is completely novel, when it says _\"this is the first work to explore the capabilities of LLMs to process asynchronous time series data and works on multiple tasks\"_. \n\n3. *(Note: please add equation numbers to every single equation in the paper. This ensures that researchers can precisely reference parts of the paper)* When stochastic soft prompting is defined (the text and equations at the end of section 4) it doesn't seem super motivated why it is reasonable to only take prefix-slices of the prompt. Later in the paper there is some analysis about this (going into details about the \"coarse-to-fine structure\") but I think this section would be improved if it had some just a couple sentences of motivation for this (seemingly) arbitrary construction."
            },
            "questions": {
                "value": "1. Right now the method is zero-shot, according to the prompts in the appendix. Did the authors consider doing few-shot versions of their experiments as well?\n\n2. Can the authors please clarify the language used to describe the \"anomaly detection\" task? In Section 3 it says _\"the model is tasked with identifying this out-of-place element\"_ but in Figure 1 it says the model has _\"the goal of predicting the correct event\"._\n\n3. Did the authors investigate why LASTS + StoP performed so poorly on the Amazon dataset on RMSE, relative to the other models?\n\n4. I had trouble understanding what was going on with the \"coarse-to-fine\" analysis. The paper says: _\"The training paradigm of StoP forces all prefixes of StoP to act as valid standalone prompts, as they are used as prompts during training for some batches (if trained for long enough). This further strengthens our belief that tokens in StoP are arranged from coarse, independent tokens at the beginning to tokens with tokens containing finer information towards the end.\"_ Is there any other evidence that indicates that there is a coarse-to-fine structure being learned? More generally, what is the benefit (if any) of such a coarse-to-fine structure being learned? It seems to me like the main practical benefit is that the stochastic version of soft prompting results in 25% faster training. Are there any other practical benefits?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel prompt learning framework to leverage the LLM's world knowledge and capability to model async time series.  A stochastic soft prompting is designed to achieve this. Overall, this paper proposes a method on LLM for time series, an interesting topic. But it lacks enough quality from many aspects to be accepted."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This is a good topic. LLM for time series is still a very promising direction. There are still many research questions to be answered on how to effectively leverage LLM for time series data. This paper designs a prompting method to use LLM for various time series tasks, including forecasting, anomaly detection, and imputation."
            },
            "weaknesses": {
                "value": "1. \"Related work lacks LLM for TS\". In the related work section, there is a lack of discussion of LLM for TS. There is already some related work. For example, https://arxiv.org/abs/2402.01801 this survey contains a lot of them.\n2. \"Performance is not competitive.\" From Table 1, the StoP prompt learning method is not significantly better than QLORA.\n2. \"Lacks comparison with related work.\" There lacks a comparison with other LLM for TS methods. Currently, this paper only compares their backbone with different prompting strategies.\n2. \"Figure 1 lacks many details.\" Figure 1 should present more details of the framework. \n3. \"Written is weak.\" The author should improve the writing quality. There are many places hard to understand. For example, the abstract is hard to understand."
            },
            "questions": {
                "value": "See details in weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new approach to model asynchronous time series with LLMs which solves three different tasks: forecasting, imputation, and anomaly detection. First, they explored the representations of the asynchronous time series as inputs to LLMs. Second, they studied different parameter-efficient techniques to adapt an LLM for modeling asynchronous time series. The proposed framework achieves competitive performance across different temporal event benchmarks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper is the first to propose using LLMs for asynchronous time series data. This task has promising research prospects and the experimental results are also encouraging.\n2. This paper designs a text-based representation of asynchronous time series for LLMs and explores mainstream parameter-efficient fine-tuning methods on this basis. The results on different datasets demonstrate the effectiveness of the proposed framework."
            },
            "weaknesses": {
                "value": "1. Although the model in this paper has shown a significant performance improvement in the selected dataset, there is a concern that the performance of the model on all tasks seems to be low (Not sure whether it exceeds or approaches the human level, and it is relatively easy for people to predict daily events, event imputation, or detect event anomalies). This makes me worry that the current task definition is not perfect enough, whether it is too difficult for the model, or usable enough.\n2. One of the main experiments in the paper (Table 1) lacks more credible baselines. The author mainly compares with the random guess, which is often not a particularly credible or competitive comparison target. Finding more baselines will help reflect the performance of the method.\n3. Scaling laws have been widely demonstrated in LLMs, and I noticed that this paper uses Llama-3-8B-Instruct as a base model, so I was curious whether this approach would generalize to larger models."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "There is no ethics concern needed."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}