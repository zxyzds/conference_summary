{
    "id": "fvyuKLTC3s",
    "title": "Cayley Maze: Universal Open-Ended Reinforcement Learning Environment",
    "abstract": "Parametrizable environments with variable complexity are crucial for advancing fields such as Unsupervised Environment Design (UED), Open-Ended Learning, Curriculum Learning, and Meta Reinforcement Learning. However, the selection of environments in evaluation procedures, along with their complexities, is often either neglected or lacks formal justification. We propose the formal definition of complexity for Markov Decision Processes using Finite Automata and Group Theory machinery. We introduce Cayley Maze, a novel open-ended reinforcement learning environment that naturally generalizes problems like solving the Rubik's Cube, sorting, and integer factorization. Cayley Maze is universal: every deterministic sparse MDP is an MDP of a certain instance of Cayley Maze. We demonstrate how Cayley Maze enables control over complexity, simplification and combination of its instances. Finally, we evaluate UED algorithms on various instances of the Cayley Maze and analyze their capacity to produce agents with robust generalization capabilities.",
    "keywords": [
        "Reinforcement Learning",
        "Unsupervised Environment Design",
        "Open-Ended Learning"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=fvyuKLTC3s",
    "pdf_link": "https://openreview.net/pdf?id=fvyuKLTC3s",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes an interesting RL environment that has theoretical properties and tuneability to control for complexity over different MDPs problems. However, rather than an environment or a family of environments, the proposed Cayley Maze is a tool to interpret a wide range of MDPs.  The environment is built from a mathematical foundation using group theory and finite automata concepts. Experiments combine the approach with  PAIRED (Protagonist Antagonist Induced Regret Environment Design) and PLR (Prioritized Level Replay) to provide evidence that  that Cayley Maze can support diverse unsupervised environment design approaches."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper proposes a rigorous mathematical framework using algebraic structures, specifically group theory and finite automata theory, to define the complexity of Markov Decision Processes (MDPs). This mathematical rigor provides a foundation for measuring and controlling complexity more precisely, which is valuable in the field of reinforcement learning (RL), particularly for curriculum learning and adaptive agent development.\n- Claim of universality: the Cayley Maze can represent any deterministic MDP. \n- Problem representation through a formal method. This structured approach offers researchers a reliable way to analyse task properties and provides a clear foundation for designing new tasks within Cayley Maze. This can lead to better reproducibility and comparability of results, as tasks can be rigorously defined and consistently replicated across studies.\n- Applicability to unsupervised environment design: this approach could be particularly useful to create specific benchmarks for RL evaluation that currently relies on benchmarks with unclear properties and complexity."
            },
            "weaknesses": {
                "value": "1. While the principles are interesting, it's unclear how this can be used on a large variety of benchmarks to experiment with open-endedness.  It would strengthen the work if the authors demonstrated how Cayley Maze aligns with or diverges from existing benchmarks in terms of complexity, adaptability, and the variety of problems it can handle\n2. The paper discusses the variable complexity of Cayley Maze but could further demonstrate this aspect through empirical tests showing how increasing or decreasing complexity affects agent performance. \n3. Can the authors discuss how can the approach be adapted to work with stochastic environments? Since many real-world applications involve stochastic elements, this is a crucial gap. Cayley Maze\u2019s deterministic nature could limit its real-world applicability, as it does not address environments where randomness or partial observability plays a role. The paper could benefit from a discussion or proposed modifications for incorporating stochastic transitions, which are often essential for testing generalization and robustness in RL agents.\n4. While I appreciate the foundation in group theory, monoids, and algebraic structures, this is also a limitation. For those that are not too familiar with the mathematical formalism, it would be good to read a more thorough discussion of a longer list of problems that can be formalized with Calyey Maze, and those that they cannot be formalized in such a way. To improve accessibility, the paper could offer more concrete examples of specific problems that Cayley Maze is well-suited to address and explicitly identify cases where Cayley Maze\u2019s mathematical structures may not apply. This would clarify both the scope and limitations of the environment for a wider audience.\n5. One question remains on whether the RL strategies can generalize. The paper would benefit from experiments or discussions that illustrate how agents trained in Cayley Maze fare on distinct yet related tasks. For example, are there cases where skills learned in one Cayley Maze configuration (like Rubik\u2019s Cube) transfer effectively to another (e.g., different types of sorting problems)? Providing empirical evidence or a theoretical argument for generalization would significantly strengthen the paper\u2019s claims.\n6. I could not find the JAX implementation: this would be very useful for reproducibility.\n7. The language is at time informal."
            },
            "questions": {
                "value": "I would like to see some modifications to the paper to address the weakness above. In particular, point 2, 3, 4 and 5 are quite central and addressing those point could strengthen the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes both a spaces of parameterised environments, and a complexity measure for these environments. The environments are effectively problems involving the navigation of Cayley diagrams through the generators of a monoid, and the complexity of an environment being the size of the smallest monoid the environment has a reward-preserving homomorphism to. This space of environments, dubbed Cayley Mazes, are implemented in JAX, and they are tested as benchmarks for UED algorithms."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "This paper addresses a real need in the field of Open-Ended Learning and UED. Moreover, it does so in a very natural and powerful way, brining to bear a powerful suite of existing tools from abstract algebra. The idea that environments that are more symmetric are simpler all else being equal is intuitive and natural. Moreover, the structure of monoids gives ample opportunity to see emergent structure from our environment design algorithms if our algorithms are capable of effectively searching for this structure. It is clear to me that this is a promising direction for the field of UED and that the environment in JAX is a strong contribution."
            },
            "weaknesses": {
                "value": "Unfortunately, I believe there are some serious weaknesses with the current form of this paper which will make it difficult for it to achieve that impact. My two main concerns are:\n1) The exposition is likely to loose most readers in UED\n2) The empirical evaluation and presentation does not meet the standards in RL and UED, so it is difficult to use as a baseline.\n\nI believe both of these issues are resolvable, though likely not in the rebuttal period. I would encourage the authors to try to really over-do it on fixing points 1 and 2. I believe many in the UED space would be excited about this work if those points were soundly addressed. Unfortunately, due to these concerns I will currently have to recommend rejection. More specific details of these concerns are described below.\n\n\n\n### Improving the Exposition\n\nMuch of the paper is too fast for people without a strong abstract algebra background, which the vast majority of the target audience does not have. I think the paper will effectively have to teach the readers enough of abstract algebra to get through the main ideas of the paper, and do so assuming they have never seen the field before. I believe this is quite doable, but will require a good amount of effort. \n\n\nThe paper is quite fast through pages 2 and 3. At the same time, it is essential that the reader understands these ideas deeply as the intuition being drawn on here relies on a quite robust understanding of the monoids. The paper needs to impart the intuition that they have something to do with complexity and symmetry that only becomes obvious after the reader really groks the concept. This will require some hand-holding -- \"alternatively its an element of the free monoid on A\" is quite a complicated throw-away phrase for someone who just was told about free monoids, and most readers would not realise that it is not saying anything complicated. It would be better to introduce this idea in a few lines, with an example so they understand why that framing makes it easier to think later.\n\nI think that if example 1 was introduced much earlier, ideally in the introduction, and used to introduce all of the definitions, it would be much easier to follow.  Moreover, I would include a lot of visuals, namely Cayley diagrams would make everything much easier to follow and would make the ideas concrete.\n\nIn definition 5, it's unclear how exactly this maps on the UED, in that the parameters of the UMPD being proposed aren't defined explicitly. I would suggest defining the Cayley Maze concretely as a UMPD to avoid this confusion. Without this, it is hard to know what the scope is of a specific environment, and it is then hard to interpret the experiments.\n\nProposition 2 is a bit narrower than is claimed in the intro (constraining to deterministic sparse and finite), you should mention these constraints in the intro when you mention these results.\n\nIn section 4.3, you should reference OMNI-EPIC as it is also universal, and comes with a notion of complexity (program length).\n\nThere are often references to group-theoretic concepts that the reader doesn't know, but would need to understand to understand the rest of the paper.  For instance, the reference to \"the symmetries of the 3 cube\", \"Group of order 6\" and \"wreath product\" in the experiments section all will be lost on readers.\n\n\n**Some minor clarity concerns:**\n - 016 should be \"A\" formal definition of complexity\n - 038 \"For\" should not be capitalised\n- 085 in the definition of syntactic congruence, the right hand side of the implication should be xby \\in L not xby \\in M\n - 088 It's not clear what is meant by a transition kernel\n - 095 It's not clear what is meant by \"it's realisation\" or \"a resulting kernel\"\n - 100 Referencing this as matrix multiplication is confusing since T_\\alpha are functions, not matrices. I think this means composition where the \"matrix\" being referenced is the probability transition matrix representation of T, but that is a few more levels of indirection than necessary. Saying composition here is fine (relying on the implicit fact that a function of a random variable also gives a random variable)\n- 107 it's not clear what the \"corresponding trajectories\" would be \n- 317 there is a stray \"i\"\n\n\n### Improving the Evaluation\nThe goal of the evaluation section ought to be to set this up as a benchmark that others in UED can aim to improve on. As it stands, it is missing several components for that.  Namely:\n\n- The evaluation protocol should match that in prior UED works\n- The task should be clearly delineated in a easy-to-hard order with the easiest ones being solved and the hardest ones only partially working \n- There should be a clear ideas what the scores mean in each setting\n\n*Evaluation protocol:*\n It should follow the conventions of evaluation in papers like PAIRED and PLR, describing an explicit test set of levels and corresponding bar charts, the inter-quartile scores as described in [1]. These test levels should vary from easier examples to hard examples and should be diverse while giving signal to partially-working methods. There should also be visual depictions of the levels being generated, since the level-generation is what methods would be evaluating.  The return plots should all have the appropriate error bars. The goal for being rigorous on this is to lay the foundation for researchers who use this environment as a benchmark to have the information they need to evaluate their approaches, and for the readers to have the information they need to tell if this is a benchmark that is too hard, too easy, or measuring current frontier progress. It should be clear that the methods work on some of the environments (for instance the Cayley Mazes equivalent to minigrid), and fail on others (the full Rubix cube setting). Ideally, there would be some instances of nearly-solved Rubix cubes in the test set that the methods show some performance on so others have a signal to hill-climb on. \n\nIn Figure 3 it looks like PLR is still improving, It would be best to run the methods for longer to make sure the baseline reports the best numbers for current methods so that they can be more readily beaten with new methods. It also looks like all of the methods need to be tuned, or at least it is difficult to tell if they have been tuned will given the information provided. This is also why it would be best to give some easy tasks, or easy instances of the given tasks to show the methods are tuned enough to work a bit. Steps per second should also be reported for the environment during training, since this is a critical limiting factor and selling point for any Jax environment. \n\n*Clear Task Definitions:*\nGiven the wide space of Cayley Mazes, it would be best to delimitate specific subsets which can serve as self-contained environments to test UED aparoches on. This is like how minigrid has a range of  different settings provided by default, along with current algorithms performances on these settings. These tasks should be clearly delineated and named so that other papers could easily reference the definition of the task that they are training on.  Moreover, it is best that this paper as the benchmark defines several of these tasks since it could then be presented as standard suites, and authors would no longer be able to easily pick the problem that their method performs well on.\n\n*Clear meaning of tasks:*\nIt would be best of there was some sort of visualisation of the tasks, along with a much slower non-group-theoretic description of them. The performance on these problems is only useful to the reader if they understand how to interpret the difficulty of the tasks. As such, the main message I think most would get from these are \"these seem to be hard tasks\", but they get no sense of if these are \"proving a novel theorem\" levels of hard, or something more manageable for a new algorithm. \n\n[1] Agarwal, Rishabh, et al. \"Deep reinforcement learning at the edge of the statistical precipice.\" Advances in neural information processing systems 34 (2021): 29304-29320."
            },
            "questions": {
                "value": "How do you think the edits in methods like ACCEL could best be applied to Cayley maze?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a definition of complexity for deterministic MDPs; it also introduces Cayley Maze, which can model a general class of deterministic MDP problems for unsupervised environment design (UED) and other frameworks with an extra level of complexity over the traditional reinforcement learning framework. The paper first views the sequences generated in an MDP from the perspective of Finite Automata theory and proposes the new complexity accordingly. Further, the paper introduces the Cayley Maze and shows that every deterministic finite MDP with sparse rewards corresponds to an instance of the Cayley Maze. Limited experiments are performed to examine the performance of different UED algorithms on some Cayley Maze instances."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The strengths of the paper are its originality and potential significance:\n1. The perspective developed in this paper is novel to the knowledge of the reviewer. The proposed complexity measure seems grounded and removes redundancy in the MDP\u2019s structure.\n2. The paper has some potential to inspire and be useful to future research on UED and other fields like meta reinforcement learning. The proposed Cayley Maze seems to have the potential to be useful for these fields."
            },
            "weaknesses": {
                "value": "While the paper has notable strengths, there are several significant weaknesses that impact its overall contribution:\n1. The quality of the paper is poor. The paper is rough and seems to be incomplete. Specifically,\n* The experiments seem to be limited, and their conclusions are unclear. There are only three small experiments provided, and their implications are unclear. What are the goals of the experiments? Other than some results of the three algorithms\u2019 performance in a few instances, what can the reader learn about the proposed environment? Are the current set of experiments sufficient? Having more detailed discussions in the experiment section and including a conclusion section will help clarify the implications. If needed, more experiments should be conducted to justify the utility of the proposed environment.\n* Sufficient details about the experiments are not provided despite the fact that there are a few more pages available. It may be useful to address the following concerns:\n  * What exactly are the used environment instances? Is there a way to describe them better? From reading the paper, I cannot understand what these environments are and their implications. Including some more details even in the appendix would help.\n  * While there isn\u2019t any discussion or citation for the domain randomization algorithm, the reader might not be able to figure out what it is.\n  * What does the y-axis in all the plots represent? In addition, the x-axis should also have a label for clarity.\n  * The performance variation across different random seeds is not provided.\n  * It\u2019s unclear what Figure 3 represents. The text also doesn\u2019t give sufficient information.\n* While the proposed Cayley Maze is general and includes both easily solvable and difficult instances, how to generate interesting instances is not thoroughly discussed apart from a very short discussion in Section 4.4. In other words, what makes Cayley Maze a good class of problems to work on? And how can it be used?\n2. While a new complexity measure is proposed, the paper doesn\u2019t provide any further theoretical results, empirical implications, or justifications for its usefulness.\n3. The paper also needs to improve its clarity. In addition to the missing information mentioned above, in the Questions section, there is a list of small issues that reduce the paper\u2019s clarity."
            },
            "questions": {
                "value": "Other than the questions asked in the Weaknesses section, here are questions that might affect the evaluation:\n1. In Line 213, what does it mean by saying $M(T)$ acts on the state space $S$ by multiplication of action and state? And is it good for evaluating agents\u2019 generalization capabilities and architecture\u2019s inductive biases?\n\nOther minor questions or suggestions:\n* Line 021 - Inaccurate claim in the abstract: Only deterministic sparse MDPs are shown to be instances of Cayley Maze.\n* Line 060 - Confusing expression: It\u2019s better to put a comma after $m\\in M$.\n* Line 066 - Undefined operation: What does $g\\times h$ mean? Is it the same as $g\\cdot h$?\n* Line 078 - Delayed definition: The definition of isomorphism should be before Theorem 1. Also, it would be good to add a citation that contains the proof of the theorem.\n* Line 101 - Unclear acronym: Does DFA mean deterministic finite automaton? If so, be consistent with the definition in line 99.\n* Line 117 - Confusing expression: Having the definition for congruences that preserve reward structure after the proposition statement confuses me. It might be better to remove it.\n* Line 158 - Unclear concepts: What are words and language here?\n* Line 173 - Unclear notation: What is $Im(T)$?\n* Line 247: The sentence \u201cBut it\u2019s certainly possible for MDP\u2019s\u201d does not connect to the previous sentence and is confusing. Do you mean \u201cfor some MDPs\u201d?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce Cayley Maze, a universal mathematical framework based on Finite Automata and Group Theory machinery, that may be used to represent an open-ended reinforcement learning environment that naturally generalizes problems like solving Rubik\u2019s Cube, sorting, and integer factorization, and that enables control over complexity, simplification, and combination of its instances.\n\nI found this paper extremely unclear about its goals and its main messages, and I\u2019m strongly in favor of rejecting it."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "No idea, sorry"
            },
            "weaknesses": {
                "value": "- the authors claim that Cayley Maze is a novel open-ended reinforcement learning environment, but they never define what an open-ended reinforcement learning environment is.\n- the authors mention what it is possible to do with the Cayley Maze, rather than what they did\n- the paper does not have a conclusion\n- the paper is very poorly written, with many unclear statements, english mistakes, typos, unclear figures with poor captions, etc.\n- no related work section, no comparison to anything, no ablations..."
            },
            "questions": {
                "value": "I\u2019m not using this section only to ask questions, but also to criticize the current form and to suggest improvements to the authors.\n- line 39: \u201cwe doubt that such an environment allows for producing challenging,\u201d What makes the authors doubt so? Did the authors perform experiments to backup their doubts? Science is not about expressing raw beliefs and doubts, it is about establishing facts.\n- line 43: \u201calgorithms cannot be better than their evaluation procedures\u201d \u2192 how can the authors compare an algorithm to an evaluation procedure? Don\u2019t the authors mean \u201calgorithms cannot be better than what their evaluation procedures allows\u201d? What do the authors mean exactly?\n- line 46: \u201cThe diversity of parametrizable environments is an assumption of UED, hence it also relies on some notion of similarity/metric.\u201d I don\u2019t understand the sentence. Can the authors be more explicit about the relation between the diversity of parametrizable environments and the notion of similarity/metric?\n-line 50: \u201cWe \u2026 hopefully prove its usefulness\u201d. \u2192 I\u2019m afraid I\u2019m not convinced by the \u201cproof\u201d.\n- why is Theorem 1 useful in the context of the paper? What claim about open-ended RL does it support?\n- line 107: \u201cLoosely speaking, we define two MDP\u2019s to have same complexity, if the corresponding trajectories yield the same cumulative reward.\u201d \u2192 How do the authors define the fact that 2 trajectories correspond to each other?\n- line 138 (Example 1): \u201con the right side of the grid\u201d \u2192 what grid? We are missing some context here\u2026\n- line 172: what is a monoid generator?\n- line 217: \u201cis simple in group-theoretic sense\u201d what does this mean?\n- line 250: \u201cwhose construction is similar to it\u2019s group-theoretic analogue.\u201d \u2192 why \u201csimilar\u201d? What is the point?\n- all figures should be self-contained: the caption should specify what is the environment, what the figure shows, what we should conclude from watching it. Figure 1 does not have labels on the x and y axis, we don\u201dt even know what it measures. This is not acceptable. Do the figures show a single realization or a mean? What about the variability of the results? These mistakes are enough to kill the paper, even if the paper had a clear message.\n- same for figures 2, 3 and 4\n-the paper should come with a conclusion\n# Typos, minor errors:\n- there should alsways be a space before \u201c(\u201c, but none in \u201c) ,\u201d\n- on the figure X \u2192 in Figure X (many times)\n- the definition X \u2192 Definition X. Same with proposition.\n- Since MDP \u2192 Since an MDP. A lot of articles are missing\n- Note, that \u2192 Note that (many times)\n- MDP\u2019s \u2192 MDPs (many times)\n- line 213: in this cases \u2192 these cases (or this case)\n- it\u2019s can be either \u201cit is\u201d (do not use contractions in scientific papers, no \u201cdoesn\u2019t\u201d etc.) or its (the possessive). Please correct them all.\n- line 226: (Demaine E., 2018). \u2192 is it rather \u201cEisenstat& Demaine\u201d? The reference \u201cEisenstat S. et al. Demaine E.\u201d looks incorrect. Use bibtex to get proper references.\n- Fig 3: of of"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Mathematics are harmless (I hope)"
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}