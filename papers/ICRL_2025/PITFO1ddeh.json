{
    "id": "PITFO1ddeh",
    "title": "Unlocking Efficient, Scalable, and Continual Knowledge Editing with Basis-Level Representation Fine-Tuning",
    "abstract": "Large language models (LLMs) have achieved remarkable performance on vari-\nous natural language tasks. However, they are trained on static corpora and their\nknowledge can become outdated quickly in the fast-changing world. This moti-\nvates the development of knowledge editing methods designed to update certain\nknowledge in LLMs without changing unrelated others. To make selective edits,\nprevious efforts often sought to update a small amount of parameters in some spe-\ncific layer(s) of a LLM. Nonetheless, in challenging scenarios, they still fall short\nin making successful edits while preserving knowledge irrelevant to the updates\nsimultaneously, resulting in a notable editing-locality trade-off. In this work, we\nquestion if the trade-offs are caused by the fact that parameter-based updates have\na global effect, i.e., edited parameters affect all inputs indiscriminately. In light of\nthis, we explore the feasibility of representation fine-tuning, which applied some\nlinear update to a few representations in a learned subspace, for knowledge edit-\ning. While being effective to enhance an LLM\u2019s general ability as demonstrated in\nthe previous work, we theoretically show that this linear update imposes a tension\nin editing-locality trade-off. Subsequently, BaFT is proposed to break the linear-\nity. BaFT computes a weight for each basis that spans a dimension of the subspace\nbased on the input representation. This input-dependent weighting mechanism al-\nlows BaFT to manage different types of knowledge in an adaptive way, thereby\nachieving a better editing-locality trade-off. Experiments on three LLMs with five\nediting benchmarks in diverse scenarios show the superiority of our method.",
    "keywords": [
        "Knowledge Editing",
        "Representation Fine-tuning",
        "Large Language Models"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=PITFO1ddeh",
    "pdf_link": "https://openreview.net/pdf?id=PITFO1ddeh",
    "comments": [
        {
            "summary": {
                "value": "The paper discusses the challenge of updating LLMs with new knowledge without disturbing the existing knowledge they hold. Traditional methods of parameter-based updates have limitations in achieving this, as they tend to affect all inputs globally. The study introduces a new method called BaFT which achieves a better balance between making necessary updates and preserving unrelated knowledge. The effectiveness of BaFT is demonstrated through experiments on several LLMs across different editing benchmarks, showing superior performance compared to previous methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to follow. It also provides a clear introduction of the Knowledge Editing task matter, enhancing its accessibility to a broad audience.\n\n2. The paper addresses a significant problem within the field of Knowledge Editing, focusing on a pertinent limitation associated with current methodologies. The investigation into this particular trade-off is could potentially lead to substantial advancements in the field of Knowledge Editing.\n\n3. The experimental design and execution are robust, utilizing well-chosen benchmarks to effectively demonstrate the proposed method\u2019s validity."
            },
            "weaknesses": {
                "value": "1. This paper lacks visual illustrations such as diagrams or figures, which would significantly aid in the comprehension of the methods and results. I recommend the authors add figures to enhance the reader\u2019s understanding and engagement with the content.\n\n2. There is an absence of publicly shared code in the paper or on platforms such as OpenReview. This hinders the reproducibility of the proposed method. I would suggest sharing the code through an anonymous GitHub repository or similar platform. This would greatly aid other researchers and reviewers in replicating and understanding the research.\n\n\n3. While the motivation behind the study is well-articulated, the methods deployed are somewhat conventional. This paper devotes considerable space to arguing for directly applying the ReFT method to the Knowledge Editing tasks faces limitations. However, the proposed solutions introduced by the authors do not add intriguing or novel aspects to the existing array of techniques in the field."
            },
            "questions": {
                "value": "Please refer to the previous section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Building on the ReFT, this paper introduces a novel method called Basis-level Representation Fine-tuning (BaFT) for editing knowledge within Large Language Models (LLMs) while preserving unrelated information. The authors perform a theoretical analysis that highlights the inherent limitations of existing approaches, particularly linear representation fine-tuning, which often necessitates a trade-off between editing effectiveness and the retention of unrelated knowledge (locality). To address these challenges, BaFT calculates the weight for each basis in the subspace based on the input representation, facilitating a more adaptive management of diverse knowledge types. The authors conducted experiments across three different LLMs and evaluated them against five editing benchmarks, demonstrating that BaFT surpasses existing methods in both editing performance and parameter efficiency. Ultimately, BaFT strikes a superior balance between integrating new knowledge and maintaining existing unrelated information."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. BaFT introduces a non-linear, input-dependent weighting mechanism for basis-level representation fine-tuning, which is a significant departure from traditional parameter-based updates.\n\n2. The authors demonstrate the effectiveness of BaFT through extensive experiments on three different LLMs and five editing benchmarks, showing superior performance in various scenarios.\n\n3. This paper provides a detailed and clear explanation of the proposed method BaFT in conjunction with the theory."
            },
            "weaknesses": {
                "value": "1. Innovation and Improvement Effect: The improvements of the method presented in this paper compared to ReFT are limited. Although the authors propose the ReFT-based enhancement method BaFT, experimental results indicate that these improvements show weak effectiveness in knowledge editing benchmark, thus suggesting a lack of innovation in this work.\n\n2. Questions of Method Applicability: \n- In Assumption 2.1, the authors assume as follows: \"Let text x encode s and r; text y generated by the LM will convey o if its intermediate representation takes some targeted value t.\" For instance, a sentences in the WikiData dataset: \u201cThe name of the country which Goursez Vreizh is associated with is []\u201d is input into the model, and the generation probabilities are used to assess the accuracy of knowledge editing. Although multiple datasets are presented in this paper, these datasets exhibit high homogeneity in type. \n\n- In contrast, there are more complex benchmark datasets in the field of knowledge editing, such as MQuAKE[1] and KEBench[2]. These datasets require inputting questions into the model and determining whether the generated responses contain the corresponding answers. For example, the question from MQuAKE, \u201cWhich sport is Dudley Town F.C. associated with?\u201d is answered with, \u201cDudley Town F.C. is associated with the sport of association football.\u201d The complexity of such questions is significantly higher than that of the datasets used in this paper, making them more aligned with real-world application scenarios and challenging the authors' assumptions in Assumption 2.1. The generality of the methods in this paper has been questioned.\n\n[1] MQUAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions\n\n[2] Stable Knowledge Editing in Large Language Models\n\n3. Choice of Baselines: The baselines in this paper are relatively limited. Key literature, including LTE [1], MELO [2], StaleKE [3], and InstructEdit [4], which are fine-tuning-based methods, are not discussed or compared, resulting in a lack of comprehensiveness regarding the current field of knowledge editing.\n\n[1] Learning to edit: Aligning llms with knowledge editing. \n\n[2] Melo: Enhancing model editing with neuron-indexed dynamic lora.\n\n[3] Stable Knowledge Editing in Large Language Models\n\n[4] InstructEdit: Instruction-based Knowledge Editing for Large Language Models\n\n4. Performance of Baseline Results: The baseline results reported in the paper are significantly lower than those in existing literature, especially in the Batch Editing and Continual Editing settings, where the performance of the MEMIT method is notably inferior to previous reports. This starkly contrasts with results from several studies (e.g., [1, 2, 3]), casting doubt on the validity of this paper.\n\n[1] Model Editing at Scale leads to Gradual and Catastrophic Forgetting\n\n[2] MQUAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions\n\n[3] Learning to edit: Aligning llms with knowledge editing."
            },
            "questions": {
                "value": "1. Should anLM in line 187 be changed to an LM?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the challenge of updating specific knowledge within Large Language Models (LLMs) while preserving other unrelated knowledge. Traditionally, methods have attempted to update only a small number of parameters in specific layers of LLMs, but these methods often fail to maintain the precision required for effective knowledge editing due to the inherent trade-off between editing and locality. The authors propose a novel approach called Basis-level Fine-Tuning (BaFT), which builds upon the Representation Fine-Tuning (ReFT) method. Theoretical analysis supports the introduction of BaFT, highlighting the limitations of linear representation fine-tuning and suggesting that a more precise method could improve both the specificity and locality of knowledge edits.  Instead of applying a uniform linear update across the subspace, BaFT computes a unique weight for each basis vector depending on the input representation. This allows BaFT to handle different types of knowledge adaptively, potentially resolving the inherent tension between editing performance and locality. The experiments on several models under different settings demonstrate the effectiveness of the proposed model."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The prposed method obtains great performance under different knowledge editing settings including the single\uff0ccontinual and batch editing.\n2. The motivation is clear and reasonable and the experiments consider different kind of knowledge dataset which makes the evaluation strong."
            },
            "weaknesses": {
                "value": "1. There are some details missing from the main part and I have listed in the question part.\n2. The proof for the failure in the ReFT is reasonable, but why the loss used in RaFT can alleviate the problem is not clear. A proof here can make the method and theory complete and robust."
            },
            "questions": {
                "value": "1. Some details of the method are not clear and I'm wondering when conducting ReFT or BaFT, how to decide the position for the fine-tuning? Is it the same position for different knowledge? In addition, is the experiment conducted on all layers of the specific LLM? This may be the basic information in ReFT, but for readers, it's a bit confusing.\n2. I agree that editing the knowledge in a single space would lead to the general-loc trade-off, but I think the assumption about the ball in is a bit subjective, it would be better to provide more related work here.\n3. Some typos: L187, missing blank \u2018anLM\u2019."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents BaFT, a method designed to improve knowledge editing in large language models by fine-tuning representations instead of model parameters. Unlike traditional parameter-based approaches, BaFT performs selective edits at the basis level within a learned subspace, using an input-dependent weighting mechanism. This enables precise updates to targeted knowledge while preserving unrelated knowledge. Experimental results demonstrate that BaFT excels across multiple benchmarks in single, continual, and batched editing tasks, achieving efficient knowledge updates with fewer parameters. BaFT shows strong potential for effective, dynamic knowledge editing in real-world applications."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.This paper introduces BaFT, which performs updates at the basis-vector level within a representation subspace, rather than relying on traditional parameter-based updates.\n\n2.The paper provides substantial theoretical and empirical support for BaFT. The theoretical section thoroughly analyzes the limitations of existing linear update methods, offering a solid rationale for BaFT\u2019s nonlinear representation fine-tuning approach.\n\n3.BaFT offers a more efficient solution for knowledge editing in large language models, especially valuable in applications that require frequent knowledge updates."
            },
            "weaknesses": {
                "value": "1.Although the article presents the BaFT method and demonstrates its advantages in knowledge editing, the analysis of its limitations and potential flaws is relatively sparse.\n\n2.The experiments in the article primarily focus on a few specific benchmark datasets, which may not comprehensively reflect the performance of BaFT in various real-world applications."
            },
            "questions": {
                "value": "1.The paper asserts that it is the first work to explore an alternative selective representation-based update for knowledge editing. However, to my knowledge, REMEDI[1], as an established editing method, has already conducted preliminary investigations in this area.\n\n2.Assumption 2.2 has been proposed in GRACE[2]\uff0cauthors should cite it.\n\n3.Almost editing methods have examined the \u2018locality\u2019 of these methods to downstream tasks. I recommend that the authors incorporate an evaluation of downstream tasks in the paper to ensure the reliability of the proposed editing methods.\n\n4.In the experimental section, I have concerns regarding the validity of the baseline evaluation methods. The authors did not specify the evaluation framework or the parameter choices employed. If the authors utilized the EasyEdit[3] framework to evaluate ROME and MEMIT, I suggest a unified re-evaluation of the baseline methods, as the EasyEdit evaluation framework has known mistakes.\n\n5.In the context of continual(sequential) editing, BAFT exhibits slightly inferior performance compared to WISE, which is achieved at the cost of faster training and inference speeds. How should the trade-off between these two aspects be effectively balanced?\n\n6.As an update representation for achieving editing, I believe this is not a reliable knowledge editing method compared to directly updating parameters.\n\n7.There are several expression issues in the paper, such as \"anLLM\"; however, this did not influence my overall score.\n\n[1].https://github.com/evandez/REMEDI\n\n[2].https://arxiv.org/abs/2211.11031\n\n[3].https://github.com/zjunlp/EasyEdit?tab=readme-ov-file"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}