{
    "id": "d4qMoUSMLT",
    "title": "Efficient Training of Neural Stochastic Differential Equations by Matching Finite Dimensional Distributions",
    "abstract": "Neural Stochastic Differential Equations (Neural SDEs) have emerged as powerful mesh-free generative models for continuous stochastic processes, with critical applications in fields such as finance, physics, and biology. Previous state-of-the-art methods have relied on adversarial training, such as GANs, or on minimizing distance measures between processes using signature kernels. However, GANs suffer from issues like instability, mode collapse, and the need for specialized training techniques, while signature kernel-based methods require solving linear PDEs and backpropagating gradients through the solver, whose computational complexity scales quadratically with the discretization steps. In this paper, we identify a novel class of strictly proper scoring rules for comparing continuous Markov processes. This theoretical finding naturally leads to a novel approach called Finite Dimensional Matching (FDM) for training Neural SDEs. Our method leverages the Markov property of SDEs to provide a computationally efficient training objective. This scoring rule allows us to bypass the computational overhead associated with signature kernels and reduces the training complexity from $O(D^2)$ to $O(D)$ per epoch, where $D$ represents the number of discretization steps of the process. We demonstrate that FDM achieves superior performance, consistently outperforming existing methods in terms of both computational efficiency and generative quality.",
    "keywords": [
        "neural stochastic differential equations",
        "Markov process",
        "scoring rule"
    ],
    "primary_area": "learning on time series and dynamical systems",
    "TLDR": "We propose a novel class of scoring rules to compare laws of Markov processes, leading to an efficient algorithm to train neural SDEs.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=d4qMoUSMLT",
    "pdf_link": "https://openreview.net/pdf?id=d4qMoUSMLT",
    "comments": [
        {
            "comment": {
                "value": "Many thanks for your answers. I look forward to reading your revision. Let me know if you want to discuss any other point of your paper."
            }
        },
        {
            "comment": {
                "value": "It is your decision, but then you need to argue things through separability. I thought the focus of this paper should be providing a divergence for neural SDE applications. How would jump processes of graphs fit into the neural SDE context?"
            }
        },
        {
            "comment": {
                "value": "Thank you again for the insightful review.\n\n**Concerning point 3**, thank you for the reference. We'll try to include experiments on non-Euclidean datasets in the final revision.\n\n**Concerning points 5 and 6**, I agree these are interesting directions. However, they seem to be beyond the scope of neural SDEs and may deserve a separate paper.\n\n**Concerning point 7**, thank you for the insight. The sample complexity bound is currently on our to-do list. We hope to integrate it into the final revision.\n\n**Concerning point 8**, we appreciate this advice and agree to add error bars at least for some smaller datasets. However, we do not have access to our cluster in the next few days, so the error bars will be included in a later revision toward the end of the discussion period.\n\nAgain, we appreciate your time and insights."
            }
        },
        {
            "comment": {
                "value": "Thank you for your answers on points **1,2 and 4**.\n\n**Concerning point 3**, you can apply your method to any space on which you have a suitable kernel if I am not mistaken. This paper develops neural SDEs for graphs for instance https://arxiv.org/pdf/2308.12316 and could give you some inspiration. You could also think of shapes evolving through time, a topic of interest in healthcare (think about organs and cells deforming over time). Finally, you could also consider measures evolving over time - see for instance https://proceedings.mlr.press/v151/bunne22a/bunne22a.pdf. \n\n**Concerning point 5**, yes this is exactly what I mean. I believe that this would allow you to show that generating time series for training a downstream model with your method has real benefits (which is something that I don't believe to be straightforward, see for instance https://arxiv.org/abs/2402.07712v1). \n\n**Concerning point 6**: even if your method simplifies the optimization of the neural SDE through a simpler kernel (compared to the signature kernel which can be technical to compute with high precision, or the GAN-like training of Kidger et al 2021), you still have to evaluate this very kernel. To simply such a computation, a long lasting line of research going back to Rahimi (2007) has resorted to randomised approximations. I believe that this framework could allow you to train neural SDEs for generating high dimensional time series. \n\n**Concerning point 7**: my intuition would be that the sample complexity is similar. But then you need to approximate the expectation in definition 1, so you might have to deal with a concentration bound on this stochastic approximation. Hence intuitively I believe that you should end up with the classical sample complexity of kernel mean embeddings + a term that depends on the number of times you draw times to compute your scoring function. Could you maybe provide an empirical assessment of this ? A plot of your metric vs the number of samples used and a plot of your metric vs the number of times drawn would suffice to convince me. \n\n**Concerning point 8**: I sincerely believe that this is not an acceptable answer. Reporting confidence intervals is a common and well-established scientific practice. NeurIPS, for instance, requires it in the paper checklist: https://neurips.cc/Conferences/2022/PaperInformation/PaperChecklist. Providing confidence intervals on even smaller datasets is a bare minimum."
            }
        },
        {
            "comment": {
                "value": "Hi,\n\nThank you for the detailed and constructive review. We're happy to address the raised concerns.\n\n**1. Experiments are only carried out on 2-dimensional time series**\n\nWe apologize for the confusion, but this is not the case. For each dataset, we model all the features jointly, i.e., the dimension is $2$ for the metal price and exchange rate dataset, $5$ for the stock indices dataset, $4$ for the energy price dataset, $3$ for the bonds dataset, and $16$ and $32$ for the Rough Bergomi Model data. We present the two-dimensional joint marginals only because plotting higher-dimensional distributions on paper is challenging.\n\n**2. Visualizations of the full generated time series**\n\nThank you for pointing this out. We'll add them in the forthcoming revision.\n\n**3. Non-Euclidean real-world dataset**\n\nWe're not familiar with this type of dataset that is suitable to be modeled as an SDE. We would appreciate any recommendations you might have.\n\n**4. Choice of kernels**\n\nWe can include a study on the kernel choice in the appendix in the forthcoming revision.\n\n**5. Augmentation of a time-series dataset**\n\nWe're not sure what this means; could you please elaborate? Do you mean using the generative method for data augmentation and applying it to a downstream task?\n\n**6. Random feature approximations to the kernels for high-dimensional generation**\n\nCould you please elaborate on this as well? Do you mean computing the kernels with random feature approximation? It seems like this is just another way to compute/approximate the kernel.\n\n**7. Sample complexity**\n\nWe agree that this is an interesting aspect and will look into it. We'll try to integrate sample complexity analysis in the final revision by the end of the discussion period, but we cannot guarantee.\n\n**8. Confidence intervals**\n\nRepeating some models on higher-dimensional datasets or datasets with longer sequences can be computationally expensive, so we omitted the confidence intervals for consistency. The previous state-of-the-art [Issa et al., 2023](https://arxiv.org/pdf/2305.16274) in this area also didn't report error bars, so we believed this was acceptable. That being said, we're happy to include confidence intervals for some smaller datasets in the appendix in the forthcoming revision.\n\nWe thank you again for your insights, and please let us know if there is anything unclear; we're more than happy to clarify!"
            }
        },
        {
            "comment": {
                "value": "In my opinion, the \"strong assumptions regarding the Markovian properties and continuity of the processes involved\" mentioned by reviewer 4f46 are relatively acceptable for many applications - for instance stochastic modelling in biology and healthcare, with which I am fairly familiar. While I am not familiar with non-Markovian processes, I have never encountered them in my research. Do you have any examples in mind ? I am genuinely interested in this question.  \n\nI do agree however that including jumps is of high interest. The authors could maybe at least empirically verify that their scoring rules are effective for training neural jump SDE (see https://arxiv.org/pdf/1905.10403) on a simple example. The code of this paper is available (https://github.com/000Justin000/torchdiffeq/tree/jj585) and seems to be well-built. However, I am unsure whether such an extension can be reasonably implemented during the short reviewing period."
            }
        },
        {
            "comment": {
                "value": "Thanks to reviewer SGBZ and the authors for this discussion. I have myself also read carefully read the proof, and do no see any issues. This strengthens my opinion that the contributions of the paper are strong and of high interest."
            }
        },
        {
            "comment": {
                "value": "Got it. I agree wo do need the separability for the last paragraph in the proof of Theorem 5. I'll add the Polish assumption for sure. \n\nThe reviewer DrUo mentioned  $\\mathcal{E}$ could be a space of graphs, so would $\\mathcal{E}$ being Euclidian a bit too restrictive? \n\nThank you again for the insightful and timely comments."
            }
        },
        {
            "title": {
                "value": "Polish and sensitivity"
            },
            "comment": {
                "value": "I misinterpreted your $X,Y$ taking value in $\\mathcal E$. I thought you were saying that $\\omega\\rightarrow X(\\omega,\\cdot )$ is in $\\mathcal E$. In any case, you do need the processes to be separable (continuity would suffice), i.e. the FDD is determined by a dense subset of $[0,T)$, to argue for the last part of Theorem 5. This is not explicitly stated in the assumption. I would suggest you just go with $X\\in C_{\\mathcal E}[0,T]$ or $D_{\\mathcal E}[0,T]$ where $\\mathcal E$ is a Euclidian space.\n\nFor the sensitivity, I am wondering if the scoring rule is smooth (and how smooth) in a change in the parameter of the neural SDE. This will affect the convergence rates of your algorithm. I think this is interesting especially for the volatility part, as we know that the KL is infinity if you perturb the volatility (the two laws are not absolutely continuous)."
            }
        },
        {
            "comment": {
                "value": "Hi,\n\nThank you for the review, and we're happy to address the raised concerns.\n\n1. We're going to fix the template in the forthcoming revision.\n\n2. *Continuity and Markov Assumption*\n\nAs mentioned in the response to reviewer SBGZ ([link](https://openreview.net/forum?id=d4qMoUSMLT&noteId=zKB258o4r6)), the proof can be directly extended to cadlag Markov processes defined on an open interval $[0, T)$. The only modification needed in the proof is to construct the sequences to converge from the right in the last paragraph of the proof of Theorem\u00a05. If you and the other reviewers deem it necessary, we are happy to extend the proof to the cadlag case. This allows our theory to cover jump processes.\n\nRegarding the Markov assumption, we believe this can be partially addressed by augmenting the paths with more information or leveraging a hidden Markov model. However, these are beyond the scope of neural SDEs and may warrant a separate paper. If you feel it is necessary, we can add additional discussion on the relaxation of these assumptions.\n\nWe thank you again for your insights, and please let us know if there is anything unclear; we're more than happy to clarify!"
            }
        },
        {
            "comment": {
                "value": "For the sensitive properties, could you recommend any literature? We'd deeply appreciate it."
            }
        },
        {
            "comment": {
                "value": "Thank you for the quick response!\n\nIndeed, the proof can be directly extended to cadlag Markov processes defined on an open interval $[0, T)$. The only modification needed in the proof is to construct the sequences to converge from the right in the last paragraph of the proof of Theorem\u00a05. As the focus of the paper is on neural SDEs, we did not include the proof for the cadlag case. That being said, if you and the other reviewers feel it is necessary, we are happy to extend the proof to cover the cadlag case."
            }
        },
        {
            "title": {
                "value": "Response to the clarification"
            },
            "comment": {
                "value": "I see, I forgot about the property of the scoring rule. \n\nBy the way, in responding to the concerns of the other reviewer about the jumps, I think this should work for (at least a large subclass of) Feller processes. Because essentially the law of the Feller process will be determined by the generator. This essentially means that you only need to match the joint distribution over an infinitesimal interval. So, the a.e. Lebesgue would suffice. \n\nIn this case, I will raise my score to 5 for now. If you can clarify your paper as suggested by me and other reviews, I will further improve the score to 6. \n\nAs the reviewer DrUo helpfully pointed out, this would be a better submission if you could say something about the qualities/properties of the scoring rule, especially sensitivity properties,  i.e. how perturbations in $\\mu$ and $\\sigma$ would translate to $S$."
            }
        },
        {
            "comment": {
                "value": "Hi,\n\nThank you for the detailed review and we're happy to address the raise concerns.\n\n1. For the proof, it is important that we choose $\\nu$ to be an equivalent measure to the Lebesgue measure $\\mu$ on $[0, T] \\times [0, T]$. So there exists a $\\mu$-a.e. positive function $\\lambda(t_1, t_2)$ such that $d\\nu = \\lambda d\\mu$. (in case you need a proof, see https://math.stackexchange.com/questions/1393425/equivalent-finite-measures-if-and-only-if-strictly-positive-radon-nikodym-deriv)\n\nThen \n$$E_{(t_1, t_2) \\sim \\nu} S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)}) = E_{(t_1, t_2) \\sim \\nu} S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)})$$ \nsuggests\n$$E_{(t_1, t_2) \\sim \\mu} \\lambda(t_1, t_2) S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)}) = E_{(t_1, t_2) \\sim \\mu} \\lambda(t_1, t_2) S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)}),$$\nwhich further implies \n$$E_{(t_1, t_2) \\sim \\mu} \\lambda(t_1, t_2) [ S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)}) - S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)})]  = 0.$$\n\nRecall that by definition of the proper scoring rule $S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)}) \\geq S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)})$ and $\\lambda(t_1, t_2) > 0$ $\\mu$-a.e. due to the equivalence of $\\nu$ and $\\mu$. This makes the integrand to be non-negative $\\mu$-a.e., forcing $\\lambda(t_1, t_2) [ S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)}) - S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)})]  = 0$ $\\mu$-a.e.. \n\nAgain, due to the fact that $\\lambda(t_1, t_2) > 0$ $\\mu$-a.e., $S(P_{\\pi_{t_1, t_2} (Y)}, P_{\\pi_{t_1, t_2} (Y)}) - S(P_{\\pi_{t_1, t_2} (X)}, P_{\\pi_{t_1, t_2} (Y)}) = 0$ $\\mu$-a.e.. \n\nI think two important points here are the equivalence of between $\\mu$ and $\\nu$ and that $s$ is a strictly proper scoring rule.\n\n2. I'm checking where we need $\\mathcal{E}$ to be Polish. The disintegration theorem we used (Theorem 8.5 of Kallenberg (2021)) only requires the value space to be Borel. We'd sincerely appreciate it you can help us to point it out.\n\n3. For the other minor issues, we can fix them in the upcoming revision.\n\nWe thank you again for the insights and please let us know if you feel there is anything unclear; we're more than happy to clarify!"
            }
        },
        {
            "comment": {
                "value": "Hi,\n\nWe deeply appreciate the detailed reviews and are happy to address the concerns.\n\n*1. In Theorem 2, does the result hold for any scoring rule $s$, or does $s$ also need to be strictly proper?*  \nYes. $s$ has to be strictly proper. This is stated in the first paragraph of section 4.1: \"*Let $s$ be any strictly proper scoring rule defined on ...*\". We agree this is probably not sufficiently clear and will move this condition to the theorem statement in the forthcoming revision.\n\n*2. The complexity reduction claim*  \nWe apologize for this confusion. $D$ refers to the discretization step in the numerical integration of the SDE, i.e., for the SDE\n$$\ndZ_t = \\mu^{\\theta}(t, Z_t)  dt + \\sigma^{\\theta}(t, Z_t)  dW_t,\n$$\nwe evaluate the integral\n$$\nZ_T = Z_0 + \\int_{0}^{T} \\mu^{\\theta}(t, Z_t)  dt + \\int_{0}^{T} \\sigma^{\\theta}(t, Z_t)  dW_t\n$$\nby numerical integration with $D$ discretization steps using the Euler-Maruyama method:\n$$\nZ_{t_{k+1}} = Z_{t_k} + \\mu^{\\theta}(t_k, Z_{t_k}) \\Delta t + \\sigma^{\\theta}(t_k, Z_{t_k}) \\Delta W_k\n$$\nwhere $\\Delta t = T/D$, $t_{k+1}=t_k + \\Delta t$, and $\\Delta W_k$ is the Wiener increment over the interval $[t_k, t_{k+1}]$.\n\n$B$ in Algorithm 1 refers to the batch size of the SGD optimizer and is different from $D$. \n\nThe $O(D^2)$ complexity comes from the previous state-of-the-art Neural SDE training method proposed in [Issa et al., 2023](https://arxiv.org/pdf/2305.16274), which requires solving a PDE\n$$\nf(s, t) = 1 + \\int_{0}^{s} \\int_{0}^{t} f(u, v) \\langle dx_u, dy_v \\rangle_1  dv du\n$$\n(see (2) in the linked paper) and backpropagate the gradients through the PDE solver. The double integral is typically numerically approximated using a rectangular rule with $D$ discretization steps:\n$$\n\\int_{0}^{T} \\int_{0}^{T} f(u, v) \\langle dx_u, dy_v \\rangle_1 dv du \\approx \\sum_{i=1}^{D} \\sum_{j=1}^{D} f(u_i, v_j) \\langle dx_{u_i}, dy_{v_j} \\rangle \\Delta u \\Delta v,\n$$\nwhere $\\Delta u = T/D$, $\\Delta v = T/D$, and $u_i = i \\Delta u$, $v_j = j \\Delta v$ for $i, j = 1, \\dots, D$. The double sum requires $O(D^2)$. Also, the method of [Issa et al., 2023](https://arxiv.org/pdf/2305.16274) does not have a better complexity on $B$ as their objective also involves a double sum over $B$ (see (4) in the linked paper, our $B$ is their $m$, the double integral occurs in their $k_{sig}$). \n\nSo overall, our method reduces the complexity from $O(D^2)$ to $O(D)$ (or, from $O(D^2 B^2)$ to $O(D B^2)$ if you prefer to also include $B$ ) as we don't need to solve the PDE with the double integral. \n\n*3. Not sufficient preliminary material on scoring rules or background on how these rules are used to measure divergence between two Markov processes.*  \nThank you for pointing out the lack of clarity. We're happy to add more explanation to the background of scoring rules in the forthcoming revision. We'll move the RBF kernel example earlier.\n\nWe thank you again for the insights and please let us know if you feel there is anything unclear; we're more than happy to clarify!"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new method called Finite Dimensional Matching (FDM) for training Neural SDEs by identifying a class of strictly proper scoring rules for comparing continuous Markov processes. Using this scoring rule, they claim to reduce the training complexity from quadratic in discretization timesteps to linear."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper addresses an important problem: the high computational complexity (quadratic in time steps) associated with training Neural SDEs using scoring rules. The authors propose a reduced complexity method, aiming for linear complexity to enhance performance. They also provide a theoretically grounded approach in designing a new scoring rule. However, despite this strong motivation, the results are somewhat unconvincing due to certain weaknesses noted below."
            },
            "weaknesses": {
                "value": "This paper has several notable weaknesses. While the authors propose a reduced complexity approach for training Neural SDEs, they do not adequately explain key concepts, making the paper difficult to follow, especially for readers without a strong background in this area. For example, despite experience with SDEs in score-based generative models and deep learning theory, I found the explanations lacking in detail and context and some results are not convincing.\n\nThe authors do not provide sufficient preliminary material on scoring rules or background on how these rules are used to measure divergence between two Markov processes. A concrete example of the scoring rule $s(P, z)$ with an RBF kernel, presented early on, would have improved clarity.\n\nAdditionally, the complexity reduction claim is unconvincing. For example, at the beginning, the authors claim they reduce the complexity to linear using $D$ to denote the time steps, however, this notation $D$ is never used again in the rest of the paper. Instead, in Section 4.2 Algorithm, they compare two stochastic processes and use $B$ to denote the total number of time steps. However, the nested summations in the top equation on page 5 suggest quadratic rather than linear complexity, i.e., $B^2$.\n\nFinally, the paper uses the **ICLR 2024 format rather than the ICLR 2025** format."
            },
            "questions": {
                "value": "In Theorem 2, does the result hold for any scoring rule $s$, or does $s$ also need to be strictly proper? Could you clarify if there are specific conditions on $s$ required for Theorem 2 to apply?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a very simple yet elegant way of comparing the similarity of the laws of two homogeneous Markov processes. The idea follows from the fact that the distribution of the process is completely determined by the transition kernel. Hence the ability to compare the transition distribution should give enable a comparison between the laws. \n\nThe authors then use this finding as a scoring rule to learn to simulate from a neural SDE, given the observations from a ground truth process. Then, they test their scoring rule and their FDD matching procedure in numerical experiments, showing that their method outperforms existing law matching techniques."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The method is very simple and elegant and the implication of this result, **if true**, could be impactful to the neural SDE and generative modeling community."
            },
            "weaknesses": {
                "value": "I think there is a significant issue in the proof that could invalidate your main theorem 2. In the middle part of page 14, you have the integral over $t_1,t_2$ of the $S(P_{t_1,t_2}, P_{t_1,t_2}')$ scoring rules being equal, but then you conclude that $$S(P_{t_1,t_2},P_{t_1,t_2}') = S(P_{t_1,t_2},P_{t_1,t_2})$$ a.e.. This is not true or I am missing something? \n\nMy intuition is that this is not an easy fix: You want to match the distribution over all $t_1,t_2$, so, in some sense, you want the expectation equality to hold for all test measures $\\nu$ instead of just one particular $\\nu$. I would be very happy to raise the score and rewrite my review if I am wrong. However, it does seem that proving a result like yours is possible, given that the generator or the resolvent will determine the law of the Markov process (see Either and Kurtz). \n\nI appreciate the rigor in defining the math notations and results. But the writing and explanations in the paper need improvements. For example, what do you mean by \"Update the model parameters $\\theta$ through backpropogation to maximize $\\hat S$\" (inside the algorithm)? Also, there is no explanation of what the data is. What are the \"Average KS test scores\"? Are you repeating the experiment across multiple batches and producing the percentage of rejection \"chance of rejecting the null hypothesis (%) at 5%-significance level on marginal\"? \n\nOther minor issues include: \n1. I think you need $\\mathcal{E}$ to be Polish. \n2. The radial basis function (RBF) kernel is not defined. \n3. The $\\pi$ notation seems a little distracting, why not just use $(x_t,x_s)$ for $\\pi_{t,s}(x)$. \n4. It would be nice to emphasize that the Markov processes you define are homogeneous Markov processes."
            },
            "questions": {
                "value": "The main concern I had was in regard to the proof. Please help me to understand or fix the issue. \n\nIf this and the writing issues I raised above can be addressed, I will happily give you at least a 6. However, since I feel that your main result is wrong, I have to give a low score for now.\n\nIf this (or a variant of the) scoring rule for Markov processes is indeed correct, I think the authors could improve the paper by exploring the sensitivity properties of this scoring rule; for example, what kernel to use and how the score behaves when P and Q are close? Is there a simple formula to compute the gradient?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a scoring rule for continuous time stochastic processes that is directly derived from a scoring rule on a generic space. They show that this rule is proper (i.e. injective from the space of paths to the space of laws), which is a non-trivial contribution. Experiments show that this method outperforms existing concurrent methods based on signature kernels and SDE-GANs. I stress that the experiments are carried out on a vast array of datasets."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The paper is well written and structured, making it easy to read and to follow. The introduction is sound and features a thorough literature review.\n \n* The main technical contribution is Theorem 2, which allows to convert any scoring rule on a generic space. I believe this contribution to be non trivial and novel, although simple to prove.  \n\n* The experiments are carried out on a vast array of time series datasets and show overall superior performance of the proposed approach. The authors compare themselves to all relevant baselines to the best of my knowledge. Large generative models such as diffusion models are not included ; however, I do believe that they do not belong to the same class of models and do not require a comparable computational budget."
            },
            "weaknesses": {
                "value": "* While the contribution made in Theorem 2 is elegant and novel, one could object that it is slightly insufficient --- this is not my point of view, but another reviewer might disagree and I am willing to discuss this point. In order to strengthen their theoretical part, I encourage the authors to consider for instance the sample complexity of their kernel i.e. how fast does the empirical divergence they define through a kernel on $\\mathcal{E}$ converge through the expected divergence ? Do sample complexities in $\\mathcal{E}$ carry over to the space of paths ? See Gretton (2012) for an example. \n\n* A blind spot of the paper is in my opinion the choice of the kernel. The authors do not seem to consider other kernels for $\\mathbb{R}^d$ valued processes, which could yield an interesting extension. This might especially be interesting since some kernels are sometimes used because of their specific properties (invariances, ...). I would suggest that the authors consider this point, at least in the Appendix. \n\n* This approach nicely extends to kernels defined on any space - this could be graphs, images, etc. and could allow to generate time series in these spaces. This would provide, in my sens, a extremely valuable extension to the paper. \n\n* The experimental section is hard to read and a tad unstructured. I encourage the authors to use less tables, add more comments and broaden the analysis of their experiments. Also, a notable restriction of this part is that experiments are only carried out on $2$ dimensional time series. I strongly encourage the authors to extend their experiments to high dimensional datasets. Also, there are no confidence intervals in the tables. \n\n* Regarding this last point, I believe that a valuable extension could be to consider random feature approximations to the kernels for high dimensional generation, which is still a major hurdle in the field. Similarly, the authors could consider sliced kernels on $\\mathcal{E}$ when the dimension is high.  \n\n* Concerning experiments, an interesting task to consider could be the augmentation of a time-series dataset, and the analysis of the gain in performance for any model trained on this dataset. \n\n* Concerning experiments, I believe that it would be highly valuable to extend applications beyond finance. Generating time series is a major hurdle in many domains with great social impact such as neuroscience, healthcare, biology, climatology, economics ... \n\n* A valuable extension of this work would be the investigate the use of the devised score for other purposes than training generative models, such as two-sample tests for instance."
            },
            "questions": {
                "value": "* Please include confidence intervals in your tables: variability of your results is a very important aspect.\n\n* Could you please include vizualizations of the full generated time series, rather than only plotting the time marginals ?\n\n* Could you add experiments on at least one high dimensional and one non euclidian real-world dataset ?\n\nI would considered increasing my score if a significant number of concerns on the experiments are addressed. Similarly, I could consider lowering my score during the discussion phase if other reviewers relativise the strength of the theoretical contribution --- which again seems sufficient to me."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel approach to training neural stochastic differential equations by introducing Finite Dimensional Matching, a new scoring rule designed for continuous Markov processes. The proposed method leverages the Markov property of stochastic processes to reduce the computational complexity of training neural SDEs, with the goal of enhancing both efficiency and generative quality. Theoretical contributions establish that the new scoring rule provides a strictly proper method for comparing two-time joint distributions. Experimental results demonstrate improved performance in training efficiency and generative quality when evaluated against competing methods."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper tackles a crucial challenge in training neural SDEs by introducing a new scoring rule that optimizes efficiency for continuous Markov processes. The proposed FDM method is backed by mathematical proofs, providing a strictly proper scoring rule that extends from finite-dimensional distributions to continuous Markov processes. This theoretical contribution is valuable to the literature on neural SDE training methods. Experiments show that FDM offers computational efficiency gains, reducing training complexity from quadratic to linear in the number of discretization steps. The approach outperforms prior methods in computational efficiency, as shown in multiple experimental benchmarks."
            },
            "weaknesses": {
                "value": "The paper\u2019s main theorem relies on strong assumptions regarding the Markovian properties and continuity of the processes involved. These assumptions may limit the applicability of the FDM algorithm in more complex, non-Markovian stochastic processes or those with jumps, which are common in real-world scenarios. Explicitly discussing these limitations and potential ways to relax these assumptions would make the contributions more transparent.\n\nAlso, the writing template is for ICLR 2024, not ICLR 2025."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}