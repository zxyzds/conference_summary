{
    "id": "ffuHn3Q6Hc",
    "title": "Reinitializing weights vs hidden units for maintaining plasticity in neural networks",
    "abstract": "Loss of plasticity is a phenomenon where a neural network loses its ability to learn when trained for an extended time on non-stationary data.\nIt is a crucial problem to overcome when designing systems that learn continually.\nAn effective technique for preventing loss of plasticity is reinitializing parts of the network.\nIn this paper, we compare two different reinitialization schemes: reinitializing units vs reinitializing weights.\nWe propose a new algorithm named \\textit{selective weight reinitialization} for reinitializing the least useful weights in the network. \nWe compare our algorithm to continual backpropagation, a previously proposed algorithm that reinitializes units.\nThrough our experiments in continual supervised learning problems, we identify two settings when reinitializing weights is more effective at maintaining plasticity than reinitializing units: (1) when the network has a small number of units and (2) when the network includes layer normalization.\nConversely, reinitializing weights and units are equally effective at maintaining plasticity when the network is of sufficient size and does not include layer normalization. \nWe found that reinitializing weights maintains plasticity in a wider variety of settings than reinitializing units.",
    "keywords": [
        "Continual Learning",
        "Supervised Learning",
        "Deep Learning",
        "Loss of Plasticity"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "We compare reinitializing hidden units vs reinitializing weights in neural networks for maintaining plasticity in continual supervised learning; reinitializing weights was more effective in a wider variety of the settings that we tested.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ffuHn3Q6Hc",
    "pdf_link": "https://openreview.net/pdf?id=ffuHn3Q6Hc",
    "comments": [
        {
            "summary": {
                "value": "The paper considers continual learning of neural networks (NNs), and in this context proposes a simple method for maintaining plasticity, i.e., the ability to learn as the problem changes dynamically: *selective weight reinitialization (SWR)*. SWR is proposed to the known method of selective node reinitialization (continual backpropagation). SWR compares favorably, especially on small NNs and modern architectures that employ layer normalization (e.g., transformer). The proposed method is very simple, and has implications for transfer learning as well as continual learning."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "**Originality:** The paper proposes a simple, yet underexplored idea of reinitializing weights (instead of entire neurons) for the purpose of maintaining NN plasticity. The proposed approach is elegant, and much simpler to implement (and thus arguably more efficient) that the state-of-the-art competitor: continual backpropogation. The authors study different ways in which the weights can be reinitialized, and also consider architectures with and without layer normalization. While the proposed approach does not come first in all the experiments conducted, interesting and original observations are made, e.g., the inferior performance of continual backpropagation in the presence of layer normalization.  \n\n**Quality and Clarity:** The paper is very clear, and the methodology is clearly outlined, as well as detailed in the appendices. The proposed method is very simple and straightforward to understand. The paper does not make any ambiguous statements. The paper is practically void of typos and grammatical mistakes.\n\n**Significance:** I believe the implications of the paper are significant, given that (1) transformers are dominating the landscape of modern NN research, (2) continual learning ideas and techniques may be directly transferable to transfer learning, which is widely adopted."
            },
            "weaknesses": {
                "value": "The authors state that for the transformer architecture, only the feed-forward weights were reinitialized. However, applying the method across all weights, including the attention weights, should be relatively trivial. I feel that \"freezing\" the attention weights is an unnecessary simplification. I also wonder if the results will be significantly different if attention weights were allowed to reinitialize."
            },
            "questions": {
                "value": "Page 3, line 142: \"We focus our study... to the continual...\" -> We focus our study... **on** the continual...\n\nThe paper only considers image classification tasks (MNIST, CIFAR datasets). It would have been interesting to see the effectiveness of the method on other data modalities. If not feasible, then perhaps you should clearly outline in the introduction that the paper is focused on computer vision classification tasks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposed a combination of utility functions and weights reinitialization scheme to maintain\nthe network's ability to learn continuous stream of data and tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Maintaining plasticity has recently been brought to the attention of the community. Overcoming this problem is key to building an adaptive model in the real world.\n\nIt does offer improved performance in some settings when compared with the popular baseline."
            },
            "weaknesses": {
                "value": "Selecting unused units and reinitializing them has been the baseline method for handling the loss of plasticity problem [1].\n\nThe proposed method is a variation of the method in [1] with different utility functions. Instead of reinitializing the unit, individual weights are evaluated and reinitialized.\n\nSimilar methods have been proposed in the dynamic sparse training literature.\n\nThe finding is purely empirical."
            },
            "questions": {
                "value": "In most of the tasks and settings, simply using l2 regularization has the best performance. Is more justification needed for the effectiveness of the proposed method?\n\nIn [1], the Continuous backpropagation is used with l2 regularization and the combination does offer better performance. In this work, the proposed method is not compared with this combination. What is the performance of the proposed method when compared with this combination?\n\nThis work only evaluates the proposed method for supervised learning. Other literature also evaluates their method for reinforcement learning. Compared to supervised learning, reinforcement learning is a more relevant problem as it would be very useful for a deployed agent to keep learning and adapt to new tasks. Is there a reason not to include reinforcement learning as an experiment?\n\nReferences:\n\n[1] S. Dohare, J. F. Hernandez-Garcia, Q. Lan, P. Rahman, A. R. Mahmood, and R. S. Sutton, \u201cLoss\nof plasticity in deep continual learning,\u201d Nature, vol. 632, no. 8026, pp. 768\u2013774, 2024."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work presents a novel method for re-initializing weights of a neural network during continual learning tasks in order to maintain network plasticity. In particular, a multi-stage process is described in which the utility (importance) of network weights is measured, and the lowest utility weights replaced with re-initialized weights at specific ratios and in particular intervals. Utility is measured in two ways, both based upon existing proposals for measurement of parameter importance in network pruning literature. The re-initialization of weights is also achieved in two different manners, one by a random value (based upon the initial parameter initialization process) or based upon a constant value (the mean of the initial layer weights). Performance of this method, as well as a few baselines, is shown to be highly dependent upon network size as well as whether layer normalization is present in the network architecture. It is concluded that weight reinitialization can work well (in particular cases) for plasticity maintenance in neural networks applied to continual learning tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The paper provides a clear overview of the existing literature on network re-initialization as well as the problem at hand. It is also well written in general.\n- The method description is well structured and the method appears to combine existing approaches in a novel and simple to implement manner.\n- Extensive appendices provide details on the network constructions and architectures, as well as other factors in the success of compared methods.\n- The test cases shown appear comprehensive and the method is applied to a range of network scale"
            },
            "weaknesses": {
                "value": "- The depth of the theoretical contribution of this work is limited, especially given that the utility measuring methods are a part of existing literature and the reinitialization methods at a different scale have already been proposed. Therefore the degree of novel contribution is limited.\n- Most importantly, it is unclear how to interpret the results given that the proposed method is only capable of outperforming alternative methods in a single demonstrated case. Otherwise existing methods appear to be generally more performant (especially the L2 and CBP methods).\n- The take-away sections at each section of results are a good way to focus the reader\u2019s attention, however they do not provide insights of the level that one might desire. For example, it is clear that layer normalization has a major impact upon the performance of continual learning methods. However, the reason as to why this is the case is never fully explored. More focus upon how the results can impact a reader's understanding of network re-initialization would be appreciated..\n- The paper compares reinitialization of weights vs reinitialization of nodes but could be clearer about the fact that CBP is in fact a method of reinitialization of nodes - this point is lost within the text."
            },
            "questions": {
                "value": "The weaknesses section, above, contains a number of concerns to be resolved. Here a few additional questions are posed.\n- How would you place your method amongst those in the existing literature? It is clear that there is no claim to state of the art, but what is the message for the broader community of researcher about the relative placement of such a work?\n- Are there any methods outside of re-initialization (or the L2 method) which might be appropriate as a baseline? I\u2019m thinking more of methods more of the style of elastic weight consolidation (EWC).\n- Why does reinitialization work differently for networks with layer normalization? What property of layer normalization brings about the effects you observe?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}