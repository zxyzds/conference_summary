{
    "id": "OQqNieeivq",
    "title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models",
    "abstract": "The increasing sizes of large language models (LLMs) result in significant computational overhead and memory usage when adapting these models to specific tasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have been devised to mitigate these challenges by training a small set of parameters for the task-specific updates of the model weights. Among PEFT methods, LoRA stands out for its simplicity and efficiency, inspiring the development of a series of variants. However, LoRA and its successors disregard the knowledge that is noisy or irrelevant to the targeted task, detrimentally impacting model performance and leading to suboptimality. To address this limitation, we introduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that leverages singular value decomposition (SVD) with knowledge-aware singular values to dynamically activate knowledge based on its relevance to the task at hand. We conduct extensive experiments across a range of LLMs on tasks spanning natural language understanding (NLU), generation (NLG), and instruction following. The experimental results demonstrate that KaSA consistently outperforms FFT and other popular PEFT baselines across 7 benchmarks and 4 synthetic datasets, underscoring our method's efficacy and adaptability.",
    "keywords": [
        "Large Language Models",
        "Parameter-efficient Fine-tuning",
        "Singular Value Decomposition"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=OQqNieeivq",
    "pdf_link": "https://openreview.net/pdf?id=OQqNieeivq",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a novel parameter-efficient learning algorithm for LLMs. It addresses two issues of the prior research: i) a subset of model updates are associated with the noise encoded in the base model; and ii) the low-rank matrices A and B are initialized using the knowledge from the base model that is not relevant to the downstream tasks. The new method tackles the two issues with four components: knowledgebased SVD truncation, knowledge-aware singular value adaptation, singular value regularization L2, and orthogonal regularization. The ablation studies show that all four of them are effective for the selected evaluation tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The evaluated tasks are comprehensive, including NLU, NLG and instruction-following.\n* The ablation study provides evidence to demonstrate the effectiveness of all four design choices on selected NLP tasks."
            },
            "weaknesses": {
                "value": "* The improvement of the proposed method over the baselines is marginal. The variances and the results of the significance tests may help justify the improvement.\n* It is unclear why GPT-2 is used for NLG tasks, while Gemma, Mistral and LlaMA3 are used for instruction following tasks. Hence, the experimental design is not systematic."
            },
            "questions": {
                "value": "It would be great to justify why only MRPC, CoLA and RTE are chosen for the ablation studies."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This study proposes a new technique for low-rank finetuning and inference. \u201cKaSA\u201d reparameterizes finetuned weights in two steps: task-specific SVD truncation, and \u201cknowledge-aware singular- value adaptation\u201d that selects particular singular values based on their relevance to particular tasks.\n\nThis study shows that KaSA is competitive with popular low rank approaches such as LoRA across multiple models and tasks. In particular, they report extensive results for RoBERTa evaluated on the GLUE tasks, GPT2 evaluated on the E2E NLG challenge, and three 7-8B LLMs evaluated on four custom synthetic instruction following datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "KaSA seems like a promising technique, and is competitive with LoRA and SVD style techniques like PiSSA and MiLoRA. The authors do extensive experiments and benchmarking, and the paper is very well written.\n\nMinor notes:\n* The paper has extensive citations that are very helpful to the reader\n* Figure 2 with \u201cablations\u201d is very informative - the trends are quite clear\n* The \u201cno robots\u201d dataset is a good choice for seeding synthetic data, since it was generated by human annotators."
            },
            "weaknesses": {
                "value": "The experimental results are overall quite strong. The main weakness of the manuscript is that it lacks a straightforward explanation of the method. I\u2019m not sure I fully understand the KaSA method here based on the description, and the diagram is slightly confusing as well. It would be very helpful to have a pseudocode block/section.\n\n1. My current understanding is that the method requires (1) LoRA finetuning followed by (2) SVD truncation followed by (3) \u201cknowledge aware singular-value adaptation.\u201d Is this correct? If so, doesn\u2019t this mean that it will require more training/compute than vanilla LoRA? Can you do a direct comparison of training compute/FLOPs for LoRA vs. KaSA?\n\n2. \u201cKaSA employs a small set of parameters \u03a8 to reparameterize the task-specific update \u25b3\u0398\u201d is the task specific update full finetuning or LoRA? I assume the task specific update is vanilla LoRA.\n\n3. How do you calculate $W_{fft}$ for $\\mathcal{L}_2$? Do you have to do full finetuning? I assume not\u2026\n\nThere are a few smaller details that I think are worth mentioning:\n\n1. What is the rank for instruction following? I don\u2019t see it in the manuscript\n\n2. It feels like important baselines are missing from Table 4 - how well do the models do out of the box? Since these datasets are created specifically for this study, it is hard to get a sense of task difficulty or to compare to other papers\n\n3. The authors claim no extra inference latency due to the technique. It would be helpful to show these numbers. If I understand correctly, however, there will be extra _training_ latency. Can you expand on this in the paper? \n\n4. The most similar methods to KaSA are PiSSA and MiLoRA. In Table 4 it could be helpful to do a comparison with PiSSA and/or MiLoRA"
            },
            "questions": {
                "value": "1. What exactly is the reader supposed to take away from the visualizations in Figure 4? It seems somewhat unclear. It might be helpful to have a comparison with and without KaSA\n\n2. Why scale between 0 and 100 when using GPT4o as a judge? It seems a bit arbitrary/unnecessary. Do you have strong motivation for using this scaling?\n\nSome small nits:\n* Typo: line 043 \u201cgets popular\u201d\n* Typo: line 426 \u201cfour synthetic datasets using GPT-4\u201d; is it GPT-4 or GPT4o?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces KaSA (Knowledge-aware Singular-value Adaptation), a parameter-efficient fine-tuning (PEFT) method that adapts large language models (LLMs) using knowledge-aware singular values derived from singular value decomposition (SVD). KaSA aims to selectively activate task-relevant knowledge, discarding irrelevant or noisy information to improve model performance on specific tasks. The method consists of knowledge-based SVD truncation to filter noise and knowledge-aware singular value adaptation to dynamically manage task-specific knowledge activation. Experiments across natural language understanding, generation, and instruction-following tasks demonstrate that KaSA consistently outperforms other PEFT approaches, including LoRA and its variants."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "KaSA combines SVD truncation with a knowledge-aware adaptation process, enabling it to achieve impressive performance on various NLP tasks. KaSA often outperforms other PEFT methods on benchmarks, showing its effectiveness in balancing performance and efficiency. The experiments are thorough, covering natural language understanding, generation, and instruction-following.\nThe ablation studies break down how each component (like the knowledge-aware adaptation) contributes to the overall performance, giving readers a clearer picture of why KaSA works so well."
            },
            "weaknesses": {
                "value": "The method adds some complexity, especially with the dynamic singular value adaptation, which might make it harder to implement compared to simpler PEFT methods. A potential limitation is the risk that SVD truncation might discard useful knowledge, especially if it\u2019s not fully adapted to a task. It would also help to see this method applied to a wider range of LLM architectures to confirm its generalizability. While KaSA does well on the tested models, applying it to newer transformer architectures or other types of large models could demonstrate its versatility even more."
            },
            "questions": {
                "value": "The SVD truncation stage may discard knowledge components deemed noisy or irrelevant. However, there\u2019s a risk that some truncated components might contain task-relevant information. Did you experiment with different truncation thresholds, or analyze the potential trade-offs of truncation in various tasks? A discussion here would enhance understanding of KaSA\u2019s robustness.\n\nThe SVD rank and regularization coefficients play an important role in KaSA\u2019s performance. Could you provide practical guidelines or a sensitivity analysis to help practitioners choose these values for new tasks or datasets? This could make the method more accessible to those less familiar with PEFT or SVD."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel PEFT method called KaSA. The main idea is to leverage singularvalue decomposition with knowledge-aware singular values to dynamically activate knowledge based on its relevance to the task at hand. Experiments on NLU, NLG and instruction tuning tasks demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is well written and easy to follow. \n- The performance is good."
            },
            "weaknesses": {
                "value": "- The proposed method has a more complex training objective compared to baselines like LoRA, PiSSA, and MiLoRA. Consequently, the training time for KaSA may be longer than that of the baselines. However, the paper does not provide detailed information on this.\n- The training objective introduces new hyperparameters, including \\beta and \\gamma, but there is no analysis regarding their impact.\n- How does KaSA perform at different ranks? Can it consistently exceed the baselines across various ranks? This aspect also needs to be validated.\n- Some important baselines are missing, like [1]\n\n[1] CorDA: Context-Oriented Decomposition Adaptation of Large Language Models for Task-Aware Parameter-Efficient Fine-tuning"
            },
            "questions": {
                "value": "- The PEFT methods are sensitive to hyperparameters like the learning rate. How does the paper ensure a fair comparison with the baseline models? For instance, in Section 4.2, a hyperparameter search is conducted for KaSA for each dataset. Is a similar hyperparameter search performed for all the baseline methods? For Section 4.3 and 4.4, do KaSA and baselines share the same hyperparameters?\n- The setup for the instruction-following experiments is questionable. Given the availability of numerous instruction tuning datasets, why not conduct experiments using these existing datasets? Since other researchers may not have access to the synthetic dataset, reproducing the results could be challenging."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents Knowledge-aware Singular-Value Adaptation (KaSA), an innovative PEFT method aimed at overcoming the computational and memory challenges of adapting LLMs to specific tasks. KaSA employs singular value decomposition with knowledge-aware singular values to dynamically activate relevant parametric knowledge for downstream tasks. Through extensive experiments, the authors show that KaSA consistently outperforms full fine-tuning and other popular PEFT methods across a range of tasks, including NLU, NLG, and instruction following."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The method is novel, integrating SVD with knowledge-aware singular values. This method allows for the dynamic activation of relevant knowledge, which is a significant advancement over existing PEFT techniques.\n2. Extensive experiments (various tasks with different LLMs, a wide range of baselines) consistently validate the efficacy and adaptability of the proposed method.\n3. The paper is well written with good clarity."
            },
            "weaknesses": {
                "value": "My main concern -- most experiments, except experiments in Table 4 on instruction following, only use a small model (less than 1B). Need more experiments and fair comparison with the baselines on larger models. And the improvements on instruction following evaluation results are not significant, and there are even drops in performance on LLaMA3 8B."
            },
            "questions": {
                "value": "How well does KaSA scale to even larger models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}