{
    "id": "cwbJxUGVOI",
    "title": "OCN: Learning Object-centric Representations for Unsupervised Multi-object Segmentation",
    "abstract": "We study the challenging problem of unsupervised multi-object segmentation on single images. By relying on an image reconstruction objective to learn objectness or leveraging pretrained image features to group similar pixels as objects, most existing methods can either segment simple synthetic objects or discover a rather limited number of real-world objects. In this paper, we introduce OCN, a new two stage pipeline to discover many complex objects on real-world images. The key to our approach is to explicitly learn our carefully defined three level object-centric representations in the first stage. After that, our multi-object reasoning module directly leverages the learned object priors to discover multiple objects in the second stage. Notably, such a reasoning module is completely network-free and does not need any human labels to train. Extensive experiments show that our OCN clearly surpasses all existing unsupervised methods by a large margin on 6 real-world benchmark datasets including the particularly challenging COCO dataset, achieving the state-of-the-art object segmentation results. Most notably, our method demonstrates superior results on extremely crowded images where all baselines collapse.",
    "keywords": [
        "unsupervised learning",
        "object segmentation",
        "objectness representation"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We propose a two stage pipeline for unsupervised multi-object segmentation on single images by learning and reasoning with three level object-centric representations.",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=cwbJxUGVOI",
    "pdf_link": "https://openreview.net/pdf?id=cwbJxUGVOI",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a two-stage pipeline consisting of an object-centric representation learning stage followed by a multi-object reasoning stage for unsupervised multi-object segmentation. The proposed three levels of objectness: 1) a binary object existence score, 2) an object center field, and 3) an object boundary distance field are used to learn object-centric representations. Given experiments show that the suggested method achieves state-of-the-art object segmentation performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper is well-presented and provides sufficient detail, making it easy to follow.\n\nThe task of unsupervised multi-object segmentation that the authors have investigated is both interesting and challenging. \n\nCompared to the competing methods, the proposed approach demonstrates a significant performance improvement."
            },
            "weaknesses": {
                "value": "Could the authors provide more details on how the rough masks are generated from ImageNet without using human annotations? Specifically, what method is used to distinguish foreground from background, and how is this process unsupervised?\n\nHave the authors considered how their method might be adapted for use in domains like medical or sonar imaging, where the nature of objects and backgrounds differs significantly from natural images? What modifications might be necessary to make the approach more generalizable across diverse image types?"
            },
            "questions": {
                "value": "How are the rough masks obtained, and does the process require supervised training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses unsupervised multi-object segmentation by learning an object-centric representation. The proposed method is composed of two stages. In the first stage, an object-centric representation of three levels is derived, encompassing object existence, center, and boundary levels. This representation is class-agnostic, enabling the segmentation of objects from unseen classes. In the subsequent stage, a multi-object reasoning module, built upon the derived representation, identifies object instances. The proposed method is evaluated on multiple datasets in different settings and achieves promising results."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper, in general, is well-written and easy to follow.\n\n2. The proposed method is simple and reasonably designed.\n\n3. Recognizing the limitations of the COCO validation set, the authors annotated object instances that were not originally labeled, significantly enhancing its value for unsupervised object discovery.\n\n4. The proposed method demonstrates superior performance across various datasets and experimental settings. Additionally, ablation studies confirm the effectiveness of each component in the three-level, object-centric representation."
            },
            "weaknesses": {
                "value": "1. My primary concern regarding this paper is the limited novelty and technical contributions. The proposed method consists of two main components: a) an objectness network for extracting a three-level, object-centric representation and b) a multi-object reasoning module for unsupervised object discovery.\n\na. The three-level representation, encompassing object existence, center, and boundary information, has been widely explored in the literature. For example, techniques like the Hough transform and Chamfer distance have been extensively used to capture similar representations, where object centers and boundaries are encoded. Using these inherently class-agnostic representations for unsupervised object segmentation is a relatively straightforward extension, limiting the degree of novelty.\n\nb. The multi-object reasoning module, composed of four sequential steps, is designed in a heuristic way. Each step processes the features from individual representation levels, potentially hindering the model's ability to fully exploit the interdependencies between these levels.\n\n2. In general, this paper is clearly written. However, to further enhance its clarity and impact, the following suggestions may be considered:\n\na. It may be better if Figures 3, 4, and 5 can be integrated into Figure 1. The three-level presentation is repeated several times on pages 1 and 2 with a reference to Figure 1. However, readers may clearly realize what the three-level representation is after seeing the example in Figures 3, 4, and 5 on pages 3 and 4. \n\nb. In Section 2, it would be better to discuss why the proposed method is superior to existing methods, especially those learning object-centric representations with pre-trained features, since the proposed method uses pre-trained features, too.\n\nc. A deeper analysis of the experimental results is necessary. While the paper emphasizes the improved performance of the proposed method, a more in-depth exploration of the underlying reasons for this superiority would strengthen the overall argument.\n\nd. The indexing of the four steps in the reasoning module should be consistent throughout the paper, either using #0 to #3 on page 5 or #1 to #4 on page 6.\n\n3. The sensitivity analysis presented in Table 10 of the supplementary materials is limited in scope. The narrow value ranges of hyperparameter values and the lack of evaluation on multiple datasets hinder a comprehensive assessment of the method's sensitivity to hyperparameter variations across different datasets."
            },
            "questions": {
                "value": "1. The authors might address my comments given in Weaknesses.\n\n2. Please check the correctness of the statement in Lines 255 ~ 258. Consider a proposal where two objects separated by a distance greater than five pixels are present. Can this proposal be correctly excluded by using the designed kernel in Figure 6? \n\n3. Why are different competing methods adopted in different experiments, namely those in Tables 1 ~ 4?\n\n4. As the images in the COCO* dataset are newly annotated by the authors, did the authors tune the hyperparameters of the competing methods to report the performance of these methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the challenging problem: unsupervised multi-object segmentation. Previous methods based on slot-attention usually fell short on complex scenarios such as COCO, while self-supervised feature distillation methods usually fail to discover multi-objects. This paper proposes a two-stage framework, including object-centric representation learning and multi-object reasoning. For the first stage, the authors first explicitly identify the object existence score, the object center field, and the object boundary distance field, as the representation, and then train an objectiveness network to learn this type of representation on ImageNet. For the second stage, an iterative algorithm is applied. Experiments under various evaluation protocols demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The topic is challenging and worth studying.\n- This paper is well-written and easy to follow.\n- The figures have vividly illustrated the proposed method.\n- The proposed method is quite effective.\n- The defined explicit object-centric representation is reasonable."
            },
            "weaknesses": {
                "value": "I only have one concern: the latency. The proposed method needs to iteratively leverage the objectiveness network, which is not that efficient. Could you compare the evaluation cost?"
            },
            "questions": {
                "value": "I have no further questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces an unsupervised object discovery framework for real-world images, called OCN (Object-Centric Representations via the Objectness Network), which operates without human annotations. To achieve this, this paper proposes Objectness Network, trained on ImageNet using masks generated by CuVLER [1], and it produces three outputs: i) an Object Existence Score, which determines if an object is present in the image; ii) an Object Center Field, which estimates pixel locations relative to the object center; and iii) an Object Boundary Field, which estimates pixel distance to the object\u2019s boundary. Then, it adopts a Multi-Object Reasoning Module, where bounding boxes are iteratively updated based on the Objectness Network\u2019s outputs. OCN achieves state-of-the-art performance on the object discovery task across several datasets, including COCO and COCO*, an extended version with additional object annotations.\n\n\n---\n[1] Shahaf Arica et al., CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers, CVPR 2024"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* This paper revisits the important concept of object discovery by decomposing objectness into three object-centric representations, followed by a network-free multi-object reasoning module.\n* The use of boundary distance gradients for extending and shrinking bounding boxes is particularly effective, as it is parameter-free and potentially faster.\n* The model successfully captures multiple objects of varying scales in the challenging COCO dataset.\n* The paper is well-written, easy to follow, and supported by clear explanatory figures."
            },
            "weaknesses": {
                "value": "* The model is more similar to MaskCut [1] supervised rather than unsupervised, as the objectness network is trained using masks from MaskCut. Therefore, the objectness network should be compared to CutLER [1] or CuVLER [2], but not to the pseudo-labeling mechanisms of them, ie MaskCut or VoteCut, as shown in Table 1. Since OCN includes an extra training step on ImageNet with pseudo-labels, whereas MaskCut and VoteCut do not involve training, this comparison is unfair. If we assume $g$ is the MaskCut operation and $I$ represents the data, Table 1 compares $g(I)$ to $f(g(I))$, where $f$ represents the OCN training.\n* Similarly, Table 3 incorporates an additional level of training, giving OCN an advantage. The OCN results in this case are $p(f(g(I)))$, while the others are only $p(g(I))$, where $p$ is the detector training.\n* The use of anchors and the existence network closely resembles the Region Proposal Network (RPN) in Faster R-CNN [3]. In this sense, the objectness network can be seen as a modified version of RPN (with additional outputs), which diminishes the novelty of the proposed network.\n* The Objectness Network, particularly the center field module, is trained on images with single objects. However, it is used to detect multiple objects in an image, which is not represented during training. Is this possible due to the random cropping augmentation? The authors should provide more insights into this.\n\n**Minor Comments**\n* In the appendix, it states \u201cMaskCut proposed in CuVLER,\u201d but MaskCut was actually proposed in CutLER [1].\n* The related work section on Object-Centric Learning with Pretrained Features is missing relevant references, such as SOLV [4] and VideoSAUR [5].\n* There is no step #4 mentioned in the text, though it is referred to in line 306.\n* Typos in Table 5: row 2 (\u201cexsitence\u201d) and row 6 (\u201cfiled\u201d).\n\n\n---\n[1] Xudong Wang et al., Cut and Learn for Unsupervised Object Detection and Instance Segmentation, CVPR 2023\n\n[2] Shahaf Arica et al., CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers, CVPR 2024\n\n[3] Shaoqing Ren et al., Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, arXiv\n\n[4] G\u00f6rkay Aydemir et al., Self-supervised object-centric learning for videos, NeurIPS 2023\n\n[5] Andrii Zadaianchuk et al., Object-Centric Learning for Real-World Videos by Predicting Temporal Feature Similarities, NeurIPS 2023"
            },
            "questions": {
                "value": "* Why didn\u2019t the authors utilize DINOv2 [1], which has been shown to exhibit greater object awareness, instead of DINO [2]?\n* On average, how many iterations does it take to form the final bounding box?\n---\n[1] Maxime Oquab et al., DINOv2: Learning Robust Visual Features without Supervision, arXiv\n\n[2] Mathilde Caron et al., Emerging Properties in Self-Supervised Vision Transformers, ICCV 2021"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}