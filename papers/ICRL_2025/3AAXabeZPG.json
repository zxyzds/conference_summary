{
    "id": "3AAXabeZPG",
    "title": "Debiased Medical Report Generation with High-Frequency Amplification",
    "abstract": "In recent years, automated medical report generation (MRG) has gained significant research value for its potential to reduce workload and prevent diagnostic errors. However, generating accurate radiology reports remains challenging due to the prevalence of normal regions in X-ray images and normal descriptions in medical reports. Despite various efforts to address these issues, the definitions of visual bias and textual bias remain unclear and there is still a lack of comprehensive analysis of how these biases affect model behavior. \nIn this work, we rigorously define and conduct an in-depth examination of visual and textual biases inherent in MRG dataset. Our analysis emphasizes that global patterns, such as normal regions and findings, contribute to visual and textual bias. Further, we discuss how these biases make MRG models especially prone to frequency bias, where models tend to prioritize low-frequency signals that capture global patterns, while neglecting high-frequency signals. To debiase the frequency bias, we propose the high-frequency amplification layer (HAL), aimed at enhancing the model's perceptiveness to fine-grained details. Our extensive experiments show that by amplifying high-frequency signals, HAL reduces both visual and textual biases, leading to improved performance in MRG tasks.",
    "keywords": [
        "Medical Report Generation",
        "Debiased Generation",
        "Visual Bias",
        "Textual Bias",
        "Frequency Bias",
        "Fourier Transform",
        "High-pass Filtering"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=3AAXabeZPG",
    "pdf_link": "https://openreview.net/pdf?id=3AAXabeZPG",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses the issue of low frequency (global) visual and textual biases in report generation caused by visual imbalance, textual imbalance, and skewed distribution of disease labels. The authors propose a novel approach called the High-Frequency Amplification Layer (HAL), which uses DFFT on the time axis and feature axis, followed by masking to perform high-pass filtering. This method emphasizes high-frequency components in the feature and may reduce biases. The paper includes experiments on the MIMIC-CXR and IV X-ray datasets to demonstrate improved performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper provides novel insights into visual and textual biases important for report generation and attempts to reduce them.\n- It offers a thorough examination of these biases and their impact on model performance.\n- The clear problem definition contributes to a more focused discussion in the MRG field."
            },
            "weaknesses": {
                "value": "- Some experimental settings are unclear; further explanation would improve clarity.\n- Although the implementation of the HAL layer (DFFT on the time and feature axes) is simple, this layer requires further comprehensive evaluation and ablation studies."
            },
            "questions": {
                "value": "1. The structure of the whole model of proposed approach is not clearly mentioned, like how many HAL layers were inserted. Providing a global view of the model pipeline will make it clearer and easier to follow. \n2. In line 422, HAL is placed after the cross-attention layer. If HAL is after this layer, how does it influence the already computed cross-attention?\n3. In line 201 and Figure 3a, \"classification accuracy improves as the number of diseases increases.\" How should this conclusion be interpreted, given that a higher number of diseases might exacerbate distribution imbalance?\n4. How is the hyperparameter alpha for the high-pass filter set to 8? From Figure 4, performance appears to still improve as alpha increases.\n5. How was the decision made to train for 39 epochs, while the generalization assessment plots the training/validation curve for 20 epochs?\n6. The baseline without the HAL layer is not reported, which could illustrate the influence of the HAL layer on the model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors conduct an examination of visual and textual biases in medical report generation (MRG) datasets. The analysis find that global patterns, such as normal regions and findings, contribute to visual and textual biases. These biases make MRG models prone to frequency bias, where global patterns are prioritized and local patterns (e.g. abnormal findings) are ignored. In order to mitigate this issue, the authors propose an architectural modification in the form of a high-frequency amplification layer (HAL), which aims to enhance a model\u2019s perceptiveness to fine-grained details. HAL reduces biases, leading to improved performance in MRG tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper introduces an approach for improving the quality of medical report generation, which is a high-impact problem with potential for positively impacting the field of medicine.\n2. The authors demonstrate that their proposed approach HAL leads to performance improvements over several existing methods in this domain."
            },
            "weaknesses": {
                "value": "1. **Inadequate evaluations for demonstrating the utility of HAL**: The key claim of this paper is that the proposed method HAL improves robustness of medical report generation models, which may struggle to learn fine-grained abnormal findings. However, this claim is not sufficiently evaluated in Section 7, and as a result, it is unclear if HAL is improving robustness to these biases. Only aggregate performance values are reported on the MIMIC-CXR and IU datasets.\n\n    a. Does HAL improve report generation performance (i.e. NLG and CE scores) when there is a single abnormality in the image? What about multiple abnormalities? Does HAL improve report generation performance when findings are small in size? Does HAL reduce performance on normal cases? All of these questions are critical for determining whether HAL mitigates biases as claimed, but none of these are evaluated. \n\n    b. Additionally, in order to demonstrate the usefulness of HAL, Tables 1 and 2 could benefit from an additional ablation using the exact same experimental setup but without the novel HAL layer. \n\n    c. In Tables 1 and 2, I recommend that the authors use more recently-developed (standard) report generation metrics for evaluating report quality with respect to factuality, such as RadGraph-F1 [1] or RadCliQ [2].\n\n2. **Inadequate evaluations for demonstrating the existence of visual and textual bias in report generation datasets:** The evaluations in Section 4.1 show that a classifier $f_{Z|X}$ trained on the images demonstrates lower performance when abnormalities occupy small regions. Similarly, a classifier $f_{Z|\\hat{Y}}$ trained on  generated reports demonstrates lower performance when there are more normal samples in the training data. These results show that the classifier $f$ picks up on several biases, but how do these experiments relate to the report generation task that is the focus of this work? Do report generation models learn these same biases? It is unclear to me why classification models are the focus of this analysis. \n\n3. **Presentation issues:** There are several presentation issues in this manuscript.\n\n    a. First, the notation provided in Section 3.2 is overly convoluted and unclear; for instance, how can the value of an image or text report be set to 0 or 1 (Lines 136-138)? What is meant by positive and negative in this context? This notation also seems unnecessary, since most of this notation is never referenced again in the manuscript. \n\n    b. Additionally, section 4.2 is critical to this paper yet does not include adequate implementation details in the main text to understand the goals of the experiments, with most of this material being relegated to the appendix instead. For instance, details on the classification task, classification model, dataset, etc. are not provided in the main text, making it difficult to understand the problem setup. \n\n[1] Delbrouck et al. \"Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards\u201d.\u201d 2022.\n\n[2] Yu et al. \u201cEvaluating progress in automatic chest X-ray radiology report generation.\u201d 2023."
            },
            "questions": {
                "value": "My questions are listed above in the \u201cweaknesses\u201d section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper identifies transformer models\u2019 bias towards low-frequency regions of an image as a potential source for their low performance on the medical report generation (MRG) task. It provides evidence for visual and textual bias, where larger abnormal regions and the number of diseases in a study leads to a higher F1 score of the generated report. Since most of an image is normal, models are biased towards classifying images as normal. The paper addresses this issue by proposing a high-frequency amplification layer (HAL) in order to filter out low-frequency regions. It demonstrates that models trained with HAL learn more discriminative representations of diseases, among other benefits, which leads to comparable performance on natural language generation (NLG) and clinical efficacy (CE) metrics to the state-of-the-art (SoTA)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The work presents a novel perspective on medical report generation, identifying bias towards low-frequency regions as a challenge for learning good visual representations. The authors introduce the problem with clarity, providing evidence for the correlation between signal frequency and performance. Using Fourier transforms to filter out low-frequency regions from an image is an interesting solution to the problem. The efficacy of the method is backed by empirical results: the model trains better and achieves comparable performance with the SoTA. Overall, there seems to be potential both for mitigating visual and textual bias as an area of research and this specific method for doing so."
            },
            "weaknesses": {
                "value": "Table 1:\n\nAlthough HAL achieves performance that puts it in the top 3, ultimately its F1 is still more than 8 points lower than the SoTA, which brings into question its advantage over PromptMRG. It would be interesting if the performance gain from HAL composes with gains from other methods. For instance, would RGRG + HAL result in better performance than just RGRG alone? Therefore, the authors should include a comparison with a simple transformer that does not use HAL in order to quantify the effect of HAL on model performance.\n\nTable 2:\n\nAs the authors themselves noted, this comparison is unfair because the baseline models were evaluated zero-shot on IU-Xray while HAL was trained. The authors should provide a fairer comparison, perhaps by also evaluate zero-shot a model with HAL trained on MIMIC-CXR but not IU -Xray.\n\nLine 130-131:\n\n> Each medical image is paired with a corresponding medical report\u2026 indicates the size of the vocabulary.\n\nThe notation is weird here. Why does $Y = [y_1, \\cdots, y_t, \\cdots, y_T]$ belong in $\\{0, 1\\}^{|v|}$? What does this set, $\\{0, 1\\}^{|v|}$ refer to?\n\nLine 133-138:\n\nI think it is unnecessary to use math notation here to talk about positive and negative samples. It does not add clarity to the explanation. For example, the notation $|X^{(z)}|$ does not give the reader any more information about how the size of an abnormal region is calculated.\n\nFigure 3a (left) is very hard to read. I cannot figure out which bar has the score of 0.50. Furthermore, although the discussion of textual bias is interesting, it is left unaddressed by the paper as it focuses on visual bias."
            },
            "questions": {
                "value": "I have listed some questions in the \u201cWeaknesses\u201d section. Below are a few more.\n\nLine 267:\n\nWhy is $T$ the first dimension of $A$? I think it should be $N$ because the $U$ is $N \\times |d|$.\n\nLine 412 and figure 5:\n\nIt is unclear what \u201cneurons\u201d refer to here. Is it the output of the attention layer or MLP layer, or something else?\n\nFigure 4: \nHow is accuracy calculated here?\nSince the loss keeps decreasing for larger $\\alpha$, have the authors considered increasing the $\\alpha$ beyond 8?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper identifies the challenge of visual and textual biases in automated medical report generation, which stems from the overwhelming presence of normal features in both medical images and reports. The authors define visual bias and textual bias, associating these biases with *frequency bias*, where models tend to emphasize low-frequency (normal) signals over high-frequency (abnormal) signals. To counter this, they propose the High-Frequency Amplification Layer (HAL), designed to heighten the model\u2019s sensitivity to abnormal (high-frequency) details, thus enhancing diagnostic accuracy. Validation on MIMIC-CXR and IU X-ray benchmarks shows HAL\u2019s effectiveness through various analyses and demonstrates competitive or superior performance compared to state-of-the-art models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper defines visual and textual biases, highlighting their impact on MRG model performance.\n2. The empirical analysis of visual and textual biases confirms the presence of each bias and demonstrates the existence of the frequency bias.\n3. The work introduces a high-frequency amplification layer to amplify high-frequency signals, enabling improved detection of abnormal features.\n4. The paper provides a thorough experimental analysis, including ablation studies and qualitative comparisons, to substantiate the effectiveness of the proposed methods."
            },
            "weaknesses": {
                "value": "1. Many of the experiments are conducted to demonstrate the presence of visual and textual biases, but the experimental details are not clearly articulated. For example, how many samples were utilized to analyze the visual bias, and what is the text classifier? Moreover, most of the figures for analysis should have more explanations (e.g., Figure 3, Figure 9 and Figure 10). It is not clear right now.\n2. It is not clear where HAL applied. Were they adopted in all cross-attention layers? \n3. The paper lacks sufficient novelty, as it only combines HAL. However, it does not adequately explain the results of the baseline model.  Exactly how HAL works in the final report generation should be further enhanced with examples of generated reports."
            },
            "questions": {
                "value": "1. There should be more explanations about why clinical efficacy is lower than the SOTA model. The paper aims at utilizing HAL to capture more abnormal regions, but the CE metric for detecting abnormalities was not been improved. \n2. Can HAL be applied in other existing MRG models? More ablation studies of HAL should be conducted to demonstrate its effectiveness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}