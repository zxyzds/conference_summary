{
    "id": "X5rO5VyTgB",
    "title": "Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models",
    "abstract": "Recent knowledge editing methods have primarily focused on modifying structured knowledge in large language models. However, this task setting overlooks the fact that a significant portion of real-world knowledge is stored in an unstructured format, characterized by long-form content, noise, and a complex yet comprehensive nature.\nTechniques like ``local layer key-value storage'' and ``term-driven optimization'', as used in previous methods like MEMIT, are not effective for handling unstructured knowledge.\nTo address these challenges, we propose a novel \\textbf{Un}structured \\textbf{K}nowledge \\textbf{E}diting method, namely UnKE, which extends previous assumptions in the layer dimension and token dimension.\nFirstly, in the layer dimension, we propose non-local block key-value storage to replace local layer key-value storage, increasing the representation ability of key-value pairs and incorporating attention layer knowledge. \nSecondly, in the token dimension, we replace \u201cterm-driven optimization\u201d with \u201ccause-driven optimization\u201d, which edits the last token directly while preserving context, avoiding the need to locate terms and preventing the loss of context information.\nResults on newly proposed unstructure knowledge editing dataset (UnKEBench) and traditional structured datasets demonstrate that UnKE achieves remarkable performance, surpassing strong baselines. In addition, UnKE has robust batch editing and sequential editing capabilities.",
    "keywords": [
        "Knowledge Editing",
        "Large Language Models"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=X5rO5VyTgB",
    "pdf_link": "https://openreview.net/pdf?id=X5rO5VyTgB",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a method called the unstructured knowledge editing method (UnKE).\nTraditional knowledge editing methods are mainly focused on structured data (triples with subject, relations, and objects).\nHowever, this paper argues that a vast amount of knowledge is unstructured, often complex, and presented as free-form text.\nUnKE uses non-local block key-value storage and cause-driven optimization, effectively capturing and editing unstructured knowledge without sacrificing context. This paper also proposes a new dataset UnKEBench. It consists of paraphrased questions and counterfactual unstructured texts for knowledge editing."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The proposed methods (non-local key-value storage and cause-driven optimization) are interesting as they can handle unstructured knowledge editing. They are quite different from previous methods.\n2. The reported experiments are extensive. They show UnKE outperforms baseline models (like MEMIT and ROME) across multiple evaluation metrics, validating its effectiveness in handling unstructured knowledge editing.\n3. The paper proposes a new benchmark for unstructured knowledge editing."
            },
            "weaknesses": {
                "value": "1. The motivation is quite similar to [1]. The differences should be discussed.\n2. The constructed dataset UnkBench only uses counterfactual unstructured texts from ConflictQA. I want to see how UnKE performs on real-world unstructured knowledge as in [1].\n3. The paper makes me feel confused about the input of the expected output of unstructured knowledge editing. It seems the input should be a question and the expected output should be a text.\n4. The paper lacks some details about how to use MEMIT, ROME, and MEND for unstructured knowledge editing as they mainly aim for structured knowledge.\n\n\n[1] Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing (https://arxiv.org/abs/2402.18909)"
            },
            "questions": {
                "value": "1. Maybe give an example of the proposed unstructured knowledge editing setting in the manuscript.\n2. The introduced UnKEBench only uses counterfactual samples. How is the performance on real-world unstructured knowledge?\n4. MEMIT and ROME mainly aim for structured knowledge. How do you use them for the unstructured knowledge in UnKEBench?\n5. Why is the performance of FT-A so low?\n6. How does IKE (with in-context learning) perform on unstructured knowledge editing?\n3. Line 873, FT-ALL --> FT-A."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces UnKE, an approach that addresses limitations in existing knowledge editing methods that primarily handle structured knowledge. The proposed UnKE method expands upon current techniques through \"non-local block key-value storage\" and \"cause-driven optimization\" to enhance the handling of complex, unstructured knowledge. Experimental results on a new benchmark, UnKEBench, demonstrate that UnKE outperforms baseline models in unstructured and structured knowledge editing, achieving high accuracy and robustness in sequential and batch editing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe introduction of non-local block key-value storage and cause-driven optimization effectively improves the representation and editing of unstructured knowledge, making the method more adaptable than traditional term-driven optimization approaches.\n2.\tIt creates a new benchmark UnKEBench for unstructured knowledge editing.\n3.\tIn experiments, the proposed UnKE outperforms baselines across lexical, semantic, and factual correctness metrics, with robust transferability across various LLM architectures and effective batch and sequential editing capabilities."
            },
            "weaknesses": {
                "value": "1.\tThe paper claims that existing knowledge editing methods have primarily focused on modifying structured knowledge in large language models, but it is not correct. Fine-tuning based methods do not rely on structured knowledge, such as LoRA, RoseLoRA [1], and RECT [2]. In experiments, the paper should set the three methods as baselines as well.\n2.\tThe evaluation metric of general ability is not reasonable. Simply evaluating the performance of edited models on MMLU can not show the general ability correctly. In Table 2, almost all the methods have the same performance on MMLU. If you want to evaluate the locality of edited models, you need to collect extra data which is close to the edited knowledge.\n3.\tThe proposed method relies on the choice of layers to edit. From Table 7, if we choose different layers, the performance will vary significantly. It is difficult to apply to real-world applications.\n\n[1] Wang H, Liu T, Zhao T, et al. RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning[J]. arXiv preprint arXiv:2406.10777, 2024.\n[2] Gu J C, Xu H X, Ma J Y, et al. Model editing can hurt general abilities of large language models[J]. arXiv preprint arXiv:2401.04700, 2024."
            },
            "questions": {
                "value": "refer to the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel approach to knowledge editing in large language models (LLMs), specifically targeting unstructured knowledge. The authors argue that current knowledge editing methods are limited in their ability to handle the complex and free-from information found in unstructured formats, which constitute a significant portion of real-world knowledge.\n\nThe key contributions of this paper are as follows:\n\n1. **Unstructured Knowledge Editing (UnKE) Method**: The authors propose UnKE, a method that extends knowledge editing from structured knowledge to unstructured knowledge. This is a advancement as it addresses the gap in handling the majority of real-world knowledge that is not neatly packaged in structured formats.\n\n2. **Cause-Driven Optimization**: The paper replaces term-driven optimization with a cause-driven approach, which edits the last token directly while preserving context. This avoids the need to locate specific terms and prevents the loss of contextual information, which is a common issue with term-driven methods.\n\n3. **UnKEBench Dataset**: To evaluate the performance of UnKE, the authors develop a new benchmark dataset, UnKEBench, which is designed to be more challenging than existing structured editing benchmarks due to the complexity of unstructured knowledge.\n\n4. **Experimental Results**: The paper demonstrates that UnKE outperforms baselines on the newly proposed UnKEBench dataset, as well as on KEBench. \n\n5. **Robustness Analysis**: The authors conduct robustness analysis experiments, confirming UnKE's ability to perform batch and sequential editing, and its superiority over baseline models in structured knowledge editing.\n\nIn summary, this paper makes a compelling case for the need to extend knowledge editing to unstructured data and provides a robust method and benchmark to facilitate this advancement. The proposed UnKE method shows promising results in accurately handling free-format unstructured knowledge, which is a good step forward for the field of knowledge editing in LLMs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "**Originality:**\n- The paper introduces an approach to editing unstructured knowledge within large language models (LLMs), which is a novel contribution to the field.\n- The proposal of the Unstructured Knowledge Editing (UnKE) method breaks new ground by extending the scope of knowledge editing beyond traditional structured knowledge.\n- The concept of non-local block key-value storage and cause-driven optimization is innovative and addresses a previously unmet need for handling complex, unstructured information.\n- The authors have developed a new benchmark dataset, UnKEBench, which provides a way to assess unstructured knowledge editing capabilities.\n\n**Clarity:**\n- The paper is well-organized and clearly structured, making it easy for readers to follow the progression of ideas and the logical flow of arguments.\n\n**Significance:**\n- The successful editing of unstructured knowledge has broad implications for various applications, including but not limited to information retrieval, question answering, and conversational agents.\n- By demonstrating UnKE's effectiveness on both newly proposed and traditional datasets, the paper highlights the potential of the method to impact real-world applications where unstructured knowledge is prevalent.\n\nOverall, the paper is a significant contribution to the field of knowledge editing, particularly in the area of knowledge editing within LLMs."
            },
            "weaknesses": {
                "value": "- Lack of baselines: Although UnKE has demonstrated quite good results, the baselines used for comparison are not the most advanced methods in the field. It would be more convincing if UnKE could be compared with state-of-the-art methods such as WISE, GRACE, and FT-M, and show better results. In particular, UnKE should against with non-term-driven optimization method GRACE for a more fairly comparison.\n- Contributions of UnKEBench: First, before UnKEBench, there have already been works on long-form knowledge editing (e.g., LEME[1]), but this is not discussed in the paper. Second, UnKEBench is generated by ChatGPT and lacks steps to ensure data quality, such as human verification.\n- Description inconsistent with reality: \n    - The paper hypothesizes that unstructured knowledge is distributed across multiple layers of the language model, but the experiment only edits one layer.\n    - The paper claims that UnKE's cause-driven optimization can preserve pre-trained knowledge during the editing process. However, in the experiments, UnKE's ability to retain original knowledge is worse than the baseline (i.e., MMLU in Table 2 and Src-Acc and Tgt-Acc in Table 3).\n\n[1] Rosati D, Gonzales R, Chen J, et al. Long-form evaluation of model editing[J]. arXiv preprint arXiv:2402.09394, 2024."
            },
            "questions": {
                "value": "- Why does unstructured knowledge contain more information? Intuitively, unstructured knowledge has more grammatical and structural words, which carry low information.\n- What is the relationship between LEME and UnKEBench? If LEME and UnKEBench have similar contributions, the statement \"the lack of a benchmark for editing unstructured knowledge\" in the paper would not hold.\n- In \"EXPERIMENTS ON STRUCTURED KNOWLEDGE EDITING,\" why choose KEBench instead of knownedit? How does UnKE perform on knownedit?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Based on the analysis of knowledge editing methods for LLMs, this article proposes two hypothesis for unstructured knowledge editing, and a method named Unstructured Knowledge Editing(UnKE)  ,which incorporates non-local block key-value storage and cause-driven optimization, enabling it to effectively represent and edit unstructured knowledge with ease. In order to address the limitations of existing knowledge editing benchmarks, which primarily focus on structured knowledge triples, the paper introduces UnKEBench, and  experimental results on UnKEBench demonstrate the superior performance of UnKE, significantly surpassing powerful baseline models on various evaluation metrics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Pros\n   1. proposed an Unstructured Knowledge Editing(UnKE)  method;\n   2. constructed UnKEBench"
            },
            "weaknesses": {
                "value": "The article is fluent in writing and has a complete structure, but some expressions need improvement\uff0cfor example, in the abstract, there is \"unstructure knoledge\",etc."
            },
            "questions": {
                "value": "The paper expressed is very clear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the limitations of current knowledge editing methods in large language models, which primarily focus on structured knowledge. The paper introduces a new method called Unstructured Knowledge Editing (UnKE). A novel dataset for unstructured knowledge editing, UnKEBench, is also proposed."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tThe paper introduces Unstructured Knowledge Editing (UnKE), which addresses the limitations of existing methods by focusing on unstructured knowledge.\n\n2.\tThe use of a newly proposed dataset (UnKEBench) with traditional datasets provides a strong evaluation.\n\n3.\tUnKE extends the method in both layer and token dimensions. It enhances the capacity for knowledge editing.\n\n4.\tThe paper is generally well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1.\tThe proposed method may be complicated, potentially posing challenges for real-world applications. The authors are suggested to give more details on computational resources and complexity analysis.\n\n2.\tThe authors used LLAMA2 and QWEN1.5 models for evaluation. Since newer versions of these LLMs have been released, it is better to show the performance of UnKE on newer LLMs.\n\n3.\tThe authors trimmed too much space. For example, check Figure 2 and Table 1.\n\n4.\tWhile a new benchmark is introduced, the paper might lack the detailed process of data processing and quality control steps, possibly limiting the quality of the benchmark."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}