{
    "id": "zCJqgXnV7f",
    "title": "Dynamic Elimination For PAC Optimal Item Selection From Relative Feedback",
    "abstract": "We study the problem of best-item identification from relative feedback where a learner adaptively plays subsets of items and receives stochastic feedback in the form of the best item in the set. We propose an algorithm - Dynamic Elimination (DE) - that dynamically prunes sub-optimal items from contention to efficiently identify the best item and show a strong sample complexity upper bound for it. We further formalize the notion of inferred updates to obtain estimates on item win rates without directly playing them by leveraging item correlation information. We propose the Dynamic Elimination by Correlation (DEBC) algorithm as an extension to DE with inferred updates. We show through extensive experiments that DE and DEBC significantly outperform all existing baselines across multiple datasets in various settings.",
    "keywords": [
        "probably approximately correct",
        "optimal item selection",
        "relative feedback",
        "multi armed bandits",
        "Plackett Luce Model",
        "Condorcet winner",
        "Bayesian updates",
        "active learning"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "Algorithms for PAC optimal item selection from subset wise relative feedback based on suboptimal item dynamic elimination that outperforms SOTA benchmarks; additionally introduce the notion of inferred updates to utilize item similarity information",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=zCJqgXnV7f",
    "pdf_link": "https://openreview.net/pdf?id=zCJqgXnV7f",
    "comments": [
        {
            "title": {
                "value": "Response to Reviewer DQ7C"
            },
            "comment": {
                "value": "We would first like to thank Reviewer DQ7C for his feedback and time taken to review the paper.\n\nWe respond to the weaknesses raised by Reviewer DQ7C as follows:\n\n>The algorithmic contribution of this looks narrow. The core idea of DE is flexibly eliminating items once they are deemed suboptimal. This idea is old in the bandit literature ... The core idea of DEBC is exploiting the generalized linear structure on the correlation among arms. This idea is also not new ...\n\nWe agree that early elimination of suboptimal items and exploiting a linear structure is generally speaking not new to bandits. However, we are exploring the problem of best-item identification from **relative feedback** by playing fixed subsets. \n\nRegarding early item elimination, all existing SOTA algorithms that investigate this issue directly (a detailed discussion about these algorithms and why certain baselines are not comparable is in Appendix G.1) play a fixed subset repeatedly until the set optimal item is found before eliminating all other items in the set. The reason for this is because elimination of items before the set optimal item has been found renders the pairwise win ratios irrelevant and the win counts need to be accumulated again for the other items in the set. This is precisely where our algorithm differs because we allow elimination of items in the set by introducing the novel idea of inheriting pairwise win statistics under certain conditions and proving its validity (running winner inheritance discussed in lines 224-229 and proved in Appendix E.4, Lemma 9-10). In practice, this can yield huge sample complexity improvements since challenging sets (where there are two or more items with very similar win ratios) need to be played a large number of times to differentiate the two competitive items; our algorithm allows other items to be eliminated and replaced while this is happening. This is reflected in the sample complexity improvements demonstrated in our experiments. We welcome further discussion on this point.\n\nRegarding exploiting a linear structure, we are again the first (to the best of our knowledge) to investigate this in the relative feedback from fixed-size subset plays setting. We present a novel of inferred updates by investigating the question: Given what we know about items i, j and k, if item i is ranked above/below item k, how likely is it that item j is ranked above/below item k? This has only been investigated in a few works which we have discussed in the related works section (line 93-101), but not in the setting of best-item identification from fixed-size subset plays. Moreover, we do not require knowledge of the item's precise vector representation but only the item correlations. We further discuss extensively the limitations of our results in Appendix B.\n\n> Could the author elaborate on the novelty of the proof?\nAs discussed above, the algorithm is itself novel (dynamically eliminating items instead of the whole subset) and relies on the validity of running winner inheritance which is a new result. We prove these results in the process of proving correctness and obtaining sample complexity bounds on our algorithm. Insofar as the algorithm is fundamentally very different from the algorithms in [1] and [2], I am not unsure how the proof can be considered as similar although it does rely on similar techniques. \n\n> The theoretical improvement over SOTA techniques is not clear. The improvement on the sample complexity compared with SOTA works is not stated. How does it improve the sample complexity upper bound?\n\nWe improve against the existing algorithms by a factor of ln(n/ns). This is mentioned in the Appendix but we will explicitly mention the comparison in the main section. However, in practice, the margin of improvement is much larger as shown in the experiments.\n\n> The second paragraph of the related work overstated the limitations of previous works without any supporting evidence. Previous algorithms may require up to millions of samples to rank only a few items, but this possibility depends on the setting of the problem. ...\n\nThe two SOTA algorithms that are directly compatible with our setting are TTB and DAB and these are non instance optimal algorithms, hence we can determine their sample complexities beforehand. These are presented in Section 8 and are in the 10^7-10^10 range for a few hundred items. Comparing instance optimal algorithms, we used a modified version of DKWT, but the directly compatible PAC wrapper [4] is shown in [2] to require more than 10^8 samples to obtain the Generalised Condorcet Winner.\n\n> Lemma 1 is confusing. It is highlighted as a lower bound, but the sample complexity is stated using the big O notation.\n\nWe apologise for the typo and will correct it.\n\n[4] Aadirupa Saha and Aditya Gopalan. From pac to instance-optimal sample complexity in the plackett- luce model. In International Conference on Machine Learning, pp. 8367\u20138376. PMLR, 2020b."
            }
        },
        {
            "summary": {
                "value": "This work addresses the problem of identifying the best item from a set of items based on relative feedback, specifically using a method called Dynamic Elimination (DE). DE efficiently prunes sub-optimal items as it progresses, improving sample complexity compared to existing algorithms. The authors also propose an extension, Dynamic Elimination by Correlation (DEBC), which incorporates inferred updates based on item correlations. DEBC significantly outperforms DE in settings where item correlation is strong, reducing sample complexity further. Extensive experiments demonstrate that both DE and DEBC outperform existing state-of-the-art (SOTA) methods in terms of sample complexity across multiple datasets and settings. Additionally, the paper explores future directions for improving sample complexity bounds and extending the methods to partial/full rankings."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. DE and its extension, DEBC, significantly improve sample complexity for identifying the best item compared to existing algorithms, reducing the number of subset plays needed.\n\n2. The incorporation of inferred updates through item correlation in DEBC provides a robust mechanism to handle correlated item structures, leading to superior performance in certain datasets.\n\n3. The paper extensively evaluates DE and DEBC across various synthetic and real-world datasets, demonstrating their practical effectiveness and robustness across different settings."
            },
            "weaknesses": {
                "value": "1. While DE and DEBC perform well in practice, the theoretical sample complexity bounds provided in the paper are not as tight as their practical performance would suggest, leaving room for further theoretical refinement.\n\n2. DEBC\u2019s performance heavily relies on the strength of item correlations, this raise potential limiting its applicability in scenarios with weak correlations. \n\n3. The paper primarily focuses on cosine similarity for item embeddings and correlations. Extending this to other similarity measures or more general settings is only briefly mentioned and not fully explored.\n\nSome cosmetics: for example on row 330: `we can can combine`."
            },
            "questions": {
                "value": "How can the sample complexity bounds be further improved to match the practical performance observed in experiments, and is there potential for achieving instance-optimal sample complexity in the PAC best-item setting?\n\nCould the proposed DE and DEBC algorithms be adapted or extended to work with partial or full rankings instead of just identifying the best item, and what challenges might arise in such extensions?\n\nHow would the algorithms perform in settings where item correlations are dynamic or evolve over time, and what adjustments to DE/DEBC might be necessary to handle such changes effectively?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors have introduced a dynamic elimination method for item selection based on relative feedback. They propose two distinct algorithms: one that implements the fundamental dynamic elimination approach and another that incorporates item correlations into the elimination process. The paper provides theoretical analysis on both the sample complexities and the correctness of the proposed methods. Furthermore, the authors demonstrate the proposed methods' ability in terms of reducing sample complexities when compared to several baseline approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1: The proposed methods enhance existing approaches by dynamically eliminating suboptimal items, significantly reducing the algorithm's complexity.\n\nS2: By incorporating correlations between items, the proposed methods extend their applicability to items initially absent from the played set.\n\nS3: The authors offer theoretical assurances regarding the sample complexity of DE and DEBC. They also demonstrate that the sample mean of an inferred update sequence serves as an unbiased estimator."
            },
            "weaknesses": {
                "value": "W1: The DE and DEBC algorithms are designed for the task of item selection, yet the performance of best item identification is neglected. The authors dedicate substantial space to discussing the efficiency of the proposed methods in reducing sample complexity. However, the mathematical formulation lacks clarity, as the best item identification problem and the relative feedback are not thoroughly formulated.\nW2: The proposed DEBC algorithm presumes that item correlations are known to the user, raising concerns about the validity of this assumption. The authors do not address the implications of this assumption in real-world applications or indicate whether it is a common assumption in existing literature.\nW3: The current work lacks demonstration in real-world scenarios. Although the authors mention that learning to rank is crucial in fields like sociology, information retrieval, and search engine optimization, they do not provide examples of its application in these areas. Consequently, the practical applicability of this work remains uncertain."
            },
            "questions": {
                "value": "Q1: It would be appreciated if the authors could include additional experiments conducted in real-world scenarios. These experiments should aim to demonstrate the effectiveness of the proposed methods in best item identification. Additionally, it is recommended that results be presented using widely accepted metrics such as accuracy, AUC, F1, precision, and recall. \nQ2: The authors might consider providing a more precise and explicit formulation of the item selection problem in Section 3. Furthermore, it would be valuable to discuss in greater detail how DE and DEBC can be applied in practical, real-world contexts."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the problem of best-item identification from relative feedback in the setting where a learner adaptively plays subsets of items and receives stochastic feedback in the form of the best item in the set. An algorithm named Dynamic Elimination (DE) is proposed, which dynamically prunes sub-optimal items from contention to efficiently identify the best item. Then the model is extended to capture the generalized linear correlation of items. An algorithm named DEBC, an extension of DE is proposed to handle this extension. The core idea is leveraging the generalized linear correlation to obtain estimates on item win rates without directly playing them by leveraging item correlation information. Extensive experiments are conducted to validate the empirical performance of the proposed algorithm."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper studies an important problem.  \n\nThe proposed algorithm is complemented with theoretical analysis as well as extensive experiments."
            },
            "weaknesses": {
                "value": "The algorithmic contribution of this looks narrow. The core idea of DE is flexibly eliminating items once they are deemed suboptimal. This idea is old in the bandit literature. The authors can refer to Chapter 6 of [3] for some reference.  Also, a simple google search would gives you a number of work on elimination algorithms. The core idea of DEBC is exploiting the generalized linear structure on the correlation among arms. This idea is also not new since linear structure has been extensively studied in linear bandits, reinforcement learning. Please refer to Part V of [3] from some details.  \n\nThe proof techniques of this paper are not new, most of them are drawn from literature. Thus, this paper does not contribute to new proof techniques.  To me more specific, compared to [1,2], I do not see enough new ideas in the proof.  For example, the analysis of concentration, probability of event, etc., looks very normal. Could the author elaborate on the novelty of the proof? \n\nThe theoretical improvement over SOTA techniques is not clear. The improvement on the sample complexity compared with SOTA works is not stated.  How does it improve the sample complexity upper bound? \n\nThe second paragraph of the related work overstated the limitations of previous works without any supporting evidence. Previous algorithms may require up to millions of samples to rank only a few items, but this possibility depends on the setting of the problem. It should not be stated as a general claim. Furthermore, this paragraph is not precise. What do you mean by often? Could you quantify it? \n\nLemma 1 is confusing. It is highlighted as a lower bound, but the sample complexity is stated using the big O notation.  \n\n[1] Yisong Yue, et al. The K-armed Dueling Bandits Problem, Journal of Computer and System Sciences, 78(5): 1538\u20131556.\n\n[2] Bj\u00f6rn Haddenhorst. Identification of the Generalized Condorcet Winner in Multi-dueling Bandits, NeurIPS, 2021\n\n[3] Tor Lattimore, et al. Bandit Algorithms. Cambridge press."
            },
            "questions": {
                "value": "See weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the best item selection problem from noisy multi-wise comparisons. There are totally n items, and at each round the agent can select n_s items to compare, and the comparison will return one item as the winner according to the PL model. The better item will have a higher chance to win the comparison. The problem is to find the best item with 1-\\delta confidence with the least amount of comparisons. \n\nThe authors propose a new algorithm for best item selection from multi-wise comparisons and give the worst-case, best-case, and expected sample complexity. The authors further propose a method to estimate the winning probabilities between two items without directly comparing these two items."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper proposes new algorithms for best item identification and winning rate estimation. These algorithms do have some novelty and are inspiring."
            },
            "weaknesses": {
                "value": "The significance of this paper's results is questionable. For the best item identification, the sample complexity (worst-case) is O(n*\\epsilon^{-2} *\\log(n*n_s^{-1}*\\delta^{-1})). However, in a previous paper [1], when n_s = 2 (i.e., pairwise comparisons), the sample complexity (expected) for best item identification is O(n*\\epsilon^{-2} *\\log\\delta^{-1})) (Theorem 5 of [1]), which is log(n) better than the proposed algorithm. When n_s is large enough like \\Omega(n), the sample complexity of the proposed in this paper will become the same as that in [1]. Hence, the proposed algorithm does not show superiority compared to existing algorithms, or at least be as good as existing ones. Although its sample complexity is worst case instead of in expectation, but this difference is not large enough to support the significance of the new results. \n\nBesides, the winning chance estimation and the sample complexity of best item identification seem not to be correlated enough to be put in the same paper. Putting them in one paper makes the paper's scope to be ambiguous. If the winning chance estimate is significant enough, it is better to be placed in another paper focusing on a more related topic.\n\n[1] Ren, W., Liu, J., & Shroff, N. (2020, November). The Sample Complexity of Best-$ k $ Items Selection from Pairwise Comparisons. In International Conference on Machine Learning (pp. 8051-8072). PMLR."
            },
            "questions": {
                "value": "It will help if the authors can have more evidence to demonstrate this paper's results' significance. \nOr if I perceive this paper wrongly, please let me know."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}