{
    "id": "wGqf7YMF8R",
    "title": "HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows",
    "abstract": "Despite recent advancements in large language models (LLMs), their performance on complex reasoning problems requiring multi-step thinking and combining various skills is still limited. To address this, we propose a novel framework HDFlow for complex reasoning with LLMs that combines fast and slow thinking modes in an adaptive manner. Our approach consists of two key components: 1) a new approach for slow, deliberate reasoning called Dynamic Workflow, which automatically decomposes complex problems into more manageable sub-tasks and dynamically designs a workflow to assemble specialized LLM or symbolic reasoning tools to solve sub-tasks; 2) Hybrid Thinking, a general framework that dynamically combines fast and slow thinking based on problem complexity. \nFinally, we propose an easy-to-scale method for automatically synthesizing a large-scale dataset of 27K challenging reasoning problems for complex reasoning and a hybrid thinking tuning method that trains smaller LLMs on this dataset to internalize the fast/slow hybrid reasoning strategies.\nExperiments on four reasoning benchmark datasets demonstrate that our slow thinking with dynamic workflows significantly outperforms Chain-of-Thought, and hybrid thinking achieves the highest accuracy while providing an effective balance between computational efficiency and performance. Fine-tuning using our hybrid thinking approach also significantly boosts the complex reasoning capabilities of open-source language models. The results showcase the promise of slow thinking, dynamic workflows, and hybrid thinking in expanding the frontier of complex problem-solving with LLMs.",
    "keywords": [
        "Large Language Models (LLMs)",
        "Complex Reasoning",
        "Hybrid Thinking",
        "Symbolic Reasoning"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "This paper proposes HDFlow, a novel framework that enhances complex problem-solving in LLMs by dynamically combining fast and slow thinking and dynamic workflows, significantly improving reasoning performance and efficiency.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=wGqf7YMF8R",
    "pdf_link": "https://openreview.net/pdf?id=wGqf7YMF8R",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a fast-slow thinking mechanism where the fast thinking is direct CoT and slow thinking is a dynamic workflow method. It also utilizes a dataset containing fast thinking process and slow thinking process to train a model to internalize the fast/slow thinking strategy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. strong performance improvement compared with direct CoT thinking"
            },
            "weaknesses": {
                "value": "1. missing citation and discussion for System-1.x: Learning to Balance Fast and Slow Planning with Language Models, which also talks about the combination of fast thinking and slow thinking\n2. This paper basically use cot as fast thinking and agentic planning as slow thinking. I feel like there's not much novelty here\n3. missing baselines such as the method from System-1.x: Learning to Balance Fast and Slow Planning with Language Models"
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a framework called HDFlow aimed at enhancing the complex reasoning abilities of LLMs. HDFlow combines fast & slow thinking modes in an adaptive manner to tackle problems that require multi-step reasoning and the integration of various skills. The framework is designed to automatically decompose complex problems into manageable sub-tasks and dynamically assemble specialized LLMs or symbolic reasoning tools to solve them, thereby improving both efficiency and accuracy in problem-solving."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "## Strengths\n\n1. The paper presents a new approach that facilitates deliberate, slow reasoning. (Compared to previous methods like CoT/PAL, ) this method automatically breaks down complex problems into smaller sub-tasks and designs a dynamic workflow to solve each sub-task using specialized LLMs or symbolic reasoning tools.\n2. The proposed HDFlow is tested on 4 reasoning benchmark datasets. The Slow Thinking approach with Dynamic Workflow outperformed traditional CoT-like methods, achieving a notable average accuracy improvement.\n3. Authors introduces an easy-to-scale method for automatically generating a large-scale dataset of ~27K reasoning problems. Using this dataset, they propose a hybrid thinking tuning approach to fine-tune smaller, open-source LLMs."
            },
            "weaknesses": {
                "value": "## Weakness\n\nMajor Concerns:\n\n1. The whole framework seems like an engineering design, which incorporates adaptive modules and workflows to address some complex reasoning problems. It lacks the detailed technical contributions of a well-established research paper. I suggest the authors provide more explanations on the technical novelty.\n2. The authors claim that the framework is novel. However, there exist many previous works, combining fast and slow thinking to solve complex scenarios. Such as \"SWIFTSAGE: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks\" (it is just one of the examples). Could you please make a comparison with these previous baselines in the experiments? CoT baselines seem a little weak in 2024.\n\nMinor concern:\n\n1. CoT is considered to be fast thinking in this paper. It is quite different from the definitions in other works. Because CoT can also involve deliberate trial and error, or self-reflection. Could you provide some explanations on this point?"
            },
            "questions": {
                "value": "I will read authors' rebuttal and discuss more about the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents HDFlow, a novel framework designed to enhance complex reasoning in large language models (LLMs) by integrating fast and slow thinking modes. Inspired by dual process theory, HDFlow features two main components: Dynamic Workflow and Hybrid Thinking. Dynamic Workflow breaks down complex problems into sub-tasks, using specialized LLMs and symbolic tools to solve them. Hybrid Thinking adapts between fast and slow reasoning based on task complexity, improving efficiency and accuracy. The authors also developed a large-scale dataset of 27K challenging reasoning problems to train LLMs in these strategies. Experiments on four benchmark datasets show that HDFlow significantly outperforms existing methods like Chain-of-Thought, with Hybrid Thinking achieving the highest accuracy **on three out of four benchmarks**. This approach demonstrates the potential of combining dynamic workflows and hybrid thinking to advance LLMs' problem-solving capabilities."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "- The paper is well-written, clearly conveying the core ideas and methodology.\n- It presents a comprehensive process, covering theoretical framework, data synthesis, fine-tuning, and evaluation. This entire process provides strong evidence supporting the superiorty of HDFlow compared to existing methods."
            },
            "weaknesses": {
                "value": "- In the \"Reasoning Problem Synthesis\" section, using GPT-4-Turbo with CoT to filter synthesized problems may limit the dataset's ability to enhance slow thinking, as all problems are solvable with GPT-4 + CoT?\n- A contamination test is needed to ensure training data differs sufficiently from evaluation datasets. If the result is not promising, please decontaminate your training data.\n- The claim that \"hybrid thinking achieves the highest overall accuracy\" is misleading, as it only tops three out of four benchmarks and does not have the highest average accuracy. This statement should be revised for precision."
            },
            "questions": {
                "value": "Minor comments:\n1. The last sentence in the second paragraph of the introduction feels awkward.\n2. The captions for Tables 1 and 3 mention a Fast/Slow ratio, which is not found in the Tables.\n3. The last sentence of the first paragraph in sec 6.3 mentions an interesting finding. This could be further discussed for more insights.\n4. There seems to be a contradiction in section 6.4 regarding the reliance on fast thinking, as the statement does not match the results in Figure 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces HDFlow, a framework designed to improve complex reasoning in large language models (LLMs) by adapting task-solving strategies from simple to more complex problems. According to the authors' ablation studies, the system achieved better results compared to the setting without the proposed modules."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "**+1.** This paper introduces a reaonable method to enhance LLM reasoning.\n\n**+2.** The experiments show that Hybrid Thinking outperforms Slow Thinking and original LLM baselines (COT).\n\n**+3.** The paper is clearly written and easy to understand."
            },
            "weaknesses": {
                "value": "**-1.** Although the concept of slow and fast thinking is fancy, the authors did not clearly define what constitutes slow and fast thinking. The proposed method fails to capture the full complexity of human cognition. I suggest either clarifying the related claims or reducing them if they do not strongly align with the method. Simply labeling quick responses as \"fast thinking\" and more detailed problem-solving as \"slow thinking\" seems to be an incorrect interpretation of the book [1].\n\n[1] Kahneman, Daniel. Thinking, Fast and Slow. 2017.\n\nNeed more reasonable claims and demonstrations to support `To address these limitations, we propose a novel framework for complex reasoning with LLMs that combines fast (System I) and more analytical slow thinking (System II) adaptively, inspired by the dual-process theory of human cognition (Kahneman, 2017).`\n\n**-2.** I suggest that the authors conduct a more careful and comprehensive literature review. Based on the reviewer's experience, several important and key references have been missed (published at least six months prior), such as [2], [3], and [4]. Additionally,  recent [5] provides a useful summary of  (many)  related similar work that the authors could refer to.\n\n[2] A Dynamic LLM-Powered Agent Network for Task-Oriented Agent Collaboration.\n\n[3] GPTSwarm: Language Agents as Optimizable Graphs.\n\n[4] XAgent: An Autonomous Agent for Complex Task Solving.\n\n[5] Automated Design of Agentic Systems.\n\n**-3.** I suggest adding more baselines beyond the self-produced ablations. The current experiments are weak and less convincing without at least two additional public-available baselines included."
            },
            "questions": {
                "value": "It would be appreciated if solve the questions mentioned in the weaknesses. Besides, there is a question about the workflow design:\n\n**Additional**: Where are the graph-related illustrations used in this paper? It is suggested that this missing part be added."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}