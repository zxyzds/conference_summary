{
    "id": "eeJz7eDWKO",
    "title": "A Meta-Learning Approach to Bayesian Causal Discovery",
    "abstract": "Discovering a unique causal structure is difficult due to both inherent identifiability issues, and the consequences of finite data.\nAs such, uncertainty over causal structures, such as those obtained from a Bayesian posterior, are often necessary for downstream tasks.\nFinding an accurate approximation to this posterior is challenging, due to the large number of possible causal graphs, as well as the difficulty in the subproblem of finding posteriors over the functional relationships of the causal edges.\nRecent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.\nYet, these methods are limited as they cannot reliably sample from the posterior over causal structures and fail to encode key properties of the posterior, such as correlation between edges and permutation equivariance with respect to nodes.\nTo address these limitations, we propose a Bayesian meta learning model that allows for sampling causal structures from the posterior and encodes these key properties.\nWe compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods, demonstrating the advantages of directly learning a posterior over causal structure.",
    "keywords": [
        "neural processes",
        "bayesian causal discovery",
        "transformers"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "We propose a method that allows for sampling from an approximate posterior over causal structures using neural processes.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=eeJz7eDWKO",
    "pdf_link": "https://openreview.net/pdf?id=eeJz7eDWKO",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes the Bayesian Causal Neural Process (BCNP), a Neural Process-based framework for learning a posterior distribution over causal graphs given a dataset $P(G \\mid X)$ . The proposed method is scalable and captures distinctions between graphs within the same Markov equivalence class. Since BCNP learns causal structures across multiple (synthetic) datasets, it is considered a meta-learning approach."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. This paper provides a well-structured and self-contained summary of prior works in Bayesian causal discovery, allowing readers to clearly follow the evolution of Bayesian approaches for learning causal graphs. As a reviewer, this summary enables me to track the advancements in the field and understand the recent progress in addressing challenges like scalability and uncertainty in causal inference.\n\n2. The paper clearly outlines its unique contributions in Table 1, highlighting significant advancements over existing methods. The proposed model addresses critical aspects such as acyclicity, permutation invariance, and edge dependencies\u2014all of which are critical for accurate causal graph learning. These improvements over prior approaches directly enhance the reliability and precision of inferred causal structures, making the contributions both clear and impactful.\n\n3. The proposed BCNP is particularly attractive due to its innovative use of Neural Processes to directly sample the posterior distribution $ P(G | X) $. This approach enables BCNP to achieve scalability and uncertainty-aware inference by learning across tasks (= datasets), allowing the model to efficiently adapt to new datasets while maintaining a robust representation of causal uncertainty. This combination of scalability, direct posterior sampling, and adaptability positions BCNP as a strong advancement over existing Bayesian causal discovery methods."
            },
            "weaknesses": {
                "value": "1. One of the main limitations of this paper is the assumption that there are no latent confounders between variables. This assumption may limit the applicability of the method to real-world datasets where unobserved confounders are common. \n\n2. I think this method is heavily relying on the assumptions on the choice of modeling class of functions F, the types of graphs and the noise model. Unlike fully nonparametric approaches like the PC algorithm, which do not impose strict functional or noise assumptions, BCNP\u2019s effectiveness depends on these choices being well-suited to the data.\n\n3. The proposed framework may be sensitive to hyperparameter settings and architecture choices, such as the hyperparameters for the encoder-decoder network, or the types of prior distributions. Fine-tuning these parameters is often data-dependent, which could reduce the model's robustness and generalization capabiltiy."
            },
            "questions": {
                "value": "1. Is it nontrivial to consider the setting where latent confounders between variables exist? \n\n2. Is the proposed method computationally efficient when a function class is chosen as neural networks? \n\n3. How sensitive the proposed framework is regarding to the sparcity of the graph? \n\n4. Are there any interesting example where the Bayesian approach beats the Markov-equivalence-based method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a Bayesian meta-learning model for causal discovery, named the Bayesian Causal Neural Process. This \"meta-learning\" algorithm learns a model from pairs of datasets and their associated causal graphs. Specifically, the model incorporates a neural process to address model uncertainty and employs an encoder-decoder architecture carefully designed to achieve desirable properties for causal discovery in a meta-learning context. These properties include permutation invariance to sample order, permutation equivariance to nodes, and acyclicity, achieved by decomposing the adjacency matrix into a lower triangular matrix and a permutation matrix\u2014some of which build on existing approaches. The authors demonstrate the empirical superiority of this model over other explicit Bayesian and Bayesian meta-learning models"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- As summarized in Table 1, this approach implements several key desiderata for a Bayesian meta-learning model more effectively than existing alternatives.\n- The paper is well-written, allowing readers to easily follow the motivation and desiderata of Bayesian meta-learning models."
            },
            "weaknesses": {
                "value": "- While I appreciate the overall architecture of the model, it is challenging to identify which components provide truly novel technical contributions. For instance, the results on pages 4 and 5 appear to largely rely on existing findings, and, if I'm not mistaken, page 6 includes results from Annadani et al. (2024). The contributions of this paper are not clearly or explicitly articulated.\n- The Bayesian prior is learned through pairs of datasets and directed acyclic graphs (DAGs). From my perspective, learning P(X,G) is likely very challenging. Indeed, Appendix B.1 notes that, for a case involving two variables, the model was trained on 200,000 datasets. I understand that Section 4.1 is intended to evaluate the posterior, but in Appendix B.2, 500,000 datasets are used for training. This information would be better suited for the main text, and details on computational resources should be transparently reported there as well (they are not provided even in the appendix).\n- I find it difficult to be fully convinced by the meta-learning approach to causal discovery. While I understand the importance of establishing a strong Bayesian prior, can we realistically expect access to hundreds of thousands of dataset-graph pairs?"
            },
            "questions": {
                "value": "- For DiBS and BayesDAG, the authors mention that they \u201ckeep all other hyperparameters to their preset values.\u201d What if these hyperparameters were tuned? Would the results differ significantly? For instance, DiBS and BayesDAG perform well on the Syntren dataset for certain metrics, so tuning may further widen this performance gap.\n- In the caption, it says, \u201cEach dataset contains D nodes and N samples.\u201d Does this imply that all datasets must be of the same size? What if the sample sizes vary, such as 100, 200, or 500? Should N be set to 100, or can larger datasets (e.g., 200 and 500 samples) be split into multiple parts (e.g., 2 or 5 parts) to train the model? In that case, should there be weighting adjustments (1/2, 1/5), also training perhaps only for data-related parameters and not for those related to the graph prior?\n- If there is no training involved, does your model function like a standard Bayesian causal discovery method with a uniform prior?\n- Each variable might have distinct functional priors, such as some being linear, others non-linear, discrete, or having different means. Does the encoder \u201cimplicitly\u201d reorder these variables (perhaps using attention mechanisms) to align them by their functional type? I\u2019m trying to conceptually grasp how the encoder handles such diverse functional characteristics under the hood.\n- What if permutation equivariance among nodes was not enforced? Would this potentially improve performance, especially if nodes are ordered consistently between training and test data?\n- In Line 382, could you clarify what is meant by \u201ccorrelations between edges\u201d when dealing with just two variables, X and Y, with at most a single edge?\n\nMinor comments\n- It would be better to have some annotations in Figure 2 (given that the figure takes lots of space)\n- Not quite sure whether it is sufficient to say the dependence in permutation and lower triangular binary matrices is modeled because they share the same representation R0.\n- 047, 137 citep for Wenzel et al. \n- 115 citing PC, GES might be good (given you have some space for 119)\n- 141 Bayesian metal \u2192 meta\n- 305 Is the grammar correct? (The matrix \u2026 and thus \u2026 )\n- 340 space before Mena\n- 389 In section section 4.2\n- 389 its \n- 414 space after comma\n- 480 enable\n- 485 period\n- BayesDAG is not highlighted in Table 4 for Linear data/SHD\n- Figure 2 shouldn\u2019t o be the input to Theta? or onto the edge between R^L1 to Theta?\n- Sorry for suggesting my preference here but can we align Theta and Phi (parameters, vertically) and align Qs and As with the same horizontal line as Theta and Phi, respectively, and put Gs at far right.\n\n(I can change to weak accept (or accept) depending on the response and others' reviews.)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In Bayesian causal discovery, the goal is to approximate the posterior over graphs. Since computing the posterior over graphs requires computing posterior over functional parameters, previous approaches have tried to approximate the posterior over function parameters.  This paper uses neural processes to approximate the posterior over graphs directly by learning a map from the dataset to the set of distributions. The neural process is an encoder-decoder network that claims to sample, permutation-invariant, acyclic graphs that capture edge dependencies."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper proposes a technique that can directly sample from the posterior over graphs. The main contribution of the paper is in the architecture of the encoder-decoder network that captures necessary properties like the permutation invariance by cross-attention, and ayclic DAGs and edge dependencies by sampling the decomposition of a DAG into permutation and lower-triangular matrices. The comparison of the proposed model is done with existing meta-learning approaches and Bayesian approaches using multiple metrics. The proposed model is shown to be competitive on synthetic and simulated datasets. The paper is written clearly and flows well."
            },
            "weaknesses": {
                "value": "My main concern is that of this being an incremental contribution. The framework is not new and the only contributions I see are a change in how permutation invariance and acyclicity is incorporated. Please let me know if I am missing something else. I have a detailed list of questions below whose answers might help strengthen the paper."
            },
            "questions": {
                "value": "1) The ideas that the paper uses to impose acyclicity and permutation invariance seem applicable in general. Can existing meta-learning approaches be modified to get the same? While this is not the focus of the paper. It would make it stronger to highlight it if that's the case.\n\n2) The experimental validation for the case when the true posterior is known, is done only for the two-variable case. Is it possible to scale this up? \n\n3) How can the posterior over the graphs be used for inference on that of the functional parameters? \n\n4) How is the performance on Gene Regulatory Network simulated data like SERGIO? I believe it would be useful to add that in given its importance. \n\n5) The paper says that the metrics average over the posterior. I believe this is a problem with any metric. Are there alternatives that the authors propose?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces the Bayesian Causal Neural Process (BCNP), a novel approach for Bayesian causal discovery that leverages meta-learning to address challenges in traditional methods. BCNP learns a mapping from datasets to posterior distributions over causal graphs, thereby bypassing the need to explicitly infer the posterior over causal mechanisms and allowing for efficient sampling from high-dimensional spaces. By encoding key properties like permutation equivariance and edge dependencies, BCNP accurately approximates the true posterior and generates acyclic graph samples. The paper demonstrates BCNP's effectiveness through experiments on synthetic and semi-synthetic datasets, showcasing its superior performance compared to existing Bayesian and meta-learning models for causal discovery."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The paper is well-written and clear and includes a range of well-designed experiments."
            },
            "weaknesses": {
                "value": "For me, there are two major concerns regarding the novelty and contributions of the proposed method to the community:\n\n1. The paper presents the direct mapping from data to a posterior over graphs ($P(G|D)$) as a main advantage, bypassing the need to model causal mechanisms. However, learning a distribution over causal mechanisms is crucial for many applications, such as causal inference and treatment effect estimation [1, 2]. Could the authors elaborate on potential applications of the proposed approach beyond the discovery of the causal graph?\n2. The proposed method builds on several modules from existing work. For instance, the representation of the posterior distribution as permutation and upper triangular matrices is also similar to [3]. Although the method outperforms baselines in graph-based metrics in causal discovery, the specific novelty remains unclear, particularly given the first concern.\n\n[1] Emezue, C. C., et al. (2023). Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect Estimation. arXiv, 2307.04988. https://arxiv.org/abs/2307.04988v3\n\n[2] Sch\u00f6lkopf, B., et al. (2021). Towards Causal Representation Learning. arXiv, 2102.11107. https://arxiv.org/abs/2102.11107v1\n\n[3] Cundy, C., et al. (2021). BCD Nets: Scalable Variational Approaches for Bayesian Causal Discovery. arXiv, 2112.02761. https://arxiv.org/abs/2112.02761v1"
            },
            "questions": {
                "value": "1. As my main concerns, I would appreciate the authors to elaborate on the abovementioned weaknesses.\n2. Given that the proposed method does not utilize interventional data, using CPDAG E-SHD (as used in previous papers such as in BayesDAG) might be more reflective of the performance of the models compared with E-SHD.\n3. Have the authors tried any experiments on low data regime where the number of samples is close to the number of nodes? This is particularly important since Bayesian Causal Discovery is most desirable in low data regime where $n \\approx d$. Do you have an intuition about how the proposed model performs in these particular settings?\n4. In several experiments, other baselines such as BayesDAG and DiBS achieve a better E-SHD compared to the proposed method. Could you elaborate on why this happens?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}