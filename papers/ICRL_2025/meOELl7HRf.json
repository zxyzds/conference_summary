{
    "id": "meOELl7HRf",
    "title": "Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats",
    "abstract": "We propose Long-LRM, a generalizable 3D Gaussian reconstruction model that is capable of reconstructing a large scene from \na long sequence of input images. Specifically, our model can process 32 source images at 960$\\times$540 resolution within only 1.3 seconds on a single A100 80G GPU. Our architecture features a mixture of the recent Mamba2 blocks and the classical transformer blocks which allowed many more tokens to be processed than prior work, enhanced by efficient token merging and Gaussian pruning steps that balance between quality and efficiency. Unlike previous generalizable 3D GS models that are limited to taking 1$\\sim$4 input images and can only reconstruct a small portion of a large scene, Long-LRM reconstructs the entire scene in a single feed-forward step. On large-scale scene datasets such as DL3DV-140 and Tanks and Temples, our method achieves performance comparable to optimization-based approaches while being two orders of magnitude more efficient.",
    "keywords": [
        "3D Reconstruction"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "Enabling high-quality large-scene 3D Gaussian reconstruction in 1.3 seconds.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=meOELl7HRf",
    "pdf_link": "https://openreview.net/pdf?id=meOELl7HRf",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces Long-LRM, a feed-forward model for large-scale 3D Gaussian reconstruction that can process 32 high-resolution (960\u00d7540) input images in just 1.3 seconds on a single A100 GPU. The key innovation lies in its hybrid architecture combining Mamba2 and transformer blocks, along with efficient token merging and Gaussian pruning strategies to handle long sequences and memory constraints. The model achieves 600\u00d7 faster reconstruction than optimization-based 3D Gaussian Splatting while maintaining comparable or better quality, as demonstrated through comprehensive evaluations on DL3DV and Tanks and Temples datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Enhance feed-forward scene reconstruction methods, eg, GS-LRM to more input views.\n\n2. The usage of hyrbid network of Mamba and transformer is reasonable for handling extreme long-sequence tokens, though it is not the first paper in this field that introduce Mamba.\n\n3. Practical solutions for memory efficiency through token merging and Gaussian pruning, enabling scaling to high resolutions (960x540) where other variants fail.\n\n4. The ablation study is comprehensiev, well demonstrating the effectiveness of each component, with clear metrics on performance gains."
            },
            "weaknesses": {
                "value": "1. Lack of novelty. The core contribution of this paper seems a combination of GS-LRM and Hamba, Gamba  and MVGamba. \n\n2. The lack of discussion on the above Mamba-based 3D reconstruction models, which have been publicly available more than half years, is not acceptable.\n\n3. While this paper presents several practical innovations in memory optimization, it may be more suitable for computer vision conferences rather than ICLR."
            },
            "questions": {
                "value": "While the work on token merging and Gaussian pruning for memory efficiency is valuable, these engineering optimizations better fit computer vision venues like CVPR. Despite the technical advances,  could you justify how this work aligns with ICLR's focus on fundamental machine learning methodology rather than computer vision conferences?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed.",
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposed a generalizable 3D reconstruction framework for a long range of input images. 3D Gaussian Splatting is used as the 3D representation like many previous works. The network architecture is design as mixture of Mamba2 and transformer layers to process input tokens with long length.  The whole model is trained in single stage and can reconstruct large scale 3D secenes on DL3DV-140, Tanks and Template datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Extends the application of feed-forward 3D scene reconstruction to longer-range inputs.\n2. Sound network architecture design by combining transformers and Mamba2 to process long token sequences.\n3. Applies a token merging module to reduce computational overhead for processing long-range input views.\n4. The author provides justification for using Mamba in Table 2, although the comparison with GS-LRM is somewhat unfair."
            },
            "weaknesses": {
                "value": "1. Insufficient justification for using Mamba. GS-LRM claims it can accept arbitrary input view numbers by downsampling images with large patch sizes to shorten the overall token length for global attention. The features after attention can then be upsampled to predict a large number of Gaussians. However, in Table 2, the authors provide the same patch size for both the 7M1T and GS-LRM architectures, leading to an unfair comparison.\n\n2. Why not cost volumes and abadon 3D inductive biases. Although the authors have argued that methods like MVSplat are prone to out-of-memory (OOM) issues, these challenges are largely engineering problems that can be addressed with techniques like FlashAttention or through lightweight network architecture design. The authors need to clarify this point; otherwise, this work may mislead the feed-forward 3D scene reconstruction community.\n\n3. Lack of discussion on 3D reconstruction works utilizing Mamba. This work seems to overlook prior research utilizing Mamba for 3D reconstruction, such as Hamba, Gamba, and MVGamba, which have been publicly available for over six months. Discussing these related works is necessary to emphasize the motivation for this study.\n\n4. Limited technical contribution and insight. The technical contributions of this work are quite limited, as are its insights. It mainly extends previous 3D reconstruction efforts that use Mamba for scene reconstruction. Notably, combining Mamba and transformer blocks cannot be considered novel, as this setup was proposed in the Mamba v2 paper and has been widely adopted in various Vision Mamba works with Mamba v2. When evaluating the technical contributions, it is challenging to provide a positive rating, as nearly all modules in this paper have been widely used in numerous feed-forward 3D object reconstruction studies over the past year. Additionally, the claims regarding cost volumes contradict established practices in feed-forward 3D scene reconstruction.\n\nBased on the weaknesses outlined above, I think this paper is marginally below the acceptance threshold."
            },
            "questions": {
                "value": "please refer to the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "They propose a generalizable 3D Gaussian reconstruction model that can reconstruct a wide -coverage scene from a long sequence of input images with Mamba2 blocks. Some validation results shows the effeciveness compared with original 3DGS."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.Introducing a method able to infer the 3DGS for wide-coverage scenes.\n\n2.Utilize Mamba2 architecture to model the long token relations."
            },
            "weaknesses": {
                "value": "1.The comparison is not enough. Only compared with naive 3DGS. There are recent 3DGS/NeRF variants designed for large scale scene modeling: Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields, Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering, Mip-Splatting: Alias-free 3D Gaussian Splatting.\n\n2.Despite of the inference speed, it shows in the videos the floaters appear without further regularizations.\n\n3.They main contribution is to use Mamba2 for long sequence modeling, which limits the technical contribution of the paper.\n\n4.It is better to show the NVS comparison under sparse view setting compared with generalizable 3DGS methods like MVsplat and pixelSplat.\n\n5.The method only shows the NVS results, it would be better to show some surface reconstruction results since with the development of \"2DGS\" and \"High-quality Surface Reconstruction using Gaussian Surfels\". Nowadays surface reconstruction with Gaussians already achieves very good results.\n\n6.No regularization for aliasing effect is proposed."
            },
            "questions": {
                "value": "1.Is it able to seamlessly concat all sets of gaussians inferred by your models for large scale scenes which need hundreds of images? If so, how is it compared with city-scale reconstruction methods like CityGaussian and Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians, which are designed for real large scale scene reconstruciton."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}