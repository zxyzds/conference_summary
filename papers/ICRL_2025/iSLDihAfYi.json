{
    "id": "iSLDihAfYi",
    "title": "Sparsely multimodal data fusion",
    "abstract": "In order to create unified representations of multimodal data, masked multimodal transformer architectures use attention masking to constrain attention to occur between unimodal and fused intermediate representations. In this study, it is demonstrated that they can create an aligned embedding space when samples include only a fraction of data modalities. This is done by measuring the quality of generated embedding spaces as a function of modal sparsity. An extension to the masked multimodal transformer model is proposed which incorporates modal-incomplete channels in the multihead attention mechanism called modal channel attention (MCA). Two datasets with 4 modalities are tested, CMU-MOSEI for multimodal sentiment recognition and TCGA for multiomics. Models are shown to learn uniform and aligned embedding spaces with only two out of four modalities in most samples. It was found that, even with no modal sparsity, the proposed MCA mechanism improves the quality of generated embedding spaces, recall metrics, and subsequent performance on downstream tasks.",
    "keywords": [
        "multimodal",
        "representation learning",
        "contrastive",
        "transformer",
        "masked attention",
        "sentiment",
        "sparsity",
        "embedding space"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "Representation learning of multimodal data with improved rank and recall when samples have only a fraction of the set of modalities",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=iSLDihAfYi",
    "pdf_link": "https://openreview.net/pdf?id=iSLDihAfYi",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes a method called Modal Channel Attention (MCA) to enhance masked multimodal transformer models for learning from multimodal data, even in the presence of missing modalities. The approach extends existing masked multimodal attention (MMA) by incorporating channels for incomplete modalities, which significantly improves the quality of learned embeddings."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. It addresses the challenge of missing modalities.\n\n2. It extends the masked multimodal attention (MMA), improving its capability to handle incomplete data.\n\n3. Improves the quality of learned embeddings."
            },
            "weaknesses": {
                "value": "1. The contributions primarily emphasize performance improvements and extensions to the existing MMA. More detailed explanations of the specific contributions and the importance of the novelty would be beneficial.\u00a0\n\n2. The technical section is quite brief (half a page), and it would be helpful if the figure showing the architecture and self-attention provided more detail. Moreover, part of the technical section is devoted to describing the architecture by listing details like activations, hidden size, and the number of attention heads. However, no explicit motivations are provided for these choices. Additionally, the figures should have been more curated to avoid text pixelation. Given the current shape of the paper, the novelties seem to be present, but the paper fails to properly highlight them, relying mostly on an empirical evaluation."
            },
            "questions": {
                "value": "The paper suggests novel contributions, but they are not sufficiently highlighted. Can you expand on how MCA distinguishes itself from existing methods in terms of theoretical innovations or novel mechanisms, beyond empirical performance? Providing explicit motivations for architectural choices would also make the contributions clearer and more impactful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper is not ready for publication in ICLR"
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The topic is very interesting and important."
            },
            "weaknesses": {
                "value": "The presentation is poor."
            },
            "questions": {
                "value": "No"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "**Summary of this paper:**\n\nThis work proposes an extension to the masked multimodal transformer model which incorporates modal-incomplete channels in the multihead attention mechanism called modal channel attention (MCA).\n\n**Strengths:**\n\n1.\tThis paper addresses an interesting problem by extending the masked multimodal attention model architecture to work with modality-incomplete datasets, a common scenario in real-world applications.\n\n2.\tThe paper is straightforward.\n \n3.\tExperimental results demonstrate the effectiveness of the proposed method.\n\n**Weakness:**\n\nThere is no visual comparison between the proposed architecture and previous structures, which would help clarify the improvements and differences.\n\n**Comments, Suggestions And Typos:**\n\n1.\tIt is recommended to add a figure in the introduction to briefly introduce the task of this paper, or to add a figure somewhere to compare the proposed model architecture with previous MMA architecture.\n\n2.\tFigure 1 is not good-looking, the authors are encouraged to improve the quality of the figure.\n\n3.\tFor clarity and rigor, it is recommended to express important definitions or functions (i.e., modal sparsity) by formulas.\n\n4.\tThe citation formats for figures differ in this paper."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Refer to the summary"
            },
            "weaknesses": {
                "value": "Refer to the summary"
            },
            "questions": {
                "value": "Refer to the summary"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Traditional multimodal learning methods often assume that all modes are uniformly present in training and reasoning, which may be impractical in practical applications. To solve this problem, the authors propose a modal channel attention (MCA) model, which is an extension of the masked multimodal attention (MMA) approach. By integrating a dedicated attention mechanism, MCA achieves efficient fusion and embedding of multimodal data, even in the case of sparse modes. We evaluate MCA on the CMU-MOSEI and TCGA datasets, and the results show that MCA outperforms MMA in creating aligned, uniform embeddings with different modal sparsity. In downstream tasks such as multimodal sentiment analysis and tumor type prediction, MCA also shows higher recall rates and classification/regression performance, making it a versatile tool for real-world multimodal data fusion."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. MCA provides a novel method for dealing with modal sparsity in multimodal transformers, addressing a common limitation in multimodal learning. The approach enhances the MMA model by adding a modality-aware attention channel, innovatively allowing robust embedding creation from incomplete datasets.\n2. The study is rigorous, using two datasets (CMU-MOSEI and TCGA) to evaluate the model's effectiveness across varied tasks, including sentiment analysis and cancer classification. The experiments are thorough, with evaluations under multiple levels of modal sparsity and comparisons with established models.\n3. This model has important implications for real-world applications where complete multimodal data is often unavailable, such as in medical data analysis and surveillance systems. MCA enables more resilient model applications by tolerating missing modalities without significant loss of performance, thus broadening the scope of multimodal transformers."
            },
            "weaknesses": {
                "value": "1. This paper does not explore in depth the interactions between modes to further explore the specific impact of different combinations of modes on MCA model performance. You may wish to consider exploring whether particular combinations are more conducive to improving model performance in order to gain a fuller understanding of the relative importance of each mode.\n2. Although MCA is described as an efficient solution, this paper does not further quantify its computational efficiency and resource consumption on larger or more complex datasets to effectively assess the feasibility of its practical application.\n3. The attention mechanism of the MCA model in dealing with missing modalities is still complex and not easy to understand intuitively. I would like to see the interpretability of the model in applications, which would help build user trust in the model's decisions.\n4. The comparison experiments in this paper are limited to comparisons with the MMA model, which makes it difficult to fully demonstrate the relative strengths of the MCA model in multimodal approaches. You can evaluate the advantages and limitations of the MCA model more comprehensively by increasing the number of comparison experiments with multimodal methods other than MMA."
            },
            "questions": {
                "value": "1.\tIn the MCA model, are important modalities treated differently from minor modalities? Or are different modalities given different weights in the attention mechanism?\n2.\tAt which critical point does the performance of MCA significantly degrade as modal sparsity increases? Are there optimisation methods to maintain embedding quality at higher sparsity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a sparse multimodal fusion method in the presence of modal incompleteness. An extension to the masked multimodal transformer model is proposed which incorporates modal-incomplete channels in the multi-head attention mechanism called modal channel attention (MCA). The validity and usefulness of the method is verified by experiments on two multimodal datasets with different metrics and scenarios."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "* This paper demonstrates the importance of how to cope with representation learning in the case of incomplete modalities in real applications.\n\n* The authors provide extensive implementation details and interesting experiments to demonstrate the need for the proposed structure.\n\n* The authors' review of the relevant literature is well organized."
            },
            "weaknesses": {
                "value": "* This paper is clearly not ready for publication, including confusing typography, inadequate page counts for major sections, and formatting errors. For example, Fig and Figure are mixed up and line 221 is missing punctuation.\n\n* The experimental section focuses on the comparative analysis of different metrics. However, the authors lacked an effective comparison with previous work to highlight the advantages of the proposed methodology.\n\n* In addition, this study does not have enough qualitative analysis and ablation studies to explore the effect of different combinations of modal deletions in the proposed structure on performance."
            },
            "questions": {
                "value": "* As far as I know, CMU-MOSEI primarily provides information in three modalities, including audio, video, and text. I am not sure what exactly the four modalities the authors are referring to when they use them.\n\n* The core structure presented in this paper is very similar to previous work [1], leading to limited improvements and contributions. I suggest that the authors clarify the differences between them in detail to highlight their contribution.\n\n[1] Shvetsova, N., Chen, B., Rouditchenko, A., Thomas, S., Kingsbury, B., Feris, R. S., ... & Kuehne, H. (2022). Everything at once-multi-modal fusion transformer for video retrieval. In Proceedings of the ieee/cvf conference on computer vision and pattern recognition (pp. 20020-20029)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}