{
    "id": "H9plefjzuR",
    "title": "Transforming Ocean Analysis: Learning 4D ocean field from in-situ observations via uncertainty-aware implicit representations",
    "abstract": "A complete and accurate representation of Earth's time-evolving ocean field is crucial for understanding global warming as well as climate dynamics. However, the sparsity of current in-situ ocean measurements presents a significant challenge in estimating values in largely unobserved regions. Traditional methods, such as objective interpolation (OI), struggle with accuracy due to their reliance on discrete grids and fixed spatial correlation structures. In this paper, we propose a novel approach to reconstruct 4D ocean fields only from raw observations using implicit neural representations (INRs). Our method improves field representations by leveraging neural networks to capture continuous, complex, and nonlinear patterns inherent in ocean data. To address uncertainties in ocean measurements and the limited availability of daily observations, we incorporate uncertainty estimates and a meta-learning strategy into existing INRs. These innovations enable our approach to provide daily, resolution-free ocean temperature reconstructions, a significant improvement over  monthly averaged discrete fields. Experiments demonstrate the accuracy and adaptability of our method compared with approaches, establishing our method as a transformative solution for future ocean analysis and climate monitoring.",
    "keywords": [
        "implicit neural representation",
        "meta learning",
        "climate",
        "ocean gridded dataset"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "We propose a novel method to reconstruct ocean field from raw observations at a higher quality with uncertainty-aware neural network.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=H9plefjzuR",
    "pdf_link": "https://openreview.net/pdf?id=H9plefjzuR",
    "comments": [
        {
            "summary": {
                "value": "The authors use implicit neural representation (INR) to represent physical fields describing the dynamics of the evolution of ocean properties. The INR architecture is used, which simultaneously predicts both the mean and the variance to simulate uncertainty. The meta-learning approach based on fine-tuning the model using a dedicated test sample further improves the accuracy of the forecast. Based on a number of real data describing the properties of the ocean, the proposed method showed high accuracy of the forecast."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) the authors considered the problem statement, related to the restoration of the values of the physical field given partial measurements, which is important for practical applications\n\n2) the authors demonstrated that INR, in the case of processing data on various characteristics of the ocean, makes it possible to achieve a high quality forecast\n\n3) the authors conducted a fairly detailed experimental analysis of the properties of the proposed method based on data on ocean characteristics"
            },
            "weaknesses": {
                "value": "1) This work is not the first in which IN\u041a is used to model a physical system, fields of physical properties, see, for example, \n\nContinuous PDE Dynamics Forecasting with Implicit Neural Representations, ICLR 2023\nhttps://openreview.net/forum?id=B73niNjbPs\n\nContinuous Field Reconstruction from Sparse Observations with Implicit Neural Networks, ICLR 2024\nhttps://openreview.net/forum?id=kuTZMZdCPZ\n\nTherefore, from this point of view, this work is more application-driven rather than method-driven in the sense that the authors show how the existing INR-based approach with some additional modifications works when modeling fields of physical properties of the ocean.\n\n2) the description of the architecture of the model and the protocol for conducting experiments is not very detailed: for example, a) it is not clear how the dynamics of physical properties between observations at different moments in time is taken into account; b) the architecture of the branch of the neural network that predicts uncertainty is not clear; what benefit does this additional forecast bring? c) it seems that not all necessary baseline methods for comparison were considered - for example, a comparison with reconstruction methods based on tensor decomposition was not provided."
            },
            "questions": {
                "value": "1) Using INR the authors trained a separate model for each month (12 models in total). What is about the continuity of the transition from model to model between months? How to take dynamics w.r.t. time into account when constructing a model even for one month? How to guarantee smoothness of transitions between consecutive days? Neural Networks can have spurious oscillations so that transition can be not always physically plausible.\n\n2) How to evaluate quality of uncertainty estimate? Why do we need it? The authors did not provide any evidence of efficiency of the proposed uncertainty estimate. Moreover, if sigma is modelled is a separate NN branch which depends on input vector x, during training sigma can converge to zero, so the overall criterion in (5) will be not stable.\n\n\"Our approach here not only allows the model to represent the ocean field data but also provides data-driven uncertainty\nestimates, addressing limitation of INRs in this context.\" - Please, provide some evidence that these data-driven uncertainty\nestimates are useful in practice.\n\n3) 215-216: \"The inner-loop samples and optimises daily profiles on N days, while the outer-loop.\" - the sentence is not finished.\n\n4) 253:  \"we train a separate model for each month (twelve models in total).\" - this looks like too computationally intensive. Is it possible somehow to re-use results from previous months/days? Also, I propose to specify computational complexity of the proposed method and compare it with computational complexities of competing approaches. \n\n5) It is not clear why the authors did not incorporate any dynamics w.r.t. time when fitting the model to data inside the considered month.\n\n6) The authors proved that they can represent ocean physical fields using INR. How does efficiency of such representation influence any further downstream task? Is it possible to demonstrate effectiveness of the proposed approach based on some downstream task?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This article makes use of Implicit Neural Representation to model thd\ntemperature field of the ocean in 4 dimensions (latitude, longitude,\ndepth and time). The main contribution is to provide a fine-grained\nmodel at the temporal scale (1 day instead of 1 month in prior works)\nfrom only sparse measurement (that is real data available and not the\noutput of interpolation products) along with a prediction ability. With\nthe help of a few-shot learning technique, and contrary to usual INR\nmodels, the representation is not only viable for a given period of\ntime, but also for future days. An experimental validation compares the\nproposed method with traditional physical models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "A few existing techniques (INR, few-shot, uncertainty modeling) are\ncombined in a novel way for the modeling of the ocean dynamic. The most\ninteresting point for me is the combination of INR and few-shot learning\nto give the model a predictive ability. This overcome a limitation of\nINR which is to model only the state at a given time. Experiments are\nconvincing from the applied point of view but may be seen as limited for\na machine learning perspective. The overall structure of the article is\ngood enough."
            },
            "weaknesses": {
                "value": "The main problem of this article is the writing. Some parts are barely\nunderstandable. Section 3.1 is particularly problematic from this point\nof view: it is not clear if the training is made for 1 day or for all\nthe period, function names seems to change ($f$ and $g$). The meaning\nof | changes from Equation (1) to Equation (2) (given some points, then\ngiven a loss). The support of sums \u03a3 is not clear and change in\nunpredictable way (it is not enough to reuse letters from the previous\nlines to given an insight of the source of the terms). Another\nproblematic section is the Algorithm 1: the term \"Projection function\"\nwas not introduced before, the bold expression \"Inner loop\" and \"Outer\nloop\" are mislead since it qualifies the while loop and the for loop and\nnot the inside of the loop. About the uncertainty estimation, it's\nconfusing to see that in some parts the prediction target is a\nscalar and in another parts a distribution.\n\nI have the feeling that this work may not be adequately targeted to the\nmachine learning community.\n\nMisc remarks\n- lines 072 073: no idea of the meaning of tildas\n- subsection 3.2.3: make clear that this works for a fixed theta; \"while\n  the outer-loop\" a word may be missing; \"meat-learner\"\n- the acronym OI should be developed everywhere, since it is not space\n  consuming and not commonly known in the ML community\n- line 327 \"generalizes to unseen data\" should make clear you are\n  speaking of future days\n- All figures should be black and white proof and color-blind proof\n- Figure 2 is barely readable\n- lines 411-413: use of \"will\" is surprising"
            },
            "questions": {
                "value": "How is the uncertainty prediction evaluated ? I am usually not convinced\nby this kind of output. Is it supposed to model the uncertainty from the\nobservations or the uncertainty of the prediction ?\n\nUnlimited resolution provided by INR is interesting in theory, but I do\nnot see how to evaluate in practice. Figure 2 shows a non-local\nevaluation, but only with a broad view. Are you able to evaluate the\nquality at a sub-degree scale ? Or maybe to reconstruct some kind of\nfine grained structures (like eddies for example) ?\n\nFigure 1 show a shift of the error peak obtained by MARIN, could you\ncomment on this ?\n\nWhat about the prediction time of the model ? It's obviously more\ncompact than a big tensor storing all the field, but the tensor gives an\nanswer instantly. The network is relatively small so the prediction time\nshould not be a problem, right ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes MARIN, a novel method integrating implicit neural representations (INRs) with meta-learning to reconstruct 4D ocean temperature fields from sparse in-situ observations. The method addresses key challenges in ocean measurements, such as uncertainty estimations and data sparsity, by combining continuous implicit neural representations with meta-learning strategies."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "High utility, relevance, and novelty.\n\nIncorporates uncertainty estimates to handle measurement errors."
            },
            "weaknesses": {
                "value": "The results are preliminary, not a lot of validation is there. The analysis is not very detailed.\n\nTime averages are good, but it would be good to see how differences manifest in instantaneous fields. This is a key problem with ocean or atmospheric mesoscales, too; RMSE does not always capture the small scales well.\n\nLack of clarity in the detailed methodology, particularly in the implementation of meta-learning and uncertainty estimation.\n\nHow about statistically downscaling (with the aid of climate models) to get provide accurate measurements over smaller grid scales than sampled?\n\nReproducibility issues- I don't find clarity in terms of model parameters and training, they have discussed for SIREN though."
            },
            "questions": {
                "value": "How well MARIN could replicate the Kinetic energy spectrum of the atmosphere  - and compare it with previous estimates. KE spectrum is an important quantity to measure and get right. Replicating mean is easy.\n\nMore details on the implementation of meta-learning and uncertainty estimation?\n\nOcean mesoscales drive a majority of the heat transport, so the small-scale differences in atmospheric fields might be important. In the same spirit, can authors really replicate a float trajectory and get similar measurements?\n\nHow does the proposed meta-learning framework specifically contribute to the improvements in reconstruction accuracy?\n\nHow about statistically downscaling (with the aid of climate models) to get provide accurate measurements over smaller grid scales than sampled?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper deals with the data assimilation problem in oceanography, where the aim is to reconstruct the ocean field from sparse observations. The authors propose a deep learning model for this problem based on implicit neural representations, and cast the data assimilation problem as a few-shot meta-learning training objective. The learning model is evaluated on real-world a large time period."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Data assimilation is an important problem, especially for the ocean where the number of observations is typically very low. This problem is well motivated in the paper, with its implications tied to climate change.\n\nThe meta-learning framework is clearly introduced. Neural fields are a promising learning architecture for the data assimilation problem, as they allow to model the geophysical state with a continuous parametric function of space.\n\nExperiments are conducted on real-world data and the proposed method demonstrates competitive results in terms of reconstruction error, at different ocean depths and for different time periods.\n\nThe computational cost of the method is studied. Since implicit neural representations parametrize the unknown state as a parametric function of space, they offer a resolution-agnostic representation of the physical field, leading to considerable computational savings, as pointed out in Section 4.3. This is a significant advantage of using neural fields over other grid-based neural representations. \n\nAblation studies support the relevance of using meta-learning, and study the effect of the model architecture on performance."
            },
            "weaknesses": {
                "value": "My main concern is that this paper does not properly present the reconstruction problem under study, with no mention of \"data assimilation\" or \"optimal interpolation\". I feel that the authors may be misusing the term \"objective interpolation\", in place of \u201coptimal interpolation\u201d.The paper also lacks reference to the state-of-the art techniques in this field, including 3D-Var, 4D-Var and Kalman filters. In the \"Competing methods\" paragraph, the authors mention the datasets but not the interpolation techniques used, which is ultimately what they compare against. This lack of precision makes it difficult to assess the submission's contribution.\nI suggest that the authors explicitly compare their method with traditional state-of-the-art data assimilation methods and recent deep-learning-based approaches [1, 2, 3]. \n\nIf I understood correctly, the proposed method consists in applying MAML to ocean data,treating different days as tasks to predict, and with the last layer predicting a Gaussian distribution rather than a scalar prediction.. Given that the primary novelty lies in predicting a distribution rather than simply a field, I believe more insight should be provided on the method\u2019s uncertainty quantification capabilities, which are mentioned but not well illustrated. How does the proposed method lend itself to building confidence intervals, or to sampling from a posterior predictive distribution? Can uncertainty quantification be illustrated on a toy example, and compared with the existing methods?\n\nAt test time, only a single gradient step is performed to adapt the network, as mentioned in Algorithm 2. Why not more? In meta-learning, while the number of inner gradient steps is often chosen to be 1 at training time for computational reasons, it can be larger at prediction time. Further, the adaptation procedure of Algorithm 2 where the ocean state is reconstructed by tuning the model parameters should be compared with that of traditional variational data assimilation, where the state is reconstructed by maximizing the posterior likelihood.\n\nIs it relevant to train 12 separate models\u2014one per month, as indicated on line 251? Why not train a single global model using all available data? Additionally, it would be useful to discuss how the temporal dimension of the signal is handled. If I understand correctly, the proposed neural fields are functions only of space, with time treated as multiple independent tasks across days. What if there are observations at different times within the same day? Could the model incorporate time correlations by introducing a time variable or embedding in the architecture?"
            },
            "questions": {
                "value": "The meaning of \"Projection function\" in Algorithm 1 is unclear.\n\nThere are a number of clarity issues and typos in the paper. \n\n### References \n \n[1] Fablet, R., Huynh Viet, P., Lguensat, R., Horrein, P. H., & Chapron, B. (2018). Spatio-temporal interpolation of cloudy SST fields using conditional analog data assimilation. Remote Sensing, 10(2), 310.\n\n[2] Blanke, M., Fablet, R., & Lelarge, M. (2024). Neural Incremental Data Assimilation. arXiv preprint arXiv:2406.15076.\n\n[3] Rozet, F., & Louppe, G. (2023). Score-based data assimilation. Advances in Neural Information Processing Systems, 36, 40521-40541."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents MARIN, a model for reconstructing 4D ocean temperature fields from sparse in-situ data by combining implicit neural representations with meta-learning and uncertainty estimation. MARIN treats ocean temperatures as a continuous function, extending INRs to predict both mean and variance for added uncertainty assessment. Although it adapts these techniques for real-time ocean analysis, the model\u2019s design largely relies on existing INR and meta-learning frameworks, without substantial advancements in core architecture. Limited novelty lies in this application."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Unlike objective interpolation methods that rely on predefined grids, MARIN models the ocean temperature field as a continuous function\n- To account for data noise and uncertainty in ocean observations, MARIN extends the INR to predict both the mean and variance of temperature."
            },
            "weaknesses": {
                "value": "- MARIN uses implicit neural representations without significant architectural advancements. Improved geospatial encoding or spherical coordinate modeling [1,2,3], rather than reliance on standard baselines not optimized for sparse data, could enhance its performance.\n- MARIN captures only aleatoric uncertainty, omitting epistemic uncertainty, which is critical for complex, sparse data. Including both types would provide a more comprehensive uncertainty analysis.\n\n1. Kim, H., Jang, Y., Lee, J. and Ahn, S., Hybrid Neural Representations for Spherical Data. In Forty-first International Conference on Machine Learning.\n2. Mai, G., Lao, N., He, Y., Song, J. and Ermon, S., 2023, July. Csp: Self-supervised contrastive spatial pre-training for geospatial-visual representations. In International Conference on Machine Learning (pp. 23498-23515). PMLR.\n3. Bonev, B., Kurth, T., Hundt, C., Pathak, J., Baust, M., Kashinath, K. and Anandkumar, A., 2023, July. Spherical fourier neural operators: Learning stable dynamics on the sphere. In International conference on machine learning (pp. 2806-2823). PMLR."
            },
            "questions": {
                "value": "- MARIN\u2019s design overlooks temporal dynamics, which seems surprising for modeling something as continuously evolving as ocean temperatures. Including these effects could enhance its performance, and comparing it with models [1] that do account for temporal dynamics would clarify how much this omission impacts results.\n - Using negative log-likelihood for uncertainty can sometimes miscalibrate variance, especially with extreme noise. I suggest testing MARIN across varying noise levels to show how reliable its uncertainty estimates truly are.\n- Current experimental settings seem a bit confusing to me. Could you report whether MARIN\u2019s uncertainty estimates hold up consistently across different data splits, particularly with random splits?\n- I wonder if a simpler adaptation approach, like daily fine-tuning without meta-learning, could yield similar results. An ablation study comparing this with the current meta-learning approach would help determine if meta-learning is truly essential for MARIN\u2019s reported performance.\n\n1. Williams, J.P., Zahn, O. and Kutz, J.N., 2024. Sensing with shallow recurrent decoder networks. Proceedings of the Royal Society A, 480(2298), p.20240054."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}