{
    "id": "GjSstLcxAs",
    "title": "Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness",
    "abstract": "The applications of large language models (LLMs) have been widely spread across all domains. \nHowever, the basic abilities such as the controllability of LLMs are still limited.\nTo address this, we propose \"$\\textbf{Self-controller}$\", a novel agentic framework bringing self-awareness into LLMs\u2019 reasoning logic.\nThe core idea of this work is to maintain states based on the LLM's response, letting the LLM become self-aware of current status and think step by step in a multi-round chain-of-thought paradigm. \nOur experiment on the state of textual length has shown the controllability and effectiveness of the Self-controller. We further implement a binary search algorithm to accelerate the generation process based on the linearity and monotonicity of the textual length state. Another advantage of the Self-controller comes with DeepSeek's Context Caching technology, which significantly saves computational token consumption when a cluster of conversations shares the same prefix of context. Theoretically, we prove that in this scenario the extra time complexity is  $O(c \\log n)$. Results of the back-of-the-envelope estimation suggest that the token consumption of our method is no more than twice as much as that of the trivial single-round generation. Furthermore, our ablation study on word constraints demonstrates the Self-controller's consistent controllability across all foundation models.",
    "keywords": [
        "large language models",
        "self-awareness",
        "agent",
        "controllability"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "A multi-round reflection-based frame enhancing controllability in LLMs, making them self-awareness of their current status.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=GjSstLcxAs",
    "pdf_link": "https://openreview.net/pdf?id=GjSstLcxAs",
    "comments": [
        {
            "summary": {
                "value": "The authors present Self-controller, a multi-round prompting approach to more efficiently guide LLMs to generate text with length constraints. The authors claim their framework can improve the self-awareness and self-control of LLMs.\n\nThe authors apply Self-controller on the task of length-constrained text generation, but not to any other tasks, and so it is not known whether their approach would generalize to other tasks and actually improve the self-reflection of LLMs more generally. How does high performance on this task imply self-awareness? Wouldn't multi-round prompting without binary search alone be sufficient to demonstrate \"self-awareness\"?\n\nThe prompting approach is described as a binary search, but this analogy isn't very clear: What is the item that the search algorithm is aiming to find?"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The authors present a new prompting approach that guides LLMs to more accurately meet the length constraint in a length-constrained generation task.\n- The proposed method is relatively simple and could theoretically be extended to other tasks that would benefit from the model's awareness of task state information."
            },
            "weaknesses": {
                "value": "- The claim that the proposed approach facilitates self-reflection is overly broad. The authors only demonstrate an improvement on the task of length-constrained generation, and it is not known to what extent their results generalize to other tasks that benefit from self-reflection.\n- The cost model is assumed to be that of an LLM service via an API, where the cost of each prompt is given by the number of input tokens plus output tokens (possibly with each input token being more/less expensive than an output token). But this is not explicitly stated, and there is no comparison to the cost in a local setting, where the model's cost is more determined by the number of forward passes.\n- The prompting approach is described as a binary search, but this analogy is unclear/imprecise."
            },
            "questions": {
                "value": "More detailed feedback is listed below. I also include grammatical and stylistic errors but only for the first two sections, and this list is not comprehensive, so I strongly encourage the authors to carefully re-read the manuscript and correct all similar errors. Research questions/comments about the content for all sections are included below.\n\nLine 29: \"Humans are constantly troubled with self-control issues.\"\n  How so? Example? Citation?\n\nGeneral: (minor) Use `` for left double quotation marks rather than \".\n\nLine 33: \"The experimental results imply that\nwithout accurate reward assessment, the actions of human beings might converge to a local optimum\"\n  How so? Do all children end up picking one option if the delay is not set appropriately?\n\nLine 37: Adam and Eve, being non-historical figures, don't really serve as good supporting evidence for the claim that self-awareness is important in human intelligence.\n\nLine 37: \"realizes\" -> \"realize\" (grammatical number agreement)\n\nLine 40: \"building self-awareness upon LLMs\"\n  It isn't totally clear what the precise definition of self-awareness and self-control is.\n\nLine 49: \"DeepSeek\u2019s Context Caching\"\n  Needs citation.\n\nLine 50: \"extra time complexity is O(c log n)\"\n  What is c? What is n?\n\nLine 101: \"the accurate output manipulation\" -> \"accurate output manipulation\" or \"the accurate manipulation of output\"\n\nLine 108: \"the web search\" -> \"web search\"\n\nLine 145: \"initiative of the state reflector\"\n  What does \"initiative\" mean here?\n\nSection 3.3 and Figure 3: What does \"consumption\" mean here? What is the cost measured in, here? Number of prompts? Number of forward passes/FLOPs? Reading further, I think the cost is in terms of the numbed of input and output tokens (as would be charged in the use of an API for an LLM). But would there be any difference in cost if the LLM is running locally (i.e., in terms of number of forward passes)? I think further clarification is required, as well as a comparison with the cost in the non-API setting.\n\nWhy only test on text lengths between 800 and 1200? Why not try much shorter and longer lengths? Similarly, why not try shorter lengths in the binary search experiments?\n\nAre there any experiments validating the use of BERTSCORE in this task? For example, human evaluation of a subsample of outputs?\n\nTable 2: Why not compare binary-search with multi-round?\n\nLine 423: \"dawn of reasoning\"\n  This is highly vague and abstract. I assume the authors are referring to the time at which prompting methods were developed that significantly enhanced LLM performance on reasoning-intensive tasks. I strongly suggest re-wording and avoiding the use of \"dawn.\"\n\nLine 427: \"near-infinite\"\n  Though context sizes have increased, they are still quite a ways off from infinite. If what was intended was that the context size is sufficiently large for most inputs, then I suggest rewording this to be more descriptive, and avoiding comparisons to infinity."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors propose a novel framework called Self-controller for length control in LLMs. The main idea in the paper is is to maintain states based on the LLM\u2019s response, letting the LLM become self-aware of current status and think step by step in a multi-round chain-of-thought paradigm. More specifically, the framework comprises a state reflector and a multi-round dialogue session with LLMs. The reflector engages with LLMs in each round and provides state information on precise statistics of the textual length. Based on the linearity and monotonicity of the textual length state, the authors propose a binary search optimization to achieve efficiency. The authors also obtain theoretical guarantees for the extra time complexity."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Strengths:\n\n1.\tThe use of a binary search algorithm combined with the state reflector for length control shows an effective approach for optimizing response generation in LLMs.\n\n2.\tContext caching method reduces the cost for multi-round sessions, increasing the real-world applicability."
            },
            "weaknesses": {
                "value": "Weaknesses:\n\n1.\tIt seems like the weaker models such as GLM4-flash and GLM-4-air do not benefit much from the proposed multi-round strategy.\n\n2.\tThe methodology is novel, however, I believe the contribution is not enough for an ICLR acceptance. Please see the question below."
            },
            "questions": {
                "value": "Questions:\n\n1.\tCan authors elaborate on the novelty of their method as compared to the existing length control baselines? Is the state reflector module the main novelty?\n\n2.\tCan authors elaborate a little bit more on the hypothesis mentioned in row 276? What is the purpose of this hypothesis?\n\n3.\tWhy is it that the weaker models such as GLM-4-flash and GLM-4-air do worse in multi-round than in the single round? (See Figure 4)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents Self-controller, a novel framework for improving the controllability of large language models by incorporating self-awareness into their reasoning processes. The framework maintains state variables and iteratively refines outputs through multi-round dialogue sessions, allowing LLMs to adjust their responses dynamically. It also leverages a binary search algorithm for textual length control, enhancing efficiency in generating content of a specific length. Furthermore, the DeepSeek\u2019s Context Caching technology is integrated to optimize token consumption, reducing computational overhead. The framework demonstrates effectiveness in controlling text length across various datasets and models without significant degradation in text quality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The Self-controller introduces a novel idea by applying self-awareness mechanisms to control LLM behavior in a multi-round step-by-step manner. \n2. The paper offers a detailed explanation of the methodology and providing empirical evidence of the system\u2019s effectiveness across different models and datasets.\n3. The paper is generally well-written and structured, with clear diagrams and explanations."
            },
            "weaknesses": {
                "value": "1. This paper lacks of the comparison with other baselines. The authors need to add more baselines (as described in related work) to compare, this could better show the effectiveness of the proposed method.\n2. This paper lacks of the qualitative examples demonstrations, which could make the reader better understand the task and method. I suggest the authors put some examples to the appendix at least."
            },
            "questions": {
                "value": "The double quotation marks looks strange in the paper, the author may change the double quotation marks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes 'self-controller,' a new framework that brings self-awareness into LLMs' reasoning logic. Specifically, the authors use multiple rounds of conversations to make the output length of LLMs more controllable. In addition, a binary search algorithm is implemented along with DeepSeek's context caching technology to reduce the complexity of the proposed method. Experimental results show that the proposed methods can better control the output length without significant textual quality loss."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This method can effectively control the output length of LLMs."
            },
            "weaknesses": {
                "value": "1. I feel this paper is over-claiming. Controllability of LLMs is a very broad research topic, but the study in this paper mainly focuses on controlling the output length of LLMs, which is a very small part of this research area. This narrows down the applications of the proposed methods to other areas, such as sentiment control, keyword control, etc.\n\n2. There are basically no baselines except for the trial single-round baseline. Again, more controllability aspects of LLMs should be studied to demonstrate the effectiveness of the proposed methods."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}