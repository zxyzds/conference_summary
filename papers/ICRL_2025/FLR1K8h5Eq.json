{
    "id": "FLR1K8h5Eq",
    "title": "Learning Time-shared Hidden Heterogeneity for Counterfactual Outcome Forecast",
    "abstract": "Forecasting counterfactual outcome in the longitudinal setting can be critical for many time-related applications. To solve this problem, the previous works propose to apply different sequence models including long short-term memory (LSTM) networks and transformers to model the relationship between the observed histories, treatments and outcomes, and apply various approaches to remove treatment selection bias. However, these methods neglect the hidden heterogeneity of outcome generation among samples induced by hidden factors which can bring hurdles to counterfactual outcome forecast. To alleviate this problem, we capture the hidden heterogeneity by recovering the hidden factors and incorporate it into the outcome prediction process. Specifically, we propose a Time-shared Heterogeneity Learning from Time Series (THLTS) method which infers the shared part of hidden factors characterizing the heterogeneity across time steps with the architecture of variational encoders (VAE). This method can be a flexible component and combined with arbitrary counterfactual outcome forecast method. Experimental results on (semi-)synthetic datasets demonstrate that combined with our method, the mainstream models can improve their performance.",
    "keywords": [
        "Hidden Heterogeneity; Counterfactual Outcome Forecast; Time series"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=FLR1K8h5Eq",
    "pdf_link": "https://openreview.net/pdf?id=FLR1K8h5Eq",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a Time-Shared Heterogeneity Learning from Time Series (THLTS) approach for Counterfactual Outcome Forecasting, addressing the limitation in previous sequential models caused by insufficient consideration of hidden heterogeneity in sample outcomes caused by hidden factors. Extensive experiments demonstrate the effectiveness of THLTS, as well as its robustness in scenarios with unstable hidden factors or long sequence data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.This paper addresses the high relevance between decision-making tasks and temporal sequences, thoroughly analyzing the limitations of previous methods in modeling hidden factors beyond historical records. Leveraging a Variational Autoencoder (VAE), it creatively proposes a Time-Shared hidden factor learning approach to effectively bridge these gaps, demonstrating both originality and significance in the field.\n\n2.This paper begins by presenting intuitive examples to illustrate how hidden factors can lead to different counterfactual outcomes for individuals with identical historical information. It then introduces the proposed THLTS method in a progressively detailed manner, followed by a rigorous theoretical derivation to analyze the validity of this hidden factor learning approach. Subsequently, the paper provides a detailed description of the three key components that enable THLTS, as well as its training and inference processes. The logic is coherent.\n\n3.This paper conducts comprehensive experiment, validating the effectiveness of THLTS and its flexibility as a plugin of pioneering models, particularly under conditions of unstable hidden factors and long sequence data."
            },
            "weaknesses": {
                "value": "1.Clarity issues in some details. This is evident, on one hand, in the mismatch between figure legends and definitions in the text. For example, in the problem description, sample indices are indicated as superscripts, yet in Figure 1, sample indices for each latent factor are shown as subscripts, which potentially confuses them with time indices. On the other hand, some symbols lack explicit explanations; for instance, m in Equation (5), while seemingly representing the number of repetitions for sampling Time-Shared Hidden Factors and outcome prediction, would benefit from explicit clarification to enhance understanding.\n\n2. Lacking sufficient background information. It particularly in explaining of VAE. For readers unfamiliar with variational inference, it may be challenging to understand how to model and sample the Time-Shared Hidden Factors.\n\n3. The experiments are not sufficiently extensive. On one hand, the experimental data heavily relies on synthetic datasets, which significantly reduces the persuasiveness of the results and raises concerns about the practical applicability of the model. On the other hand, the choice of comparison baselines appears to lack novelty, as the most recent baseline, G-net, was proposed in 2020. Exploring and discussing more recent methods to highlight the contribution of this study would be beneficial."
            },
            "questions": {
                "value": "Q1: One argument in the paper posits that the modeling approach using Time-Shared Hidden Factors across all time steps for each sample is superior to previous methods that model hidden factors differently at each time step. This claim may appear somewhat counterintuitive and perplexing. Beyond the empirical conclusions drawn from experiments and the potential rationale of limited supervisory signals, is there a more comprehensive explanation or theoretical justification to alleviate this concern?\n\nQ2: In the experiments, synthetic datasets were used. Firstly, does the synthetic method employed in the paper generate data that aligns with real-world distributions? Is this synthetic approach a standard in the field or a heuristic design by the authors? Furthermore, do the experimental results based on these datasets have practical significance? How is this demonstrated or substantiated?\n\nQ3: There are some clarity-related concerns. Firstly, the learning of Time-Shared Hidden Factors is based on VAE, which is not reflected in the overall illustration in Figure 2. While appropriate simplification is essential, would incorporating the VAE structure into the diagram help readers better understand the model architecture? Additionally, in Section 4.3, could the mathematical description of L_t^((i)) be streamlined to aid readers in comprehending the model implementation? For instance, specifying that the KL divergence term involves the normal distributions corresponding to two contiguous time steps if correct."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper tackles the challenge of forecasting counterfactual outcomes in longitudinal settings. Previous methods using LSTM networks and transformers often neglect hidden heterogeneity caused by unobserved factors, which complicates predictions. The authors propose the Time-shared Heterogeneity Learning from Time Series method, which captures shared hidden factors using variational encoders. This approach enhances any counterfactual forecasting method and demonstrates improved performance in experiments with synthetic datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Forecasing counterfactual prediction is highly applicable in real-world scenarios.\n2. The time-shared heterogeneity based learning method is easy to implement with VAE.\n3. This paper first utilizes longitudinal method to find the latent factor of each sample, which is intuitive."
            },
            "weaknesses": {
                "value": "1. In Proposition 4.1, it would be helpful for the authors to explain more about when the prediction model $g$ is Lipschitz with respect to $e$, as this is critical for ensuring the model's effectiveness in identifying the latent factor.\n2. Since the latent factor is not directly observed, how can you guarantee that the latent factor identified by your method is the one you intend to find? It would be beneficial to provide some analysis regarding the identifiability of your method.\n3. Why did you choose VAE to implement your method? Could other structures, such as deterministic models, serve as the backbone? If so, is it possible to test different models as backbones in the experimental section?\n4. The compared baselines are not state-of-the-art methods. It would be better to select more recent methods as baselines to demonstrate the effectiveness of your approach, such as [1].\n\n\n\n[1] Estimating Counterfactual Treatment Outcomes over Time through Adversarially Balanced Representations. ICLR 2020."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Time-shared Heterogeneity Learning from Time Series (THLTS), a novel method for capturing hidden heterogeneity in longitudinal counterfactual outcome prediction. THLTS, designed as a flexible component that can be integrated with existing models, learns time-shared latent factors using VAE architecture."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.The motivation is well-presented, which helps contextualize the problem being addressed.\n\n2.The proof in Section 4.2 logically explains the motivation for employing a VAE architecture, making the rationale clear and reasonable.\n\n3.Comprehensive experimental evaluation demonstrates performance improvements"
            },
            "weaknesses": {
                "value": "1.The paper lacks novelty. The idea of recovering hidden factors has been widely explored in previous research. While learning the \"TIME-SHARED\" components is not as commonly discussed, but it is not significantly different from previous work, like Causal Effect Inference with Deep Latent-Variable Models\" (Louizos et al., 2017),Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data\" (Bouchattaoui et al., 2023) and Factual Observation based Heterogeneity Learning for Counterfactual Prediction\" (Zou et al., 2023).\n\n2.While the paper mentions that \"decision-making problems can span long periods of time,\" it does not introduce any specialized structures to capture unique features of long time series, such as periodicity or seasonality. For example, incorporating techniques like Fourier transforms for periodicity detection or wavelet transforms for handling multi-scale temporal structures could offer substantial improvements.\n\n3.Despite claiming to address long-term time series forecasting, the paper only validates its method on notably short sequences (maximum 30 time steps)."
            },
            "questions": {
                "value": "What are the unique challenges of addressing hidden heterogeneity across time?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}