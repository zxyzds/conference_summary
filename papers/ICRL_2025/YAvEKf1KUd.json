{
    "id": "YAvEKf1KUd",
    "title": "Incorporating Neural ODEs into DAE-Constrained Optimization Problems",
    "abstract": "Differential algebraic equations (DAEs) are pivotal in dynamic optimization across diverse fields, from process control to flight trajectory optimization and epidemiological modeling. Traditional methods like single shooting, multiple shooting, and direct transcription effectively optimize known mechanistic models. However, significant challenges arise when the underlying equations are unknown or deviate from empirical data. While black-box optimization strategies can address some issues, challenges persist regarding data quality, non-linearity, and the inclusion of constraints. Recent advances in machine learning, particularly Neural ODEs, offer promising tools for continuous representation of dynamic systems. This work bridges the gap between machine learning representations of dynamic systems and optimization methodologies, enabling a novel approach for solving DAEs with data-driven components. We demonstrate this approach using numerical examples of DAE problems and realistic case studies, including  biochemical reactor control and disease spread prevention. Our results highlight the efficacy of incorporating Neural ODEs into equation-based solvers, showing improved performance over existing strategies such as SINDy. Additionally, we formalize the optimization program for NN-embedded DAEs and present representations for common neural network architectures (e.g., ReLU, tanh). This work contributes a novel framework for dynamic system optimization, integrating machine learning advancements with traditional optimization techniques, and offers practical insights through comprehensive case studies.",
    "keywords": [
        "Differential Algebraic Equations",
        "Neural Ordinary Differential Equations",
        "Dynamic Optimization",
        "Hybrid Modeling"
    ],
    "primary_area": "optimization",
    "TLDR": "This paper presents a novel approach to solving DAE-constrained optimization problems by incorporating Neural Ordinary Differential Equations, demonstrating enhanced performance through realistic case studies in various dynamic systems.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=YAvEKf1KUd",
    "pdf_link": "https://openreview.net/pdf?id=YAvEKf1KUd",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses optimization challenges in dynamic systems governed by differential-algebraic equations (DAEs), which are widely applied in fields such as process control, flight optimization, and epidemiology. Traditional optimization methods, like single shooting, multiple shooting, and direct transcription, work well with known mechanistic models but struggle when models are incomplete or don\u2019t match empirical data. This paper integrates machine learning with DAE optimization by embedding Neural ODEs into the optimization process. Numerical examples include biochemical reactor control and epidemic modeling. The authors compare this method against  Sparse identification of non-linear dynamics (SINDy) method. The study also formalizes an optimization framework for DAEs with neural network components and introduces representations for standard neural network architectures."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This is an interesting paper about integrating algebraic constraints into neural ordinary differential equations. I believe the authors pose an important research question."
            },
            "weaknesses": {
                "value": "Formal aspects:\n- there are typos in the paper or missing lines - see line 094\n- authors should use both \\cite and \\citep as appropriate\n- some figures do not include units, some lack axis labels \n\nPrior work:\n- the authors do not cite many similar publications from the recent literature. I encourage authors to search for keywords such as neural DAEs, or physics-informed neural networks for DAEs\nSuggested related works include:  \nhttps://link.springer.com/article/10.1007/s00521-022-07886-y  \nhttps://ieeexplore.ieee.org/document/10669810  \nhttps://ieeexplore.ieee.org/document/9844253  \n\nTechnical aspects:\n- the limitations of this work are missing\n- the collocation method presented in section 2.2 is not novel in itself \n- the case studies are very simple, low-dimensional academic examples that can be easily solved with existing tools\nI encourage the authors to benchmark the proposed method against state-of-the-art DAE solvers, for instance, those in Julia and Matlab  \nhttps://docs.sciml.ai/DiffEqDocs/stable/tutorials/dae_example/  \nhttps://www.mathworks.com/help/matlab/math/solve-differential-algebraic-equations-daes.html  \n- the paper fails to convince that it presents state of the art method dealing with problems that are currently beyond the reach of existing methods"
            },
            "questions": {
                "value": "What type of DAE systems can tackled with the proposed method? The discussion on stiffness, and index of the DAE would be very valuable for the reader.\nThe comparison with SINDY is poorly motivated and seems a bit arbitrary; why not compare it with other nonlinear system identification techniques, such as the deep Koopman operator method or neural state space models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a learning-based approach for solving differential algebraic equations (DAE) with data-driven components. It shows that pretrained neural ODE models can be integrated within an optimization problem with dynamic constraints which take the form of differential equations, by using collocation-based methods. In this setting, neural ODEs replace traditional numerical differential solvers, which can suffer of data quality, e.g. noise, partially unknown dynamic model and non linearities."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "In settings where the dynamic model is partially unknown and/or when only data are available, neural ODEs model can effectively substitute a numerical differential solver, which would be incompatible."
            },
            "weaknesses": {
                "value": "The contribution lacks novelty in both methodology and technicality. Neural ODEs are well known to be able to capture the system dynamics from data [1]. While the authors recognize that in data-driven settings neural ODEs can be preferable over traditional numerical differential solvers, in my view it does not constitute enough contribution. The whole paper is based upon this sole idea, and as such it inevitably lacks of technicality. Section 2.2, which is the core section of the paper, as it formalizes how the system dynamic equations can be written using neural ODEs for use in a collocation-based method, provides only a simple example of how that can be done, lacking of generality. \n\n[1] P.Kidger, On Neural Differential Equations, arxiv.org/abs/2202.02435"
            },
            "questions": {
                "value": "Since I think that the authors' idea lacks of novelty for a contribution, in my view it is difficult to significantly improve this paper, but the current structure could be nonetheless improved: as anticipated above section 2.2 needs to provide a much more solid framework for using NODEs in a collocation based method in data-driven setting, which would strength the paper. The paper dedicates much attention to the impact of different hyperparameterization and training aspects of NODEs on how the dynamics are captured, but in my opinion it does not provide a valuable aspect, given that hyperparameters tuning is also a common practice in ML."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces NODEs as surrogates for constrained dynamic optimization problems, and numerically tests their effectiveness on several study cases, showing improved performance over existing strategies such as SINDy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The overall clarity and simplicity are good."
            },
            "weaknesses": {
                "value": "1. The significance of contribution.  The idea of using a neural network as a surrogate in control is not novel. What is the necessity and contribution of using a particular network architecture (i.e. NODE) in control problems?\n1. The quality of baselines. The only compared baseline is SINDy, which is designed mainly for symbolic discovery but not for dynamics modeling or control. Does the proposed NODE model also have the ability to discover symbolic expression? If not, then SINDy might not be a suitable baseline. Maybe the commonly used network architectures such as MLP/ResNet/Transformer are the counterparts of NODE."
            },
            "questions": {
                "value": "See the 'Weaknesses' part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper \"Incorporating Neural ODEs into DAE-Constrained Optimization Problems\" presents a framework that integrates Neural Ordinary Differential Equations (NODEs) with differential-algebraic equation (DAE) constrained optimization. The authors address the challenge of optimizing dynamic systems when underlying equations are unknown or partially known, by using NODEs as data-driven surrogates for the system dynamics.\n\nThrough a series of case studies, ranging from biochemical reactors to epidemiological modeling, the paper demonstrates how NODE-ADOpt can effectively solve complex, non-linear optimization problems. The authors also compare their approach with existing methods like SINDy and black-box optimization techniques, highlighting scenarios where NODE-ADOpt outperforms these strategies."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The framework removes limitations from prior optimization strategies by allowing the incorporation of data-driven components, which can be particularly useful when dealing with complex, non-linear, and noisy systems.\n- Multiple experiments are conducted to validate the proposed method, and the results are systematically compared with existing approaches like SINDy and black-box optimization. This comparison highlights the advantages and performance improvements achieved by the proposed framework\n- The framework's ability to outperform existing strategies under certain conditions makes it a promising candidate for real-world applications, offering both improved performance and flexibility."
            },
            "weaknesses": {
                "value": "- Broaden the literature review to include a more comprehensive discussion of alternative approaches, particularly those that integrate machine learning with optimization. Highlight where NODE-ADOpt stands in relation to these methods, its unique advantages, and any scenarios where alternative methods might be preferred.\n- Although the paper mentions the tuning of hyperparameters, it lacks a discussion or strategy for optimizing them. This aspect is crucial, as the performance of neural networks can be highly sensitive to hyperparameter choices, especially in the context of dynamic optimization. It is also recommended to mention the hyperparameters that are used in each case for repudicibilty.\n-It is recommended to include additional experiments that evaluate the performance of NODE-ADOpt on datasets with varying noise levels, different initial conditions, and unseen scenarios. Provide insights on regularization techniques, training strategies, or architectural adjustments that could improve generalization.\n- While detailed, some mathematical explanations may be difficult to follow. It is highly recommended to explain elaborate your approach more clearly"
            },
            "questions": {
                "value": "I added the recommendation in the box above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}