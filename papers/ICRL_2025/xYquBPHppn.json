{
    "id": "xYquBPHppn",
    "title": "A VARIATIONAL FRAMEWORK FOR GRAPH GENERATION WITH FINE-GRAINED TOPOLOGICAL CONTROL",
    "abstract": "Controlled graph generation is the process of generating graphs that satisfy specific topological properties (or attributes). Fine-grained control over graph properties allows for customizing generated graphs to precise specifications, which is essential for understanding and modeling complex networks. Existing approaches can only satisfy a few topological properties such as number of nodes or edges in output graphs. This paper introduces CGRAPHGEN, a novel conditional variational autoencoder that, unlike existing approaches, uses graph adjacency matrix during training, along with the desired graph properties, for improved decoder tuning and precise graph generation, while relying only on attributes during inference. In addition, CGRAPHGEN implements an effective scheduling technique to integrate representations from both adjacency matrix and attribute distributions for precise control. Experiments on five real-world datasets show the efficacy of CGRAPHGEN compared to baselines, which we attribute to its use of adjacency matrix during training and effective integration of representations, which aligns graphs and their attributes in the latent space effectively and results in better control.",
    "keywords": [
        "Controlled Graph  Generation"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=xYquBPHppn",
    "pdf_link": "https://openreview.net/pdf?id=xYquBPHppn",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces CGRAPHGEN, a novel framework for controlled graph generation that allows for fine-grained control over graph topological properties. The authors propose a conditional variational autoencoder (VAE) that, unlike previous approaches, utilizes both the graph adjacency matrix and attribute vectors during training for improved decoder tuning and relies only on attributes during inference. This enables CGRAPHGEN to generate graphs that closely match the specified structural attributes."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The method utilizes a conditional VAE that integrates information from both the adjacency matrix and attribute vectors during training, resulting in more precise graph generation.\n\n2. The scalability of the method is quite good. The method can be used to generate large-scale graphs, which is quite competitive compared to other auto-regression models. \n\n3. The paper is well-written and easy to understand."
            },
            "weaknesses": {
                "value": "1. The baselines and the datasets are quite simple. The authors are recommended to compare with more recent graph conditional generation methods. e.g. [1] [2] [3]\n\n[1] Yang, Carl, et al. \"Conditional structure generation through graph variational generative adversarial nets.\" Advances in neural information processing systems 32 (2019).\n[2] Ommi, Yassaman, et al. \"Ccgg: A deep autoregressive model for class-conditional graph generation.\" Companion Proceedings of the Web Conference 2022. 2022.\n[3] Mo, Zhanfeng, Tianze Luo, and Sinno Jialin Pan. \"Graph principal flow network for conditional graph generation.\" Proceedings of the ACM on Web Conference 2024. 2024.\n\n2. it is unclear how the hyper-parameters are defined. In Figure 5, the performance seems quite stable for different gamma, e.g. there's a drop when gamma = 0.8 on arxiv dataset. \"When \u03b3 increases and more information is drawn from the prior p\u03b8, the generation error increases.\" is not always true.\n\n3. No theoretical analysis of how the proposed method can reduce the generation error better than other baseline methods."
            },
            "questions": {
                "value": "Please refer to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper focuses on controlled graph generation that generates graphs satisfying specific topological attributes. It introduces a new scheduling technique, MIXTURE-SCHEDULER, to combines desired attributes with adjacency matrix representations during training for precise graph generation, and it then uses only attributes during inference. Experiments demonstrate that generated graphs have better aligned attributes."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. mixing the attributes and graph representation in latent space for VAE is somehow new for controlled generation. \n2.  the results for controlled graph generation is seemingly good regarding attribute alignment."
            },
            "weaknesses": {
                "value": "1. The biggest concern is the paper lacks of a rigorous deduction for the VAE model and learning objective. For most VAEs, we generally start from the miminization of log likelihood and use variational inference to factorize it. However, the formulations in this paper are very heuristic. We do not know whether the mixing of attributes and graph representation is valid. Mixing the prior with posterior looks also weird to me. What I expect should be starting something like $P(G|c) = \\int_{Z_G, Z_c} P(G|Z_G, Z_c, c)P(Z_G|\\theta, c) P(Z_c|c) dZ_G dZ_c$.\n2. It seems the graph encoder/decoder can only deal with adjacency matrix, but how about graphs with node features?\n3. The evaluation only measures the attributes, but the validness of the graph in many domains is also important (e.g. for molecules)."
            },
            "questions": {
                "value": "What is d(Z_c) in Eq. (6)? There is no explanation for this notation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a conditional variational autoencoder for graph generation with fine-grained topological control. The proposed model incorporates a scheduling technique to integrate representations from both the adjacency matrix and attribute distribution to enable fine-grained control."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper proposes a new setting for the controlled graph generation task, which is highlighted by the injection of fine-grained topological control.\n2. The proposed method seems technically sound to me."
            },
            "weaknesses": {
                "value": "1. The number of baseline models compared in the experiments appears to be limited.\n2. I'm not sure if it's reasonable to use only the MAD metric to evaluate the generation results based on various topological attributes."
            },
            "questions": {
                "value": "Please refer to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes CGRAPHGEN, a novel conditional variational autoencoder framework for generating graphs with fine-grained control over topological attributes. The framework introduces a MIXTURE-SCHEDULER, a scheduling technique to combine structural and attribute-based latent representations. Experiments on multiple datasets show that CGRAPHGEN outperforms baseline models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The model offers flexibility in controlling multiple structural properties (e.g., graph density, connectivity, clustering coefficient), enabling accurate graph generation across various domains.\n- The mixture-scheduler seems to be novel and it smoothly integrates prior and posterior distributions, improving the quality and stability of generated graphs."
            },
            "weaknesses": {
                "value": "- The proposed model doesn't seem to be much of an improvement compared to GraphVAE-like models. The condition architecture is very common in generative models, and feature/attribute based conditional graph generation seems to be a common trick in most methods. Therefore, I think the proposed model may lack enough novelty.\n- Lack of baselines. I have noticed this paper include the diffusion-based model (EDGE), why not other SOTA graph generative models like DruM, DIGress and so on. For graph generation, I think it is more convincing to compare these models or at least other vae-based models. As far as I know, I believe these models can also incorporate the attribute feature to achieve conditional graph generation.\n- For the mixture-scheduler part, I don't really understand the meaning of regarding the time $t$ as epoch in the training stage. From Figure 4(b), it seems there is no clear effect on whatever the $\\beta(t)$ is.\n- In your ablation, I find the experiments with masked only one attribute, is there any flexibility attributes choice?\n\n[1] Efficient and degree-guided graph generation via discrete diffusion modeling. \n[2] Graph generation with diffusion mixture.\n[3] Discrete denoising diffusion for graph generation."
            },
            "questions": {
                "value": "- Is there any code for the proposed model?\n- Have you tried other more complex neural network architecture?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}