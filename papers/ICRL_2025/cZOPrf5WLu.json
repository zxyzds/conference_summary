{
    "id": "cZOPrf5WLu",
    "title": "Learning on LoRAs: GL-Equivariant Processing of Low-Rank Weight Spaces for Large Finetuned Models",
    "abstract": "Low-rank adaptations (LoRAs) have revolutionized the finetuning of large foundation models, enabling efficient adaptation even with limited computational resources. The resulting proliferation of LoRAs presents exciting opportunities for applying machine learning techniques that take these low-rank weights themselves as inputs.  In this paper, we investigate the potential of Learning on LoRAs (LoL), a paradigm where LoRA weights serve as input to machine learning models. For instance, an LoL model that takes in LoRA weights as inputs could predict the performance of the finetuned model on downstream tasks, detect potentially harmful finetunes, or even generate novel model edits without traditional training methods.  We first identify the inherent parameter symmetries of low rank decompositions of weights, which differ significantly from the parameter symmetries of standard neural networks. To efficiently process LoRA weights, we develop several symmetry-aware invariant or equivariant LoL models, using tools such as canonicalization, invariant featurization, and equivariant layers. We finetune thousands of text-to-image diffusion models and language models to collect datasets of LoRAs. In numerical experiments on these datasets, we show that our LoL architectures are capable of processing low rank weight decompositions to predict CLIP score, finetuning data attributes, finetuning data membership, and accuracy on downstream tasks.",
    "keywords": [
        "LoRA",
        "Weight-space learning",
        "Foundation models",
        "Finetuning",
        "Equivariance"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "We develop methods, tasks, and datasets for processing the weights of LoRA finetuned models using other neural networks.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=cZOPrf5WLu",
    "pdf_link": "https://openreview.net/pdf?id=cZOPrf5WLu",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces Learning on LoRAs (LoL), an approach where low-rank adaptation weights, commonly used for efficient fine-tuning of large foundation models, serve as inputs for predictive models. The authors develop several GL(r)-equivariant and invariant neural architectures that process LoRA weights for various downstream tasks, such as predicting model accuracy, analyzing finetuning attributes, and performing data membership inference. The models leverage geometric deep learning techniques like canonicalization and invariant featurization, allowing efficient performance prediction without loss of structural information. The authors validate their approach through experimentation across diverse tasks on newly generated datasets of LoRA weights, including diffusion finetunes and language models finetunes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1 - The paper contributes to the field by capitalizing on the structural properties of LoRA weights, enabling efficient analysis and predictions without needing full model access or extensive retraining. By focusing on parameter symmetries in LoRA weights, the method facilitates tasks like predicting model performance on downstream tasks and analyzing fine-tuning attributes directly from the LoRA weights themselves without requiring compute- and parameter-heavy inferences. \n\n2 - The mathematical rigor in defining GL-invariant and GL-equivariant properties strengthens the reliability of the model design. In particular, Theorem 1 and Theorem 2 (Section 4)\u200b define the necessary properties of the proposed models, providing a clear foundation for future work in this domain. By establishing these invariance properties, the authors ensure that their architectures are theoretically grounded in symmetry-aware learning. The use of canonicalization and alignment methods for symmetry processing is well-supported by previous studies in geometric learning (see Maron et al., 2019) and further extends the concepts to the LoRA domain. \n\n3 - The paper demonstrates extensive experiments across multiple datasets (Section 5, Tables 2 and 3)\u200b. Notably, the authors generate three novel datasets of LoRAs (Section 5.1)\u200b, including CelebA-LoRA, Imagenette-LoRA, and Qwen2-ARC-LoRA, providing a robust basis for evaluating their models."
            },
            "weaknesses": {
                "value": "1 - The paper could benefit from a more thorough introduction to concepts like GL-invariance, O-invariance, and O-Align before discussing them within the context of Learning on LoRAs (LoL). While these concepts are central to the proposed architecture, they may be unfamiliar to some readers, especially those not specialized in geometric deep learning. Including a dedicated background section or a more extensive explanation would make the work more accessible and improve readability.\n\n2 - GL-net\u2019s superior performance may be partly due to a higher number of parameters or computational requirements compared to other LoL architectures. This could imply a cost-performance trade-off, where GL-net\u2019s success on specific tasks may not be as scalable or efficient in scenarios requiring high throughput or limited compute resources. An analysis of this cost-performance trade-off would provide helpful insight into its practical applicability.\n\n3 - The visuals, such as Figure 3 showcasing CLIP predictions, could benefit from clearer labeling and expanded captions to help interpret performance differences among models\u200b. While the data is comprehensive, more explanatory notes within the figures would enhance accessibility for readers.\n\n4 - The GL(r)-equivariant models, while theoretically sound, are complex and may pose practical challenges for adoption. The multi-step processing involving canonicalization, invariant featurization, and the invariant head layer adds architectural overhead (Section 3.3.3). While this complexity is justified for theoretical exploration, a discussion on trade-offs and simplifications would make it easier for practitioners to implement the approach. Previous work in weight-space learning, such as Navon et al. (2023), has shown simpler approaches that could be integrated as baselines to contrast model complexity and efficiency\u200b."
            },
            "questions": {
                "value": "I have no major concerns and consider the paper as a strong submission, but it would be good if the authors could elaborate on the following issues:\n\n1 - Can the proposed methodologies (such as GL-equivariant architectures) be directly applied to other LoRA-based fine-tuning variants, like DoRA (Liu et al., 2024)? If modifications are necessary for such variants, what aspects of the approach would need adaptation, particularly in handling their unique low-rank structures?\n\n\n2 - Is the performance boost primarily due to the model\u2019s increased number of parameters or computational requirements compared to other LoL techniques (Section 5.2, Table 2)? If so, how would you describe the cost/performance trade-off for GL-net in practical applications, especially in contexts where computational efficiency is prioritized?\n\n3 - In Table 4, GL-net shows relatively lower performance on the dataset size prediction task. Could this lower performance be attributed to overfitting? If so, would any regularization techniques be effective here, and are there any architectural adjustments that could improve generalization on this specific task?\n\n\n4 - The authors briefly mention future applications of GL-equivariant networks, such as model merging and LoRA editing (Conclusion)\u200b. Could authors please elaborate on the specific challenges or potential approaches you foresee for these applications? In particular, how might the GL-net architecture be adjusted or extended for these tasks, which may have different requirements compared to the predictive tasks presented?\n\n\nReferences\n\n 1- Maron, Haggai, et al. \"Invariant and equivariant graph networks.\"\u00a0arXiv preprint arXiv:1812.09902\u00a0(2018).\n\n 2 - Navon, Aviv, et al. \"Equivariant architectures for learning in deep weight spaces.\" International Conference on Machine Learning. PMLR, 2023.\n\n3- Liu, Shih-Yang, et al. \"Dora: Weight-decomposed low-rank adaptation.\"\u00a0arXiv preprint arXiv:2402.09353\u00a0(2024)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors explore the potential of Learning on LoRAs (LoL), a paradigm where LoRA weights are used as inputs to machine learning models. They fine-tune thousands of text-to-image diffusion models and language models to collect datasets of LoRAs and develop several symmetry-aware, invariant or equivariant LoL models using techniques such as canonicalization, invariant featurization, and equivariant layers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Several GL(r) equivariant and invariant neural architectures are proposed to effectively process weights of LoRAs.\n2. Creating novel datasets for Learning on LoRAs\n3. Authors conduct experiments across various finetuned models."
            },
            "weaknesses": {
                "value": "1. The detailed information regarding the models, such as the number of parameters and the training costs associated with different model structures and methods, is not sufficiently clear.\n2. The motivation behind the task selection for LoL models is not clearly articulated. For instance, the LoL models aim to predict hyperparameters, CLIP scores, and training images of fine-tuned diffusion models using their LoRA weights. However, it is not immediately clear why these tasks are important or how they contribute to advancing the field. \n3. Other methods used for comparison in this work are not clearly defined and lacks sufficient discussion."
            },
            "questions": {
                "value": "1. The LoRA model datasets used in this work are derived from Stable Diffusion V1.4 and Qwen2. A key question is whether the LoL model will remain effective if LoRA models are obtained from different versions, such as Stable Diffusion V2.1 or Qwen V2.5. \n\n2. Is there a clear rationale behind the choice of model architecture for the LoL models? Specifically, is using an MLP sufficient for the tasks at hand, or could other architectures be more effective?\n\n3. The paper mentions that a large number of LoRA models were collected. How many GPU hours during the collection of these LoRA models?\n\n4. The practical usage of the LoL models is not explicitly addressed. Are there any potential real-world applications except the dataset size prediction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The work introduces the Learning on LoRAs (LoL) paradigm; LoL is an ML model which has LoRA adapters as input and it outputs predictions about the weights."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Shows that LoRA adapters have information in them that can be learned.\nI guess the idea of learning a model for LoRA adapters is technically novel, then again the fact that weights encode information and that information can be extracted isn't a wild thought."
            },
            "weaknesses": {
                "value": "I don't really understand why this is at all useful..."
            },
            "questions": {
                "value": "- The model allows you to predict the accuracy of the model if a set of LoRA weights is applied; how is this useful? Why not just apply the LoRA weights and actually measure the accuracy?\n\n- Why is it useful to predict how many data points the model was fine tuned on... If I have a set of LoRA adapters, I'll try every single one and the set of LoRA weights that does best is the one I'll use (regardless of how many data points it was trained on...)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}