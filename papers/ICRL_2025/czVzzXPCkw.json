{
    "id": "czVzzXPCkw",
    "title": "ON EXTRAPOLATION IN MATERIAL PROPERTY REGRESSION",
    "abstract": "Deep learning methods have yielded exceptional performances in material property regression (MPR). However, most existing methods operate under the assumption that the training and test are independent and identically distributed (i.i.d.). This overlooks the importance of extrapolation - predicting material properties beyond the range of training data - which is essential for advanced material discovery, as researchers strive to identify materials with exceptional properties that exceed current capabilities. In this paper, we address this gap by introducing a comprehensive benchmark comprising seven tasks specifically designed to evaluate extrapolation in MPR. We critically evaluate existing methods including deep imbalanced regression (DIR) and regression data augmentation (DA) methods, and reveal their limitations in extrapolation tasks. To address these issues, we propose the Matching-based EXtrapolation (MEX) framework, which reframes MPR as a material-property matching problem to alleviate the inherent complexity of the direct material-to-label mapping paradigm for better extrapolation. Our experimental results show that MEX outperforms all existing methods on our benchmark and demonstrates exceptional capability in identifying promising materials, underscoring its potential for advancing material discovery.",
    "keywords": [
        "material property prediction",
        "regression",
        "extrapolation"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "We explore extrapolation in material properties regression (MPR), revealing limitations in current methods. Our new Matching-based EXtrapolation (MEX) framework achieves state-of-the-art performance, enhancing material discovery.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=czVzzXPCkw",
    "pdf_link": "https://openreview.net/pdf?id=czVzzXPCkw",
    "comments": [
        {
            "summary": {
                "value": "(Note: The reviewer does not have a background in material property prediction; thus, this review is based on informed estimates. The reviewer welcomes discussions and is open to adjusting scores or comments based on feedback from the authors and other reviewers.) \n\nThe paper introduces a novel approach that reframes material-property regression (MPR) as a material-property matching problem, aiming to simplify target function complexity. This reframing addresses the difficulty neural networks face in capturing complex non-linearity beyond the training data, improving model extrapolation.\n\nThe core idea is that focusing on the proximity between material and property representations, rather than on precise value predictions, reduces learning difficulty and enhances extrapolation. The authors propose two objectives for learning aligned feature spaces for material-property representation matching. First, they use absolute matching optimization with a negative cosine similarity loss to pull paired material and label representations closer together. Second, the method employs Noise Contrastive Estimation (NCE) to help the model distinguish target from noisy labels, thereby capturing fine-grained relative matching relationships.\n\nWithin these well-aligned latent spaces, the proposed method (MEX) predicts by optimizing for the nearest target value for a given sample. Experiments demonstrate that MEX not only performs best on the benchmark but also shows strong detection capabilities for promising materials, underscoring its extrapolation potential and suitability for robust material discovery.\n\n------\nWhile reading this paper, I hypothesized that the label encoder could easily overfit to the training data, effectively reducing it to a look-up table and thereby losing any extrapolation capability. However, this risk may be mitigated by the inclusion of a noisy label component, which introduces stochasticity to the model, reducing its tendency to overfit. And the Gaussian applied to the label likely encourages continuity in the label space, which could help to foster the model\u2019s extrapolation abilities."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "\u2022\tThe approach addresses a significant problem in material property prediction.\n\n\u2022\tThe results look promising"
            },
            "weaknesses": {
                "value": "\u2022\tDataset Limitations: The dataset is small and simplistic, limiting the evaluation of the method's effectiveness. The number of samples (ranging from 4,764 to 18,982) is limited, and details about the dimensionality of data points are not provided. Additionally, the design of y target $y_{\\text{target}}$, as described in section 3.1, seems unrealistic since the training and target data are entirely disjoint. This choice could disadvantage baseline methods.\n\n\u2022\tBaseline Choice: The Deep Imbalanced Regression (DIR) technique is designed for handling imbalanced data distributions with underrepresented target values. However, the proposed dataset\u2019s disjoint target-training setup may hinder DIR\u2019s performance. DIR methods are not specifically tailored for extrapolation, which is central to this work, making it challenging to evaluate against MEX."
            },
            "questions": {
                "value": "1.\tCould the authors clarify the Geometric Mean metric to aid readers unfamiliar with it?\n2.\tIn Figure 6, the performance seems to decrease as $\\lambda$ increases, suggesting that NCE might negatively impact results. Could the authors explain this trend?\n3.\tThe authors claim that the matching-based approach enhances extrapolation, but how does this method handle out-of-distribution data or outliers? Can contrastive learning effectively handle these cases? \n4.\tCould the authors consider an additional setting where the target and training data overlap slightly, such as by adding extreme high or low values to the training set, to simulate an imbalanced distribution?\n5.\tHow well does the method scale with higher-dimensional targets?\n6.\tIs there a threshold in the matching function M(x, y) to determine when a match is strong enough?\n7.\tHow does the model avoid overfitting in the label encoder, potentially transforming it into a look-up table? Does the noise component mitigate this risk, supporting extrapolation?\n8.\tWhile $y^*$ is estimated via Monte Carlo sampling, could gradient-based methods be viable for this estimation? \n9.\tWhat is the dimensionality of the input data sample x?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the challenge of extrapolation in material property regression. Existing deep learning models for MPR assume that the training and test data follow similar distributions, thus limiting their ability to make predictions beyond the known range. To address this issue, the authors introduce the Matching-based Extrapolation (MEX) framework that reframes MPR as a material-attribute matching problem.MEX employs both absolute and relative matching objectives to optimize the consistency of the material and attribute representations, thereby facilitating better extrapolation of material property predictions. The authors also develop a new benchmark."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Originality:\n  - Novel perspective of material property prediction. Reframe the task as a material property matching problem.\n- Quality:\n  - A new benchmark is constructed and a new framework is proposed to address the critical problem of out-of-domain material property prediction.\n- Clarity:\n  - Most of the paper is clearly presented, with some details that should be explained more clearly. The section on noise contrastive estimation-based optimization.\n- Significance:\n  - The problem is critical for new material discovery. The benchmark provides an important validation of the OOD material property prediction problem."
            },
            "weaknesses": {
                "value": "- Limited novelty in method.\n  - The key components, NCE, and cosine similarity-based matching are well-known techniques.\n- scalability and computational complexity\n  - The MEX framework\u2019s inference requires iterative candidate label refinement, which introduces considerable computational overhead compared to traditional regression methods.\n- Experiments\n  - Traditional methods, like DFT, are supposed to be compared to find the gap between DL-based extrapolation and traditional methods.\n  - More DL-based methods should be compared to provide evidence that previous works lack the generalization of OOD properties."
            },
            "questions": {
                "value": "- Dataset\n  - The diversity of the dataset, for example, the distribution of atom numbers and the lattice constants, etc.\n- Matching choice\n  - Are there any insights into adapting Noise Contrastive Estimation (NCE) instead of other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The author addresses the issue of material property regression, focusing specifically on regression problems where the feature values lie outside the boundaries of the training set.\nThe author performs the regression task using two encoder models: (1) an encoder for material properties and (2) an encoder for target values.\nFinally, using Monte Carlo sampling, the model outputs target values that can yield features most similar to the object properties within the given boundary.\nThe author structured the dataset using Matminer ensuring that the target values in the training and evaluation environments do not overlap.\nThe proposed method achieved a high level of performance compared to other methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The problem setting proposed by the author is, to some extent, justifiable, and within this setting, the author presents a state-of-the-art algorithm."
            },
            "weaknesses": {
                "value": "(1) Narrowly defined problem:\nThe experimental setting proposed by the author is highly narrow in scope.\nAn algorithm that performs well only within the proposed setting does not provide insight into whether it effectively considers material properties within the boundaries of the training data.\nFurthermore, the experimental setting proposed by the author appears highly challenging, and the actual MAE values are relatively large compared to the target values.\nTherefore, it is difficult to conclude that the author has sufficiently demonstrated the practicality of the proposed method.\n\n(2) Main method which lacks novelty and analysis:\nSpecifically, it is challenging to discern any reasonable approach proposed by the author for addressing extrapolation.\nThe two matching optimizations proposed by the author are both methods aimed at accurately predicting the given labels in the training set.\nThe author utilizes MC sampling to identify target values outside the range of the training set; however, it is unclear whether the encoding of target values beyond the training range has been effectively learned.\nThis suggests that the algorithm \"may\" achieve high performance if there is significant variance in the value encoder, hyperparameters, and other factors.\nTherefore, to verify the extrapolation performance of the proposed method, the author should present additional ablation studies.\n\n(3) Lack of fairness:\nFirst, there is a question regarding the author\u2019s validation setting.\nIt is unclear why the target value range is the same in both the test and validation environments.\nSecond, the author is aware of the lower and upper bounds of the label range but does not address the issue of setting these bounds beyond the range of the test set.\nThis strongly conflicts with the motivation for extrapolation that the author discusses.\nLastly, the author does not provide the hyperparameter search space for the comparative methods.\nThese are details that should be explicitly documented if new training was conducted on a new dataset."
            },
            "questions": {
                "value": "The first question concerns whether the practicality of the author\u2019s method can be extended.\nNaturally, defining the boundary of target values in the training set is highly unnatural.\nIt is natural for materials with target values similar to those of a new material to be sparsely represented.\nThis implies that the author\u2019s algorithm should also be capable of addressing imbalanced regression problems.\nCan the author demonstrate the effectiveness of this algorithm on established imbalanced regression benchmarks or in environments where labels are sparsely shared between the training and evaluation sets?\nIf feasible, the author should suggest providing a rigorous comparison framework to ensure fairness, as discussed in the weaknesses section.\n\nThe second question is whether the author can explain how the method intuitively aligns with the concept of extrapolation.\nWhether through theoretical or experimental approaches, it is essential to establish confidence that this method genuinely addresses the MPR problem with consideration for extrapolation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}