{
    "id": "Yv8FrCY87H",
    "title": "Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding",
    "abstract": "The ubiquity and value of tables as semi-structured data across various domains necessitate advanced methods for understanding their complexity and vast amounts of information. Despite the impressive capabilities of large language models (LLMs) in advancing the natural language understanding frontier, their application to large-scale tabular data presents significant challenges, specifically regarding table size and complex intricate relationships. Existing works have shown promise with small-scale tables but often flounder when tasked with the complex reasoning required by larger, interconnected tables found in real-world scenarios. To address this gap, we introduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning capabilities over large and complex tables. Our method employs Table Condensation and Decomposition to distill and reorganize relevant data into a manageable format, followed by the construction of a hierarchical Table-Tree that facilitates tree-structured reasoning. Through a meticulous Table-Tree Execution process, we systematically unravel the tree-structured reasoning chain to derive the solutions. Experiments across diverse datasets, including WikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new benchmark with superior performance, showcasing remarkable efficiency and generalization capabilities in large-scale table reasoning.",
    "keywords": [
        "LLMs",
        "Table Reasoning"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Yv8FrCY87H",
    "pdf_link": "https://openreview.net/pdf?id=Yv8FrCY87H",
    "comments": [
        {
            "title": {
                "value": "Clarification on Ethics Concerns"
            },
            "comment": {
                "value": "We would like to quickly clarify the identity leakage concern before submitting the formal rebuttal. The issue you mentioned in Lines 138-141 is actually a typo; it should be \u201cour proposed tree-of-table\u201d rather than \u201cchain-of-table\u201d, indicating our proposed method in this paper. Therefore, it does NOT reveal any information about the authors\u2019 identity. We apologize for the typo and any confusion it may have caused, and we will correct it in the next version."
            }
        },
        {
            "summary": {
                "value": "This paper proposes a tree-of-table method, which generates the tree thoughts to improve the LLMs' reasoning ability on large-size tables. The experiments are conducted on multiple datasets such as WikiTQ, TableFact, FeTaQA and BIRD and show the better performance than baselines."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The experimental results show the proposed tree-of-table method leads to better performance than baselines.\n2. The experiments are conducted on multiple table-based datasets and show the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. Deriving such a huge tree for table QA can raise the efficiency concern. \n2. It would be better to show some cases in which tree-of-table can handle better than chain-of-table."
            },
            "questions": {
                "value": "1. What types of queries and tables can mainly benefit from tree-of-table rather than chain-of-table?\n2. How easy will it go into a dead loop during the derivation of the trees?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces \"Tree-of-Table\" to enhance LLMs' ability to understand and reason with large-scale tabular data. Key contributions include a framework with table condensation that distills relevant information from large tables, table-tree construction, which organizes reasoning steps into a hierarchical tree structure, and then table-tree execution which systematically processes the tree through DFS. The structure breaks down complex table understanding tasks into manageable sub-problems to allow more efficient processing compared to linear chain approaches. Their experiments demonstrated enhanced performance over existing methods on large-scale tables across multiple datasets including wikiTQ, TableFact, FeTaQA, and BIRD."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "This paper introduced a tree structure for handling tabular data which is different from the traditional linear chain-of-thought and more recent chain-of-table methods. What I like in particular is how they combined table condensation with tree decomposition - the authors seem to have thought carefully about how humans break down complex problems, and they've used the insights and built this into their approach. The experimental work is solid. They tested their method on several different datasets (WikiTQ, TableFact, FeTaQA, and BIRD), which gives us confidence in the results. The numbers are impressive - they're getting better performance than existing methods, especially on BIRD which has those really large tables that are typically hard to handle. I was particularly convinced by their ablation studies.\n\nThe paper is easy to follow. The figures really help explain what's going on - Figure 1 does a great job showing how their approach differs from previous methods. They've managed to explain some pretty complex technical stuff without making it too dense. That said, they could have made some of the implementation details clearer. In terms of impact, this work matters because large-scale table understanding is a real problem that comes up all the time in practical applications. Their method shows promise for handling tables in finance, healthcare, and other fields where you often deal with complex tabular data. The performance improvements they're showing are consistent across different LLMs, and across various table understanding datasets. What stands out most to me is that they've taken a practical problem (with demonstrated efficiency improvement against other methods) that lots of people struggle with and come up with a solution that actually works better than what we had before. The evidence is there in their results, and they've explained their approach well enough that others could build on it."
            },
            "weaknesses": {
                "value": "1. The theoretical foundation needs more work. While the tree-based approach shows good empirical results, there's limited analysis of why it works better than linear chains. \n\n2. Some key experimental details are missing or unclear: They don't specify how they chose parameters like MAXDegree and MAXDepth for the Table-Tree. These seem pretty important for the method's performance. Alsothe computational overhead of building and traversing the tree structure wasn't properly analyzed, for example - memory requirements for storing intermediate results at tree nodes and overall computational complexity compared to simpler approaches\n\n3. The ablation studies could go deeper. There's no clear analysis of how the tree structure's depth affects accuracy. The comparison with Chain-of-Table focuses mainly on final accuracy, but doesn't explore cases where their method might perform worse"
            },
            "questions": {
                "value": "1. The authors should explain the theoretical advantages of their hierarchical decomposition - when does it work better and why? This would help us understand the method's limitations and where it might fail.\n2. There's no discussion of error propagation through the tree structure. In a tree structure, errors at higher levels will propagate down through all child nodes. For example, if the table condensation step (at the root) removes important information, or if an early operation in the tree is incorrect, how does this affect the final result? The paper shows good overall accuracy but doesn't analyze these failure cases.\n3. Related to above, how sensitive is your method to the quality of the initial table condensation step? What happens if crucial information is accidentally filtered out?\n4. What is the complete set of operations in the operation pool? How were these operations selected and validated?\n5. Have you analyzed cases where Tree-of-Table performs worse than Chain-of-Table? This would be valuable for understanding the method's limitations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces the \"Tree-of-Table\" method, designed to improve the reasoning abilities of large language models (LLMs) when dealing with large and complex tabular data. The approach involves two main steps: Table Condensation and Decomposition, which simplifies and organizes the data, and Hierarchical Table-Tree Construction, creating a structured representation that benefits systematic reasoning. This method enhances the efficiency and generalization capabilities of LLMs, demonstrated through superior performance on datasets like WikiTQ, TableFact, FeTaQA, and BIRD. This study advances LLM methods for parsing and understanding extensive tabular datasets, setting new benchmarks in handling complex table-based information."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The idea of using tree as a roadmap to guide the LLMs through table(s) is sound but seems like an adaptation from other work to table tasks. It's not very novel to consider increment LLMs using chain-of-thoughts to tree-of-thoughts, which have been already verified on other domains, like graphs."
            },
            "weaknesses": {
                "value": "W: I'm unclear about the logic in the introduction from lines 94 to 103, specifically why the Chain-of-table is limited to smaller tables. What does 'smaller' refer to exactly? Is it generally about the number of rows/columns or the total number of tokens across all cells?\n\nW: The performance of the proposed tree-of-table is limited, especially compared with the chain-of-table referred to in Table 1 and 2. Additionally, it's not very easy to differentiate the contribution of tree-of-table and chain-of-table. The authors should consider providing a critical analysis about the difference in the introduction or method section, and show how this improvement can account for the performance enhancement.\n\nSeveral relevant papers should be considered in references:\n\n* Large Language Models are few(1)-shot Table Reasoners\n* StructGPT: A General Framework for Large Language Model to Reason over Structured Data\n* TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning\n* Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study\n* TableRAG: Million-Token Table Understanding with Language Models"
            },
            "questions": {
                "value": "Q1: I'm unclear about the logic in the introduction from lines 94 to 103, specifically why the Chain-of-table is limited to smaller tables. What does 'smaller' refer to exactly? Is it generally about the number of rows/columns or the total number of tokens across all cells or like a database: the number of tables linked with keys?\n\nQ2: what is the OP pool mentioned in Figure 1? I suggest the authors to rephrase the process of chain-of-table in case not all readers are familiar with this method. Additionally, the authors should also describe the difference between chain-of-table and proposed tree-of-table explicitly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "**In the review of the manuscript, I observed that lines 138-141, where the authors state \"our proposed chain-of-table approach innovates by generalizing a broader set of ....\", may validate the double-blind requirement of the ICLR. The mentioned chain-of-table, which is another paper, might reveal the authors' identities.**\n\nI recommend that the ACs evaluate this situation to decide if the paper warrants a **desk reject**.\n\nReference: \n\nChain-of-table: Evolving tables in the reasoning chain for table understanding (https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2401.04398&hl=en&sa=T&oi=gsr-r-gga&ct=res&cd=0&d=13815199908318046768&ei=7D0XZ8LsJsDBy9YP75aH4Qc&scisig=AFWwaeauOr6b6P9gI77Y9IO8x6Tf)"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}