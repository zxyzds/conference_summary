{
    "id": "uZVDJfV2Ex",
    "title": "A graph-based global optimization framework for problems with nonconvex norm constraints and penalty functions",
    "abstract": "Optimization problems with norm-bounding constraints appear in various applications, from portfolio optimization to machine learning, feature selection, and beyond. A widely used variant of these problems relaxes the norm-bounding constraint through Lagrangian relaxation and moves it to the objective function as a form of penalty or regularization term. A challenging class of these models uses the zero-norm function to induce sparsity in statistical parameter estimation models. Most existing exact solution methods for these problems use additional binary variables together with artificial bounds on variables to formulate them as a mixed-integer program in a higher dimension, which is then solved by off-the-shelf solvers. Other exact methods utilize specific structural properties of the objective function to solve certain variants of these problems, making them non-generalizable to other problems with different structures. An alternative approach employs nonconvex penalties with desirable statistical properties, which are solved using heuristic or local methods due to the structural complexity of those terms. In this paper, we develop a novel graph-based method to globally solve optimization problems that contain a generalization of norm-bounding constraints. This includes standard $\\ell_p$-norms for $p \\in [0, \\infty)$ as well as nonconvex penalty terms, such as SCAD and MCP, as special cases. Our method uses decision diagrams to build strong convex relaxations for these constraints in the original space of variables without the need to introduce additional auxiliary variables or impose artificial variable bounds. We show that the resulting convexification method, when incorporated into a spatial branch-and-cut framework, converges to the global optimal value of the problem under mild conditions. To demonstrate the capabilities of the proposed framework, we conduct preliminary computational experiments on benchmark sparse linear regression problems with complex nonconvex penalty terms that existing global solvers cannot model or solve. This establishes our framework as the first algorithm capable of globally solving such challenging mixed-integer nonlinear programs.",
    "keywords": [
        "Norm Constraints",
        "Sparse Parameter Estimation",
        "Nonconvex Regularization",
        "Global Optimization",
        "Mixed-Integer Nonlinear Programs",
        "Decision Diagrams"
    ],
    "primary_area": "optimization",
    "TLDR": "This paper introduces the first algorithm in the literature to globally solve mixed-integer nonlinear programs that contain complex nonconvex regularization terms arising in statistical parameter estimation models",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=uZVDJfV2Ex",
    "pdf_link": "https://openreview.net/pdf?id=uZVDJfV2Ex",
    "comments": [
        {
            "comment": {
                "value": "We have specifically addressed the \"weakness\" points raised in the review, which appear to have led to both the questions and the overall rating, rather than the questions themselves, which appear relatively marginal by comparison.\n\nRegarding the first point, as previously noted, the proof format we used is standard in this field. Breaking down such a standard proof into simpler components would require significantly more space, which is an impractical approach for a conference paper with strict length limitations.\n\nRegarding the second point, questions 5-7 do not substantiate \"weakness #4,\" which states that \"the experiments are insufficient to support your conclusion.\" We seek clarification on which specific conclusion is deemed unsupported by the experiments. Nowhere do we claim runtime comparisons between our method and state-of-the-art methods for convex or nonconvex cases. Our primary claims are that (a) the proposed framework can globally solve a broad class of problems, which we have mathematically proven; and (b) there are problem structures, such as those involving the SCAD penalty, that cannot be handled by any existing methods. This is due to the fact that SCAD penalties cannot be represented within existing solvers, regardless of parameter selection. In contrast, our framework is mathematically proven to converge to the global optimal solution of the SCAD problem, independent of parameter settings. Therefore, altering parameters would not affect these core conclusions.\n\nIn summary, adding test cases with different parameter settings, iteration counts, or gap tolerance would neither strengthen nor impact the validity of our main conclusions or contributions. The specific test instances and parameters presented are intended solely to demonstrate that our proposed approach is capable of solving these instances, something no other method currently achieves."
            }
        },
        {
            "comment": {
                "value": "1. The format of your proof is unfriendly to readers.\n2. Experiment section: you should refer to questions 5-7.\nFor question 7, my point is: For a convex problem, have you compared your results with any SOTA method? Separately, for a nonconvex problem, have you compared your results with any SOTA method? The intent is not to compare with other SOTA methods across both convex and nonconvex conditions.\n3. You didn't answer my \"questions\"."
            }
        },
        {
            "title": {
                "value": "Reviewers have missed the forest for the trees..."
            },
            "comment": {
                "value": "The reviewers are missing the forest for the trees, perhaps due to a lack of background in this area. I will therefore clarify the significance of our work as simply as possible here. We address a critical problem in statistical inference that has been unsolvable due to its highly complex functional form (SCAD). This means that, even for small instances (e.g., n = 10), no global solution methods or solvers\u2014commercial or open-source\u2014have been able to handle this problem, as they cannot construct a suitable convex relaxation for it that can converge to global optimality.\n\nIn this paper, we introduce the first global solution framework capable of solving this problem, supported by rigorous mathematical proof and convergence guarantees. This means that a problem previously deemed unsolvable can now be solved using our framework, representing a significant breakthrough. Criticizing our work for using limited problem sizes in computational experiments misses the point; the impact of our method lies in making global solutions achievable at all, even for small instances.\n\nDespite repeated clarification of this contribution in the paper, reviewers continue to request comparisons with \"alternative\" methods, which do not exist. Likewise, requests for experiments on larger problem sizes are misplaced, as even the smallest instances are beyond the reach of current state-of-the-art solvers."
            }
        },
        {
            "comment": {
                "value": "For global solution algorithms that employ divide-and-conquer techniques, it is impossible to provide a bound on the number of iterations\u2014this is a well-known fact common to all general-purpose global algorithms, not specific to our approach. As for comparison with existing methods, we reiterate that no existing methods can globally solve the problem classes examined in our work. Consequently, there are no alternative methods to benchmark our approach against. The breakthrough of our paper is precisely this: for problems previously unsolvable from a global perspective, we present an algorithm capable of achieving global solutions for the first time."
            }
        },
        {
            "comment": {
                "value": "1. The proofs provided are standard and should be straightforward for readers within the relevant fields to follow.\n\n2. Solving an outer approximation of a problem yields a dual bound, a well-known fact in optimization. Furthermore, there is extensive literature that discusses how an outer approximation can be derived from decision diagrams, making a detailed repetition of these arguments unnecessary and redundant in a conference paper with space limitations. As such, we have provided a summary along with relevant references in the appendix for readers who may be less familiar with this background.\n\n3. Could you clarify which specific claims you found lacking in computational support? We have clearly indicated that there are no existing methods or state-of-the-art approaches that can solve the problem classes examined here. In other words, our algorithm is the first in the literature capable of globally solving these problems, so direct comparisons with non-existent state-of-the-art methods are not possible. Our claim, mathematically proven, is that we can solve these problems globally, independent of experimental validation."
            }
        },
        {
            "comment": {
                "value": "The main point of this paper is missed in this reviewer's comments. The key point here is that no existing methods can globally solve even small instances of this problem class. Therefore, our ability to achieve global solutions\u2014even for small and medium-sized instances\u2014marks a significant breakthrough in both the theoretical and practical aspects of solving these extremely challenging problems."
            }
        },
        {
            "summary": {
                "value": "The paper introduces a graph-based global optimization framework targeting problems with norm-bounding constraints and nonconvex penalty functions, such as SCAD and MCP. Utilizing decision diagrams (DDs), the method constructs strong convex relaxations directly in the original variable space without adding auxiliary variables. Preliminary experiments on sparse linear regression benchmarks demonstrate the framework\u2019s ability to solve challenging instances that existing global solvers cannot handle."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The framework accommodates a wide range of norm types, including both convex ($\\ell_p$ for $p \\geq 1$) and nonconvex ($\\ell_p$ for $p \\in (0,1)$, SCAD, MCP) regularization, enhancing its versatility across various optimization problems.\n\n2. The paper provides the theoretical convergence guarantee to the global optimum and properties of the convex relaxations generated by the DD-based method."
            },
            "weaknesses": {
                "value": "1. The computational experiments presented are preliminary and focus on small to medium-sized instances. To fully assess the framework\u2019s scalability and performance, more extensive benchmarking on larger and more diverse datasets is necessary.\n\n2. The DD-based method can grow exponentially with the number of variables. Although node-merging techniques and width limitations are proposed to control DD size, the practical scalability for very large-scale problems remains uncertain and requires further empirical validation.\n\n\n3. The paper allocates a disproportionate amount of space to providing proofs in the main text while omitting essential technical details, such as the graph-based convexification method."
            },
            "questions": {
                "value": "Please refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose an innovative graph-based method to globally solve optimization problems with generalized norm-bounding constraints. This approach leverages decision diagrams to create strong convex relaxations for these constraints directly in the original variable space, eliminating the need for auxiliary variables or artificial variable bounds. The preliminary computational experiments on benchmark sparse linear regression problems show the effectiveness of this framework."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper presents a new graph-based framework that leverages decision diagrams to address a broad class of optimization problems with norm-bounding constraints. Unlike traditional methods, it offers a unified approach to solving convex and nonconvex problems.\n2. The authors provide mathematical proof showing that, under mild conditions, the proposed method guarantees convergence to global optima.\n3. Certain computational experiments are provided on benchmark problems to demonstrate the algorithm's performance."
            },
            "weaknesses": {
                "value": "1. The proof is unreadable for readers.\n2. In Section 4.2, there is no brief description of the method to obtain dual bounds inside an outer approximation framework.\n3. In Figure 1, the instance number is difficult for readers to understand.\n4. The experiments are insufficient to support your conclusion."
            },
            "questions": {
                "value": "1. Could you present the proofs of your propositions in an easier way for readers to understand? For instance, consider breaking them into multiple paragraphs instead of a single block of text.\n2. In Section 4.2, you should provide a brief description within the main body rather than summarizing it in the appendix.\n3. The description of the x-axis in Figure 1 is challenging for readers to understand. Could you clarify its meaning?\n4. Can you explain why you chose 5% for a relative optimality gap as the stopping criterion for your algorithm?\n5. Did you conduct any experiments to justify setting 50 (and 100) iterations for your tests?\n6. Have you conducted any experiments to explore the impact of $\\lambda$ and $\\gamma$? \n7. Have you compared the runtime of your method with the state-of-the-art (SOTA) method for the same problem under either convex or nonconvex conditions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper considers convex optimization with a norm bounding constraint. These constraints can be any $p$-norm, where $p \\in [0,\\infty)$ as well as some non convex penalty terms such as SCAD and MCP. When $p\\in (0,1)$, the norm is neither convex nor concave, and as a result standard methods don\u2019t work directly. These kinds of problems appear in several applications and sometimes also appears as a regularizer. Current methods that give exact solutions either use extra variables, thus increasing the size of the problem by a lot, are tailored to the objective function, or are heuristic methods.\n\nThis paper gives a unified algorithm that can handle all the different constraints, including non continuous and non convex constraints. The method is based on using decision diagrams. The method roughly uses a scale function to capture these domain constraints, and then uses a decision diagram based relaxation to capture these constraints. The key is that the scale function is able to capture all the listed domain constraints. The paper focusses on proving how to use these scale functions within DD\u2019s to capture the constraints. In the end there are some experiments that use a quadratic function with the SCAD penalty function and they show the solution times for selected datasets with different penalty functions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is able to handle an important set of problems and gives a new technique. It is an interesting connection between non convex optimization and graph theory, since most of the graph theoretic optimization results are captured via convex optimization."
            },
            "weaknesses": {
                "value": "I think there is no provable bound on the number of iterations, or the rate of convergence of the method. It seems like the authors can prove that the method converges in the limit but there is no way to show the rate of convergence even for simple objectives. Also, in the experiments it is not clear what the method is compared against."
            },
            "questions": {
                "value": "I have some questions to the authors:\n\n1. Points (i) to (viii) on Pages 2 and 3 seem to have a lot of redundant statements and is repeating what was stated in the paragraph before. I think it can be compressed so that the main message is clear while covering all the points.\n2. The SCAD and MCP penalty terms are defined in Prop 1. Would be useful to define in the main text!\n3. What all objective functions can be handled by the method? It would be useful to include this explicitly. The constraints are very clear but it is useful to know the functions we can handle as well.\n4. Is it possible to show any rates of convergence even for some easy objectives?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}