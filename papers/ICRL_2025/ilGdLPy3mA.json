{
    "id": "ilGdLPy3mA",
    "title": "A New 3D Image Block Ranking Method Using Axial, Coronal and Sagittal Image Patch Rankings for Explainable Medical Imaging",
    "abstract": "Although a 3D Convolutional Neural Network (CNN) has been applied to medical\nimaging in recent years, understanding the relationships among input 2D image\npatches, input 3D image blocks, extracted feature maps, and final diagnosis remains\na significant challenge, particularly in explainable medical imaging. To\nhelp address this challenge, firstly, we created a new Grad-CAM-based method\nusing feature selection to produce explainable heatmaps with a small number of\nhighlighted image patches corresponding to top-ranked features. Secondly, we\ndesigned a new 2D image patch ranking algorithm that leverages the newly defined\nfeature matrices and relevant statistical data from numerous heatmaps to\nreliably rank axial patches, coronal patches, and sagittal patches. Thirdly, we created\na novel 3D image block ranking algorithm to generate a \u201cBlock Ranking Map\n(BRM)\u201d by using the axial patch ranking scores, coronal patch ranking scores, and\nsagittal patch ranking scores. Lastly, we developed a hybrid 3D image block ranking\nalgorithm to generate a reliable hybrid BRM by using different block ranking\nscores generated by the 3D image block ranking algorithm using different top\nfeature sets. A preprocessed ADNI (Alzheimer\u2019s Disease (AD) Neuroimaging\nInitiative) dataset with 982 64\u00d764\u00d764 brain images with 4, 096 4\u00d74\u00d74 blocks\nfor three-class (cognitively normal class, mild cognitive impairment class, and AD\nclass) 3D image classification is used to extract 19640 axial images, 19640 coronal\nimages, and 19640 sagittal images for simulations. The associations between\nbrain areas and AD are generated efficiently by using information from ChatGPT\nand relevant publications. Simulation results show that the hybrid 3D image block\nranking algorithm is able to effectively identify 10 top-ranked blocks (i.e., 0.24%\nof all 4, 096 blocks) that are associated with the 16 brain areas that are in the six\nmost important brain regions associated with AD. A doctor may conveniently use\nthe hybrid BRM with axial, coronal, and sagittal views to better understand the\nrelationship between the top-ranked blocks and medical diagnosis so that he/she\ncan efficiently and effectively make a rational and explainable medical diagnosis.",
    "keywords": [
        "convolutional neural networks",
        "feature selection",
        "gradcam",
        "medical imaging",
        "disease diagnosis",
        "image classification"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ilGdLPy3mA",
    "pdf_link": "https://openreview.net/pdf?id=ilGdLPy3mA",
    "comments": [
        {
            "summary": {
                "value": "This paper aims to tackle the limitation of explainability for medical image analysis, the contribution can be summarized as follows:\n1) Proposed a new Grad-CAM-based method using feature selection to produce explainable heatmaps with a small number of highlighted image patches corresponding to top-ranked features\n2) Designed a new 2D image patch ranking algorithm"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The strength of this paper can be summarized as follows:\n1) The problem that this paper aims to tackle is important\n2) The adaptation of feature selection with Grad-CAM seems to be an interesting method"
            },
            "weaknesses": {
                "value": "The weakness of this paper can be summarized as follows:\n1) The writing and organization is poor\n2) The innovation cannot be easily understand and a lot of definition with unclear steps are demonstrated in the first two sections\n3) Clarity on the innovation is not clear"
            },
            "questions": {
                "value": "1) Can you clarify your innovation with a simple paragraphs? A lot of definitions are demonstrated from section 2.1 to 2.3, in which they are not interconnected to demonstrate a clear step-by-step story towards section 2.4. \n2) For 3D image block ranking, I am wondering can you directly use sliding window to extract patches for ranking? Seems like you are ensembling all different 2D orientated slices result. It will be great to clarify why you want to do it in this way. Is there any advantage on this?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper attempt to provide a more explainable 3D GradCam map by combining ideas of GradCam in each of the respective projections (coronal, axial, sagittal) of MRI data with feature selection concepts. The feature maps produced in the maxpooling convolutional layers are used to derive various representations such as heatmap matrics, feature matrices, and the values within them are ranked individually per view and then combined into a 3D block ranking. The authors claim the resulting visualization gives better indication of the disease and demonstrate this on ADNI data for Alzheimer's disease. \n\nThe paper is poorly written and many of the details seem to be automatically written through a translation software or perhaps LLM judging by the language used. For example, reading the abstract had a lot of details  that typically seen in results sections later rather than focusing on a high-level summary of the approach.  Another example is a sentence in line 164-165 which reads \"Different from traditional CAM-based methods without FS a new FS-Grad-CAM methods uses a FS method to select the top k features from m flattened features.\" - Is this referring to their proposed approach. Normally we would phrase it as \"Unlike traditional CAM-based methods, we propose a new method called FS-Grad_CAM where we employ a feature selection method to select the top K feature from m flattened features first before applying GradCAM.\" \n\n Many details are unclear including the novelty with respect to other 3DGradCam methods (see eblow). Overall, it needs a major rewrite and using clinically relevant terminology with better motivation of the healthcare problem addressed."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Paper is about explainable AI showing clinicians relevant features useful for diagnosis in the 3D MRI images by taking slices in multiple views and offering top-ranked patches that are correlated with disease and understand the relationship between the top blocks and the decisions made by 3D CNN. As such, the paper attempts an important problem, namely, making the disease classification more explainable to clinicians. The familiar mechanisms of GradCam are used and attempt is made to process complex MRI datasets in multiple views. If the method could be clearly explained, one could even see value in the technique for 3DGradCam in general although other 3D GradCam tools are available. The main argument appears to be that GradCam should be applied after feature selection in the feature maps."
            },
            "weaknesses": {
                "value": "As mentioned above, the paper is poorly written to determine if the idea being proposed is a variation of 3D gradCam. No comparisons are made to any methods to even see its merit. Several open questions arise (see below). \nThere are several tools available for 3DGradCam such as these. If they are not relevant for comparison, it would be helpful to at least explain how your method differs from these. \nhttps://github.com/fitushar/3D-Grad-CAM\nhttps://www.researchgate.net/publication/357899396_Automated_grading_of_enlarged_perivascular_spaces_in_clinical_imaging_data_of_an_acute_stroke_cohort_using_an_interpretable_3D_deep_learning_framework\n\nThe paper in current problem needs a full rewrite starting with explanation of the MRI disease visualization problem, the role of existing 3D GradCam and the need for feature selection prior to GradCam. The whole idea of class activation maps was to allow us to see the rationale for the classification with the visualization itself in a way doing regional feature selection. By applying a separate feature selection operator a priori, what would be the impact on the gradient operators and the resulting activation maps?\n\nChatGPT is briefly mentioned and it is not clear what it is being used for.\nWhat does it mean to say ChatGPT is used to verify if a brain area is associated with a disease? What is the prompt used? What are the input, only text or text and image, is a bounding box and a prompt given as input. How accurate is ChatGPT in identifying  the brain areas associated with the disease. All these should be added to explain the use of ChatGPT."
            },
            "questions": {
                "value": "1. What is the rationale for a top-ranked 3Dimage block being correlated with diseases? Real-life experiences with 2d heat maps alone indicate they are not always a reliable indicator of a disease. Since a disease may be seen in some view better than other views, the method of fusion is important between the 3 views. Provide more discussion or justification for the correlation between top-ranked blocks and diseases, and the fusion method would help clarify better. \n\n2. How is the ranking of the blocks done? In general, what does ranking mean in your context, is it just a matter of selecting high-valued entries in the feature and heat map matrices?\n\n3. What is the purpose of ChatGPT in the work? It is said it is to verify if a brain area is associated with a disease. How does it work? Are both prompt text and image supplied as input? How accurate is ChatGPT in identifying  the brain areas associated with the disease. This discussion is brief and unconvincing so elaborating on how exactly ChatGPT is used and what its inputs are would explain this section better."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors propose a new method for explaninable medical imaging. By combining Grad-CAM-based feature selection, 2d image patch ranking, and 3d image block ranking together, the proposed method can effectively provide accurate medical diagnosis with explainability. They validate the proposed method on an ADNI dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Overall, the whole framework makes sense and looks like a good solution in practice."
            },
            "weaknesses": {
                "value": "1. My major concern is that combining axial, coronal and sagittal images for 3d medical image analysis is not something new. Although the whole framework makes sense practically, there are no major innovations in my opinion.\n2. Experimental section looks weak. There are no solid performance evaluation and comparison with SOTA methods."
            },
            "questions": {
                "value": "1. Is it possible to build 3d analysis directly whithout resorting to 2d analysis? Can we do convolution, feature selection, FS-CAM+feature analyzer, and block ranking directly on 3d images? What are the major advantages of do 2d image analysis first, then fuse them totether by 3d block ranking?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Privacy, security and safety"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This study involves human data collection. So the authors are expected to address the privacy concerns in this submission."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Authors present a method for modifying Grad-CAM feature attribution maps that is able to identify the most important 'blocks' in a 3D MRI brain image. The method is applied to output features of a trained CNN by sectioning each 3D image axis into an equal number of patches. The features from Grad-CAM are passed through a feature selection (FS) method consisting of a combination of standard library functions including recursive feature elimination (RFE). The resulting `k` ranked features are accumulated axis- (or patch-) wise, and the patches from different combinations of FS methods are passed into final step that aggregates the 2D features into 3D block features. The blocks that contain the most patches with highest ranking features are selected as the most important blocks. Authors evaluate their method by verifying that the selected blocks correspond with those that are know to be important in the literature, as well as asking Chat-GPT. Author's provide clinical reasoning to explain the attributions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The target of the Authors' work is important and moves towards a more explainable and trustworthy result for use by clinicians.\n* Authors are thorough in their definitions and attempt to give the reader the detail to reproduce their work."
            },
            "weaknesses": {
                "value": "* In general, this paper is badly formatted and overly verbose. The notation is difficult to keep consistent and often badly defined. Further comments to this are made in the `Questions` section below.\n* Authors spend very little time reviewing prior work and setting their method in context - Authors should add explanations of related prior work including methods for using statistical analysis of Grad-CAM attribution and saliency maps to identify significant regions in input data.\n* Authors inexplicably use Chat-GPT to test the reliability of their method by asking it to verify the important brain regions associated with AD - there is no explanation for this, and no reason to be doing that instead of actually asking clinicians.\n* Authors present their method only on a single 3D MRI dataset and do not discuss its applicability to other modalities, or indeed any other domain. Authors cannot claim that this is a method for \"Explainable Medical Imaging\" when results on a single dataset are reported."
            },
            "questions": {
                "value": "### Major Comments\n* The definitions and notation presented in the paper are cumbersome, and difficult to read. This starts with the statement `P (H-bar/H) x (W-bar/W) patches for P=HW` (line 92) that is repeated several times (187, 214 etc.) which could be replaced by a less obtuse definition of patch size. Authors also do not define _n_ in this Section 2. Authors should better define their variables. Additionally, the cumbersome notation in definitions 1-6 is largely unnecessary - Authors can simplify this section by removing superfluous 'definitions' and describing the process through which they yield the ranking matrices: this will avoid repetition of the `i` and `j` indices and shorten this bloated paper.\n* On a similar note, Authors introduce additional notation for the 'top feature map' `T^Q`. This terminology is confusing. It is not a top \"feature map\", but rather an aggregated \"top k features\" map combining the Grad-CAM features selected by 'some feature selection method'. Authors should consider re-wording this.\n* Lines 221-234 - Authors present their 8 steps for Image Block Ranking algorithm. This is presented badly - the reader is capable of understanding that the same steps are applied to the 3 different axis without making each step of this method so verbose. Figure 1 shows this much better in fact. Authors should describe steps 1-7 on a single axis to improve readability.\n* Authors show a visualization of important blocks identified by their method in Figure 2b. The full Grad-CAM output without feature selection is shown in Figure 3b. It is evident that applying some thresholding to the full feature map, and even just applying the brain-boundary regional constraints, would yield a similar map to their own. Can author's comment on the significant differences between using the Grad-CAM values directly in this way, rather than the additional steps in their method? It would have been helpful to show some quantitative comparison in their results given this is supposed to be an extension of Grad-CAM -based methods.\n* Why did Authors use Chat-GPT in their evaluations? What is the benefit of this over asking the clinicians which Authors repeated claim that this system is aimed at helping?\n* Have Authors used this method on other domains or modalities to demonstrate its effectiveness?\n\n### Minor Comments\n* The paragraph from lines 57 contains a lot of repetition and should be pared down: this sentiment is reflected in many parts of the paper. The reader is clear that having better explainability is important and that a clinician can use this information to inform their diagnosis.\n* Line 147 \"... makes a more impact on the decision\" - to what decision are the Authors referring?\n* Line 148 \"... we use a trained CNN to generate L heatmaps...\" - the language here is confusing: Authors are referring to the model on which they are performing Grad-CAM, not a random trained model that generates heatmaps.\n* Table 2 is unclear - why is much of the table blank?\n* Line 489 - this is confusing: what is meant by the 'the 9th ... patches are shown'?. There are 16x16 patches in each of the 3 axis images shown, and a single patch at (6, 10, 9) is highlighted.\n* Section 4.1 - it is absolutely unnecessary to bloat this section with the indicies that correspond to the brain boundary - put this in the appendix, or show it as an image if the Authors feel it adds to their explanation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I question the validity of using Chat-GPT in this work - but no significant Ethics concerns."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a feature-selected (FS) Grad-CAM method to generate more focused explainable heatmaps with smaller highlighted areas. Additionally, a novel 2D image patch ranking algorithm was developed to reliably rank patches along the axial, sagittal, and coronal axes using features extracted by FS-Grad-CAM. These ranked scores are then used to create a Block Ranking Map (BRM) via a newly developed 3D block ranking algorithm. The resulting block-ranked scores are further refined through a novel hybrid 3D block ranking algorithm to produce a reliable hybrid BRM. The method was validated on Alzheimer\u2019s Disease (AD) data and identified the top 10 ranked blocks associated with AD."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper used the 2D images in axial, sagittal and coronal axes to rank the 3D images, which makes the research novel.  This paper has detailed explanation on the algorithm, which makes the method replication easier."
            },
            "weaknesses": {
                "value": "1. Lack of competition: The cited papers (He et al., 2019 and Selvaraju et al., 2017) in the introduction part have compared their new algorithm (Grad-CAM) with other common machine learning algorithm (e.g. logistic regression) to demonstrate their better performance in the binary classification. But this paper doesn\u2019t have compared with any baseline to demonstrate its superiority. There exists 3D medical imaging visual explanation algorithm (e.g. Respond-CAM) which might be a good benchmark to compare with.\n2. Lack of generality: The paper only evaluated on one dataset, which cannot guarantee the generality of the proposed method. More tests are needed to justify the statement."
            },
            "questions": {
                "value": "1. It would be great if any qualitative/quantitative comparison with similar algorithm could be added to help the readers to better evaluate the performance of the proposed method.\n2. It would be ideal if more dataset could be used to evaluate the performance of the proposed method (e.g. LUNA 16 lung nodule dataset)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}