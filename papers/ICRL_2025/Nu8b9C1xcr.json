{
    "id": "Nu8b9C1xcr",
    "title": "CardBench: A Benchmark for Learned Cardinality  Estimation in Relational Databases",
    "abstract": "Cardinality estimation is crucial for enabling high query performance in relational\ndatabases. Recently learned cardinality estimation models have been proposed\nto improve accuracy but there is no systematic benchmark or datasets which\nallows researchers to evaluate the progress made by new learned approaches\nand even systematically develop new learned approaches. In this paper, we are\nreleasing a benchmark, containing thousands of queries over 20 distinct real-world\ndatabases for learned cardinality estimation. In contrast to other initial benchmarks,\nour benchmark is much more diverse and can be used for training and testing\nlearned models systematically. Using this benchmark, we explored whether learned\ncardinality estimation can be transferred to an unseen dataset in a zero-shot manner.\nWe trained GNN-based and transformer-based models to study the problem in three\nsetups: 1-) instance-based, 2-) zero-shot, and 3-) fine-tuned.\nOur results show that while we get promising results for zero-shot cardinality estimation on simple single table queries; as soon as we add joins, the accuracy drops.\nHowever, we show that with fine-tuning, we can still utilize pre-trained models\nfor cardinality estimation, significantly reducing training overheads compared to\ninstance specific models. We are open sourcing our scripts to collect statistics,\ngenerate queries and training datasets to foster more extensive research, also from\nthe ML community on the important problem of cardinality estimation and in\nparticular improve on recent directions such as pre-trained cardinality estimation.",
    "keywords": [
        "cardinality estimation",
        "zero-shot",
        "fine tuning",
        "databases"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Nu8b9C1xcr",
    "pdf_link": "https://openreview.net/pdf?id=Nu8b9C1xcr",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a benchmarking framework aimed at cardinality estimation within relational databases, using advanced learning methods like GNNs and Transformers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper details a systematic data preparation process, including SQL query generation, dataset statistics calculation, and annotated query graph creation, which offers a replicable approach for dataset-agnostic testing.\n\nThe paper\u2019s emphasis on creating a model that can generalize to unseen datasets is a unique and relevant shift in the CE field, considering the increasing need for adaptable models in dynamic data environments."
            },
            "weaknesses": {
                "value": "1. The authors said that they have collected data from 20 datasets with diverse sources compared with existing benchmarks. But I can't see this comparsion to conclude that how novel this part is. It deserves detailed discussion.\n\n2. Although it includes single-table and multi-table queries, it lacks support for deeply nested and highly complex SQL queries, which are common in real-world database applications. This limitation in query complexity could lead to suboptimal model performance in practical scenarios.\n\n3. Only q-error is used as the main evaluation metric, which may not fully capture model performance. Additional dimensions, such as runtime and resource consumption, could provide a more comprehensive assessment."
            },
            "questions": {
                "value": "see weakness above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces CardBench, a benchmark for evaluating learned cardinality estimation models in relational databases. Cardinality estimation is vital for query optimization, but existing models lack a comprehensive benchmark for systematic evaluation. CardBench provides this with extensive queries across 20 real-world databases. The study evaluates GNN and transformer-based models in instance-based, zero-shot, and fine-tuned setups, highlighting challenges in zero-shot accuracy with complex queries but demonstrating the potential of fine-tuning pre-trained models. By releasing scripts and data, the authors encourage further research, showing that pre-trained models can achieve high accuracy with reduced training overhead."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1: Cardinality estimation is critical for the database community.\n\nS2: This paper proposes several datasets, which will be useful for academic and industry communities.\n\nS3: Zero-shot cardinality estimation seems to be useful."
            },
            "weaknesses": {
                "value": "W1: The details of the datasets are unclear.\n\nW2: The baselines are too weak and lack state-of-the-art and representative cardinality estimation baselines.\n\nW3: The experiments lack detailed analysis of the proposed models regarding the zero-shot setting."
            },
            "questions": {
                "value": "D1: This paper proposes several synthetic cardinality estimation datasets. But what are the patterns and distributions in these datasets?\n\nD2: Why are these datasets comprehensive and diverse? From a database view, are these proposed datasets complete? It is better to add more justifications.\n\nD3: This paper proposes zero-shot estimation but only investigates limited GNNs. In cardinality estimation, whether sampling-based approaches or summary-based approaches, all work under a zero-shot setting. These approaches do not need any training instances. But this paper does not explore these approaches.\n\nD4: Even for GNN-based baselines, they are too simple. \n\nD5: How about the training time and inference time compared with the time of the training-free methods? If the training-free methods are better than the proposed method, it is meaningless to propose a pre-trained model.\n\nD6: This paper only explores the performance on cardinality estimation error. But how to prove it can achieve better performance on downstream applications? It is better to deploy this model on a real database system to see its improvements."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes the cardbench, a benchmark dataset for cardinality estimation in relational databases, which contains over 20 distinct real-world databases. This proposed dataset shows clear diverse and proposes several baseline models including the GNN and transformer modules to form a benchmark evaluation of this benchmark dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "+ A large-scale benchmark dataset for Cardinality Estimation\n+ Good evaluations and benchmark analyses.\n+ Clear organizations and easy to read."
            },
            "weaknesses": {
                "value": "+ My major concern is about the benchmark contributions to this research field. In the related work section, the authors talked about how existing benchmarks only contain one or two datasets which is insufficient for testing pretraining models. Thus my question is, how does this proposed benchmark test these pretrained models? It seems the authors only test typical GNN or Transformer architectures. \nThis dataset seems not to be comprehensive as a benchmark in this research field.\n+ Besides, gathering different datasets or re-organizing them also may help the aforementioned problems. Why is this proposed benchmark unique? I am concerned about the realistic usage and if this is a real problem for the community.\n+ There are also several minor issues, including the presentations for the Sect. 3 and the table format for table 1. These presentations could be improved."
            },
            "questions": {
                "value": "Please refer to the weakness section and I am concerned about the realistic usage of this proposed benchmark or it is an ``made\" problem."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents CardBench, a benchmark for evaluating learned cardinality estimation models in relational databases. CE is vital for optimizing query performance, yet traditional methods often lack accuracy. CardBench offers a diverse set of datasets and queries, featuring hundreds of thousands of queries across 20 real-world datasets, enabling systematic assessments of new CE approaches.\nExperiments with GNN and transformer-based models were conducted under three setups: instance-based, zero-shot, and fine-tuning. While zero-shot estimation shows promise for simple queries, its accuracy declines with complex joins. However, fine-tuning pre-trained models can enhance performance significantly, reducing training costs.\nThe authors emphasize that CardBench will lower barriers for research in learned CE and encourage further exploration from the machine learning community."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- CardBench includes a broad range of datasets, 20 distinct real-world datasets, that provide a more comprehensive evaluation framework for learned cardinality estimation models compared to existing benchmarks.\n- The benchmark facilitates systematic testing of various learned CE approaches, allowing researchers to assess model performance comprehensively. By open-sourcing the benchmark, query generator, and associated scripts, the authors foster collaboration and further research in the field, lowering barriers for other researchers to experiment with learned cardinality estimation.\n- The paper is clearly written and organised."
            },
            "weaknesses": {
                "value": "- There are several typos that need to be corrected in future revisions.\n- It would be beneficial to include more detailed statistical experimental results. While boxplots effectively illustrate the distribution of results, providing exact values enables precise comparisons between data points.\n- The descriptions of the GNN and Transformer models used in the experiments are lacking. More detailed explanations would help readers gain better insights into the methodologies.\n- The paper should discuss how the performance of other state-of-the-art methods compares on CardBench, which would provide context and strengthen the findings."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}