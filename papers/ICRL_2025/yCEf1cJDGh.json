{
    "id": "yCEf1cJDGh",
    "title": "Truthful Aggregation of LLMs with an Application to Online Advertising",
    "abstract": "The next frontier of online advertising is revenue generation from LLM-generated content. We consider a setting where advertisers aim to influence the responses of an LLM to align with their interests, while platforms seek to maximize advertiser value and ensure user satisfaction. The challenge is that advertisers may misreport their preferences. To address this, we introduce MOSAIC, an auction mechanism that ensures that truthful reporting is a dominant strategy for advertisers, and which aligns each advertiser\u2019s utility with their contribution to social welfare. Importantly, the mechanism operates without LLM fine-tuning or access to model weights and provably converges to the output of the optimally fine-tuned LLM for the platform\u2019s objective as computational resources increase. Additionally, it can incorporate contextual information about the advertisers, accelerating convergence. Via experiments with a publicly available LLM, we show that MOSAIC significantly boosts advertiser value and platform revenue with low computational overhead. While our motivating application is online advertising, our mechanism can be applied in any setting with monetary transfers, making it a general-purpose solution for truthfully aggregating the preferences of self-interested agents over LLM-generated replies.",
    "keywords": [
        "mechanism design",
        "llm",
        "auction",
        "online advertising"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "we give a truthful auction mechanism allowing agents to bid to influence LLM outputs, with a focus on advertising applications.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=yCEf1cJDGh",
    "pdf_link": "https://openreview.net/pdf?id=yCEf1cJDGh",
    "comments": [
        {
            "comment": {
                "value": "Thank you for the review. Below are our responses:\n\n\n**\"No real-world testing with actual advertiser data.\"** This is a great suggestion and we would really like to do it. The problem is that any such data would be closely held by advertising companies, and we don\u2019t have access. As far as we are aware, there is no such public data available.\n\n\n**\u201cAn analysis of how the mechanism handles scalability under different numbers of candidate replies or advertisers:\u201d** In Section 4.2, we explain why we consider our mechanism computationally efficient. Our mechanism scales linearly in both the number of participating advertisers and the number of candidate replies. This is also the case for the first and second price auctions that are used by major online platforms to run hundreds of billions of ad auctions on a yearly basis. We will expand on this section in the final version of the paper. \n\n\n**\"Given that the mechanism optimizes for advertiser reward and divergence from a reference LLM, there is a risk of unintentional bias in the final output.\u201d** In Section 4.1 and Appendix A.2, we prove that MOSAIC is an unbiased estimator of the optimal distribution for the platform\u2019s objective. If the platform\u2019s objective is unbiased, the same will be true for the output of our estimator. If bias here refers to societal bias, then using a base LLM which has been post-trained to remove such bias should help mitigate this issue.\n\n**\"What is the mathematical variance of the estimator?**\" The precise variance is provided in Section 4.1, lines 239-245, with a detailed derivation in Appendix A.2.\n\n**\"Convergence rate with number of candidate sequences.\"** In section 6.2 figure (a), we show experimentally that MOSAIC can converge to the target distribution using 20 candidate replies. In Section 4. and appendix A.2, we show MOSAIC\u2019s variance as an estimator. From the form of that variance, using standard concentration inequalities we can prove that our estimator converges to the true distribution at a rate proportional to 1$/\\sqrt{M}$, where $M$ is the number of candidate replies generrated. We will add this detailed derivation in the appendix. \n\n\n**\"How does the choice of hyperparameter $\\tau$ qualitatively influence the trade-off between advertisers\u2019 rewards and divergence from the reference LLM?\"** The reference LLM can be interpreted as one additional advertiser with her own reward function. By setting $\\tau$ equal to 1, all participants (the reference LLM and the advertisers) are treated equally. By setting $\\tau$ to any other number, it is as though we insert $\\tau$ such identical \u201creference LLM participants\u201d in the auction. Thus, larger values of tau place more weight towards the reference LLM, and smaller values place more value towards the advertisers.\n\n**\"The strategy proofness guarantee hinges on honest reporting by advertisers. But how robust is MOSAIC if advertisers engage in complex forms of gaming?\"** MOSAIC is **dominant** strategy incentive compatible. This means that it is always in an advertiser\u2019s best interests to report truthfully her preferences, even if the other advertisers are misreporting. There are no complex forms of gaming that will result in better outcomes for the advertisers \u2013 at least not unilaterally. This is one of MOSAIC\u2019s greatest strengths. If advertisers are able to collude with each other, they might be able to benefit themselves, but this is an unavoidable problem that always arises in strategyproof mechanism design, and platforms can prevent this possibility in practice.\n\n\n**\"In scenarios where advertisers have strongly opposing interests, does MOSAIC risk generating responses that conflict with each other?\"** Potentially yes, but the platform\u2019s objective can account for this. Intuitively, if the total utility of an \"equivocating\" answer for advertiser A and advertiser B is less than either \"just prefer A\", or \"just prefer B\", a single advertiser is more likely to be picked. On the other hand, if the advertisers are happy to be promoted together, that outcome is more likely. In our experiments, MOSAIC only includes 54% of the advertisers on average when it has converged, as opposed to 81% prior to convergence. We will include this result in the appendix."
            }
        },
        {
            "comment": {
                "value": "Thank you for the helpful review. Below are our responses:\n\n\n**\"Differences between reference and context-aware LLM from a theoretical perspective.\"** In Section 4.1, lines 239-246, we explain how our allocation rule is an importance-sampling based estimator, and show how the variance of that estimator depends on how well the LLM that generates the candidate replies \u201cmatches\u201d with the reference LLM. If that LLM is not tuned well, the variance of the estimator will blow up, meaning it will require more samples to achieve the same quality of approximation. We provide all details in Appendix A.2.\n\n\n**\"Do the authors have any preliminary insights for how to introduce contextual information into the current model?\"** This depends on the application. For our flagship application of online advertising, we detail how we do this in the footnote of line 269. For 50 practical examples, please see the file advertiser_prompts.py provided in the supplementary material. We will also include these examples in the appendix for convenience. \n\n \n**\u201cCan the mechanism incorporate constraints such as advertisers\u2019 budget/ROI constraints, or the maximum length of the LLM output?\u201d:** Yes, MOSAIC can incorporate all three of these considerations. The maximum length of the output reply can be easily incorporated by the platform. The platform chooses the LLM that generates the candidate replies, and it can enforce that constraint in the reply generation. For budget constraints, the advertiser should only bid rewards up to her maximum budget. For ROI constraints, the advertiser should \u201cbid shade\u201d when reporting her reward function to ensure that their ROI constraint is satisfied. Both of these changes would lead to worse utility per instance for the advertiser compared to truthful bidding. This is the case for any strategyproof mechanism, with the upshot being that she can extend her budget to more auction instances. However, for our mechanism we can additionally prove a new version of the \u201cwhat you give is what you get\u201d property (equation (5)) for this case. Informally: if an advertiser\u2019s shaded reported rewards still contribute to the social welfare of the final allocation, then her true utility will be positive, and even higher than Lemma 5.2 in the current version would suggest. We will add this discussion and the new theoretical result in the appendix."
            }
        },
        {
            "comment": {
                "value": "Thank you for the constructive feedback.\n\n\nAt a high level, we want to acknowledge your correct intuition that thinking about VCG is the right direction for this problem. This was also our starting point for this research project: \u201chow can we apply a VCG-like mechanism to an RLHF setting?\u201d However, the obvious ways of doing this either are intractable to implement, lose the nice properties of VCG in practice, or don\u2019t target the objective we focus on.\n\n\nWe took care to design a mechanism that can be implemented using familiar, easy operations on LLMs; can scale up or down with more or less compute; and, crucially, maintains good properties, even when scaled down. If it still looks very VCG-like even after meeting all those constraints, we consider this a success.\n\n\nBelow, we address specific points:\n\n\n**\"MOSAIC is only an approximation of VCG.\"** In Section 3.2, we clarify why VCG is not applicable in our setting. There are two versions of VCG to consider. Running VCG directly in distribution space is impractical due to high RLHF costs and latency constraints that the platform cannot afford on a per query basis, and it would not be strategy-proof without perfect convergence. Running VCG over a set of candidate replies also does not yield the optimal distribution for the platform's objective. Our allocation rule achieves this target, and implementing it in dominant strategies requires a different, non-VCG payment rule for truthfulness. Thus, while we are aiming for some similar goals, MOSAIC is not simply approximate VCG.\n\n\n**\"Other contributions are case-by-case operations that do not bring significance to the mechanism itself.\"** These contributions are tailored specifically for online advertising, a multi-billion-dollar application, making them highly meaningful.\n\n\n**\"Compare VCG with MOSAIC when applicable.\"** VCG is not applicable in our setting (see above). We consider naive MOSAIC a strong benchmark, as it also provably converges to the optimal distribution. Please also see our first reply to reviewer pFaF. \n\n\n**\"Why define KL divergence with $\\pi_{ref}$ on the right hand?\"** We use the standard RLHF objective, which has led to significant progress in LLM performance over the past five years. In principle, the platform could choose some other notion of distance between the two distributions. As long as the corresponding optimization problem has a closed-form solution, MOSAIC is in principle applicable, under two requirements. The allocation rule would have to correspondingly change to correspond to the new target distribution, and the payment rule would have to change to ensure truthfulness. This can be achieved iff the new allocation rule also satisfies cyclic monotonicity due to [Rochet 1987].\n\n\n**\"If a sub-optimal solution is chosen, VCG\u2019s strategy-proofness is no longer guaranteed.\"** Correct. There are numerous studies that detail how in general VCG\u2019s strategy-proofness fails without the optimal solution, see (Nisan & Ronen, 2007; 1999; Lehmann et al., 2002).\n\n\n**\"Feasible to sample from (2) using rejection sampling and $\\pi_{con}$.\"** Indeed, there is a strong connection between our mechanism and rejection sampling, as there is a fundamental connection between rejection and importance sampling algorithms. Your rejection sampling suggestion using $\\pi_{con}$ can be viewed as a dynamic, online version of MOSAIC, and would converge to the optimal distribution if advertisers reported truthfully. However, your rejection sampling proposal introduces two new challenges that make it inapplicable: Now the mechanism is dynamic, with each advertiser\u2019s report in one round influencing follow-up rounds. The design of appropriate payments to make such a dynamic mechanism dominant strategy incentive compatible is much more challenging, and it is unclear if such payments even exist. Second, the mechanism can no longer be parallelized across the generation of candidate replies. Thus, even if this suggested mechanism converged using the same number of replies as ours, it would still result in a large increase in user-perceived latency compared to our mechanism or directly querying an LLM.\n\n\n**\"MOSAIC\u2019s performance in the presence of low-probability large rewards.\"** You have correctly identified many of the design challenges we faced. The aim of the context-aware LLM is precisely to solve this problem, and we make a formal argument of exactly how it achieves this goal in Section 4.1 and Appendix A.2. The variance of our allocation rule in Section 4.1 ensures that MOSAIC converges at a rate of $1/ \\sqrt{M}$ regardless of the distribution of rewards. Additionally, please note that for our realistic prompts, we experimentally show that the use of the context-aware LLM solves this issue."
            }
        },
        {
            "comment": {
                "value": "Thank you for the constructive feedback. We address each comment below:\n\n\n**\"The authors can strengthen the differences between their proposed mechanism and the algorithms used in standard RLHF and rejection sampling.\"** Rather than emphasizing the differences, we want to highlight the similarities between our mechanism and traditional rejection sampling/RLHF. The use of these familiar operations, which are well-optimized and well-understood, is a key strength of our approach. Our focus was on building an incentive-compatible system from established, reliable components, rather than creating novel fine-tuning techniques that may be less practical or harder to optimize.\n\n\n**\"No comparative analysis between MOSAIC and other mechanisms.\"** The only comparable mechanism in the literature that aggregates multiple LLMs is Duetting et al., which is not strategy-proof. Additionally, the authors provided no implementation details/code, making it very hard to compare against. The only other potential comparison is VCG, which, as explained in Section 3.2, is not applicable since it does not align with the platform\u2019s objective. Hence, there is no valid baseline for comparison other than naive MOSAIC without advertiser contexts, which we consider a high benchmark given that it provably converges to the platform\u2019s optimal distribution based on Corollary 4.1.\n\n\n**\"Evaluate across different LLMs.\"** We have evaluated MOSAIC with T5, and the results were nearly identical. We will extend this evaluation with additional LLMs and include the results in the appendix.\n\n\n**\"Could the authors provide the different prompts used in the experiments?\"** All experimental prompts are available in the supplementary material under advertiser_prompts.py. We will also include them in the appendix for convenience.\n\n\n**\"How different prompts affect the mechanism\u2019s performance?\"** MOSAIC\u2019s performance across a wide range of prompts is demonstrated in our experiments (see section 6.2). Theoretically, the variance formula in lines 239-245 explains the impact of out-of-distribution prompts. Regardless of the prompt distribution, the variance result ensures that MOSAIC converges at a rate of $1/\\sqrt{M}$, where $M$ is the number of candidate replies generated. Please also refer to our response to reviewer MGd7.\n\n\n**\"Extend comparison to other mechanisms from similar studies.\"** Please refer to our response above regarding the unavailability of other comparable mechanisms.\n\n\n**\"Utilize various closed-source models.\"** Our implementation is fully compatible with both open- and closed-source models, and the provided source code only relies on API calls compatible with both types of models. While testing with closed-source models is of interest, it is not an expense we can process with our institution in one week."
            }
        },
        {
            "summary": {
                "value": "This paper introduces an auction mechanism, MOSAIC, to aggregate the preferences of multiple self-interested advertisers over LLM-generated replies. The authors claim that this mechanism can converge to the outputs of the optimally fine-tuned LLM as computational resources increase, without requiring fine-tuning or access to model weights. The authors also present context-aware versions of MOSAIC, which accelerates convergence and yields high advertiser value and platform revenue. Experiments with a publicly available LLM demonstrate that MOSAIC achieves high advertiser value and platform revenue with minimal computational overhead."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well structured, offering clear explanations of the problems addressed and the key terms used.\n2. The proposed mechanism has a firm theoretical grounding.\n3. The proposed mechanism seems to demonstrate strong applicability to real-world scenarios, especially in the realm of online advertising with LLM-generated content."
            },
            "weaknesses": {
                "value": "1. The novelty of this paper is limited and the scientific contribution seems to be not obvious. The proposed mechanism addresses the problems using conventional approaches. The authors can strengthen the differences between their proposed mechanism and the algorithms used in standard RLHF and the rejection sampling.\n2. The experiments are insufficient. There are no comparative analyses between MOSAIC and other mechanisms, which makes it difficult to comprehensively assess its performance. The experiments are restricted to the use of Llama-2-7b-chat-hf, lacking generalizability across different LLMs. It would be nice to compare with other mechanisms mentioned in the related work and evaluate across different LLMs like Llama-3-8B, T5, and Mistral-7B."
            },
            "questions": {
                "value": "1. Could the authors provide the specific prompts utilized in the experiments detailed in the paper? Additionally, could you further discuss how different prompts might affect the mechanism's performance?\n2. Could the authors extend their experiment to include comparison with other mechanisms from similar studies?\n3. Given the paper's claim that the proposed mechanism can operate without LLM fine-tuning or access to model weights, could the authors extend the experiments to include utilization of various closed-source models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a mechanism called MOSAIC, that aggregates multiple advertising LLMs (represented by reward functions) and try to find a distribution on replies that maximizes the total rewards of advertisers together with a KL-divergence regularization term on user preference $\\pi_{ref}$. MOSAIC takes the reward functions as input, and output a (stochastic) reply to the user.\n\nMOSAIC first samples $M$ candidate replies from arbitrary general and pre-defined distribution $\\pi_{gen}$. After this, MOSAIC computes the distribution on replies (regarding the distributions as mechanism allocation) and sample one reply from this distribution as final output. The mechanism payments are computed by Rochet payment (1987). As $M$ tends to infinity, MOSAIC is guaranteed to converge to VCG mechanism.\n\nIn experiments, the paper specifies reward functions and $\\pi_{gen}$ by LLM distributions and contextually prompting LLMs, respectively. Experiments show that contextual-prompting MOSAIC performs far better than naive MOSAIC with $\\pi_{gen} = \\pi_{ref}$, with the log-probability of reply close to  optimal distribution."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The author provides  an example throughout the paper, making the model easy to understand. The aggregation of LLMs is an important topic, while the introducing of regularization of user preference is novel. The idea of approximating VCG is also interesting."
            },
            "weaknesses": {
                "value": "Major Issues:\n\n* I think the main drawback of this paper is that MOSAIC is only an approximation of VCG mechanism. Moreover, such approximatio\nn is natural and not challenging to discover and define. Specifically, VCG outputs the distribution on full reply space, while MOSAIC\n first discretizes the full space into finite points and then outputs a distribution on finite points. This operation is simple a\nnd do not change the nature of VCG mechanism. Therefore, I believe that the contribution of MOSAIC is not significant.\n* The other contributions of this paper, eg, context-aware LLM in Line 237 $\\pi_{con}$, and payment offset in Line 335, are case-by-case operations and do not bring significance on the mechanism itself. These ideas are also natural. Besides, the payment contribution is a direct application of Rochet payment (1987). Overall, I believe that the contributions are incremental and limited.\n* Regarding the experiments, the authors only compare the contextual-prompting MOSAIC with naive MOSAIC. There is no comparison\n with baselines, thus I cannot evaluate whether the performance of MOSAIC is acceptable from these experiments. A suggestion is\n to compare MOSAIC with VCG mechanism directly when VCG is applicable.\n\nBesides, the presentation needs improvement. For example,\n\n* In Line 419, it appears $\\pi_i$. However, $\\pi_i$ is only mentioned in Line 146. The definition of $\\pi_i$ should be better placed between its first use, i.e., just before Line 419.\n* In Section 1.2, the authors mentioned 7 contributions of this paper. However, these contributions are incremental, or only the technical details appeared in this paper.\n* In the paragraph of Line 242, the notation $\\pi_r$ have never defined before these appearances. I think it should be $\\pi_{ref}$.\n* In line 313-314, I think that the term $\\log (\\frac{\\pi_{ref}}{\\pi_{gen}}) should be included in the $\\exp(\\cdot)$.\n* In the appendix, the sections are titled with \"Details from Section xx\", \"Omitted Proofs from Section xx\". It is conventional to use 'in' instead of 'from'."
            },
            "questions": {
                "value": "* In equation (1) in line 152, why do you define KL-divergence of the two distributions and why $\\pi_{ref}$ is on the right hand? Will other choices fail?\n * In the paragraph between line 196 and 201, the author says, \"*The VCG allocation rule requires calculating the exact optimal solution to the optimization problem, which is intractable for choosing an LLM to maximize Equation (1) and is even difficult for choosing a single optimal sequence. If a sub-optimal solution is chosen, VCG\u2019s strategyproofness is no longer guaranteed (Nisan & Ronen, 2007; 1999; Lehmann et al., 2002).*\"\n  * In my understanding, choosing an LLM to maximize Equation (1) is equivalent to choosing an LLM that satisfies (2). Since we already have access on $\\pi_{ref}$, when $r(x,y) = \\sum_i r_i(x,y)$ is upper bounded given $x$, it's feasible to sample from (2) by rejection sampling. Besides, we can also use $\\pi_{con}$ replacing $\\pi_{ref}$ to decrease variations. In this sense, I do not find the advantage of using MOSAIC rather than using VCG directly. Could you make some clarifications on this concern?\n  * Even in the case that $r(x,y)$ is not upper bounded and VCG can not be implemented, it's possible that sub-optimal solutions are chosen and strategyproofness still hold, MOSAIC is exactly one example. Besides, I think MOSAIC will also behave badly in this case because the probability of large value of $r(x, y)$ is small, and it's likely to sample $M$ candidates $y_1,...,y_M$ with all $r(x,y_i)$s are small."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors studied a setting in which the advertisers would like to influence the LLMs to generate their preferred contents and the platform would need to satisfy both advertiser preference and user utilities. The authors proposed an auction mechanism called MOSAIC that enjoys a number of advantages, including ensuring that truthful reporting is a dominant strategy for advertisers. The authors also suggested that the proposed mechanism is equipped with technical feasibility and practicality. To validate their claims, the authors provided both theoretical results and numerical experiments with a publicly available LLM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is well written and organized.\n- LLM and its application to online advertising, especially the domain of ad auctions, is a novel area to be studied with practical relevance.\n- The theoretical results provided appear sound. The authors also clearly stated the difference between their proposed mechanism and previous auction mechanisms such as VCG.\n- The numerical experiments (and the motivating example) provide interesting insights."
            },
            "weaknesses": {
                "value": "- I wonder if the authors can provide more explanations for why the ref LLM is not performing as well as the context-aware LLM. I understand that the authors have provided some intuitive explanations in Sections 4, but the ref LLM still appears to be an intuitive choice based on Corollary 4.1. Would it be possible to gain more insights into this difference from a theoretical point of view? Does the authors have any preliminary insights for how to introduce contextual information into the current model? \n- The current framework does not consider a number of constraints that could impact the advertisers' decision-making process, such as each advertiser's budget and/or ROI constraints, or the maximum length of the LLM output. I wonder if the authors can comment on whether their mechanism can incorporate any of the above features."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces MOSAIC, an auction mechanism designed for aggregating advertiser preferences within the outputs of large language models (LLMs), particularly for applications in online advertising. The authors address the challenge of balancing the interests of multiple advertisers with user-centric content by creating a mechanism that incentivizes truthful reporting from advertisers. MOSAIC uses an approach that combines an allocation rule based on importance sampling, allowing it to converge to the optimal output distribution as computational resources increase, without requiring direct model fine-tuning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper introduces MOSAIC which effectively combines the preferences of self-interested advertisers while maintaining user-centric content. This is achieved without requiring direct access to LLM weights, which adds flexibility and broad applicability.\n\nThe mechanism ensures that truthful reporting is a dominant strategy for advertisers, thanks to its carefully constructed payment and allocation rules. This strategy-proofness is backed by theoretical proofs.\n\nThe design is computationally efficient, using only API access and avoiding expensive fine-tuning."
            },
            "weaknesses": {
                "value": "1. There is no real-world testing or application with actual advertiser data to validate the effectiveness of MOSAIC in practical applications.\n\n2. Although MOSAIC is designed to be efficient, it may still face scalability challenges as the number of advertisers or candidate replies grows. An analysis of how the mechanism handles these scenarios under different computational limits would strengthen the paper.\n\n3. Given that the mechanism optimizes for advertiser rewards and alignment with a reference LLM, there\u2019s a risk of unintentional bias in the final output.\n\n4. MOSAIC relies on advertisers truthfully reporting their preferences and reward functions, yet it does not fully address how misreporting could impact results. Further discussion on mid-reporting would be important."
            },
            "questions": {
                "value": "1. The paper claims that MOSAIC\u2019s allocation rule converges to an optimal distribution as computational resources increase. How does the rate of convergence depend on the number of candidate sequences?\n\n2. The allocation rule is based on importance sampling to estimate the probability distribution over sequences. What is the mathematical form of the variance for this estimator?\n\n3. How does the choice of the hyperparameter \\tau in front of the KL term quantitatively influence the trade-off between advertiser reward maximization and alignment with the reference LLM?\n\n4. The strategyproofness guarantee hinges on honest reporting by advertisers, but how robust is MOSAIC if advertisers engage in complex forms of gaming or misreporting? \n\n5.  In scenarios with advertisers holding strongly opposing interests, does MOSAIC risk generating responses that conflict with each other?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}