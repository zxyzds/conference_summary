{
    "id": "iMJpmcYucq",
    "title": "Stochastic variance-reduced Gaussian variational inference on the Bures-Wasserstein manifold",
    "abstract": "Optimization in the Bures-Wasserstein space has been gaining popularity in the machine learning community since it draws connections between variational inference and Wasserstein gradient flows. The variational inference objective function of Kullback\u2013Leibler divergence can be written as the sum of the negative entropy and the potential energy, making forward-backward Euler the method of choice. Notably, the backward step admits a closed-form solution in this case, facilitating the practicality of the scheme. However, the forward step is no longer exact since the Bures-Wasserstein gradient of the potential energy involves \"intractable\" expectations. Recent approaches propose using the Monte Carlo method -- in practice a single-sample estimator -- to approximate these terms, resulting in high variance and poor performance. We propose a novel variance-reduced estimator based on the principle of control variates. We theoretically show that this estimator has a smaller variance than the Monte-Carlo estimator in scenarios of interest. We also prove that variance reduction helps improve the optimization bounds of the current analysis. We demonstrate that the proposed estimator gains order-of-magnitude improvements over the previous Bures-Wasserstein methods.",
    "keywords": [
        "Variational inference",
        "Bures-Wasserstein space",
        "Riemannian manifold",
        "optimization"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=iMJpmcYucq",
    "pdf_link": "https://openreview.net/pdf?id=iMJpmcYucq",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes an improved optimization technique for variational inference with a multivariate Gaussian variational family.\n\nBuilding on the prior work that proposed optimization on the Bures\u2013Wasserstein manifold and simple one-sample stochastic gradient estimators, this work offers improved stochastic gradient estimators. These are based on a simple idea: as iterates get closer to the optimum, they provide additional information about the next gradient that can be used to reduce variance of its stochastic estimator.\n\nAuthors support the superiority of the new optimization technique with both theoretical analysis and empirical evaluation, the latter on a set of synthetic benchmarks."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is written very well. It is a pleasure to read.\n- The theoretical analysis is convincing (I didn\u2019t rigorously check the proofs but I don\u2019t doubt the claims and I am pretty sure the methods authors use are quite appropriate).\n- Empirical evaluation shows very strong improvement over the baselines, more so than the theoretical analysis (which is not claimed to be tight) suggests."
            },
            "weaknesses": {
                "value": "-I\u2019m not an expert in optimization, so it\u2019s somewhat hard for me to judge the impact. I can speculate that the problem might seem somewhat narrow: variational inference with _Gaussian_ variational family. However, I don\u2019t really think so myself. Furthermore, in my opinion, a good solution to even a somewhat narrow problem definitely warrants publication.\n\nI would actually give this paper a score of 9, but only 8 and 10 are available."
            },
            "questions": {
                "value": "As mentioned above, in my opinion the paper is very well-written. I therefore don\u2019t have any content-related questions, only a small number of typographical suggestions for the authors:\n- Perhaps use the en-dash (--) instead of the simple dash (-) in \"Bures\u2013Wasserstein\". I believe this is the standard when it comes to joining two names.\n- I believe that \"FB\" abbreviation (forward-backward) is never introduced.\n- The term \u201cL-smooth\u201d seemed weird to me, why not \u201cL-Lipschitz\u201d?\n- Page 4, line 174, \u201caffine map\u201d -> \u201caffine maps\u201d.\n- Page 4, line 198, \u201cshows that\u201d -> \u201cshowed that\u201d.\n- Page 5, line 233, I would remove parentheses around the \u201calso see ...\u201d, they look ugly immediately after a citep.\n- Page 5, line 237, perhaps add commas around \u201cwhere $c \\in \\mathbb{R}$\u201d, otherwise the sentence is hard to read.\n- Perhaps, when introducing Algorithm 1, you could briefly mention there are recipes for defining the constants $c_k$ that you investigate further in the text. An algorithm without parameters you don\u2019t know how to set would come across as more useful.\n- Page 8, line 387, \u201cWe also note that conditioning\u201d -> \u201cWe also note that by conditioning\u201d.\n- Page 8, footnote 1, please expand what is the minor correction. Also, perhaps start with a capital letter.\n- Page 9, line 457, missing \u201ce\u201d in \u201ccovariancs\u201d.\n- Page 9, line 472, \u201cIn The\u201d -> \u201cIn the\u201d.\n\nNote: no need to respond to the small items above in the rebuttal, save yourself some time."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "- The authors propose a control-variate-based variance reduction technique for gradient estimation in stochastic Gaussian variational inference (SGVI).\n- They theoretically demonstrate that, in specific cases such as high-curvature distributions, the gradient estimator with their method achieves lower variance than the standard SGVI.\n- Additionally, they show that their variance reduction scheme enhances the convergence of SGVI when $V(x)$ is (strongly) convex.\n- Empirically, they confirmed that their method improves the convergence properties of SGVI."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The authors extend the control variate method\u2014a well-established variance reduction technique in stochastic variational inference (VI)\u2014to variational inference in Bures-Wasserstein space.\n- The variance reduction performance of the proposed method is theoretically guaranteed in (strongly) convex settings.\n- The authors demonstrate improved convergence over existing SGVI and Bures-Wasserstein gradient descent (BWGD) methods through several numerical experiments."
            },
            "weaknesses": {
                "value": "I would like to express my sincere respect for the efforts the authors have invested in this paper. However, I am unable to strongly recommend it for acceptance at ICLR 2025 for the following reasons:\n\n### Concerns Regarding Theoretical Analyses:\n- The evaluation of the derived bound is primarily qualitative and limited to a comparison with the existing upper bounds in [Diao et al., 2023]. However, detailed analysis of each term and the behavior of the bound as the iteration count $N$ approaches infinity\u2014specifically in terms of convergence and the conditions required for convergence\u2014is somewhat lacking. This limits a comprehensive understanding of the proposed method\u2019s advantages and challenges the assessment of this paper\u2019s contribution.\n- In the convex case, the variance reduction effect is guaranteed only in the neighborhood of the optimal solution (Thm. 1). However, the convergence analysis in Thm. 3 assumes that variance reduction holds \u201cthroughout all iterations of the algorithm,\u201d which seems to suggest that parameters are already near the optimal solution from the outset\u2014a somewhat unrealistic assumption (or am I misinterpreting this?).\n- Additionally, from the proof, it appears that the improvement in the bound is only valid under the aforementioned assumption: \u201cwhen variance reduction is assured for all iterations.\u201d This assumption seems to diverge from the result in Thm. 1. Is there a clear link between them? Is the radius $r$ of this region always sufficiently small?\n\n### Concerns Regarding Numerical Experiments:\n- One key motivation for variance reduction in stochastic variational inference is to enhance convergence and generalization in real-world data applications (e.g., [Ruiz et al. (2016); Roeder et al. (2017); Miller et al. (2017); Buckholz et al. (2018)]). However, the numerical experiments in this paper are primarily conducted on synthetic data, and the discussion of the practical applicability of the proposed method is somewhat limited.\n- Additionally, there are no direct measurements of gradient variance, leaving insufficient empirical evidence regarding the extent of gradient variance reduction compared to existing methods. If the empirically measured gradient variance does not differ substantially from that of other methods, it is possible that other factors are driving the observed improvement in convergence. Furthermore, based on the results presented, the effectiveness of gradient variance reduction appears to depend on the setting of $c$. Practical guidance on choosing $c$, based on an analysis of the sensitivity of variance-reduction performance to $c$, would be beneficial. Currently, such guidance is absent, leaving limited information on how to apply the proposed method in practice.\n- When comparing with variance-reduction methods in SVI in Euclidean space (EVI), this study adopts the method of Roeder et al. (2017); however, the rationale for this choice is unclear. While both methods share a similarity in achieving performance improvements through modest algorithmic modifications, concluding that the proposed method outperforms EVI without comparison to more recent approaches seems premature (e.g., [Miller et al. (2017); Buckholz et al. (2018)]).\n\n### Lack of Discussion on Other Variance Reduction Studies in EVI:\n- Recent years have seen substantial progress in variance reduction research within EVI, with many theoretical analyses and methods proposed (e.g., [Kim et al. (2023); Domke et al. (2023)]). These approaches extend beyond control variate methods to include enhancements to Monte Carlo methods and techniques such as reparameterization tricks in Gaussian settings, as in Roeder et al. (2017). While the use of control variates as an initial approach to variance reduction in SGVI is reasonable, the motivation for extending only the control variate approach may seem somewhat limited given the variety of variance reduction techniques available. It might be helpful to mention, for example, the specific challenges or limitations that prevent the application of alternative variance reduction techniques in SGVI, if applicable.\n\n### Citation:\n- Ruiz et al. (2016): Francisco J. R. Ruiz, Michalis K. Titsias, and David M. Blei. The Generalized Reparameterization Gradient. NeurIPS2016. https://arxiv.org/abs/1610.02287.\n- Miller et al. (2017): Andrew C. Miller, Nicholas J. Foti, Alexander D'Amour, and Ryan P. Adams. Reducing Reparameterization Gradient Variance. NeurIPS2017. https://arxiv.org/abs/1705.07880\n- Buckholz et al. (2018): A. Buchholz, F. Wenzel, and S. Mandt. Quasi-Monte Carlo Variational Inference. ICML2018. https://arxiv.org/abs/1807.01604.\n- Kim et al. (2023): K. Kim, K. Wu, J. Oh, and J. R. Gardner. Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. ICML2023. https://proceedings.mlr.press/v202/kim23w.html.\n- Domke et al. (2023): J. Domke, R. Gower, and G. Garrigos. Provable convergence guarantees for black-box variational inference. NeurIPS2023. https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0bcff6425bbf850ec87d5327a965db9-Abstract-Conference.html."
            },
            "questions": {
                "value": "Based on the concerns summarized in the weaknesses section, I would like to pose the following questions, categorized into \u201ctheoretical\u201d and \u201cexperimental\u201d aspects:\n\n### Questions on Theoretical Analyses:\n1.\tCould the authors provide a more detailed discussion on the behavior of each term in the derived bound and how the bound behaves as the iteration $N$ approaches infinity, particularly in terms of convergence and conditions for convergence?\n2.\tIn the convex case, variance reduction is guaranteed only near the optimal solution (Thm. 1), while the convergence analysis in Thm. 3 assumes variance reduction is achieved \u201cin all iterations.\u201d Does this assumption imply that parameters are initially close to the optimal solution, and if so, how realistic is this assumption?\n3.\tThe improvement in the bound relies on the assumption that variance reduction is guaranteed for all iterations. How does this assumption align with the results of Thm. 1? Is the radius $r$ of the region always small enough to ensure consistency between the two theorems? If not, there may be a significant gap between these results.\n\n### Questions on Experimental Analyses:\n1.\tThe numerical experiments are primarily conducted on synthetic data. Could the authors consider conducting experiments on real-world datasets to provide more practical insights into the usefulness of the proposed method?\n2.\tThere are no experiments measuring the reduction in gradient variance. Could the authors include empirical measurements of gradient variance to illustrate how much variance is reduced compared to existing methods? The following references may be relevant for this consideration: [Miller et al. (2017); Buckholz et al. (2018)].\n3.\tIn the proposed method, the degree of variance reduction appears to depend on the parameter $c$. Could the authors provide additional practical discussions and sensitivity analyses on the selection of $c$ and its impact on variance reduction performance, particularly in terms of gradient variance? Although Figure 2 presents the relationship between $c$ and the degree of variance reduction, it would be beneficial to confirm whether this behavior is consistent across various experimental settings.\n4.\tThe comparison with the method of Roeder et al. (2017) in Euclidean SVI is understandable; however, could the authors clarify the rationale for not including comparisons with more recent variance-reduction methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper propose improvements on a gaussian variational inference algorithm in the Bures-Wasserstein manifold.  The idea is to find the best Gaussian approximation (in the KL sense) to a probability distribution of the form $Ce^{-V}$ (where $C$ is unknonw) and to use the Wasserstein geometry on the space of Gaussian distribution (Bures-Wasserstein manifold) to guide us toward the optimal solution.  Several authors have studied this question in the last few year leading to an implicit-explicit algorithm.  In this framework the implicit backward (JKO-style) step is computable explicitly and the explicit forward step involves the computation of the the expectations of the gradient and  the Laplacian of $V$ under gaussian measures.  The central contribution of the paper is to perform a variance reduction (using control variates)  at each step and to study the effect of this on the rate of convergence of the algorithm.  Some synthetic examples are studied."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "I found the paper to be very overall very well-written with a very clear presentation of the background, literature, and of the technical ideas involved.  The results and the proofs are clearly presented.  Since the measure involved are Gaussian, the analysis of the control variate is quite straightforward and this lead to an improved algorithm at essentially no additional cost.  I think that it is the main contribution of the paper to point out this very cheap improvement to the algorithm. The empirical results also supports this improvement of the stability of the algorithm leading to a substantially better approximation.  At the technical level, control variates for Gaussian measures are quite straightforward and the analysis of the variance reduction relies on standard techniques as well (Stein's lemma).  The convergence of the algorithms is then analyzed by leveraging the results recently obtained Diao et a. (ICML 23) and propagating the improved variance through the convergence analysis of Diao et al.  This leads to improved convergence results."
            },
            "weaknesses": {
                "value": "I think the main weakness is the lack of interesting examples. The algorithms seems to do great on the synthetic examples but it remains to be seen how it will perform in a realistic  Bayesian inference example based on real data."
            },
            "questions": {
                "value": "+  Are there any obstacles in applying this to more realistic statistical inference problems?  I really do appreciate the mathematical elegance  of the proposed method but t would be nice to have a better test problem  to make the case for the method.\n\n+ Any head-to-head comparisons with different inferences methods such that MCM, Hamiltonian MC, or likelihood free inferences (e.g. using diffusions models) on a test problem would be helpful to convince the reader of the efficiency of the method., \n\n+  The improvement due to control variates looks quite impressive (as it  sometimes does with control variates!).  The convergence analysis  is nice but it is not clear it shed light on this improvement. Any other explanation, even the hand-waving kind?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper considers the variational inference (VI) problem by minimizing the Kullback-Leibler (KL) divergence over the Bures-Wasserstei space of Gaussian distributions. Building on the work by Diao et al., this paper employs the forward-backward Euler method to tackle the composite nature of the KL objective and non-smoothness of the entropy. The forward step involves computing the Bures-Wasserstein (BW) gradient, which needs to be estimated using Monte Carlo (MC) method with a single sample. However, this approach results in noisy BW gradients, leading to inefficient convergence. The main contribution of this paper is to overcome this limitation, proposing a variance-reduced estimator for the BW gradient, leveraging a control variate approach. In addition, this paper also provides convergence analysis and present experimental results that demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well structured, clearly presenting the problem and the proposed solution. The main idea of using a control variate to reduce the variance of BW gradient is both well-motivated and reasonable. Additionally, it provides strong theoretical foundations for the derived variance-reduced Gaussian VI. The experimental results further validate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "I have two major concerns regarding the proposed method in this paper:\n\n1) A straightforward approach to addressing the noisy BW gradient is to sample multiple $X_{k}$ from $\\mu_{k}$. This is both effective and efficient, requiring low extra computational cost if estimating $\\nabla V$ and $\\nabla^{2}V$ is not expensive. I am curious how the performance of the proposed method compares to this trivial approach.\n\n2) The paper only considers the case where $\\mu_{k}$ is Gaussian, and the proposed method appears to work well for simple target distributions. Note that both compared methods (BWGD and SGVI) can be extended for Gauss mixtures, while extending the proposed method in this paper to cases of Gaussian mixtures may not trivial. In such cases, the proposed control variate approach might lose its effectiveness and efficiency, as $E[Z_{k}]$ is not zero (the mean) and estimating it is non-trivial."
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}