{
    "id": "VuTrZzrPfn",
    "title": "OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning",
    "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have shown great potential in automating complex tasks like web browsing and gaming. However, their ability to generalize across diverse applications remains limited, hindering broader utility. To address this challenge, we present OSCAR: Operating System Control via state-Aware reasoning and Re-planning. OSCAR is a generalist agent designed to autonomously navigate and interact with various desktop and mobile applications through standardized controls, such as mouse and keyboard inputs, while processing screen images to fulfill user commands.\nOSCAR translates human instructions into executable Python code, enabling precise control over graphical user interfaces (GUIs). To enhance stability and adaptability, OSCAR operates as a state machine, equipped with error-handling mechanisms and dynamic task re-planning, allowing it to efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR\u2019s effectiveness through extensive experiments on diverse benchmarks across desktop and mobile platforms, where it transforms complex workflows into simple natural language commands, significantly boosting user productivity. Our code will be open-source upon publication.",
    "keywords": [
        "Large Language Model",
        "Autonomous Agent",
        "Graphical User Interface"
    ],
    "primary_area": "applications to robotics, autonomy, planning",
    "TLDR": "We present a generalist agent that navigates various applications in an operating system using only screen input.",
    "creation_date": "2024-09-23",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=VuTrZzrPfn",
    "pdf_link": "https://openreview.net/pdf?id=VuTrZzrPfn",
    "comments": [
        {
            "summary": {
                "value": "- This work presents an LLM+LMM-based agent to solve Desktop/Mobile OS tasks, including key modules such as GUI elements recognition and SoM prompting, plan/re-plan state machine and code execution for general mouse/keyboard control.\n- Experiments on multiple, both static and dynamic, benchmarks demonstrate the proposed framework's efficacy and generalizability."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This work shows a robust and efficient OS agent by resorting to a general purposed language models without fine-tuning. To cope with GUI recognition difficulties (beyond general vision tasks), SoM techniques are applied to improve reliability.\n- Many baseline comparisons and detailed implementation are also provided."
            },
            "weaknesses": {
                "value": "- Discussion on safety may be helpful since the agent has control over an OS.\n- Although it uses a state machine and re-planning, OSCAR lacks a self-improvement mechanism. Do you have more insights on representing states, e.g. system errors/task failures, beyond pure text language?"
            },
            "questions": {
                "value": "- What makes OSCAR outperform other baselines mostly (since many methods also have their feedback loop)?\n- Will a fine-tuned LM be eventually required for the robustness in real-world scenarios beyond those benchmarks? To what degree is a user/expert required to supervise the agent's operation?\n- Is plan -> execution -> error -> re-plan enough even for complex tasks or sampling-based methods such as evolutionary search (but costly and redundant) should be also considered."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents OSCAR, a generalist agent designed to autonomously navigate and interact with both desktop and mobile applications using standard controls like mouse and keyboard. The agent aims to interpret user commands, interact with graphical user interfaces, and adapt its strategies based on real-time feedback. OSCAR is constructed as a state transition process and integrated with a GUI dual-grounding observation and task-driven re-planning. Further, the authors evaluate OSCAR on three digital task benchmarks, OSWorld, GAIA and AndroidWorld, outperforming current SOTA AI systems in completing digital tasks."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The use of a task-driven re-planning strategy allows OSCAR to adjust its actions based on real-time feedback, which enhances its ability to correct itself, do the state-aware reasoning and complete complex tasks autonomously.\n2. OSCAR is evaluated against a diverse set of benchmarks, demonstrating superior performance in both desktop and smartphone environments, which underscores its generalizability and effectiveness.\n3. The state transition process in OSCAR allows for systematic handling of tasks by structuring operations into distinct phases, such as observation, planning, execution, and verification. This structured approach enhances error recovery and adaptability by enabling the agent to assess and resolve issues at each state"
            },
            "weaknesses": {
                "value": "1. I think it would be better to give some detailed cases to explain how the state transition works to complete the task and handle the errors.\n2. There could be more discussions about how to fit OSCAR into different OS envs and generalize it to more benchmarks and systems."
            },
            "questions": {
                "value": "1. In the dual-grounding observation approach, how do you add the labels to each element to provide explicit semantic grounding?\n2. What does \"evaluation scripts\" in section 2.1 refer to? Do you leverage the task-specific evaluation scripts from OSWorld? You may make it more clear about how you evaluate OSCAR on each of the three benchmarks.\n3. As you allow 4 attempts per run for the agent to finish the task, is it crucial for a better performance and higher score on the benchmark? Do they always learn from failures and need more attempts to do better?\n4. A more detailed error analysis is needed to specifically analyze the reasons for failure cases of reaching step limits, as this may help further improve OSCAR's error handling mechanism."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces OSCAR, a generalist agent that autonomously navigates and interacts with desktop and mobile applications through standard controls like mouse and keyboard inputs. OSCAR\u2019s framework includes state transitions that dynamically adapt to various environments and are equipped with error-handling mechanisms. OSCAR also addresses the challenge of VLM\u2019s difficulty in interpreting GUI screenshots by grounding them with semantic symbols. Finally, OSCAR incorporates task-driven replanning for efficient real-time adjustments based on feedback and exceptions. OSCAR is evaluated on GAIA, OSWorld, and AndroidWorld benchmarks. The results show that OSCAR significantly outperforms other baseline methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. OSCAR demonstrates strong performance on evaluated benchmarks, achieving an average success rate of 28.7% and a success rate of 13.5% on the most challenging Level 3 tasks in the GAIA benchmark.\n2. OSCAR implements a state machine with well-defined behaviors to manage complex, dynamic environments effectively.\n3. Grounding GUI images with semantic symbols offers a more systematic approach for VLM to interpret the current state of the OS environment."
            },
            "weaknesses": {
                "value": "The [Verify] state is crucial to OSCAR\u2019s framework; however, its exact functionality remains unclear. For instance, what occurs when [Verify] yields a false positive, such as validating an invalid plan? Can the system recover from these failures? Conducting an in-depth analysis of the [Verify] step's failure modes and success rate would significantly enhance the paper's quality."
            },
            "questions": {
                "value": "No questions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces OSCAR, a computer agent framework mainly focused on planning and aimed to generalize across diverse applications. The experiments demonstrate OSCAR\u2019s effectiveness on GAIA, OSWorld, and AndroidWorld."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed agent framework is formulated as a state machine, making it clear to follow.\n2. OSCAR outperforms several baselines in both desktop and mobile environments."
            },
            "weaknesses": {
                "value": "1. The proposed modules (task-driven re-planning, context memory, GUI observations, and code actions) are not novel. Many closely related methods are not discussed, e.g.:\n- Kim et al. \"Language models can solve computer tasks.\" NeurIPS 2023.\n- Sun et al. \"Adaplanner: Adaptive planning from feedback with language models.\" NeurIPS 2023.\n- Zheng et al. \"Synapse: Trajectory-as-exemplar prompting with memory for computer control.\" ICLR 2024.\n\n2. The experiments only ablate GUI observations and the replanning module. The analysis claims that the improvements come from \u201cfewer re-planning attempts\u201d and \u201csmaller, more efficient steps\u201d, but it is unclear how the proposed planning module contributes to this compared to the baselines.\n\n3. In Table 3, OSCAR outperforms baselines in medium and hard cases but is worse in easy cases, for which the authors should analyze the potential reasons.\n\n4. It is unclear how OSCAR leverages \u201creal-time\u201d feedback from the OS. Additional experiments on AgentStudio, a more complex, dynamic environment, are helpful.\n\n5. The limitations of OSCAR are not discussed.\n\n6. Minor: there are many typos, e.g.:\n- line 300, \u201ci.e. when\u201d -> \u201ci.e., when\u201d; line 332, \u201c(e.g. Chrome)\u201d -> \u201c(e.g., Chrome)\u201d; and so on.\n- missing or abundant space in Section 1 \u201c(LLMs)(Ouyang \u2026\u201d, \u201c(LMMs)(Li \u2026\u201d, Section 3 baselines \u201cUFO(Zhang et al., 2024a)\u201d, Table 1 caption \u201c(i.e. GPT-4-turbo )\u201d, etc.\n\nI will raise my score if the authors resolve the above concerns."
            },
            "questions": {
                "value": "See Weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}