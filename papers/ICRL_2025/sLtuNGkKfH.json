{
    "id": "sLtuNGkKfH",
    "title": "Subject Information Extraction for Novelty Detection with Domain Shifts",
    "abstract": "Unsupervised novelty detection (UND), aimed at identifying novel samples, is essential in fields like medical diagnosis, cybersecurity, and industrial quality control. Most existing UND methods assume that the training data and testing normal data originate from the same domain and only consider the distribution variation between training data and testing data. However, in real scenarios, it is common for normal testing and training data to originate from different domains, a challenge known as domain shift. The discrepancies between training and testing data often lead to incorrect classification of normal data as novel by existing methods. A typical situation is that testing normal data and training data describe the same subject, yet they differ in the background conditions. To address this problem, we introduce a novel method that separates subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. The proposed method minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations solely and hence is not affected by the variation of domains. Extensive experiments demonstrate that our model generalizes effectively to unseen domains and significantly outperforms baseline methods, especially under substantial domain shifts between training and testing data.",
    "keywords": [
        "novelty detection"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=sLtuNGkKfH",
    "pdf_link": "https://openreview.net/pdf?id=sLtuNGkKfH",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces Subject-Novelty Detection (SND), an approach for unsupervised novelty detection in settings with domain shifts between training and testing data. Unlike typical methods, which may misclassify normal samples from unseen domains as novel, SND separates subject information from domain-dependent background variations. By minimizing mutual information between the subject and background representations, SND ensures robust novelty detection across unseen domains, outperforming baseline methods. Comprehensive experiments validate SND's efficacy, showing it achieves state-of-the-art results across challenging datasets such as Multi-background MNIST, Fashion-MNIST, and the Kurcuma dataset."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The study problem is relevant and important. \n2. In general, this paper is well written and easy to follow."
            },
            "weaknesses": {
                "value": "1. The study of out-of-distribution (OOD) detection under domain shift is a well-established problem in the field. In addition to the related works mentioned in this paper, a simple Google search can yield the following relevant papers. However, the research gaps or limitations of these previous works (including those cited or uncited papers) are not clearly explained.\n \n  a) Bozorgtabar, B., Vray, G., Mahapatra, D., et al. \"SOoD: Self-supervised Out-of-Distribution Detection Under Domain Shift for Multi-Class Colorectal Cancer Tissue Types.\" In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021: 3324-3333.\n\n   b) Gao, Z., Yan, S., He, X. \"ATTA: Anomaly-Aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation.\" Advances in Neural Information Processing Systems, 2023, 36: 45150-45171.\n\n2. Similarly, in the experiments, the methods compared are primarily from before 2022, neglecting more recent works in this field.\n\n3. The authors evaluate their experiments solely on the relatively simple MNIST dataset, which seems outdated given current standards. The ability and advantages of the proposed framework in tackling more challenging natural images have not been adequately validated.\n\n4. The proposed solution of separating foreground and background is reasonable and straightforward. However, it remains unclear whether this strategy would still be robust in more complex scenarios, such as when multiple objects exist in an image or when separating the background from the foreground is difficult.\n\nOverall, while this manuscript is generally complete, its contributions and novelty may be incremental, and its advantages to the field are not clearly articulated."
            },
            "questions": {
                "value": "Please see the above weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work presents a framework for unsupervised novelty detection problem. It introduces a method that disentangles subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. It then minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations nd hence is not affected by the variation of domains. Experiments on MNIST-like datasets demonstrate some effectiveness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "* This work tackles a popular problem of unsupervised novelty detection, where domain shift quantification and transfer learning is important in the era of foundation models.\n* Experiments demonstrate the effectiveness of the proposed method on some simple baselines, some ablation studies were performed to validate the contribution of certain components.\n* Codes and algorithms are available for reproducibility"
            },
            "weaknesses": {
                "value": "* The settings of UND is more commonly addressed as anomaly detection/one-class classification problems, where there are already significant development in this field with many renowned benchmarks (e.g., MVTEC) and methods (e.g., DeepSVDD, PaDIM, CutPaste, etc.). I think the MNIST dataset is the easiest one and while the authors ignored a significant body of competitive baselines and benchmarks.\n* The method only separates background from the subjects, which is a coarse-grained feature in images. For instance, a simple OTSU method preinstall in open-cv can isolate the subject from the background, while training on these processed subject image can enable to model to learn sufficient subject information. In this sense, authors should strengthen the motivation and technical contribution of the proposed method.\n* Related to above, the experiments are insufficient to meet the bar. Although the authors present a lot of tables, they are mainly on the same datasets (MNIST-like) and only quote different metrics. It is expected that the method to be applied to mode modern datasets (at least TinyImageNet level with 200 classes) to validate its scalability and generalizability to other datasets. Additional metrics are fine but should be presented in the Appendix. \n* While checking the codes, the authors only tested their method on simple CNNs, where the commonly used architectures in the field of novelty detection, such as ResNet and ViT, were not tested. This also bring concerns on the scalability or applicability of the proposed method on more modern vision models. \n* Although K\u2019 is defined in problem formulations, the authors did not present how they resolve novel background types from the new samples. It seems that the K\u2019 new backgrounds (unseen in any training samples) will still be fitted in the K GMM components, which severely limits its capability on new background types.\n\nMinor:\n* Many baselines are of very low performance. This posts questions on whether these baselines are too simple. For instance, DeepSVDD, although a renowned method, is already 6 years old. Authors are suggested to choose more competitive baselines (e.g., the following works of ERM). \n* It would be preferred if the standard deviation of each experiment is provided, instead of just reporting the means."
            },
            "questions": {
                "value": "* The novelty score seems to require a training set to work. How could the method work when we have a pretrained model where we only have access to the training weights?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the unsupervised anomaly detection under domain shift problem. Specifically, it introduces a Subject-Novelty Detection (SND) algorithm that disentangles content (or \u201csubject\u201d) information from background in images, allowing to perform unsupervised anomaly detection only on the content part of the image representation. The number of different backgrounds in the training set is assumed to be known in SND. It is validated on two toy datasets (MNIST and Fashion-MNIST) and one small-scale dataset (Kurkuma)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "\u2022 Addressing ouf-of-domain (OOD) generalization for Anomaly Detection (AD) is an interesting and currently understudied topic;\n\n\u2022 The idea of separating content from style (or \u201csubject\u201d form \u201cbackground\u201d) to perform AD is rather straightforward and yet it appears to be new in the literature."
            },
            "weaknesses": {
                "value": "\u2022 SND is a rather restricted algorithm as it only handles OOD generalization for images with new backgrounds. Other settings should be also studied (such as robustness to data corruption or new style [1, 2]) in the context of AD under domain shift. Additionally, the number of backgrounds is assumed to be known in the current algorithm, which is a rather strong assumption compared to other algorithms that do not make it [1, 3, 4].\n\n\u2022 Following my previous concern, the benchmarks used in this study are limited as they only reflect a change in the background as a new domain. Other benchmarks \u2013 such as PACS, CIFAR10, or MVTec (see [1] or [2], for instance)\u2013 should also be included to evaluate the versatility of SND on more challenging domain shifts. \n \n\u2022 This study seems to ignore the recent advances in visual AD made possible through large pre-trained (or \u201cfoundation\u201d) models such as DINOv2 or CLIP [3, 4]. These models are very efficient zero- or few-shot learners, and they deserve to be evaluated in the current benchmark. This literature is also in line with recent works on disentangling content from style with large pre-trained models [2], which I advise the authors to take inspiration from. \n\n[1] Anomaly Detection under Distribution Shift, Cao et al., ICCV 2023\n[2] Simple Disentanglement of Style and Content in Visual Representations, Ngweta, Maity et al., ICML 2023 \n[3] AnomalyDINO: Boosting Patch-based Few-shot Anomaly Detection with DINOv2, arXiv 2024\n[4] WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation, CVPR 2023"
            },
            "questions": {
                "value": "\u2022 SND introduces several hyper-parameters (weights in the loss, bandwidth in the density estimator), but how these are set in the current experiments is unclear. How did you cross-validate these hyper-parameters? \n\n\u2022 The proposed method is evaluated on a real-world dataset (Kurkuma) using only a shallow CNN as the encoder. Did you also consider using large pre-trained models (such as DINOv2) to encode the visual features and perform AD? This should reflect a more realistic setting.\n \n\u2022 The ablation study is quite limited: the benefit of imposing the background energy function and the disentanglement term should be evaluated carefully."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses Unsupervised Novelty Detection (UND) under domain shifts, where training and testing data differ due to background conditions. By separating core subject information from domain-specific background variations, the proposed method uses only subject representations for novelty detection, enhancing performance under domain shifts. Experiments show generalization to new domains, outperforming baseline methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is well-written and easy to understand.\n- The setting considered in the paper is interesting.\n- Extensive experiments validate the claims and demonstrate the superior performance of the proposed method."
            },
            "weaknesses": {
                "value": "- The scenario where training and testing data differ solely due to background conditions may not be entirely practical. I suggest the authors provide additional examples to illustrate realistic applications of this setting.\n\n- The authors reference related works (Oza et al., 2020; Yang et al., 2023; Carvalho et al., 2024) that have already explored anomaly detection under domain shift. Please clarify how the proposed approach differs from these methods and, if possible, provide comparative evaluations."
            },
            "questions": {
                "value": "Please see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}