{
    "id": "2wDXNF0Gv4",
    "title": "Prompt-Agnostic Erasure for Diffusion Models Using Task Vectors",
    "abstract": "With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations. Yet, these methods often only protect against specific user prompts and have been shown to allow undesirable generations with other inputs. Here we focus on \\textit{unconditionally} erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt. We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training. However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown. To this end, we propose a method called \\textit{Diverse Inversion}, which we use to estimate the required strength of the TV edit. Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept. We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts. Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining model utility.",
    "keywords": [
        "Concept Erasure"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-23",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=2wDXNF0Gv4",
    "pdf_link": "https://openreview.net/pdf?id=2wDXNF0Gv4",
    "comments": [
        {
            "summary": {
                "value": "The paper presents an interpretability study focused on understanding the second-order effects of neurons in CLIP. The authors propose a novel \"second-order lens\" to analyze neuron contributions that flow through attention heads to the model output."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The technical contributions are sound  and interesting.\n2. The paper is well written. \n3. The paper included thorough evaluations."
            },
            "weaknesses": {
                "value": "1. Multiple concept erasure - How does the proposed method perform on multi-concept erasure? The baselines considered in this paper (UCE and ESD) evaluate their model on erasing multiple objects simultaneously. Therefore it is fair to compare this method for multi-concept erasure.\n2. Missing baselines - Comparison to Selective Amnesia (SA) (a strong and very similar baseline in my opinion) is missing from the paper. I believe the proposed method lie under a similar umbrella as SA. \n3. Underperforms baselines on NSFW concepts\u2014The authors state that TV only reduces nudity in 52% of images compared to SD1.4, which is worse than the baselines (ESD, UCE, etc.) considered in the paper. This is a major drawback of the method in a real-world setting."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a technique for erasing concepts from diffusion models. The method is based on using task vectors to erase the concepts, in combination with diverse inversion, a form of textual inversion. A key feature is that the erasure is prompt-agnostic and is designed to work with diverse prompts, especially adversarial ones."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* There is a decent initial analysis to motivate the approach and explain why it may be suitable.\n* The method seems to perform well, maintaining the quality of the generated images for non-erased concepts, and successfully erasing the selected concepts.\n* In general the paper is easy to follow."
            },
            "weaknesses": {
                "value": "* The evaluation is quite limited, it would be good if quantitative evaluation included diverse adversarial techniques in addition to concept inversion. There are some qualitative results for UnlearnDiffAtk and P4D in the appendix, but the paper would benefit from using these and maybe even others for more extensive quantitative evaluation. Also it would be good to show the method works also on other models than Stable Diffusion v1.4 specifically.\n* The method seems to be primarily a combination of task vector technique and a version of text inversion, applied to the problem of concept erasure, so it may lack significant novelty.\n* There are quite a few issues with the writing and presentation - the font is different than the standard one, this should be corrected; various typos, grammar issues or missing words, e.g. \u201cjailbraking\u201d L145, \u201cmight in some cases the usability might degrade\u201d L358,  \u201cFig. 6 demonstrate\u201d L410, \u201chow how\u201d L414, \u2026"
            },
            "questions": {
                "value": "* What could the prompts look like for a given complexity class L? Does it directly translate to the number of words?\n* Can this method actually remove small parts of the image such as copyright logos? It was used in motivation but seems to not be tested?\n* How well does the method work when using other adversarial techniques such as UnlearnDiffAtk and P4D - quantitative evaluation, not only qualitative that is already provided?\n* Does the approach work well also on other diffusion models than Stable Diffusion v1.4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel method for concept erasure in pre-trained generative models. This method consists of two key components: (1) the development of a Task Vector Method for concept erasure; and (2) the selection of optimal parameters through novel Diverse Inversion procedure. Notably, this approach is input-independent and does not rely on specific pre-defined prompts that contain concepts. As a result, it demonstrates enhanced robustness against concept inversion when compared to previous methods, while maintaining comparable results on unrelated concepts generation tasks and within the \"given prompt generation\" setting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The authors clearly identify the problem of \u201cinput dependence\u201d associated with previous methods and provide compelling evidence of these issues via the MNIST toy experiment, which emphasizes prompt complexity rather than using a fixed set of prompts. \n\n- They propose a method to address these challenges, which combines an existing concept-forgetting technique Task Vectors with a novel procedure called Diverse Inversion to optimize parameter selection for Task Vectors. \n\n- Although Task Vectors is an already existing technique, the authors unveil its previously unexplored property of Concept Inversion Robustness.\n\n- The Diverse Inversion idea is an interesting approach that could be applied to other research areas, potentially enhancing our understanding of concept learning and erasure processes. \n\n- Overall, the text is straightforward and presents all ideas clearly and concisely."
            },
            "weaknesses": {
                "value": "- Certain aspects of the experimental workflow are not sufficiently detailed. For instance, the setup of the toy experiment on MNIST lacks information regarding the embedding grid search procedure. Additionally, the Diverse Inversion Set selection procedure may need more clarification, particularly regarding the number of restarts of the Concept Inversion procedure and a comprehensive step-by-step description.\n\n- Furthermore, it appears that the vector from the Diverse Inversion set, which is utilized for selecting the parameter alpha, was also employed in evaluating the robustness of the methods against Concept Inversion. If this is the case, it would be helpful to report how the metrics would be affected if this vector were removed from the Diverse Inversion set.\n\n- It would be beneficial to include additional visual examples to illustrate the results presented in Table 2."
            },
            "questions": {
                "value": "1. Was the vector from the Diverse Inversion set used in evaluating the robustness of the methods against Concept Inversion? If so, could you please provide information on how the metrics would change if this vector were excluded from the Diverse Inversion set?\n\n2. Could you provide a step-by-step description of the Diverse Inversion Set selection procedure? Additionally, please include details on the number of restarts for the Concept Inversion procedure.\n\n3. Why is the Control Task not utilized for selecting alpha, alongside the Diverse Inversion set?\n\n4. Can you elaborate on the toy example, specifically regarding the embedding grid search procedure?\n\n5. It would be beneficial to include additional visual examples to illustrate the results presented in Table 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the challenge of preventing style mimicry in text-to-image models by proposing an unconditioned approach to concept erasure, independent of user prompts. This approach uses Task Vectors (TV) for concept erasure, offering greater robustness to unexpected user inputs. Also, the authors introduce Diverse Inversion, a technique that estimates the required TV edit strength by identifying a broad set of word embeddings within the model\u2019s input space, each capable of generating the target concept."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Clarity and Structure: The paper is well-organized and clearly written, making it accessible and easy to follow, even for readers less familiar with the technical aspects of concept erasure and Task Vectors.\n- Visualization Quality: The visualizations of generated images are well-crafted, effectively illustrating the model\u2019s concept erasure capabilities and supporting the clarity of experimental results.\n- Clear Literature Review: The related work section thoroughly covers relevant research on concept erasure and on jailbreaking generative models. This strong contextual foundation helps to situate the authors\u2019 contributions within the broader field and underscores the necessity of robust model editing methods."
            },
            "weaknesses": {
                "value": "- Edit Block Selection: The rationale for editing the first three blocks is not fully explained. A discussion on why these specific blocks were chosen would strengthen the methodological foundation. I suggest that the authors provide a brief explanation of the model architecture and how the blocks relate to different levels of abstraction or functionality.\n- Alpha Parameter Choice: The choice of \u03b1 is not well-clarified. While Figure 4 mentions \u03b1, no figure or table apart from Figure 7 details the specific \u03b1 values used. Since Diverse Inversion is intended to estimate the optimal strength of the Task Vector (TV) edit, it would be beneficial to provide explicit \u03b1 values and clarify if the authors tested a range of \u03b1 values to identify the best-performing option. I suggest that the authors include a table or figure to illustrate how they arrived at optimal strength.\n- Figure Placement: Figure 1 appears on page 2, yet it is first referenced on page 4. It would improve readability and flow by moving the figure closer to its initial mention or adding an earlier reference to it in the text\n- Table Clarity: In Table 2 (page 10), the acronym \u201cSLD-Med\u201d lacks explanation, and the term \u201cUCE\u201d is only briefly mentioned in the related work section (page 3). It\u2019s unclear if SLD-Med and UCE refer to the same concept; clearer definitions would enhance comprehension. I suggest that the authors include a brief explanation of these terms in a footnote or in the table caption.\n- Equation Definition: In Equation 4, the variables [a, b] and [c, d] are not clearly defined. While the meaning can be inferred from the surrounding text (Lines 341-343), each variable in the equation should be explicitly defined. I suggest that the authors consider adding a brief explanation of these variables immediately following the equation, which would maintain the mathematical formalism while improving readability. Alternatively, consider replacing the equation with a detailed textual description if it enhances clarity. \n- Typos and Formatting Issues:\n  - Line 285: \"Sec.3.2\" should be \"Sec. 3.2\".\n  - Line 343: \"e.g. Van Gogh\" should be \"e.g., Van Gogh\".\n  - Line 354: \"I.e.\" should be formatted as \"I.e.,\" or, for clarity, replaced with \"For example,\".\n  - Line 355-356: The sentence lacks a verb; it currently reads \u201cwe can the value of the edit strength \u03b1.\u201d Please revise for clarity.\n  - Line 360: \"i.e. setting\" should be \"i.e., setting\". \n  - Line 400: \"In Figs\" should be \"In Fig\"."
            },
            "questions": {
                "value": "- Edit Block Selection: What was the rationale for choosing to edit only the first three blocks in the model? Would the authors consider expanding on why these specific blocks were selected for editing?\n- Alpha Parameter Choice: The choice of the \u03b1 parameter remains somewhat unclear, with few details provided outside of Figure 7. Could the authors specify the \u03b1 values used throughout the experiments and clarify whether they evaluated multiple \u03b1 values to determine the optimal edit strength?\n- Figure Placement: Would the authors consider moving Figure 1 closer to its first reference on page 4 to improve readability and flow?\n- Table Clarity: Could the authors clarify the meaning of \u201cSLD-Med\u201d in Table 2 (page 10) and confirm if it is the same as \u201cUCE\u201d mentioned briefly in the related work section? Including these definitions would improve comprehension.\n- Equation Definition: In Equation 4, the terms  and  are not clearly defined. Could the authors provide explicit definitions for each variable, or alternatively, replace the equation with a detailed textual description if that would improve clarity?\n- Typos and Formatting: There are minor typos and formatting inconsistencies (e.g., \u201cSec.3.2\u201d instead of \u201cSec. 3.2\u201d). Would the authors consider addressing these issues to enhance overall readability?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}