{
    "id": "9KiE3t6CsL",
    "title": "ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition",
    "abstract": "Bias in machine learning models can lead to unfair decision making, and while it has been well-studied in the image and text domains, it remains underexplored in action recognition. Action recognition models often suffer from background bias (i.e., inferring actions based on background cues) and foreground bias (i.e., relying on subject appearance), which can be detrimental to real-life applications such as autonomous vehicles or assisted living monitoring. While prior approaches have mainly focused on mitigating background bias using specialized augmentations, we thoroughly study both biases. We propose \\approachname, a novel adversarial training method that mitigates foreground and background biases without requiring specialized knowledge of the bias attributes. Our framework applies an adversarial cross-entropy loss to the sampled static clip (where all the frames are the same) and aims to make its class probabilities uniform using a proposed \\textit{entropy maximization} loss. Additionally, we introduce a \\textit{gradient penalty} loss for regularization against the debiasing process. We evaluate our method on established background and foreground bias protocols, setting a new state-of-the-art and strongly improving combined debiasing performance by over \\textbf{12\\%} on HMDB51. \nFurthermore, we identify an issue of background leakage in the existing UCF101 protocol for bias evaluation which provides a shortcut to predict actions and does not provide an accurate measure of the debiasing capability of a model. We address this issue by proposing more fine-grained segmentation boundaries for the actor, where our method also outperforms existing approaches.",
    "keywords": [
        "Bias Mitigation",
        "Action Recognition"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We propose an effective adversarial framework for mitigating static biases in action recognition models without requiring prior knowledge of bias attributes.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=9KiE3t6CsL",
    "pdf_link": "https://openreview.net/pdf?id=9KiE3t6CsL",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a novel adversarial learning-based method to mitigate biases in action recognition, which provides simplified end-to-end training and does not require any labels/classifiers for bias-related attributes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "+ This paper is well-written and well-organized.\n+ Good performance on the popular action recognition datasets."
            },
            "weaknesses": {
                "value": "This paper introduces adversarial learning into action recognition, which is a relatively novel idea, but I have some concerns as follows.\n\n- Are there more visual examples that can depict biases in action recognition?\n- Whether the method proposed in this paper can be used for skeleton-based action recognition task\uff1f"
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a method to improve generalization capability of an activity recognition method in temporally-segmented video datasets.  The method focuses on an adversarial approach to removing biases from static elements of the scene.  The paper takes a random frame from the video and creates a \"static\" video by repeating the frame the same length as the original clip, then using this static clip as the adversary.  The paper combines this adversarial approach with other reasonable loss terms.  It demonstrates state of the art accuracy on the problem."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The problem of bias mitigation in ML is seriously important.  The paper proposes a concrete approach to mitigating clear bias problems in action recognition.\n\n- The entropy maximization term makes sense for avoiding the static cues.\n\n- The paper uses practical mechanisms to overcome the challenges of training the models.\n\n- The evaluation is performed on a recent OOD benchmark for bias analysis, and performs well relative to other methods.\n\n- The writing is mostly clear and concrete."
            },
            "weaknesses": {
                "value": "- The paper is is somewhat \"small\" in that although it describes what seems to be a new method and its evaluation on reasonable benchmarks, there is little discussion around key elements of the method, their limitations, their rationale, etc.  (see questions)\n\n- Does the \"static clip\" way of approaching video bias mitigation, have broader utility in video understanding or beyond?\n\n- Certain interesting experiments are omitted, even though the writing suggests they may be useful.  For example, L233 reads \"A naive application of Eq. 2 results in degraded performance.\"  What exactly is a naive application?  Furthermore, this implies that the two parts of Eq. 2 is individually interesting; in particular, does the right hand side do anything?  The ablation study does not include these two parts separately."
            },
            "questions": {
                "value": "- The mechanism for adversarial learning in the paper is very specific to action recognition.  How can this mechanism be generalized to be of broader interest to the ICLR community?\n\n- The method works by sampling any frame from the video and repeating it for a static clip.  Why any frame?  Aren't certain frames better or worse than others for the stated goal?  (The pre-segmented nature of the datasets in question create itself an algorithmic bias.  In the stated real world application deployments no such pretemporal segmentation is avavilable, and hence brings into question the feasability of the method in practice.)  But, more concretely to the task, why is there no analysis whatsoever on the impact of this frame selection?  Even for a subset of one dataset, it would have been interesting to understand the breadth of potential with different static clips.\n\n- Wouldn't it be clearer to concretely specify that the $\\vby$ action label notation is a one-hot vector?  It is one-hot, right?\n\n- At line 218, shouldn't \"maximized\" be \"minimized\"?  At least, something in that sentence does not match up: \"p(t) is still matched to gt distribution y, but the similar ....maximized\"  Maximizing the \"similarity\" (a loose term here) is minimizing the ce loss.\n\n- How are there reasonable IID results in Table 3 for the case that Ladv is not used ---> when it is not used, there is no actual gradient to guide the model to do any recognition?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents ALBAR, an adversarial learning method aimed at reducing biases in action recognition models. The study focuses on addressing background and foreground biases, which can impact the performance of applications such as autonomous vehicles and assisted living monitoring. ALBAR utilizes an adversarial training technique to minimize the model's dependence on static background cues, encouraging the use of dynamic motion information for action classification."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "S1: This paper resents state-of-the-art results on established SCUBA/SCUFO background/foreground debiasing benchmarks, and formulation is technically sound.\n\nS2: Several ablations show the contribution of each component."
            },
            "weaknesses": {
                "value": "W1: Although the results demonstrate that the model outperforms state-of-the-art methods, the technical contribution is incremental and purely based on previously introduced techniques.\n\nW2: How is the fairness of the comparative experiments ensured in this paper, and how are the results of the comparative methods obtained?\n\nW3: The ALBAR performs well on specific bias evaluation protocols, but its generalization capabilities to new types of biases or different domain tasks have not been fully validated.\n\nW4: Although the paper proposes a simplified end-to-end training framework, adversarial training often involves additional computational costs. The paper does not discuss the computational efficiency and scalability of the ALBAR method in detail."
            },
            "questions": {
                "value": "Although the results demonstrate that the model outperforms state-of-the-art methods, the technical contribution is incremental and purely based on previously introduced techniques.\n\nHow is the fairness of the comparative experiments ensured in this paper, and how are the results of the comparative methods obtained?\n\nThe ALBAR performs well on specific bias evaluation protocols, but its generalization capabilities to new types of biases or different domain tasks have not been fully validated.\n\nAlthough the paper proposes a simplified end-to-end training framework, adversarial training often involves additional computational costs. The paper does not discuss the computational efficiency and scalability of the ALBAR method in detail."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}