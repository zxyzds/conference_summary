{
    "id": "RDz3EPC3Lp",
    "title": "SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models",
    "abstract": "Traditional autonomous driving systems often struggle to harmonize high-level reasoning with low-level control, leading to suboptimal and even unsafe driving behaviors. The emergence of multimodal large language models (MLLMs), capable of processing visual and textual data, presents an opportunity to unify perception and reasoning tasks within a single framework. However, integrating precise safety knowledge into MLLMs for safe autonomous driving remains a significant challenge.\nTo address this, we propose SafeAuto, a novel framework that enhances MLLM-based autonomous driving systems by incorporating both unstructured and structured knowledge. In particular, we first propose the the Place-Dependent Cross-Entropy (PDCE) loss function, which is specifically designed to enhance the accuracy of low-level control signal predictions when treating numerical values as text.\nTo explicitly integrate precise safety knowledge into the MLLM to enable safe autonomous driving, we build a reasoning component for SafeAuto, which first parses driving safety regulations into first-order logic rules (e.g., \"red light $\\implies$ stop\") and then integrates these rules into a probabilistic graphical model, such as a Markov Logic Network (MLN). The environment attributes, identified by attribute recognition models (e.g., detecting a red light), are used to form the predicates in MLN.\nIn addition, the environmental attributes utilized for reasoning are also considered factors in retrieval to construct a Multimodal Retrieval-Augmented Generation (RAG) model, which aims to learn from past similar driving experiences more effectively.\nExtensive experiments demonstrate that SafeAuto significantly outperforms baselines across multiple datasets. By bridging the gap between high-level reasoning and low-level control, SafeAuto paves the way for more accurate, reliable, and safer autonomous driving, facilitating systems that learn effectively from experience, adhere to traffic regulations, and execute precise control actions.",
    "keywords": [
        "Autonomous Driving; Multimodal Large Language Models; Multimodal Retrieval-Augmented Generation; Probabilistic Graph Model"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "We propose SafeAuto that includes a specialized PDCE loss for low-level control to improve precision and safety, and enhances high-level action prediction by integrating past driving experiences and precise traffic rules into multimodal models.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=RDz3EPC3Lp",
    "pdf_link": "https://openreview.net/pdf?id=RDz3EPC3Lp",
    "comments": [
        {
            "summary": {
                "value": "The authors propose SafeAuto, a framework that can be incorporated into multimodal large language models and that consists of 3 components: (i) a new loss function called Place-Dependent Cross-Entropy, (ii) a reasoning module based on Markov Logic Networks, (iii) a multimodal Retrieval-Augmented Generation model.\nThe Place-Dependent Cross-Entropy loss aims to better capture numerical proximity between numeric strings generated by the large language models indicating low-level control numerical signals (e.g., speed).\nThe Markov Logic Network-based module serves as a post-processor that flags the large language model's outputs which do not satisfy pre-defined knowledge rules (written in first order logic and capturing relations between predicates representing actions of the ego-vehicle---such as stop or accelerate---and objects from the environment---such as a stop sign).\nThe multimodal Retrieval-Augmented Generation model aims at helping the decision process by retrieving driving experiences similar to the current scenario, utilising information gathered from the image embeddings, control signals and a vector containing the values of binary predicates (that capture whether certain objects, e.g. a stop sign, are present in the given image or not).\nThe authors conduct an experimental analysis (on two datasets), showing (i) how these three components impact the performance when compared to state-of-the-art baselines and (ii) how background knowledge can be used to enhance the predictions of multimodal large language models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Good referencing of prior works related to most of the involved components, including recent studies.\n\nAdditionally, the paper clarifies the relation to prior works and explains how the proposed approach differs from the previous ones.\n\nThe work is clearly motivated in the paper, the research context and goals are also clearly stated.\n\nThe method is described in a way that is easy to follow.\n\nThe experimental setting is well-explained."
            },
            "weaknesses": {
                "value": "There is no discussion on how the proposed Place-Dependent Cross-Entropy Loss behaves when there is a difference in the order of magnitude between the input and the target values. From the description of the method, it appears that the Place-Dependent Cross-Entropy Loss does not take into account the decimal point position (and, for example, this means that the target probability distributions from Figure 2 for numeric string \"2.69\" will be the same as for numeric string \"26.9\").\nI would appreciate it if the authors could clarify this point and the statement in lines 247-248: \"Notice that when \\sigma is set to 0, the loss reduces to the original definition of joint CE loss for the entire numeric string\", which again is unclear as the cross-entropy loss takes into account the decimal point position.\n\nThe method offers no guarantee that reprompting the multimodal large langue models will generate a new high-level action that does not violate the knowledge rules, since such models are data-driven.\n\nThe paper is in the context of knowledge-enhanced autonomous driving and argues that the underlying models are limited as they do not account for any available knowledge when making their decision.\nSpecifically, the authors capture the knowledge rules in the form of logical formulae, yet the related work section does not discuss prior works that would be relevant here (e.g., representing and integrating background knowledge into neural network models).\n\nImprovements in clarity and readability are needed. Please see below detailed comments.\n\nFigure 2: contains pseudocode and could be moved to supplementary material, with its contents described more concisely in natural language in the main text.\n\nFormatting: cluttered text, very little space between captions and main text (e.g., lines 73 and 237), all affecting readability.\nAll abbreviations should be introduced, e.g. \"QA\" is used without doing so.\n\nMany typos:\n- in the abstract, \"the the Place-Dependent\".\n- lines 92, 93: \"contextssuch\", \"signalsto\"\n- lines 105, 106: \"scenariowhich\", \"informationwe\"\n- line 144: \"knowledgespecifically\", \"rulesinto\"\n- and other such instances of words not being separated by a space when they should be.\n- a space before each citation would improve the readability (line 108 \"BDD-X(Kim et al., 2018) and DriveLM(Sima et al., 2023)\")\n- abbreviations are introduced multiple times: e.g., \"cross-entropy (CE)\" (lines 53, 127, 180); \"Place-Dependent Cross-Entropy (PDCE)\" (lines 95, 170, 397), similarly for \"Markov Logic Networks\", etc.\n- line 277/278: \"all formula\"\n- the title of section 6 is inconsistent with the naming convention of the rest (i.e., \"Limitation.\", rather than \"Limitation\").\n\nOther comments:\n- in Figure 2, the naming of \"cumulative_probs\" (line 231) could be confusing/misleading as it suggests traditional cumulative probabilities. A clearer term, such as \"weights,\" would align with the main text (line 238).\n- repetitions: e.g., lines 83-84: \"regarding high-level action prediction, a significant limitation of current methods in high-level action prediction\"\n- line 193: \"with temperature as 1.0.\" it is unclear what is meant here, as the temperature was not yet introduced (only later on line 374 it is introduced)."
            },
            "questions": {
                "value": "One of the main components of the proposed framework is a post-processor designed to identify predictions made by the large language model that do not adhere to the knowledge rules. It would be helpful to understand how often violations of the rules were observed in the conducted experiments.\n\nHow does the method deal with cases where the large language model keeps generating a new high-level action (after reprompting) that violates the knowledge rules?\n\nAs a suggestion (also mentioned earlier, along with detailed comments), the paper would need to be improved in terms of clarity and readability."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a framework to enhance multimodal large language based autonomous driving using structured and unstructured knowledge. The main contribution of the paper is proposal of a new loss function that the authors call place dependent cross entropy loss, that is supposed to enhance accuracy of text based control instructions. They also propose building a reasoning component for converting safety regulations into first order logic rules. These rules are then used in a probabilistic graphical model along with environmental features to contruct a RAG model."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper proposes to use a lot of new methods for enhancing autonomous driving. It addresses multiple problems that are difficult to solve and poses a challenge for using large language models for autonomous driving related tasks. Understanding of numerical information from text is a common problem that this paper proposes to solve using a new loss function. Reasoning is also a challenging task for these systems, here the paper proposes a system of using safety regulations to logic within a graphical model. The RAG model is also meant to produce better driving experience by learning from past."
            },
            "weaknesses": {
                "value": "This paper proposes a few different changes and the goal of the proposals are not always clear. If the goal is to produce a better driver, there should be comparison with other autonomous driving works in standard NuScenes like evaluation, both open and closed loop. But, driving comparison with standard models like UniAD and VAD is not performed (Table 3).\n\nThe loss PDCE formulation is unclear. Any new loss function should be defined clearly with notation. Here the description of the loss is unclear. The properties of the loss needs to be studied in a more varied settings. The authors just produce a graph for a specific setting to motivate this loss, but better experiments need to be planned to demonstrate the behavior of this loss.\n\nThe action generation step from the LLM is not grounded in any way, so it is not clear how the approach would deal with invalid responses or hallucination, where it might generate unsafe actions.\n\nIt is not discussed how this approach could be used in practice, do the authors see this running in realtime in a vehicle or is it just used for data labeling offline? We need some runtime information for questions like this. Also, not all the tasks they want to solve would make sense in either case."
            },
            "questions": {
                "value": "1. Formulate the loss function in mathematical terms\n2. Perform experiments on loss behavior with error bars and more varied situations\n3. Provide runtime information\n4. Discuss inference strategy\n5. Produce more experiments with driving performance like NuScenes setup and UniAD / VAD."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents \"SafeAuto,\" a framework for enhancing autonomous driving through multimodal foundation models. It focuses on high-level action prediction and justification, as well as low-level motion prediction, leveraging datasets like BDD-X and DriveLM. The authors claim improvements in performance metrics such as BLEU, CIDEr, and METEOR. However, the paper largely reads like a technical report, lacking significant theoretical contributions or novel methodologies, which raises questions about its overall impact and originality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper provides a comprehensive set of experimental results demonstrating improvements in performance metrics, which is a solid contribution.\n2. The experimental design and results are well-organized and clearly presented.\n3. The plug-and-play nature of the framework allows it to be integrated with existing multimodal learning methods"
            },
            "weaknesses": {
                "value": "1. The paper appears to rely on established methodologies without introducing substantial theoretical advancements, limiting its originality and depth.\n2. While the components such as the PDCE loss and post-safety verification are interesting, they do not significantly diverge from existing techniques.\n3. There is little discussion on how different predicates are selected or their impact on the overall prediction performance\n4. The evaluation does not seem to adequately address edge cases or scenarios where traditional models might fail. A deeper examination of how the framework handles uncommon but critical driving situations could provide insights into its robustness and safety."
            },
            "questions": {
                "value": "1. Can the authors elaborate on the specific mechanisms used to extract and integrate environmental predicates into the retrieval process? How do these predicates influence decision-making during high-level action predictions?\n2. The paper mentions a gradual increase in the value of \u03c3 during training for the PDCE loss. How was this approach determined, and what empirical evidence supports its effectiveness compared to alternative strategies?\n3. How does the framework handle potential conflicts between high-level predictions and low-level control signals?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}