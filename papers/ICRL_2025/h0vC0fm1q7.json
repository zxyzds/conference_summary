{
    "id": "h0vC0fm1q7",
    "title": "Sensitivity Verification for Decision Tree Ensembles",
    "abstract": "Tree ensemble models, such as Gradient Boosted Decision trees (GBDTs) and random forests, are widely popular models for a variety of machine learning tasks. The power of these models comes from the ensemble of decision trees, which makes analysis of such models significantly harder than for single trees. As a result, recent work has focussed on developing exact and approximate techniques for questions such as robustness verification, fairness and explainability, for such models of tree ensembles.\n\nIn this paper, we focus on a specific problem of feature sensitivity of decision tree ensembles and build a formal verification framework for it. We start by showing theoretical (NP-)hardness of the problem and explain how it relates to other verification problems. Next, we provide a novel encoding of the problem using pseudo-Boolean constraints. Based on this encoding, we develop a tunable algorithm to perform sensitivity analysis, which can trade off precision for running time. We implement our algorithm and study its performance on a suite of GBDT benchmarks from the literature. Our experiments show the practical utility of our approach and its improved performance compared to existing approaches.",
    "keywords": [
        "Robustness verification",
        "Sensitivity analysis",
        "SAT solvers",
        "efficient encodings",
        "NP-hardness",
        "fairness"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=h0vC0fm1q7",
    "pdf_link": "https://openreview.net/pdf?id=h0vC0fm1q7",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses the feature sensitivity problem for ensembles of decision trees, with a focus on Gradient Boosted Decision Trees (GBDT). The authors demonstrate that this problem is NP-complete through a reduction from the SAT problem. They then propose an algorithm to solve the p-sensitivity problem by encoding it as pseudo-Boolean constraints. Finally, experimental results are provided, comparing the proposed approach to some existing methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well-written, with a clear structure that makes it easy to follow. This clarity enhances the readability and understanding of the material.\n\nThe problem is well motivated.\n\nThe theoretical contributions are interesting and their proofs appear to be correct."
            },
            "weaknesses": {
                "value": "The initial result on NP-hardness of sensitivity problem for all features seems redundant after establishing NP-completeness for a single feature. \n\nMy main issue with this paper is with the experiments. The comparison with VERITAS seems a bit unfair. By limiting VERITAS to the same runtime as SENSPB, the comparison may not reflect its full potential. Allowing VERITAS more runtime might yield better results, or it could have already produced sufficiently good results within its runtime. A separate table detailing the number of instances each method solved and the time taken would provide additional insights.\n\n**Minor Comments/Typos**\n- Line 068: \"just on\" \u2192 \"just one\"\n- Line 079: Rewrite this sentence for clarity: \u201cCan we use other forms of powerful reasoning, Pseudo-Boolean solvers, that have shown to be effective in other problems (Mexi et al., 2023), for the sensitivity problem?\u201d\n- Line 162: \"given set of sensitive features F\" \u2192 \"given set of features F\"\n- Caption of Table 1: \"results than mine\" \u2192 \"results than our method\""
            },
            "questions": {
                "value": "Is there a reason why the NP-hardness of the all feature problem was included in the paper? If it can be useful in some cases, some explaination here can be beneficial.\n\nIt would be nice to know why the results are specific to GBDT and why they could/couldn't be directly extended to other ensemble models, such as random forests."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This submission considers the problem of sensitivity for tree ensemble classifiers, i.e. the question of determining if, for a selection \\\\(F\\\\) of features, there exists a pair of inputs that agree on all the features outside of \\\\(F\\\\) but get classified differently by the tree ensemble. This work also develops a quantitative version of sensitivity (Def 3.2), parametrised by a number \\\\(p\\in[0,\\frac{1}{2}]\\\\), that additionally lower-bounds the \"distance\" between the two classifications. \n\nThe main theoretical contributions consist in proving that \n- the (non-quantitative) sensitivity problem is NP-hard (Thm 1)\n- the sensitivity problem restricted to singleton feature sets F={f} is also NP-hard (Thm 2)\n\nThe main practical contribution is to show that the problem of establishing \\\\(p\\\\)-sensitivity can be encoded as the satisfiability of a system of pseudo-boolean constraints (Thm 3). Experimental evidence shows that this approach scales much better than SOTA methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is very well-written, with a good overview of the literature and easy-to-follow examples, proofs and discussions. In particular the proofs are easily understandable even by someone with very limited knowledge of computational complexity theory such as myself.\n\nThe main practical novelty of this paper -- using a pseudo-boolean satisfiability encoding -- is credibly shown to be superior to the SOTA methods in a short but convincing experimental section."
            },
            "weaknesses": {
                "value": "Theorems 1 and 2 correspond to two extremes of the sensitivity problem: the first considers sensitivity w.r.t. the full set of features, the second considers only singleton subsets of features. It feels like the full story would be a result showing that sensitivity w.r.t. subsets of features of size \\\\(N\\\\) is NP-hard, for all \\\\\\(N\\\\). Similarly, the story is slightly incomplete as in does not cover trees of depth 2 or 3 (as mentioned by the author(s)). The paper would be nicer (and stronger) if these questions were solved. too \n\nHere are some minor comments/corrections\n* l69: when THE number\n* l83: whether...whether\n* l104: some OF these\n* l117: of A \\\\(d\\\\)-dimensional\n* l157: When \\\\(F=\\\\{f\\\\}\\\\)\n* l168: two-tree\n* l194: Def 3.2 is not really a special case of Def 3.1 in the sense that Def 3.1 does not correspond to a particular choice of \\\\(p\\\\). As it stands, Def 3.1 is equivalent to \\\\(\\exists p.\\\\)Def 3.2 holds. To make Def 3.1 a special case of Def 3.2 I would change it to have \\\\(p\\geq 0\\\\) and \\\\(\\sigma(c(x_1))\\geq 0.5+p, \\sigma(c(x_2))< 0.5+p\\\\) (or the other way round). Then Def 3.1 would correspond to the case \\\\(p=0\\\\).\n* In the proofs of thm 1 and thm 2, why not simply take \\\\(X_{k+1}=\\\\{-1,1\\\\}\\\\) and \\\\(X_0=\\\\{-1,1\\\\}\\\\)?\n* l275: \\\\(F\\cup\\\\{f\\\\}\\\\) (not \\bigcup and singleton)\n* l289: I don't understand the first sentence here. Which problem requires three variables \\\\(x_1,x_2,x\\\\)?\n* l307 and l313: use \\setminus for the set difference \\\\(\\mathcal{F}\\setminus F\\\\). Also, if you'd used \\\\(x,x'\\\\) or \\\\(x,y\\\\) instead of \\\\(x_1,x_2\\\\), you wouldn't have problems with double subscripts.\n* l310: \\log instead of log\n* eq (2): shouldn't \\\\(j+1\\\\) in the RHS simply be \\\\(j\\\\)?\n* l327-328: Incomplete sentence\n* l328: Since THE root\n* Thm 3: use \\eqref in the conjunction, in order to get \\\\((1)\\wedge\\ldots\\wedge(6)\\\\). Parentheses = equations. Conversely don't use (1) and (2) to refer to the two parts of the theorem, instead use 1. and 2., or better (i) and (ii).\n* l394: mine -> us\n* l420: p-sensitive -> \\\\(p\\\\)-sensitive"
            },
            "questions": {
                "value": "Do you think it is the case that sensitivity w.r.t. subsets of features of size \\\\(N\\\\) is NP-hard, for all \\\\\\(N\\\\)? If yes, do you have any intuition about whether proving this is substantially harder than your existing proofs?\n\nSame question for trees of depth 2 or 3."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper puts forward an approach for formal verification of feature sensitivity. Feature sensitivity is a characteristic of a model whereby the model changes its output depending on values of such features. In domains such as fairness checking for feature sensitivity is one of the ways in which fairness checks are meaningfully encoded.\n\nThe paper answers some complexity problems on answering features sensitivity, leaves some open. Crucially it provides a novel and efficient way based on pseudo-Boolean encodings to solve the verification problem. Some experimental results showing SoA performance are provided.\n\nOverall this is a solid paper, arguably with some weaknesses, that advances the SoA of the area."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is very well presented (some very minor typos that can be fixed). I cannot judge the soundness of the encoding but it seems reasonable. I read the complexity proofs and appear correct (even if not surprising). In terms of advancement on SoA I judge this to be in line with the standards expected at ICLR, even if perhaps not as a top paper (see weaknesses below).\n\nMost importantly solving model valuation for ensembles remains a key question in a variety of domains and this paper presents a principled and noteworthy contribution to the challenge. While the NP-hardness results may not be surprising they fill a gap in the knowledge in the area and the encoding presented achieves SoA performance."
            },
            "weaknesses": {
                "value": "While the NP hardness won't be a surprise to most, not all the theoretical questions are answered in the paper with the obvious gap being trees of depth 2 and 3. I feel this has a considerable implication even in terms of architectural suggestions from this study. Has this question been answered by the authors in the meantime? To me these corner cases are actually the most interesting ones. Finding the the case for 3 is polynomial would be a very interesting result\n\nThe reasons as to whether the approach appears to scale considerably better than present SoA were not clear to me in the paper. Do the authors have an explanation? If so, could they provide it? The reason for asking is that in principle it could even be that their implementation is just more efficient and it does not have so much to do with the encoding."
            },
            "questions": {
                "value": "See questions on the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the sensitivity verification problem of GBDTs by formalizing a pseudo-Boolean encoding. The authors claim their approach can achieve significant performance gains over existing sensitivity verification tools, specifically for GBDTs. However, the paper lacks a comprehensive presentation, robust mathematical formulation, and systematic experiments. As such, it would need major revisions to be accepted."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- **S1:** The paper addresses an important issue aimed at verifying the sensitive features of GBDTs.\n- **S2:** Mathematical proofs, which I would have expected to have a better presentation, but I appreciate the effort.\n- **S3:** The authors present an approach using pseudo-Boolean encoding, arguing that it is more suitable than other methods."
            },
            "weaknesses": {
                "value": "- **W1:** The notation is inconsistent and confuses readers, especially those who are unfamiliar with the topic. For example, input examples are denoted by $x$ and $x'$ in Def. 3.1, but then they are $x_1$ and $x_2$ in Def. 3.2; furthermore, in the proof of Th. 2 instances are symbolized $a$ and $b$ (a very unhappy notation). Similarly, trees are defined as $T$ in Section 2 but then symbolized with $D$ in the proof of Th. 1.\n- **W2:** Certain mathematical expressions and definitions are unclear or incorrect. For example, $F = f$ instead of $F = \\\\{f\\\\}$ detracts from the overall comprehensibility. As another example, the set minus ($\\setminus$) operation is properly used in Def. 3.1 but then in Section 4 is not used; that is, the authors use minus ($-$). A further example is when the authors use $\\mathcal F = F \\bigcup f$, which, again, is not a proper mathematical definition; it should perhaps be $\\mathcal F = F \\cup \\\\{ f \\\\}$.\n- **W3:** The proofs suffer from inconsistent symbols, poor spacing, and cluttered notation, making the logical progression of arguments hard to follow. For example, while reading the proof of Th. 1, I had to stop and skip such proof because the notations became heavy, and my overall cognitive overload intensified. To give a precise idea of how it felt: in $c'(x) = -n$, $n$ is the same $n$ as the number of decision trees in the ensemble (line 205)? What is the $\\Longrightarrow$ in the notation? What is $\\wedge$? Etc. As you can see, there are too many doubts that the reader has at this point. I assumed the proof was correct, even though I hadn't thoroughly reviewed it. The problem with this way of writing the proof is that the authors mixed textual explanations with mathematical ones in an unpleased way. This point is very critical.\n- **W4:** The experimental results lack clarity; terms like \"maximum, minimum, and average\" time are used ambiguously without explaining what they represent or if multiple runs were performed.\n- **W5:** Despite the general title, the paper focuses solely on GBDTs, excluding other ensemble methods like random forests without justification. If that's not the case, I expected to see experiments with random forests as well.\n- **W6:** The paper contains grammatical errors, inconsistent abbreviations (e.g., \"wrt\" vs. \"w.r.t.\"), and informal language, which detracts from the overall presentation."
            },
            "questions": {
                "value": "- **Q1:** Could you ensure consistent notation throughout, especially in proofs? E.g., $x$ and $x'$ vs $x_1$ and $x_2$.\n- **Q2:** Why did you limit the work to GBDTs? Would your framework extend to other ensemble methods, such as random forests?\n- **Q3:** Could you clarify the connection between sensitivity and $(p)$-sensitivity, especially after Definition 3.2? The special-case/general-case distinction you imply needs a clearer mathematical basis, and it is *not* easy to see (i.e., one uses the sigmoid function $\\sigma$ and the other does not).\n- **Q4:** Why do you use the sigmoid function $\\sigma$ in Def. 3.2, and then decide to drop such \"complexity\" in Section 4 when you present the encoding? I would either drop it from the definition or introduce it in the encoding; either way would be acceptable, but please avoid the asymmetric treatment.\n- **Q5:** What does \"maximum, minimum, and average time\" mean in your experiments? Were these metrics based on repeated runs, and if so, could you clarify the settings?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In the context of interpretable machine learning, this paper investigates the problem of \"feature sensitivity\" in tree ensembles. Specifically, given a classifier $ c $ and a set of features $ F $, the goal is to determine whether there exists an instance $ x $ such that the classification of $x$ by $c$ changes when only the values of the features in $ F $ are modified. The paper establishes that this problem is NP-complete for gradient-boosted trees, even when $ F $ consists of a single feature. The authors also explore an extension of this problem that considers the confidence associated with class changes, which is also shown to be NP-complete. To deal with this source of complexity, the authors propose a Pseudo-Boolean encoding for the feature sensitivity task, which they empirically validate on several benchmarks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "**Novelty:**\nArguably, the main strength of this paper lies the novelty of the complexity results for deciding feature sensitivity when the predictive model is a binary-class gradient boosted tree. Notably, the fact that the problem remains NP-hard even in the case where the sensitivity analysis is reduced to a single feature is intriguing."
            },
            "weaknesses": {
                "value": "**Clarity:** \nThe scope of the paper is quite challenging to define. As indicated in the title, summary, and introduction, it seems that the authors aim to examine feature sensitivity for \u201ctree ensembles,\u201d which is a broad category that includes several model classes, such as gradient-boosted trees (GBTs) and random forests (RFs). This is further illustrated in Section 2, where the authors attempt to provide a general definition of tree ensembles (Lines 130-136). However, upon reviewing the technical sections of the study (Sections 3-5), it becomes clear that the results are exclusively related to GBTs. This focus is reiterated toward the end of the introduction (starting at Line 65), where the authors clarify their exclusive emphasis on GBTs.\n\nTherefore, it is essential for the authors to establish a clear consensus on the scope of the paper in the revised version. If they intend to concentrate solely on GBTs, this specificity should be highlighted throughout the paper, beginning with the title and summary. The definition of tree ensembles in Section 2 should also be replaced with a definition of GBTs. Conversely, if the authors believe that their theoretical results could be easily extended to other tree ensemble classes (e.g., random forests), then the proofs in Section 4 should be modified accordingly (see Question 2).\n\nAt present, the definition of tree ensembles in Section 2 is somewhat unclear. If we denote by $c(x)$ the sum of the decisions $T_i(x)$ made by each of the $m$ decision trees $T_i$, then what class in $\\mathcal{F}$ is predicted by $c$ on $x$? This is evident for GBTs when $\\mathcal{F} = \\\\{-1,+1\\\\}$, using the sigmoid function $\\sigma$, but it remains ambiguous for other classes of tree ensembles. If the authors\u2019 goal is to address various classes of ensemble models, it is important to provide a comprehensive definition of \u201ctree ensemble\u201d that can be instantiated for both GBTs and random forests.\n\n**Significance:**\nThe main theoretical contribution of this paper lies in Theorem 2, which establishes that single feature sensitivity is NP-hard for GBTs. Other NP-hardness results presented in this study stem from this case. While this finding is commendable, I remain unsure if it is sufficient for ICRL. To enhance the theoretical significance of this study, it would be beneficial to investigate whether this problem and its variants are W[1]-hard or if some of them are fixed-parameter tractable (FPT), with the parameter of interest being the maximum depth of the trees (See Question 1). Establishing hardness results for W[1] would indeed bolster the justification for the constraint programming approach discussed in Section 4."
            },
            "questions": {
                "value": "(1) Can the NP-hardness of single feature sensitivity (Theorem 2) or subset feature sensitivity (Theorem 1) for GBTs be extended to W[1]-hardness? \n\n(2) Alternatively, can these hardness results for GBTs be extended to random forests?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}