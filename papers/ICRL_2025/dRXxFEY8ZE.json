{
    "id": "dRXxFEY8ZE",
    "title": "$\\texttt{BirdSet}$: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics",
    "abstract": "Deep learning (DL) has greatly advanced audio classification, yet the field is limited by the scarcity of large-scale benchmark datasets that have propelled progress in other domains. While AudioSet aims to bridge this gap as a universal-domain dataset, its restricted accessibility and lack of diverse real-world evaluation use cases challenge its role as the primary resource. Therefore, we introduce $\\texttt{BirdSet}$, a large-scale benchmark dataset for audio classification focusing on avian bioacoustics. $\\texttt{BirdSet}$ surpasses AudioSet with over 6,800 recording hours ($\\uparrow17\\%$) from nearly 10,000 classes ($\\uparrow18\\times$) for training and more than 400 hours ($\\uparrow7\\times$) across eight strongly labeled evaluation datasets. It serves as a versatile resource for use cases such as multi-label classification, covariate shift or self-supervised learning. We benchmark six well-known DL models in multi-label classification across three distinct training scenarios and outline further evaluation use cases in audio classification. We host our dataset on Hugging Face for easy accessibility and offer an extensive codebase to reproduce our results.",
    "keywords": [
        "audio classification",
        "multi-label",
        "dataset collection",
        "bioacoustics"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "We introduce $\\texttt{BirdSet}$, a multipurpose and large-scale dataset collection for audio classification.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=dRXxFEY8ZE",
    "pdf_link": "https://openreview.net/pdf?id=dRXxFEY8ZE",
    "comments": [
        {
            "title": {
                "value": "Response to Author's"
            },
            "comment": {
                "value": "Thanks to the authors for the rebuttal. I appreciate the proposed changes to the language: I believe it only solidifies the author's case and strengthens BirdSet's positioning in the eyes of the community.\n\nI understand the authors' comments regarding linear evaluation on cross-domain data going beyond the scope of the paper: it's difficult to do experiments while being thorough in a limited amount of time. However, I continue to feel like they would have been instrumental in understanding the nuances of cross-domain transfer and the impact of BirdSet. \n\nIn light of the above, I have increased my recommendation to 6."
            }
        },
        {
            "title": {
                "value": "Authors' Answer: Few-shot Scenarios"
            },
            "comment": {
                "value": "Dear reviewer, thank you for your detailed review and very positive feedback! We are very happy that you recognize the significance of our work. As no specific weaknesses were highlighted, we will focus on addressing your interesting question below:\n\n> I wonder if it would be feasible to define few-shot tasks within the downstream tasks to address few-shot multi-label classification?\n\nThis is an excellent question and highlights an interesting direction for future evaluation use cases, especially in the context of model adaption (Challenge 3 and contribution (2) in the paper), which is fundamental for advancing practical applications in audio (avian) classification. As noted in Line 320, BirdSet\u2019s flexible and versatile design opens up numerous potential tasks and scenarios. This is particularly relevant when fine-tuning a model that was e.g. pre-trained through self-supervised learning (SSL) (which is still largely unexplored within the field of avian bioacoustics). Here are two examples with which we could utilize the few-shot multi-label classification with BirdSet:\n\n- One possible approach is to train a model using SSL (or SL) on our large dataset XCL and then create few-shot scenarios within the dedicated subsets for fine-tuning (e.g., in the direction of [1] or [2]), where a small number ($k$) of examples are selected from the respective classes in the training subsets. This could create multiple real-world few-shot scenarios when evaluated on our test datasets. Currently, we are developing an AudioMAE-style SSL model pre-trained XCL and fine-tuning it on relevant subsets. As the preliminary results are quite promising and show potential for valuable representations, we could seamlessly extend it into few-shot scenarios, making your suggestion particularly timely and valuable!\n- Another approach could also be to directly utilizing the test soundscape recordings through a form of cross-validation to fine-tune a pre-trained model in a few-shot setting, specifically focusing on a subset of bird species (or only a single species) within these soundscapes (which could also be relevant for practitioners).\n\n[1] Burooj Ghani, Tom Denton, Stefan Kahl, and Holger Klinck. Feature Embeddings from Large Scale Acoustic Bird Classifiers Enable Few-Shot Transfer Learning. CoRR, 2023. URL https:[//doi.org/10.48550/arXiv.2307.06292](https://doi.org/10.48550/arXiv.2307.06292)\n\n[2] Jenny Hamer, Eleni Triantafillou, Bart Van Merri\u00ebnboer, Stefan Kahl, Holger Klinck, Tom Denton, and Vincent Dumoulin. BIRB: A Generalization Benchmark for Information Retrieval in Bioacoustics. CoRR, 2023. URL https://doi.org/10.48550/arXiv.2312.07439"
            }
        },
        {
            "title": {
                "value": "Authors' Answer (3): Cross-Domain Evaluation (1/1)"
            },
            "comment": {
                "value": "### **(2) Cross-Domain Evaluation**\n\n>In the context of how the paper is currently phrased, more direct comparisons, for instance, linear evaluation on cross-domain data between models trained on BirdSet and AudioSet on various downstream tasks spanning bioacoustics and other audio domains, would be needed.\n\n*Explanation and statement**:* With the abovementioned changes from (1) to tone down the implications of replacing existing datasets, we believe this improves the paper. While we understand and appreciate this remark, we feel that these additions would exceed the paper\u2019s scope in its current form after carefully updating the wording. Additionally, we acknowledge that this topic is indeed very interesting for future exploration, as stated in Limitation L.538, where we conclude that a more thorough investigation into the influence of pre-training remains an important limitation and an intriguing direction for future work. Your spotting further highlights this regarding the performance of AST and EAT after fine-tuning, which are pre-trained on AudioSet.\n\n*Utilizing your feedback*: With the changes to the wording and dataset positioning, your remark presents an exciting direction for future work branching out from BirdSet. We believe this work lays the groundwork for these investigations, such as the impact of cross-domain pre-training and fine-tuning."
            }
        },
        {
            "title": {
                "value": "Authors' Answer (2): Positioning of BirdSet (2/2)"
            },
            "comment": {
                "value": "**L.76 (1. Introduction - Contributions)** \n> \"[\u2026] BirdSet represents a comprehensive resource in audio classification.\u201d\n\n_Changes_: [\u2026] BirdSet represents a comprehensive and additional resource in audio classification.\n\n**L.91, 92-93, 101-102 (2. Current Challenges and Related Work)**\n>> \u201cAvian bioacoustics exemplifies challenges in audio classification, including managing diverse and noisy acoustic environments or dealing with class imbalance.\u201d\n>\n>> \u201c[\u2026] it serves as our primary case study for illustrating real-world evaluation use cases [\u2026].\u201d\n>\n>> \u201cAs a domain-specific audio classification task, avian bioacoustics exemplifies and adds to these complexities, making it suitable for exploring real-world audio challenges.\u201d\n\n_Explanations_: We did not change anything here but since you explicitly highlighted L.91 and the other parts go into the same directions, we want to clarify that we intended to convey that avian bioacoustics comes with unique traits that present interesting and challenging opportunities for the broader audio classification domain. This was not meant to undermine the value of AudioSet but to illustrate why avian bioacoustics is suitable as our primary case study and comes with relevant real-world evaluation use cases.\n\n**L.142-146 (2.1 Challenge 1: Datasets)**\n>\u201c[\u2026] However, these curated datasets do not fully represent real-world complexities (e.g., class imbalance) and are considerably smaller compared to vision datasets (e.g., ImageNet (Deng et al., 2009)).\u201d\n\n_Changes_: However, these datasets cannot fully represent real-world complexities (e.g., class imbalance) due to limited size and quantity compared to vision datasets (e.g., ImageNet (Deng et al., 2009)).\n\n**L. 158-164 (2.1 Challenge 1: Datasets)**\n\n_Explanations_: We believe this aspect of the related work adequately highlights some critical differences from AudioSet without implying that it is intended to replace it altogether.\n\n**L. 191-193 (2.2 Challenge 2: Model Training)**\n>\u201cThis complexity is often reduced to a more straightforward multi-class task in datasets such as ESC-50 (Piczak, 2015), limiting a model\u2019s real-world applicability where overlapping sounds and event ambiguity are common.\u201d\n\n_Changes_: [\u2026], potentially limiting a model's ability to handle overlapping sounds and event ambiguity in practice.\n\n**L. 224-226 (2.2 Challenge 2: Model Training)**\n> \u201cIn contrast, models pre-trained on general domain audio exhibit poor transferability to the domain (Ghani et al., 2023; Nolan et al., 2023)\u201d \n\n_Changes_: In contrast, pre-training on general domain audio through SSL exhibits limited transferability, compared to in-domain transfer of supervised models (Ghani et al., 2023)."
            }
        },
        {
            "title": {
                "value": "Authors' Answer (1): Positioning of BirdSet (1/2)"
            },
            "comment": {
                "value": "Dear reviewer, \nthank you very much for your thorough and insightful review. We are happy that you acknowledge the impactful contribution of BirdSet and share our perspective on the key challenges within the audio classification domain. In the following, we go through your two main remarks, explain our approach and how we have incorporated your valuable feedback.\n\n### **(1) Positioning of BirdSet compared to AudioSet**\n\n> BirdSet will be a tremendous contribution to the fields of audio classification and avian bioacoustics, I have no doubt, but I think the current language of the paper comes off as \"posturing\" a tad bit too much.\n\n*Explanation and statement**:* First, we entirely agree that AudioSet was a pivotal step for audio classification and remains a highly relevant and impactful dataset. Our intention with BirdSet was never to replace it but to provide a complementary, domain-specific dataset that is easily accessible and supports a wide range of novel/challenging evaluation use cases. We also agree that datasets like AudioSet/ESC-50 capture real-world challenges, even if they are more curated than BirdSet. We aim to add another layer of benchmarking for audio classification with an ecologically relevant focus.\n\n*Utilizing your feedback**:* We went through the paper to identify and carefully adjust sections that might have overstated BirdSet\u2019s positioning. We aim to maintain the core message and BirdSet\u2019s strong contribution while ensuring its complementary value to the domain. Any change in the paper PDF is highlighted in red (we reupload as soon as all updates are done). We summarize all changes in the following:. \n\n**L.13-16 (Abstract)**: \n>\u201cWhile AudioSet aims to bridge this gap as a universal-domain dataset, its restricted accessibility and lack of diverse real-world evaluation use cases challenge its role as the primary resource. Therefore, we introduce BirdSet, a large-scale benchmark dataset for audio classification focusing on avian bioacoustics.\u201d\n\n_Changes_:  While AudioSet is a pivotal step to bridge this gap as a universal-domain dataset, its restricted accessibility and limited evaluation use cases challenge its role as the sole resource. Therefore, we introduce BirdSet, a large-scale complementary benchmark data set for audio classification focusing on avian bioacoustics.\n\n**L.34-38 (1. Introduction)** \n>\u201cWhile AudioSet (Gemmeke et al., 2017) offers substantial training data with over 5,800 recording hours, its restricted accessibility that requires manual data retrieval, lack of diverse evaluation scenarios and test datasets (Wang et al., 2021), and concerns regarding transferability to real-world environmental domains (Ghani et al., 2023) challenge its role as the only training resource.\u201d\n\n_Changes_: Although AudioSet (Gemmeke et al., 2017) offers substantial training data with 5,800 recording hours, its restricted accessibility that requires manual data retrieval, lack of diverse evaluation scenarios (Wang et al., 2021), and studies emphasizing the need for domain-specific representation learning (Ghani et al., 2023), challenge its role as the sole training resource.\n\n_Further Explanations_: In this part, we have already emphasized that AudioSet should not be replaced. Instead, we highlighted the necessity of additional resources beyond AudioSet in the future and the importance of having diverse and versatile datasets. We hope our clarifications have further reinforced this perspective. However, we would like to maintain the wording regarding the limited use cases and test dataset availability, as this highlights a unique aspect of BirdSet \u2014 its seven different evaluation datasets, each with distinct traits and features that introduce unique domain transfer challenges not inherently present in AudioSet. Additionally, our test datasets are accompanied by strong labels, minimizing potential labeling errors often encountered when evaluating with AudioSet.\n\nRegarding in-domain transferability: Paper [1] explicitly mentions that conventional supervised learning in avian bioacoustics achieves better transferability than more general self-supervised learning representations from AudioSet. You are correct that this reinforces the expectation that in-domain transfer outperforms out-of-domain transfer, but there is a discrepancy between SL and SSL representation learning that is very interesting to research in the future: We are currently developing an AudioMAE-style SSL model with BirdSet. Preliminary results demonstrate improved transferability (in contrast to [1]) when pre-training on AudioSet and fine-tuning on BirdSet and even better fine-tuning performance with BirdSet's in-domain SSL training.\n\n[1] Burooj Ghani, Tom Denton, Stefan Kahl, and Holger Klinck. Feature Embeddings from Large-Scale Acoustic Bird Classifiers Enable Few-Shot Transfer Learning. CoRR, 2023. URL https: [//doi.org/10.48550/arXiv.2307.06292](https://doi.org/10.48550/arXiv.2307.06292)."
            }
        },
        {
            "summary": {
                "value": "This is an excellent,  comprehensive and carefully curated dataset of bird sounds. The paper also provides an excellent review of the existing literature, and provides baseline code showing use of the data. The benchmark testing tasks are a bit simple, but demonstrate the breadth of the dataset."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Careful curation of the dataset - types of collections, varying types of birdcalls from same species; includes both soundscapes, and individual recordings; comparisons with other datasets.\nInclusion of benchmark code for future researchers to use as a baseline.\nPermissive licensing\nA large scale project"
            },
            "weaknesses": {
                "value": "too many uncommon acronyms which require a reader to keep going back and forth - such shortening of the length was unnecessary. The acronyms are used in the figures as well. Figures and captions are supposed to stand on their own."
            },
            "questions": {
                "value": "Please rewrite with clarity and minimizing acronyms."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents BirdSet, a new large-scale benchmark dataset specifically for multi-label audio classification within avian bioacoustics. It significantly extends the scope of existing audio datasets by including approximately 10,000 classes, covering over 6,800 hours of training data, and incorporating 400 hours across eight distinct test datasets. BirdSet addresses several real-world machine learning challenges, such as covariate shift, label noise, and task shift, providing a unique resource for evaluating model robustness in audio classification under diverse conditions. The benchmark includes evaluations of six prominent deep learning models across three different training approaches: training on the full BirdSet, training on a subset containing only classes relevant to the downstream tasks, and training on a small subset for each downstream dataset individually.\n\nAdditionally, the authors facilitate accessibility by hosting BirdSet on Hugging Face, where they provide Python code to load the data. They also offer scripts for reproducing the experiments in the paper\u200b."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. Originality\n\nBirdSet represents a novel contribution to multi-label audio classification. With close to 10,000 classes BirdSet provides a benchmark to develop scalable methods capable of handling extreme class diversity with large imbalance. BirdSet also addresses critical machine learning challenges such as covariate shift, where the testing distribution diverges from the training distribution reflecting real-world environmental shifts in field data.\n\n\n2. Clarity\n\nThe paper is clear and well-organized, with a logical presentation of BirdSet\u2019s structure, design choices, and challenges. The descriptions of covariate and domain shifts, as well as the evaluation protocols and training setups, are concise and well-articulated.\n\n\n3. Significance\n\nBirdSet can enable the development of new self-supervised learning, active learning, and few-shot learning approaches that are resilient to covariate and domain shifts\u2014capabilities that are increasingly relevant for practical deployment of models in real-world applications. Moreover, its emphasis on multi-label classification reflects real-world scenarios in bioacoustics and similar domains, driving advancements that can translate to other fields beyond audio.\n\n\nIn summary, BirdSet is highly original, well-curated, and impactful dataset that serves as both a resource and a benchmark. It encourages tackling challenges related to robustness to distribution shifts, and multi-label classification, with methods that can be developed that extend across deep learning domains more broadly."
            },
            "weaknesses": {
                "value": "I didn\u2019t find any weaknesses in this paper."
            },
            "questions": {
                "value": "I see significant potential in BirdSet, and I wonder if it would be feasible to define few-shot tasks within the downstream tasks to address few-shot multi-label classification?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes BirdSet, which is a dataset, or more specifically, a collection of 11 different sub-datasets. BirdSet attempts to unify \navian bioacoustic evaluation on focal and soundscape recordings under one roof, providing a large, unified, accessible test bed for testing audio classification approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Well written and easy to read.\n2. Thoroughly explains the challenges experienced not only in avian bioacoustics, such as covariate shift and mismatch in focal and soundscape recordings, but also in curating, and developing a dataset of such a size and scale. \n3. The pain points addressed in the paper are very real: poor availability and accessibility of AudioSet, lack of a unified benchmark suite for evaluating segment and event-based bioacoustics tasks, and mismatch between train and test time for avian bioacoustics, are all pressing challenges. \n4. A good variety of baseline models were evaluated."
            },
            "weaknesses": {
                "value": "To me, the paper, in several places, tries to pose BirdSet as a replacement for AudioSet and that it should be the exemplary benchmark for evaluating audio classification models, with statements such as \"Avian bioacoustics exemplifies challenges in audio classification...\", and how curated datasets like AudioSet and ESC-50 do not represent real-world complexities. Pain points mentioned w.r.t. AudioSet are all very real, but AudioSet is a much broader dataset than BirdSet. Several people, in industry and academia have found AudioSet useful: a blanket statement saying AudioSet is not useful in real-world scenarios is plain wrong. \nSome statements straight up downplay AudioSet: for instance, line 37-38: where AudioSet poses \"... concerns regarding transferability to real-world environmental domains\". Whereas the paper cited simply shows that AudioSet pretrained models perform \"well enough\": of course models trained on in-domain bioacoustics data will fare better for bioacoustic evaluation!\n\nAlso, as per Table 3, AST and EAT models, which are pretrained on AudioSet, seem to perform quite well in the DT setting (cross-domain transfer setting) versus their LT and MT counterparts. For EAT, DT performance matches MT and outperforms LT scenarios. \n\nBirdSet will be a tremendous contribution to the fields of audio classification and avian bioacoustics, I have no doubt, but I think the current language of the paper comes off as \"posturing\" a tad bit too much."
            },
            "questions": {
                "value": "In the context of how the paper is currently phrased, more direct comparisons, for instance, linear evaluation on cross-domain data between models trained on BirdSet and AudioSet on a variety of downstream tasks, spanning bioacoustics and other audio domains would be needed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces BirdSet, a large-scale audio classification dataset for avian bioacoustics, with around 520,000 recordings from nearly 10,000 bird species. It includes over 6,800 hours of training data and 400 hours of evaluation data from diverse regions. The dataset supports tasks such as multi-label classification and self-supervised learning, with standardized training and evaluation protocols. A comprehensive literature review identifies key challenges in bioacoustics and provides research guidelines. The paper benchmarks multiple deep learning models and offers a codebase for reproducibility."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. The introduction of *BirdSet* fills a notable gap in audio classification by providing a large-scale, domain-specific dataset for avian bioacoustics.\n2. The paper is well-structured and clearly articulates the challenges in avian bioacoustics and audio classification more broadly. \n3. The paper provides a thorough empirical evaluation using six well-known deep learning models, covering various training scenarios, including large-scale training and fine-tuning."
            },
            "weaknesses": {
                "value": "1. The literature review in Section 2 is quite extensive, occupying a significant portion of the main paper. While the analysis is comprehensive, it might be more beneficial to allocate more space to the dataset description and details, rather than using five pages for the related work.\n2. The results focus mainly on the multi-label classification benchmark, with limited exploration of other use cases. Given the dataset\u2019s availability of precise event timestamps, it would be valuable to include benchmarks for sound event detection. Additionally, providing results for other mentioned use cases would strengthen the paper."
            },
            "questions": {
                "value": "Please refer to the weaknesses above for the questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}