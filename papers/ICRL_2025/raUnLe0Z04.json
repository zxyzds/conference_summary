{
    "id": "raUnLe0Z04",
    "title": "Lossy Compression with Pretrained Diffusion Models",
    "abstract": "We apply Theis et al. (2022)'s DiffC algorithm to Stable Diffusion 1.5, 2.1, and XL, and demonstrate that these pretrained models are remarkably capable lossy image compressors. A principled algorithm for compression using pretrained diffusion models has been understood since at least 2020 (Ho et al.), but challenges in reverse-channel coding (RCC) have rendered such algorithms impractical. We introduce some simple workarounds which allow us to compress and decompress images using Stable Diffusion in under 10 seconds. Despite requiring no additional training, our method is competitive with other state-of-the-art compression methods at low bitrates (0.005-0.05 bpp).",
    "keywords": [
        "Compression",
        "Stable Diffusion",
        "DDPM",
        "DiffC"
    ],
    "primary_area": "generative models",
    "TLDR": "We implement a principled algorithm for compressing images using Stable Diffusion.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=raUnLe0Z04",
    "pdf_link": "https://openreview.net/pdf?id=raUnLe0Z04",
    "comments": [
        {
            "summary": {
                "value": "This submission presents a set of lossy compression method based on DiffC, with pretrained StableDiffusion1.5,2.1, and XL. To enable this utilization, a solution to the reverse-channel coding problem is proposed. This submission is also the first one to publicly release an implementation of the DiffC algorithm."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper implemented the SOTA stable diffusion for single image compression usage, and also released an implementation of DiffC to the public."
            },
            "weaknesses": {
                "value": "First, I don't think the main contribution is significant. The major idea had already been proposed several years ago. \nSecond, I failed to find the comparisons of this idea with other SOTA image compression methods."
            },
            "questions": {
                "value": "Could you present the comparisons of this idea with other SOTA image compression methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to solve the reverse channel coding remaining in DiffC and to accelerate the diffusion-based compression method under 10 seconds without additional training."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Originality: The authors try their best to implement the DiffC and apply it to existing pre-trained diffusion models, such as Stable Diffusion 1.5, 2, and XL. In addition, they propose a greedy optimization technique to speed up the diffusion process and to select the best denoising timestep schedule.\n\nQuality: The manuscript is well organized and written.\n\nClarity: The authors have explained their method in detail.\n\nSignificance: The significance of this work is profound because it addresses the remaining problems in the DiffC algorithm, such as inference time and reverse-channel coding."
            },
            "weaknesses": {
                "value": "(1)The manuscript looks more like a technology report than an academic paper.\n\n(2)The authors do not provide quantitative comparisons with state-of-the-art extreme image compression methods (VQ-based methods, diffusion-based methods) and show the advantages of the proposed method.  \n\n(3) Although the main contribution of the paper is the implementation of the DiffC algorithm, the author should provide the model complexity of the proposed method (e.g., network parameters, FLOPs, encoding/decoding time, etc.)."
            },
            "questions": {
                "value": "In Section 4.1, the prompts do not support image compression or reconstruction. This result contradicts many previous prompt-guided image compression methods. The author should add more analysis and explain why they do not work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper applies the DiffC algorithm to pre-trained Stable Diffusion models (1.5, 2.1, and XL) for high-fidelity image compression at low bitrates. This approach leverages reverse-channel coding (RCC) to efficiently steer the denoising process toward realistic image reconstructions without additional training. By optimizing the denoising schedule and utilizing CUDA acceleration, the method achieves competitive reconstruction performance and compression times (under 10 seconds) compared to other state-of-the-art compression methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper extends DiffC to stable diffusion, provides an open-source implementation, and accelerates RCC with CUDA. These contributions promote the practicality of the method and pave the way for further exploration.\n\n2. The paper is well written and easy to follow. Enough background information is provided to general readers.\n\n3. The paper provides guidance on potential research directions in the Future Work section, offering insights for subsequent studies."
            },
            "weaknesses": {
                "value": "1. The paper lacks sufficient innovation and resembles more of an engineering improvement on existing methods.\n\n2. The diffusion model requires multiple inference steps for both encoding and decoding, resulting in significant computational overhead.\n\n3. Although the authors claim that their method is competitive with other state-of-the-art compression methods, no comparisons are provided in the paper. To substantiate this claim, the authors should compare their method with existing approaches such as PerCO [1], DiffEIC [2], and MS-ILLM [3] in terms of compression performance (e.g., PSNR, MS-SSIM, LPIPS, FID, etc.) and computational complexity (e.g., encoding/decoding time), presenting corresponding results in the paper.\n\n[1] Marlene Careil, Matthew J. Muckley, Jakob Verbeek, and St{\\'e}phane Lathuili{\\`e}re. Towards image compression with perfect realism at ultra-low bitrates. In The Twelfth International Conference on Learning Representations, 2024\n\n[2] Zhiyuan Li, Yanhui Zhou, Hao Wei, Chenyang Ge, and Jingwen Jiang. Towards extreme image compression with latent feature guidance and diffusion prior. IEEE Transactions on Circuits and Systems for Video Technology, 2024.\n\n[3] Matthew J Muckley, Alaaeldin El-Nouby, Karen Ullrich, Herv{\\'e} J{\\'e}gou, and Jakob Verbeek. Improving statistical fidelity for neural image compression with implicit local likelihood models. In International Conference on Machine Learning, 2023."
            },
            "questions": {
                "value": "1. On page 2, line 100, the description of CDC appears to be inaccurate. CDC is trained from scratch rather than by fine-tuning conditional diffusion models.\n\n2. In Section 4.2, why is there no R-D curve provided to illustrate the comparison between Stable Diffusion XL Base and Refiner?\n\n3. In Section 3.5, it is mentioned, ``But in practice, we have found that just hard-coding a sequence of expected DKL values into the protocol based on their averages does not affect the performance of our method too much.`` Does this mean that the $D_{KL}$ values used in practice are manually set? Could the authors provide empirical results (e.g., R-D curves) to support the conclusion that this strategy does not affect the performance too much? Additionally, what impact would increasing or decreasing the preset $D_{KL}$ values have on performance? Could RD trade-offs be achieved by adjusting the $D_{KL}$ values?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel application of pretrained diffusion models, specifically Stable Diffusion versions 1.5, 2.1, and XL, for lossy image compression using the DiffC algorithm. The authors introduce practical workarounds to overcome challenges in reverse-channel coding, enabling efficient image compression and decompression within 10 seconds without additional training. The method is shown to be competitive with state-of-the-art compression techniques at low bitrates (0.005-0.05 bpp), demonstrating its efficacy and potential in real-world applications."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) The paper introduces an innovative use of pretrained diffusion models for image compression, expanding the utility of these models beyond their typical generative applications.\n2) The proposed method achieves competitive performance with state-of-the-art compression techniques at low bitrates, showcasing its practical value.\n3) Implementation details and optimizations, such as the use of CUDA for reverse-channel coding, significantly enhance the efficiency and feasibility of the approach.\n4) The publicly available implementation of the DiffC algorithm promotes transparency and facilitates further research and development in this area."
            },
            "weaknesses": {
                "value": "1) The method's performance is constrained by the fidelity limits of the Stable Diffusion models' variational autoencoders, affecting compression quality at higher bitrates.\n2) The reverse-channel coding process, while optimized, still presents computational challenges, particularly for very large or very small DKL values.\n3) The paper does not extensively explore the combination of DiffC with other conditional diffusion approaches, which could potentially enhance performance further.\n4) The reliance on Stable Diffusion's image size limitations may affect the generalizability of the method to images outside the training distribution."
            },
            "questions": {
                "value": "1)  How does the performance of your method vary with image sizes that deviate from the training distribution of Stable Diffusion? Are there any strategies you are considering to mitigate performance degradation for such cases?\n2) Can you provide a more detailed comparison between your method and other state-of-the-art compression techniques, particularly in terms of computational efficiency, quality metrics, and bitrate?\n3) In the leftmost plot of Figure 3, could the authors explain why the performance of the 163-step is worse than that of the 54-step?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}