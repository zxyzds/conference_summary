{
    "id": "vmkpk0ed1F",
    "title": "Formalizing Spuriousness of Biased Datasets using Partial Information Decomposition",
    "abstract": "Spuriousness arises when there is an association between two or more variables in a dataset that are not causally related. Left unchecked, they can mislead a machine learning model into using the undesirable spurious features in decision-making over the core features, hindering generalization. In this work, we propose a novel explainability framework to disentangle the nature of such spurious associations, i.e., how the information about a target variable is distributed among the spurious and core features. Our framework leverages a body of work in information theory called Partial Information Decomposition (PID) to first decompose the total information about the target into four non-negative quantities namely unique information (in core and spurious features respectively), redundant information, and synergistic information. Next, we leverage this decomposition to propose a novel measure of the spuriousness of a dataset that steers models into choosing the spurious features over the core. We arrive at this measure systematically by examining several candidate measures, and demonstrating what they capture and miss through intuitive canonical examples and counterexamples. Our proposed explainability framework Spurious Disentangler consists of segmentation, dimensionality reduction, and estimation modules, with capabilities to specifically handle high dimensional image data efficiently. Finally, we also conduct empirical evaluation to demonstrate the trends of unique, redundant, and synergistic information, as well as our proposed spuriousness measure across several benchmark datasets under various settings. Interestingly, we observe a novel tradeoff between our measure of dataset spuriousness and empirical model generalization metrics such as worst-group accuracy, further supporting our proposition.",
    "keywords": [
        "Explainability Framework",
        "Spuriousness",
        "Partial Information Decomposition",
        "Blackwell Sufficiency",
        "Auto-encoder",
        "Worst-group Accuracy"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "This work proposes a novel measure of dataset spuriousness leveraging partial information decomposition.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vmkpk0ed1F",
    "pdf_link": "https://openreview.net/pdf?id=vmkpk0ed1F",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a novel framework to quantify dataset spuriousness, addressing a gap in formalizing how spurious correlations between non-causal features and the label affect model generalization. The measure is calculated based on unique information and synergistic information values obtained from partial information decomposition. Experiments show negative correlation between the values of this measure and generalization metrics under distribution shift."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1)The problem is important and relevant to OOD Generalization.\n\n2)The proposed measure is novel.\n\n3)The experiments consider a range of datasets and somewhat empirically support the claims of the paper."
            },
            "weaknesses": {
                "value": "1)The measure relies on the assumption that causal and spurious features can be separated in the image as foreground and background. However, this assumption may not hold universally or even in most of the cases; for instance, spurious features like rotation or color affect all pixels rather than specific regions. In fact, disentangling causal and spurious features in a major challenge for many OOD tasks.\n\n2)In the experiments, standard deviations or error bars are not provided, making it difficult to assess the scientific significance of the results.\n\n3)There is no theoretical proof for why a higher value of the proposed measure would correspond to worse OOD performance. \n\n4)Related to above, this paper lacks novel theoretical contribution. The theory presented is straightforward from partial information decomposition theory. Methodologically too, the main contribution comes from Bertschinger et al., (2014) which is used to calculate PID."
            },
            "questions": {
                "value": "1)During dimensionality reduction, how are the number of clusters chosen? Why do we need to approximate the distribution in a discrete way and what do we lose by doing so?\n\n2)Why are other measures like I(Y;B) etc. not clearly reported in the results? This would help us compare the proposed measure with other measures."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors propose a novel measure of spuriousness by utilizing Partial Information Decomposition (PID) and an explainability framework consisting of segmentation, dimensionality reduction, and estimation modules to specifically handle high dimensional image data efficiently. In general, the proposed measure of spuriousness is interesting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The proposed methods are novel and the experiments are extensive."
            },
            "weaknesses": {
                "value": "The writing in some places is a bit unclear and some implementation details are lacking."
            },
            "questions": {
                "value": "1, In the proposed autoencoder-based explainability framework, it seems that we need to select a non-negative constant $\\gamma$ in dimensionality reduction phase, the readers may want to know how to select the value of $\\gamma$. It will be helpful if the authors can give some guidance about the selection of $\\gamma$.\n\n2, In this paper, the authors propose a novel metric of spuriousness, then how can we identify one feature as a spurious one? It seems that we need the threshold?\n\n3, It seems that there is a typo in \"a the\" in line 266.\n\n4, In line 182, what is \"Z_3 \\bigoplus N$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The framework builds on a foundation in information theory known as Partial Information Decomposition (PID) to break down the total information about the target variable into four distinct, non-negative components: unique information (within both core and spurious features), redundant information, and synergistic information. Using this decomposition, we introduce a novel metric for assessing the spuriousness of a dataset, guiding models to prioritize spurious features over core features."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "this paper is based on a sound foundation: abstract / line 96 - line 125\nthe provided experimental evaluation doesn't include the statistical ratios (mean + std)"
            },
            "weaknesses": {
                "value": "poor writing quality"
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work focuses on the problem of spurious correlation in the data-driven models. It leverages the partial information decomposition (PID) to decompose the total information into four quantities such as the unique information of core and spurious features, the redundant information that is shared by two features, and the synergistic information that arises due to the collaboration of the two features. Based on this decomposition, the authors propose a framework called Spurious Disentangler to empirically evaluate the \u201cspuriousness\u201d of image data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper focuses on an important task that evaluates the degree of \u201cspuriousness\u201d of a dataset.\n2. The idea of decomposing the total information into the aforementioned four values to study the spurious correlation problem is very interesting.\n3. The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1. My main concern is the contribution and practicality of the proposed method. Although the idea of using information theory to quantify spuriousness is interesting, the actual use case of the proposed framework is limited and not properly discussed. Most results only show that the framework \u201cis consistent with existing knowledge\u201d (e.g. Theorem 1, experimental observations).\n\n2. The proposed framework, \u201cspuriousness disentangler\u201d, relies heavily on segmentations. This greatly reduces its application scenarios. Datasets where spurious and core features can be explicitly separated as object & background are limited.\n\n3. The requirement of the existence of a pre-trained semantic segmentation model is problematic. This is equivalent to requiring a much larger and more general dataset or a much more powerful model where the spurious correlation problems are already mitigated to a good extent. Such a \u201cDeus Ex Machina\u201d approach is questionable in practice.\n\n4. The experiment section lacks insights and does not highlight the contribution of the proposed method.\n    - The experiments are repeated on four datasets. However, the observations are all descriptive yet the contribution and the superiority of the proposed method are limited. For example, in L427-L429, the authors conclude from Fig. 7 that $M_{sp}$ is a good measure because it is consistent with worst-group accuracy. This claim treats worst-group accuracy as the standard for evaluating \u201cspuriousness\u201d. The contribution of PID is completely missing here. \n    - The qualitative visualization of Figure 8 is only one sample. In L430, it is concluded from Figure 8 that \u201cwhen the dataset is balanced or mixed background, the model emphasizes \\textbf{more} on the core features (the red regions)\u201d. This justification is insufficient. To justify that the model focuses \u201cmore\u201d on the core feature. A score such as the IoU should be computed over the entire dataset to support this claim.\n\n\n[Minor]:\n\n1. L76, L78: \u201cWe first\u201d appears twice.\n2. L82-L83: The meaning of $A$ is not specified in $\\mathrm{Syn}(Y:A,B)$. Is it supposed to be $F$? The definitions of $A$ and $F$ overlap throughout the manuscript and create unnecessary difficulty for the audience. The authors may consider unifying them for a clearer presentation.\n3. In L147-148, $\\mathcal{X}$ isn\u2019t defined above.\n4. In Figure 5, the location of the text \u201cEncoder\u201d, and \u201cDecoder\u201d and the curly brackets are misplaced.\n5. The spacing after Figure 8 is completely missing.\n6. It\u2019s better to add captions for the subfigures in Figure 8 to indicate the five variants."
            },
            "questions": {
                "value": "1. Regarding the main concern, can the authors elaborate more on the use case of the framework where it is a better choice than existing measures such as worst-group accuracy?\n2. In L53, the authors mentioned, \u201cthis notion of spuriousness in any given dataset has classically lacked a formal definition. To address this gap,\u2026\u201d. There are similar works discussing the quantification of spuriousness. e.g. [1,2]. Can the authors elaborate more on how the contribution of this work differs from this existing work? \n3. Is it possible to generalize the proposed \u201cspuriousness disentangler\u201d framework to datasets where the segmentation of two features is infeasible? For example, in tabular data, the spurious features can be sensitive attributes such as gender, race, etc. These features cannot be segmented. \n4. In counterexample 1, the authors refer to canonical example 1 and claim that this scenario should be considered as having \u201cno spuriousness\u201d. However, in canonical example 1, since $B = Y+N_B$, $F = Y+N_F$ with i.i.d. noise $N_B, N_F$, the spurious feature $B$ is equally connected to the label $Y$ compared with the core feature. Shouldn\u2019t this be the \u201cmost spurious\u201d scenario?\n\n\n[Reference]\n\n[1] Ye, H., Zou, J., & Zhang, L. (2023, April). Freeze then train: Towards provable representation learning under spurious correlations and feature noise. In\u00a0*International Conference on Artificial Intelligence and Statistics*\u00a0(pp. 8968-8990). PMLR.\n\n[2] Wang, Y., & Wang, X. (2024, April). On the Effect of Key Factors in Spurious Correlation: A theoretical Perspective. In\u00a0*International Conference on Artificial Intelligence and Statistics*\u00a0(pp. 3745-3753). PMLR."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel framework called spurious disentangler that uses Partial Information Decomposition (PID) to analyze and quantify spurious correlations in datasets. The authors propose a new measure $M_{sp}$ that assesses how likely a dataset will lead models to rely on spurious features over core features, implementing this through a three-module system of segmentation, dimensionality reduction, and PID estimation. Through experiments on multiple datasets, they demonstrate a consistent negative correlation between their spuriousness measure and model generalization metrics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper clearly explains why simpler measures are insufficient and develops a novel spuriousness measure through examples and counterexamples. \n\n2. This paper proposes a novel and complete framework called spuriousness disentangler for handling high-dimensional image data.\n\n3. This paper provides extensive experimental results. It tests on multiple benchmark datasets, examines different types of sampling biases, and provides Grad-CAM visualizations. The experimental results well support their claims.\n\n4. I think this research is of great significance. It can help identify problematic datasets before expensive model training."
            },
            "weaknesses": {
                "value": "1. This works requires manual identification of core and spurious features, which significantly limits its applicability since this might requires human-expert knowledge.\n\n2. This paper focuses on the image classification task, it might be better if the authors can validate their framework on some NLP tasks."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}