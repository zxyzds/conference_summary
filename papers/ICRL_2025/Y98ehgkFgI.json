{
    "id": "Y98ehgkFgI",
    "title": "Network-based Active Inference and its Application in Robotics",
    "abstract": "This paper introduces Network-based Active Inference (NetAIF), a novel robotic framework that enables real-time learning and adaptability in dynamic, unstructured environments. NetAIF leverages random attractor dynamics and the Free Energy Principle (FEP) to simplify trajectory generation through network-topology-driven attractors that induce controlled instabilities and probabilistic sampling cycles. This approach allows robots to efficiently adapt to changing conditions without requiring extensive pre-training or pre-calculated trajectories. By integrating learning and control mechanisms within a compact model architecture, NetAIF facilitates seamless task execution, such as target tracking and valve manipulation. Extensive simulations and real-world experiments demonstrate NetAIF's capability to perform rapid and precise real-time adjustments, highlighting its suitability for applications requiring high adaptability and efficient control, such as robotics tasks in the energy and manufacturing sectors.",
    "keywords": [
        "Active Inference (AIF)",
        "Free Energy Principle (FEP)",
        "Robotics",
        "Trajectory generation",
        "Random dynamical systems",
        "Random attractor dynamics",
        "Non-Equilibrium Steady State (NESS)",
        "Adaptive control",
        "Industrial automation",
        "Computational efficiency",
        "Cost-efficient solutions"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "Network-based Active Inference (NetAIF) is a novel framework that uses random attractor dynamics and the Free Energy Principle to enable real-time adaptive robotics in unstructured environments.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Y98ehgkFgI",
    "pdf_link": "https://openreview.net/pdf?id=Y98ehgkFgI",
    "comments": [
        {
            "summary": {
                "value": "The work at first sight is very interesting as it seems to address some of the challenges in active inference for robotics, reads well, and showing its functioning in a real robot is very much appreciated. It also shows some novelty over previous approaches. However, there is plenty of explanations missing on the methodology used. For instance, where is the learning? Furthermore, results are not deeply analysed. Thus, it is complicated to understand the level of contribution of the approach."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* Easy to read\n* Novelty of neural network active inference with pullback attractor.\n* Interesting behaviour of unstable regions.\n* Experiments with real robots"
            },
            "weaknesses": {
                "value": "* The introduction is to broad and to superficial in all three items selected. The energy transition seems to far away from this work. Also only Deep RL is mentioned. What about MPC with learning. In the active inference section survey is the only work reference. But it would be more informative how this work differs from previous robotics works. e.g., An empirical study of active inference on a humanoid robot, A novel adaptive controller for robot manipulators based on active inference, End-to-end pixel-based deep active inference for body perception and action, The Free Energy Principle for Perception and Action: A Deep Learning Perspective, etc.\nInclude a brief comparison table highlighting key differences between their approach and the cited active inference robotics works. This would give clearer guidance on how to improve the introduction and positioning of their work.\n\n* Methods are unclear. What is the state, what is being minimized and learnt how it is performed. The diffusion process, etc. A lot of further explanation is needed. Provide\n1.\tA clear definition of the state space\n2.\tAn explicit statement of what quantity is being minimized\n3.\tA step-by-step description of the learning process\n4.\tA more detailed explanation of how the diffusion process is implemented in their model\n5.\tKey methodological details you feel are missing, such as the objective function and learning algorithm equations\n\n* Results analysis can be certainly improved. For instance, pose matching only shows 2-DOF results in joint angles not in the task space. This is not pose. Note that pose considers position and rotation of the end-effector.\nProvide full 6-DOF pose results including end-effector position and orientation.\n\nThe tracking what is the input output of the NetAIF? Why you need a kalman filter? AIF can do filtering. so the NetAIF is only computing the controller? Improve the flow diagram with notation and input output and explanation.\n\nThe valve experiment. \"manipulate valves of different shapes (triangle,\nsquare, circle)\" this is not shown. It is not clear what is the NetAIF computing and what is the engineering part. Provide analysis of valve manipulation for different shapes and a clear distinction between NetAIF computations and engineering components\n\nExtra remark. Figures should be further explained, just the title is not enough."
            },
            "questions": {
                "value": "* Where is the learning? Algorithm 1 only shows execution of the net. Provide a separate algorithm or flowchart that explicitly shows the learning process, including weight updates and any optimization steps.\n* What is the Free energy landscape (what is the equation? or what is x? how this affect the weights?) how is the diffusion coefficient being computed and  dW.\n1.\tProvide the explicit equation for the free energy landscape\n2.\tClearly define all variables (e.g., x)\n3.\tExplain how these components relate to the network weights\n4.\tDetail how the diffusion coefficient is calculated\n5.\tExplain what dW represents in their implementation and how it is used\n\n* Active inference agents explore when the model is unknown. But here authors express that the system is pushed into unstable regions due to the feedback loops. Provide an explanation of the potential advantages or disadvantages of this method compared to standard active inference exploration techniques.\n\nReferences:\n\"For a comparison with DRL methods, see the companion paper (Anonymous, 2024).\" This information should be in this paper. And it is marked as under review in ICRA but it can be found as under review in ICLR2025. Better to put all the info in one paper than split into two as it reduces its impact.\n\nThe High Road to Active Inference is a chapter. May be better to cite the book and refer to the chapter."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Network-based Active Inference (NetAIF), a robotic framework that leverages active inference principles and network dynamics to enable robots to adapt in real-time to dynamic environments. Built upon the Free Energy Principle (FEP), NetAIF supposedly simplifies trajectory generation using network-driven attractors, which introduce controlled instabilities and probabilistic sampling. These design choices supposedly allow for efficient, rapid responses to environmental changes without extensive pre-training, contrasting with deep reinforcement learning (DRL) approaches that require complex reward structures."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "I think active inference principles with network dynamics is a nice idea specifcially given that application of active inferecne has been a challenge without cumbersome approximations. So looks like your approach of integrating active inference with network dynamics is promising, potentially offering a fresh perspective in robotic control.\n\nIt is also interesting idea to diverge form optimization at every level and think of exploration and perturbations to converge towards good solutions.\n\nThe mode seems to be reduce computational overhead, making it suitable for resource-constrained cases like robots.\n\nThe authors provide thorough experimental validation, showcasing the framework's effectiveness across various tasks."
            },
            "weaknesses": {
                "value": "I do have some concerns regarding the work. \n\nLack of Structure in Descriptions: The initial sections of the paper, particularly the introduction, lack clear organization, making it difficult to follow the progression of ideas. A section on DRL is presented with no experiments on DRL later on in the paper.  The authors could reintroduce the problem of challenges of control more generally and issues with active inference that you are trying to address here.  start with the general challenges in robotic control, then introducing active inference and its limitations, followed by how NetAIF addresses these issues. Next would be related works and then a proper formulation of your methodology. This would provide a clearer progression of ideas for the readers to follow.\n\nRelevant Literature : Also I dont feel the related works section is done well.  It doesn't cover earlier works that are compuationaly cheap and related such as PMP (https://link.springer.com/article/10.1007/s10514-016-9563-3) or other adaptive/neural control methods. Basically, refer to methods that are learable, adaptive and computationaly cheap to provide a relevant review and comparison.\n\nComparative Analysis: Then  paper does not sufficiently compare NetAIF against established approaches in terms of accuracy and efficacy, limiting the context of its contributions. I undersand there is another work by the authors submitted to ICLR 2025. I suggest to merge the works given the same underlying idea. I believe a combined paper would show a promising work with applications and comparisons making it stronger or more impactful.\n\nConvergence Guarantees: The method\u2019s ability to ensure convergence to high accuracy while incorporating constant perturbations is not adequately addressed, raising concerns about stability and reliability. You could provide theoretical guarantees or empirical evidence demonstrating the system's stability under various perturbation conditions.\n\nRelevance to ICLR: The focus on robotic control, as opposed to learning and representation, may limit its appeal to broader ICLR community although this is not a limitation of the work per se."
            },
            "questions": {
                "value": "Comparative Metrics: What are the specific performance metrics used to evaluate NetAIF against existing methods, and how do these metrics support the claims of improved adaptability and efficiency?\n\nAccuracy and Stability: How does the framework guarantee convergence to a high accuracy given the introduction of controlled instabilities and random perturbations? What mechanisms are in place to handle potential divergence?\n\nLong-Term and Large system Performance: What measures are taken to evaluate the long-term performance and adaptability of NetAIF in highly variable environments or highly redundant robots as perturbations may make the system unstable."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel framework for robust learning of real-world robotics tasks in unstructured environments. The framework, called NetAIF, simplifies trajectory generation by relying on stochastic Random Dynamical Systems (RDS) and training model weights using the Free Energy Principle. Explicit feedback loops are introduced between hidden layers to control instabilities and enable real-time learning of three robotic tracking and interaction tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Interesting idea of using stable attractor dynamics for trajectory generation.\n- Accompanying videos of tracking experiments suggest reasonable tracking performance."
            },
            "weaknesses": {
                "value": "- Metrics and baselines are unclear. The only metric presented is average planning time in Section 3.6. However, no concrete comparisons with existing approaches like PRMs and Hybrid RRT-PRM as mentioned in the same section. Given the simplicity of the tasks evaluated, the paper also does not discuss why a simple PID tracking controller would not work, at least for the first 2 tasks.\n- The tasks presented lack significant details to allow for a fair evaluation of the presented approach. For instance, the action space used in each of the tasks is not clear. Similarly, the type of robot controller used is also unclear and could have a significant bearing on the results of the experiment. Is the gripper state part of the system state?\n- Sensory information here seems to be a direct measurement of the state. In general, this is only true for simple tasks. For instance, imagine a driverless car. Sensory information will generally be obtained through sensors like cameras without an explicit finite-sized state space. It is not clear how this approach would apply to a more general scenario where the relationship between sensory information and state information is not clearly defined.\n- Paper lacks clarity on the data used for training. How are the weights trained for each task? Is Algorithm 1 used to train the network weights? If this is the case, how do the authors ensure that training on the robot like this is safe?"
            },
            "questions": {
                "value": "Clarifications:\n- What does weight resetting mean? How does resetting work and how does this affect the dynamics of the network?\n- How do you validate performance in the presence of environmental disturbance? All the tasks investigated here seem to have little to no environmental disturbance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an active-inference inspired neural network architecture that can be used for various tasks in robotics applications. It is claimed that the neural network architecture follows several biological and physical principles, such as the minimization of free energy, or the principle of least action. Several experiments show that the model can be used for pose matching, target tracking and a valve-turning task with a real 6-DOF robotic arm."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The idea to use active-inference or related biologically-inspired principles for robotics is interesting, and indeed, such methods can be much more sample-efficient than a standard application of Deep RL, which often tends to be sample-inefficient and have long-training cycles."
            },
            "weaknesses": {
                "value": "However, the paper reads more like a manual than a scientific paper. I was often puzzled throughout reading the paper, as the proposed model and architecture's properties are described without really introducing a method. The methodology seems very unclear, and the link to the literature is mostly not discussed, so that I was unable to form a clear idea of what the method is and what the contribution (with respect to the related work in the literature) is. Moreover in the experiments there were no comparisons with other methods, even though the method is claimed to improve significantly over deep RL baselines. Besides that, I was at least expecting a comparison with a more control-theoretic baseline, such as a (well-tuned) PD controller."
            },
            "questions": {
                "value": "I will list here some comments and questions that I had while reading the paper:\n\nSection 1\n- much more citations are needed in section 1. We're missing the connection to the literature.\n- in what way is active inference 'advanced'?\n- why is minimizing surprisal often impractical? \n- mention the relation/links to variational inference (Bayes) in section 1.3\n- \"By minimizing F, the agent balances accuracy (matching observations) and complexity (keeping the model simple)\" \nThis is not clear from the text. Characteristics of the method are often explained without really introducing the method, e.g., \n\"NetAIF computes trajectories more efficiently than traditional AIF methods\" How is this done? \nSection 2\n- It is not clear what Figure 1 is, is it a fully connected network, or a convolutional neural network? or something else (RNN, etc.)?\n- \"NetAIF introduces explicit feedback loops between hidden layers, deliberately inducing controlled instabilities. Through extensive simulations and real-world experiments, we observe that these feedback mechanisms enable the network to explore the state space more thoroughly, leading to improved adaptability in dynamic environments.\"\nWhat does it mean a controlled instability? what do you mean by 'thoroughly'? These claims are not supported by the experiments. I strongly recommend the authors to start from clear mathematical definitions.\n- Figure 2 is not clear. What does red signify? what does blue signify for instance?\n- \"NetAIF actively manipulates network dynamics to push the system into unstable regions.\" How is this done? It does not seem to be discussed in the experiments adequately. And in general, instability is a huge problem in robotics. Or perhaps the authors mean something else? (see my comment above also, these points would be clarified by starting from mathematical definitions)\n- \"These feedback loops enhance oscillatory patterns, similar to neuron firing sequences, that persist even after training. This random bursts of node activity can be observed in the supplementary video, further highlighting the parallels with brain function.\" Again this seemed very vague to me (hence the comparison to a manual, rather than a clear scientific paper).\n- Figure 3: \"rendering the system open\" What does open mean?\n- What is a non-equilibrium steady state? Not clear from the text, is there a relation to Lyapunov stability?\n- Algorithm 1 is not clear and not explained, not is it self-contained. How is desired state determined? What is new_weight? The algorithm seems to be missing a loop, given that there is feedback. Nor is the feedforward mapping of inputs to outputs properly introduced (unless there is only one hidden layer).\n- What is the Free Energy in Algorithm 1? How is it playing a role?\n- \"By iteratively updating its local components based on prediction errors and external control laws, the system converges towards the desired states.\" -> How is this to be proved?\n\nSection 3 (Experiments)\n- How would you deal with constraints?\n- How do you get the desired joint poise? Inverse Kinematics?\n- There are no comparisons. The task seems especially easy, so I would expect a well-tuned PD controller to do equally well here.\nsection 3.4\n- How is the network trained?\n\nSection 4 (Discussions)\n- \"Moreover, this natural tendency aligns with the Least Action Principle (LAP) in classical mechanics\" -> how?\n- \"The network dynamics appear to inherently seek the most efficient temporal path toward stabilization, regardless of initial conditions. This suggests that the network is optimizing its behavior by minimizing a functional analogous to action, thereby aligning with universal\noptimization principles found in physics. \" Appear and suggest are not rigorous enough, especially given that you're proposing a network structure whose novelty hinges on this explanation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}