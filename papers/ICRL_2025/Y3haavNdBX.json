{
    "id": "Y3haavNdBX",
    "title": "Towards General Certified Robustness of Combinatorial Optimization Solvers",
    "abstract": "Combinatorial optimization (CO), driven by algorithmic advancements, now spans applications like network design and bioinformatics, crucial for optimizing complex systems and tackling NP-hard problems efficiently across various industries.\nNonetheless, the study for robustness, especially certified robustness in the CO domain which ensures optimization consistency among different data distributions, persists as an unexplored domain.\nIn this study, we explore the certified robustness and robustness enhancement strategy for CO solvers.\nFirstly, this study extends the randomized smoothing technique, a widely used certified robustness method in recognition and classification, and introduces a general definition of certified robustness for CO solvers.\nSpecifically, this study provides a theoretical guarantee that the output variations of CO solvers, as measured by the 1-Wasserstein distance, remain certifiably bounded when input instances vary within a specified range.\nSecondly, inspired by the concept of smoothing\u2014replacing the output of a single sample with the statistical output of multiple similar samples\u2014we discover that \u201ceasy instances\u201d often exist near current instances. These easy instances satisfy the constraints of the current instances but result in lower solver costs. \nBased on this finding, we propose a robustness enhancement method to search for and solve easy instances instead of current instances, thereby minimizing solver vulnerabilities.\nExperiments across datasets and solvers illustrate that our proposed certification definition can achieve a solid robustness guarantee and the enhancement method significantly amplifies the model\u2019s immunity to perturbations in practice.",
    "keywords": [
        "Certified Robustness; Combinatorial Optimization"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We develop a mathematically sound method to certify the robustness of CO solvers and introduce a general robustness enhancement method based on a smoothing concept.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Y3haavNdBX",
    "pdf_link": "https://openreview.net/pdf?id=Y3haavNdBX",
    "comments": [
        {
            "summary": {
                "value": "The paper presents an approach to addressing robustness in combinatorial optimization solvers by introducing a randomized smoothing framework for certified robustness. The theoretical results are supported by experiments on DAG scheduling and  TSP tasks and lend credibility to the proposed method. However, several assumptions in the robustness definitions, such as the strict reliance on CDF stability and the Wasserstein distance as robustness metrics, could limit the model's applicability to broader CO contexts."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Novelty in the exploration of certified robustness within CO solvers. \n- Adaptation of randomized smoothing to combinatorial problems (this is nice as CO have constraints and non-categorical outputs). \n- Theoretically grounded method that could apply to several optimization tasks in dynamic environments. \n- The enhancement method for leveraging \"easy instances\" shows a promising direction for robustness without retraining."
            },
            "weaknesses": {
                "value": "- The paper\u2019s approach primarily targets DAG scheduling and TSP tasks, but it is unclear how generalizable the method is to structurally richer CO problems. \n- The use of Wasserstein distance as the primary robustness metric may be too restrictive, especially in CO tasks where cost functions or constraints may differ significantly. \n- The empirical robustness results, while promising, rely on specific perturbation strategies (e.g., random search, simulated annealing). A more comprehensive assessment involving adaptive or adversarial perturbation techniques would provide a more robust evaluation here.\n- Some sections of the theoretical framework (particularly the robustness guarantees) are challenging to follow. Consider to at least paraphrase the results in English or adding some illustrative examples."
            },
            "questions": {
                "value": "1. Does the model handle adversarial perturbations, or is it only applicable to random perturbations? \n\n2. How does the proposed enhancement method scale with increased constraint complexity in CO tasks e.g., as the constraint structures and dependencies intensify? \n\n3. Could the robustness guarantees extend to CO problems with multi-objective cost functions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper seeks to assess the robustness of combinatorial optimization solvers.\nWhile this is a valid direction, the paper fails to articulate an appropriate theoretical framework, \nand exhibits several limitations in its presentation, methodology, and experiments."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "There has been a lot of interest recently in providing formal guarantees on the performance of trained ML models.\nInvestigating such a direction in the context of combinatorial optimization is relevant, however the paper suffers from multiple limitations, outlined below."
            },
            "weaknesses": {
                "value": "It is hard to understand the logic behind the paper, and several notations / symbols / problems are used without being clearly defined.\nIn addition to these limitations, the paper lacks a principled methodological framework.\nFinally, numerical experiments are incompletely stated and only small instances are considered.\n\n## Overall paper\n\n* How robustness of classifier relevant to robustness of combinatorial optimization setting?\n* The paper discusses the robustness of combinatorial solvers, but makes no mention of the (vast) literature on robust optimization\n* Throughout the paper, multiple concepts/notations are ill-defined or not defined at all. \n\tThis includes, for instance: \n\t* the \"strictness\" of a constraint\n\t* the underlying randomness & probability distribution considered in Eq (4)\n\t* variable $v$ in Eq (5)\n\t* Matrix $H_{b}$ used throughout the paper\n\t* $g_{\\theta}$ in Eq. (6)\n\n## Methodology\n\nThe paper suffers from several fundamental methodological limitations, the first of which is the absence of a clear, relevant definition of \"robustness\" for combinatorial optimization solvers.\nThis severe limitation makes it impossible to follow the rest of the paper, and to evaluate the paper's contribution and relevance to the field.\n\n* The paper lacks a principled definition of robustness for CO solvers.\n\tAuthors are invited to review the paper [_Compact Optimality Verification for Optimization Proxies_](https://proceedings.mlr.press/v235/chen24bj.html) and the references therein for relevant literature on performance verification for ML models that output solutions to optimization problems.\n* The paper states that \"hard\" instances have higher optimal value, which is not correct.\n\tFor instance, in TSP, multiplying all the distances by $\\gamma > 1$ increases the optimal value by the same factor $\\gamma$, but the optimization problem is equivalent.\n* The function CDF F(r) in Eq. (4) seems to be defined w.r.t a probability distribution over Q... which is never defined.\n* In Theorem 4.1, the right-hand-side integral (used as upper bound on a Wasserstein distance) may be infinite.\n\tNote that this term is the integral of a CDF function, which makes it likely that it is not finite.\n\n## Experiments\n\nThe numerical experiments are hard to understand.\nThe paper does not state the mathematical formulation of either problem, nor how instances are generated.\nThis makes it impossible to evaluate the soundedness of the experiments and the validity of the results.\n\nTSP instances\n* TSP instances with 100 cities are very small compared to state-of-the-art.\n\tInstances of that size can be solved exactly to global optimality on a phone using the free Concorde app.\n\tThe authors are encouraged to consider (much larger) instances from the TSPLib, aiming for at least tens of thousands of cities for hard-to-solve instances.\n* It is extremely hard to understand how TSP instances are generated, and what the parameters introduced in the paper translate to in the context of TSP instances."
            },
            "questions": {
                "value": "* The paper should explain how it differs from the (large) literature on robust optimization\n* Please provide a valid, self-contained definition of robustness for combinatorial optimization solvers.\n\tThe change in objective value from instance to instance is not an appropriate metric.\n* Numerical experiments should include a clear mathematical formulation of the problem at hand,\n\tas well as a complete description of the data distribution used to generate instances."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper describes an approach to certifying the robustness of parametrizable combinatorial optimization solvers with respect to certain kinds of perturbations of the solver's input. The perturbations are divided into two categories: binary, where a constraint is add/deleted, and tightness, where the constraint's bound is changed. \n\nThe paper states a definition of robustness certification for combinatorial optimization solvers, quantifying robustness in terms of the closeness of input instances. A randomized smoothing technique is used to robustify solvers. The output of these robust solvers is guaranteed to be close for any inputs that are close. \n\nThe paper presents a \"robustness enhancement method\" that works by searching for easy instances that are similar to the given instance. \n\nFinally, experiments are performed demonstrating aspects of the framework."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "While previous works have focused on the empirical evaluation of robustness for combinatorial optimization solvers, this paper provides a theoretically sound robustness certification guarantee, which is helpful when, for example, a priori guarantees are required. \n\nThe paper also describes a way of using this guarantee to enhance the robustness of solvers using a randomized smoothing technique. This is arguable the main contribution of the paper, as it gives a way of producing useable, provably robust solvers. \n\nThe paper is well-placed within the existing literature: randomized smoothing applied to make robustness guarantees for combinatorial optimization solvers."
            },
            "weaknesses": {
                "value": "- The definition of \"certified radius\" does not look like a definition to me. It is just an inequality. Is the certified radius the largest $\\delta$ that satisfies this inequality? \n\n- Line 186. \"finding the optimal solution $x$ for a given problem instance $Q$ is often NP-hard\". As stated, this is not correct. A solver that completely ignores its input and just always outputs $x$ returns the optimal solution for $Q$ in constant time, but of course this does not mean $P = NP$... The problem that is NP-hard is to find the optimal solution *for any* possible input. \n\n- Line 187: \"indicating that no polynomial-time algorithm exists to solve it.\" Assuming $P \\not= NP$... \n\n- Equation 4 defines the CDF for the cost $c(f_\\theta(Q), Q)$. Where is the randomness in the cost coming from? I would have thought it was over the choice of inputs $Q$, but in Theorem 4.1 the input $Q$ is taken as given and the cost still has a CDF? The source of the randomness needs to be made more clear. \n\n- Equation 5: Should $v$ be $u$?\n\n- The matrix $H_b$. I wonder if the authors could describe more generally how this matrix is built from the set of constraints. It is stated that \"1 signifies the presence of a constraint\", since this set is inherently linear. In the DAG example, the constraints are between two jobs, so a matrix is implied, but I cannot see how this would be so in general. \n\n- Equation 6: What part of this is the definition? It seems like $G_{H_b}$ is being defined in terms of $g_\\theta$ and/or $F_{H_b \\oplus z}$, but what are these? \n\n- Algorithm 1 and subsequent: $F_{H_b + z^{(j)}}$ should be an $\\oplus$? \n\n- Algorithm 1 is called \"Randomized Smoothing...\" but it outputs a number that is a distance. What has been smoothed? Shouldn't it output a smoothed/robust solver? \n\n- Robustness Enhancement Method (Algorithm 2 and Section 4.2): Why are we trying to find an easy instance? How does this enhance the robustness of the solver? This seems important and should be explained better. \n\n- Theorem 4.1: Is $G_{H_b}$ the smoothed CDF using a vector $z$ of Bernoulli($\\beta$) RVs? Why are we interested in bounding the distance between this smoothed distribution and the perturbed distribution $G_{H_b \\oplus \\delta_b}$? Don't we want to bound the distance with the actual cost distribution $F$? The preamble defines the cost CDF $F$, but then does not use it, so I suspect I am misunderstanding something...\n\n- Both Theorem 4.1 and 4.2 define $F(r)$, but then never use it. Is this intentional? \n\n- Why are absolute values taken of CDFs? Shouldn't they be non-negative anyway? \n\n- Experimental details are pushed to the Appendix, in particular results for the enhancement method for certified robustness. \n\n- In general, I am not sure I would describe the experiments as \"Extensive\" (line 105)...\n\n- The experiments vary $m$ and $\\beta$. If I were to use this robustness certification method in practice, how would I choose values for these parameters? \n\n- Figure 1: It is not clear to me what the denominator of the ratios is. What is SFT (line 431) and why is this the right normalizing baseline?\n\nSome minor issues not affecting my recommendation:\n\n- In text citation style is used where parenthesis citation style should be used. E.g., \"Previous studies Varma & Yoshida (2021); Geisler et al. (2021); Lu et al. (2023) indicate...\" -> \"Previous studies (Varma & Yoshida, 2021; Geisler et al., 2021; Lu et al., 2023) indicate...\"\n\n- Line 205 missing word? \"two distinct perturbation types that can...\"\n\n- Equation 5: I would use a naming convention that makes the connection between $\\mu$ and $C_1$, and between $\\nu$ and $C_2$, more clear.\n\n- Figure 1, y-axis label: radio -> ratio"
            },
            "questions": {
                "value": "See Weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the robustness of combinatorial optimization (CO) solvers. As claimed by the authors, previous work has not explored the certified robustness of CO solvers. In this work, they propose a definition of robustness certification for CO solvers, along with a method to improve both certified and empirical robustness. The authors conduct experiments to validate the effectiveness of their certification approach and enhancement method. They claim that their proposed framework addresses gaps in the existing literature regarding the certified robustness of combinatorial optimization solvers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is generally well-written, with clear explanations.\n\n2. This paper focus on framework studying, which is a foundational\u00a0work in the robustness of combinatorial optimization solvers.\n\n3. Experiments are conducted on the representative problems."
            },
            "weaknesses": {
                "value": "1. In Section 5.1, the solver selection criteria for the two representative problems are not consistent. The solver for DAG scheduling does not include SOTA solvers or learning methods.\n\n2. In the work of ROCO, an evaluation was conducted on the MC problem. Why this problem was not selected in this paper?"
            },
            "questions": {
                "value": "Please reply to my comments in \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Not applicable."
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}