{
    "id": "o2o1XNeI1b",
    "title": "FARM: Functional Group-Aware Representations for Small Molecules",
    "abstract": "We introduce Functional Group-Aware Representations for Small Molecules (FARM), a novel foundation model designed to bridge the gap between SMILES, natural language, and molecular graphs. The key innovation of FARM lies in its functional group-aware tokenization, which incorporates functional group information directly into the representations. This strategic reduction in tokenization granularity in a way that is intentionally interfaced with key drivers of functional properties (i.e., functional groups) enhances the model's understanding of chemical language, expands the chemical lexicon, more effectively bridging SMILES and natural language, and ultimately advances the model\u2019s capacity to predict molecular properties. FARM also represents molecules from two perspectives: by using masked language modeling to capture atom-level features and by employing graph neural networks to encode the whole molecule topology. By leveraging contrastive learning, FARM aligns these two views of representations into a unified molecular embedding. We rigorously evaluate FARM on the MoleculeNet dataset, where it achieves state-of-the-art performance on 10 out of 12 tasks. These results highlight FARM\u2019s potential to improve molecular representation learning, with promising applications in drug discovery and pharmaceutical research.",
    "keywords": [
        "Molecular representation learning",
        "Masked language modeling",
        "Contrastive learning"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "This paper presents FARM, a model that enhances small molecule representation by integrating functional module-aware tokenization with masked language modeling and graph neural networks, achieving state-of-the-art performance on MoleculeNet.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=o2o1XNeI1b",
    "pdf_link": "https://openreview.net/pdf?id=o2o1XNeI1b",
    "comments": [
        {
            "summary": {
                "value": "The manuscript introduces FARM (Functional Group-Aware Representations for Small Molecules), which seeks to enhance molecular representation learning by integrating functional group (FG) information into SMILES and graph-based representations. The core innovation lies in FG-aware tokenization and the use of contrastive learning to align these sequence- and graph-based molecular representations. The paper reports that FARM outperforms existing models on the MoleculeNet dataset across 10 of 12 tasks, showcasing potential in drug discovery and cheminformatics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The model's performance on diverse tasks from the MoleculeNet benchmark and comparisons with state-of-the-art methods provide robust evidence for its efficacy.\n- The paper does an excellent job explaining the FG detection, tokenization process, and integration of representations through contrastive learning. The use of a functional group knowledge graph adds depth to the model's structure-learning capabilities.\n- The tables show clear improvements over existing models in both classification and regression tasks, indicating that the incorporation of functional group information yields substantial benefits."
            },
            "weaknesses": {
                "value": "- The increase in tokenization granularity from 93 to 14,741 tokens could be seen as excessive, leading to training inefficiencies. While the authors acknowledge this, a deeper discussion on the trade-offs and potential mitigation strategies (e.g., pre-training optimizations) would enhance the paper.\n- The absence of 3D information limits the model\u2019s capacity to handle stereochemistry and spatial effects, which are crucial in many chemical tasks. The authors mention this as a future direction, but its exclusion remains a significant limitation.\n- The paper briefly mentions augmentations for negative samples in contrastive learning, such as node deletion and swapping. A more detailed exploration of the impact of these strategies would provide clarity on their contribution to performance.\n-  The paper does not sufficiently address the computational requirements of training FARM, given the added complexity from FG-aware tokenization and knowledge graph embeddings.\n- The novelty is also a bit limited since similar methods based on functional groups have been well-explored in previous studies [1,2,3,4,5,6].\n\n[1] Fang Y, Zhang Q, Zhang N, et al. Knowledge graph-enhanced molecular contrastive learning with functional prompt[J]. Nature Machine Intelligence, 2023, 5(5): 542-553.\n\n[2] Sun M, Xing J, Wang H, et al. MoCL: data-driven molecular fingerprint via knowledge-aware contrastive learning from molecular graph[C]//Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining. 2021: 3585-3594.\n\n[3] Xie A, Zhang Z, Guan J, et al. Self-supervised learning with chemistry-aware fragmentation for effective molecular property prediction[J]. Briefings in Bioinformatics, 2023, 24(5): bbad296.\n\n[4] Collins E M, Raghavachari K. A fragmentation-based graph embedding framework for QM/ML[J]. The Journal of Physical Chemistry A, 2021, 125(31): 6872-6880.\n\n[5] Wang Y, Magar R, Liang C, et al. Improving molecular contrastive learning via faulty negative mitigation and decomposed fragment contrast[J]. Journal of Chemical Information and Modeling, 2022, 62(11): 2713-2725.\n\n[6] Kim S, Nam J, Kim J, et al. Fragment-based multi-view molecular contrastive learning[C]//Workshop on''Machine Learning for Materials''ICLR 2023. 2023."
            },
            "questions": {
                "value": "I think the main issue is the experiment section is too short without any in-depth analysis and discussion. The authors should continue adding content and polishing this section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "### Summary of the Paper\n\nThis paper explores methods for enhancing small molecule representation by integrating functional group information. A rule-based approach is applied to identify significant functional groups within small molecule databases, and this information is subsequently incorporated into SMILES strings. The representation of functional groups is learned through knowledge graphs that capture relationships between functional groups and their properties. The final representation is achieved using contrastive learning, where the SMILES representation is aligned with the functional group-enhanced SMILES. The authors report that their approach yields significant improvements compared to other functional group-based methods on MoleculeNet benchmark datasets.\n\nOverall, the paper is well-written and presents a novel approach. However, I have several concerns regarding the benchmarks used, inconsistencies in split reporting, and the generalization of rule-based methods for identifying functional groups, as well as the construction of knowledge graphs for functional group embeddings. Detailed comments for improving the paper are provided below."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The idea of incorporating inductive bias by using functional groups to enhance small molecule representation is intriguing. The experiments include comparisons with various existing baselines that also leverage functional groups, and the results appear promising\u2014assuming that the splits and MoleculeNet dataset variants are consistent with those reported in prior work."
            },
            "weaknesses": {
                "value": "**MAJOR Concern 1**\n\nThe use of splits in the MoleculeNet datasets is inconsistent with the original MoleculeNet recommendations. Specifically, random splits are recommended for regression tasks such as ESOL, Lipophilicity, and FreeSolv. In this paper, the authors do not consistently clarify the splits used; for example, scaffold splits are mentioned in the appendix, but captions for Tables 7 and 8 indicate random splits. \n\nA significant challenge with MoleculeNet is the absence of a leaderboard with predefined splits, leading researchers to create custom splits, and sometimes even modify the original datasets, as seen in modifications to ESOL and FreeSolv in cases like [this issue](https://github.com/IBM/molformer/issues/9). This issue may reflect the use of dataset variants such as those described in [this study](https://www.nature.com/articles/s42256-022-00580-7.epdf?sharing_token=p5m9Z0797IQeBDOiMGn71dRgN0jAjWel9jnR3ZoTv0MeIJPs9pbG9QLaEN_McFTR3KHv1tHh1FDNJB4ZuILdAmRtINVn6KqXrLkPhEiAZW5mM0dWWKSmPk82eibEUBx01sLTSHx6w903cDaUoXg9lAGzcHY_ifmakrBcIzUUDwI%3D).\n\nThe existence of multiple dataset versions and split schemes makes it difficult to accurately assess improvements toward state-of-the-art (SOTA) results, as subsequent studies often cite results without clarity on splits used. For instance, in *\"SELF-BART: A Transformer-based Molecular Representation Model using SELFIES\"* (NeurIPS 2024, AI4Mat, [link](https://arxiv.org/abs/2410.12348)), the reported MoleculeNet performance is challenging to compare with this paper due to inconsistent dataset versions and splits.\n\nI recommend the authors:\n1. Provide consistent results using the original splits recommended by MoleculeNet.\n2. Conduct additional experiments on the TDC ADMET groups (https://tdcommons.ai/benchmark/admet_group/overview), which offer leaderboards and fingerprint-based baselines. TDC ADMET provides consistent splits, making future comparisons easier.\n\n\n\n**MAJOR Concern 2**\n\nIn the paper, the authors propose methods for FG-aware tokenization and fragmentation. Functional groups are identified based on known conventional groups or potentially using domain knowledge to define new groups. However, the set of rules for identifying new functional groups appears limited, raising questions about their generalizability. How do these rules compare to frequent subgraph mining, a widely-used technique in graph mining, where common subgraphs are often predictive features for small molecules?\n\n\n**MAJOR Concern 3**\n\nThe use of a functional group knowledge graph to learn functional group embeddings is innovative, but some relationship types might provide an unfair advantage over other methods. For example, including properties like water solubility or lipophilicity (logP) could yield better results on downstream tasks related to those specific properties. It would be beneficial to assess the impact of removing such information from the knowledge graph to determine if the observed improvements are primarily due to these additional properties, which are not considered in other methods."
            },
            "questions": {
                "value": "Please see the questions in the Weakness section of the review."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents Functional Group Aware Representations for Small Molecules (FARM), pre-trained foundation model that incorporates functional group tokenization, fragmentation, and knowledge graph-based structural representation learning. Moreover, this work integrates the atom-feature and structural representation by contrastive learning, which results in achieving the SOTA results in MoleculeNet dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The figures are neat, and the clear writing enhances the comprehensibility of the paper, making it easy to follow.\n- This paper highlights the importance of functional groups, which are often overlooked in many molecular foundation models, and effectively integrates these functional groups into the molecular foundation model.\n- The analysis presented in the paper, including the knowledge graph embedding space, substitution of functional groups, and visualization of attention maps, enriches the understanding of the method\u2019s contributions."
            },
            "weaknesses": {
                "value": "- The approach is quite similar to existing motif-based tokenization and fragmentation methods. While the authors define functional groups in terms of functional groups and fused ring systems, these could typically be identified through standard fragmentation tasks. An ablation study comparing FARM with other fragmentation methods would clarify its advantages. If applied under the same training conditions, does FARM demonstrate superiority?\n- This work heavily relies on fused ring systems, which constitute over 99% of the identified functional groups. This raises concerns, as ring systems are generally not classified as functional groups. The paper emphasizes functional groups as the main contribution, as suggested by the method\u2019s name. If ring systems are excluded, does the method still show superior performance?\n- The naming process for fused ring systems seems to overlook bond types, considering only ring indices and sizes. However, bond types, including single and aromatic bonds, are crucial for understanding the ring system. How are these bond types accounted for in the analysis?\n- The limitations of related works that address functional groups are unclear. The authors state that previous works \u201cdo not extend to detecting more complex functional groups, such as ring systems.\u201d However, RDKit can identify ring systems, and simple IUPAC transformations could be applied to adapt this information for earlier works."
            },
            "questions": {
                "value": "- Which functional group detection algorithm is employed? The paper lacks a description of the algorithm that traverses the graph to identify functional groups, which is critical for the method. For instance, there should be clear priorities among functional groups to consistently identify intersected atoms across different functional groups.\n- In functional graph generation, what happens if the graph cannot be represented as a linear graph? Specifically, the node perturbation process in augmentation may be unclear. For example, if a functional group graph forms a triangle (a-b-c), the node perturbation could result in the same functional group graph, potentially generating incorrect negative samples.\n- In Figure 5, how do the removals of multiple functional groups and single functional groups yield parallel results? For instance, the orange molecule has three functional groups removed, while the green molecule has only one removed, yet both show similar results.\n- In the knowledge graph construction, how are continuous values such as LogP discretized? The original continuous values may not correlate with other functional groups.\n- Will this approach be effective for generation tasks? A simpler generation task compared to SMILESLSTM could strengthen the contribution.\n- Why does Figure 5(b) depict the link prediction performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes FARM, a functional group-aware representations for small molecules. The authors suggest to learn molecular representations via contrastive learning based on SMILES and graph information of molecules. Firstly, a string-based model and a graph-based model learn molecular representations with MLM objective and KG-graph/link prediction objectives, respectively. Then, contrastive objective is applied between two models."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The problem of interest, molecular property prediction, is important for real-world applications, e.g., drug discovery.\n\n- Utilizing functional groups is chemically reasonable, since molecular properties are highly related to functional groups."
            },
            "weaknesses": {
                "value": "- Lack of novelty.\n\nUsing functional groups in molecular representation learning has already been investigated by many works. Also each component of the framework, e.g., MLM, link prediction, and contrastive loss, has also been widely investigated. I could not find new (or novel) components in the overall framework.\n\n---\n- Imprecise motivation on contrasive learning.\n\nThe motivation of this work is vague. SMILES and graph of molecules contain the same information of molecule, i.e., a molecule can be reconstructed from both SMILES and graph. Why should we deal with them both instead of focusing on a single representation (SMILES or graph)? Since this paper strongly insist that they learn \"chemically plausible\" representation, this choice should be \"chemically\" justified (I know that the language model and the graph model may learn different features of molecules, but it is not a \"chemical\" motivation).\n\n---\n- Misclaim \"L71: Our approach overcomes these limitation ...\"\n\nThe proposed approach cannot overcome \"3D coordinates\" (L66) and \"long-range dependencies\" (L68). This method does not deal with 3D coordinates nor long-range dependencies.\n\n---\n- Complexity of method.\n\nThis work combines several objectives, e.g., link prediction, contrastive and MLM loss. However, the impact of each component is not thoroughly investigated. Furthermore, such complex objective introduces several hyper parameters and makes the training unstable."
            },
            "questions": {
                "value": "1. Why ToxCast is excluded in MoleculeNet experiments?\n\n2. In my previous experiences, 3 seeds in MoleculeNet experiments are not enough due to very high variance. I suggest to report the results based on (at least) 10 seeds.\n\n3. The authors train two models (language and graph). Which model is used in the fine-tuning phase?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}