{
    "id": "eE2PXlNydB",
    "title": "Learning Clustering-based Prototypes for Compositional Zero-Shot Learning",
    "abstract": "Learning primitive (i.e., attribute and object) concepts from seen compositions is the primary challenge of Compositional Zero-Shot Learning (CZSL). Existing CZSL solutions typically rely on oversimplified data assumptions, e.g., modeling each primitive with a single centroid primitive presentation, ignoring the natural diversities of the attribute (resp. object) when coupled with different objects (resp. attribute). In this work, we develop ClusPro, a robust clustering-based prototype mining framework for CZSL that defines the conceptual boundaries of primitives through a set of diversified prototypes. Specifically, ClusPro conducts within-primitive clustering on the embedding space for automatically discovering and dynamically updating prototypes. To learn high-quality embeddings for discriminative prototype construction, ClusPro repaints a well-structured and independent primitive embedding space, ensuring intra-primitive separation and inter-primitive decorrelation through prototype-based contrastive learning and decorrelation learning. Moreover, ClusPro effectively performs prototype clustering in a non-parametric fashion without the introduction of additional learnable parameters or computational budget during testing. Experiments on three benchmarks demonstrate ClusPro outperforms various top-leading CZSL solutions under both closed-world and open-world settings. Code will be released.",
    "keywords": [
        "Compositional Zero-Shot Learning",
        "Prototype Learning",
        "Representation Disentanglement"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We propose a clustering-based prototype mining framework for compositional zero-shot learning, which defines conceptual boundaries of primitives through a set of diversified prototypes, and automatically discovers these prototypes via clustering.",
    "creation_date": "2024-09-16",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=eE2PXlNydB",
    "pdf_link": "https://openreview.net/pdf?id=eE2PXlNydB",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a clustering-based prototype mining framework namely CLUSPRO, for Compositional Zero-Shot Learning. \nSpecifically, it considers within-primitive online clustering for automatically discovering and dynamically\nupdating prototypes. Besides, it models prototype-based primitive representation learning for promoting intra-primitive separation and inter-primitive decorrelation. Experimental results on three datasets demonstrate the superiority of the proposed method against existing methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Overall, the paper is well written and easy to follow.\nThe motivation behind addressing CZSL is clear and convincing.\nThe technical contributions are solid and novel.\nThe algorithm details are well provided and it should be possible to reproduce the results reported in the paper."
            },
            "weaknesses": {
                "value": "Figure 2 shows  the clustering-based prototype mining framework, while it is still unclear about the whole pipeline for CZSL. It is encouraged to introduce the complete network architecture in the main paper or supplementary material. It will be help to understand why the proposed method can achieve new state-of-the-art performance.\n\nIn the experiments, it is concerned about why all the compared methods including CLUSPRO employ the same ViT backbone,\nto avoid the unfair comparisons between ViT-B and ViT-L. \n\nIt is interesting to know more details about the baseline model, including network structure and training loss."
            },
            "questions": {
                "value": "see the weaknesses above please."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper reveals that exsiting compositional zero-shot learning (CZSL) methods only consider an isolated centroid for each primitive, ignoring rich and diverse intra-primitive patterns. To address this, the authors propose a clustering-based method CLUSPRO to learn a well-structured and independent embedding space with multiple discriminative prototypes for each primitive, thus improving CZSL. Specifically, CLUSPRO alternates between two steps: 1) performing within-primitive online clustering to automatically discover and dynamically update prototypes, and 2) using prototype-based primitive representation learning to encourage intraprimitive separation and inter-primitive decorrelation."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper is well-motivated, highlighting that a single centroid primitive representation demonstrates limited tolerance to intraprimitive variance.\n- The proposed method CLUSPRO is reasonable and has a good performance across three benchmarks under both closed-world and open-world settings.\n- The authors present a comprehensive analysis of their method CLUSPRO."
            },
            "weaknesses": {
                "value": "- My major concern is the number of prototype. In the experiments, the number of prototypes $K$ is empirically set to 5, which may not ne a good strategy. Additionally, using the same number of prototypes for all attributes seems unreasonable. Are there any automatic methods for discovering prototypes, thus mitigating the need for manually setting this number?\n- Does performing clustering on the entire dataset will face resource limitations when dealing with very large datasets?"
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes clustering-based method for compositional zero-shot learning.\nSpecifically,"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Clear presentation"
            },
            "weaknesses": {
                "value": "Major problem:\n\nProblem1. The definition of Compositional Zero-shot Learning (CZSL) is not correctly used.\nThe authors mentioned CZSL requires the model to recognize unseen compositions without additional training data, but in your method, you use pretrained CLIP trained by large-scale dataset: CLIP is trained from millions text-image pairs from web.\nIn other word, all your claimed unseen compositions are seen by CLIP actually.\nThus, a key question is emerged: if your visual&text encoders never meet your test compositions, can the seen and unseen compositions be seperated?\nPlease provide the results that using other visual&text encoders or using vision-language models whose pretrained training datasets have no overlap with the evaluted datasets.\n\nProblem2. Besides, in the original paper of CLIP, it has clearly claimed they changed the definition of ZSL from class-level to dataset-level. \"In computer vision, zero-shot learning usually refers to the study of generalizing to unseen object categories in image classification (Lampert et al., 2009). We instead use the term in a broader sense and study generalization to unseen datasets.\" \ufeff This excerpt is from Section 3.2 of the CLIP paper. There is a significant gap between CLIP\u2019s definition of zero-shot learning and the CZSL task you are addressing, which still focuses on classifying unseen composition categories. This difference is substantial and cannot be overlooked.\n\nIn a short, I suggest the proposed method is a transductive classification method insteat of ZSL method actually since the pre-trained CLIP have been exposed to numerous unseen composition samples.\n\nProblem3. \nYou only compare your method to CLIP-based CZSL methods, but there are many methods that do not use CLIP.\nI know those non-CLIP methods perform worsely than CLIP-based methods.\nBut, as I said in Problem1&2, since CLIP have been exposed to numerous unseen composition samples, the experiments are extramely unfair for other non-CLIP SOTAs.\n\nProblem4. Why only consider the diversities of the attribute, but do not for the objects?"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The paper uses a large-scale pretrained visual-language model CLIP. Thus, the bias problem must be considered."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a clustering-based prototype mining framework for CZSL which conducts within-primitive clustering on the embedding space for automatically discovering and dynamically updating prototypes. These representative prototypes are subsequently used to repaint a well-structured and independent primitive embedding space, ensuring intra-primitive separation and inter-primitive decorrelation through prototype-based contrastive learning and decorrelation learning. Experiments on three benchmarks demonstrate CLUSPRO outperforms top-leading CZSL solutions under both closed-world and open-world settings."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Overall this paper is well-written and is easy to understand.\n- The motivation is reasonable and the proposed framework is a little novel for CZSL.\n- The CLUSPRO outperforms top-leading CZSL solutions under both closed-world and open-world settings on three benchmarks."
            },
            "weaknesses": {
                "value": "- There is a lack of discussion and citation of some related works. In ZSL/CZSL fields, prototype learning is wide adopted in the works [A][B]. The Local-aware Prototype Assignment module is also similar to the previous work [C], but the necessary discussion is absent.\n\n- The overall novelty is limited. The Local-aware Prototype Assignment technique is adopted in the work [C], and the Prototype-based Contrastive Learning have been used in previouse works (e.g., [A]).\n\n- Writing of Chapter 3.3 could be improved. The authors do not make it clear how the K prototypes are obtained. With reference to the context, is it means k-means clustering results on visual fetaures?  In addition, when the variable notations appear for the first time, the authors should give an obvious comment (e.g., $n$ in $f_{n}$) for reducing ambiguity.\n\nI will consider updating the score if the authors can address my concerns well.\n\n[A] ProtoCLIP: Prototypical Contrastive Language Image Pretraining \n\n[B] Dual progressive prototype network for generalized zero-shot learning\n\n[C] Rethinking semantic segmentation: A prototype view"
            },
            "questions": {
                "value": "In the Prototype-based Contrastive Learning, the strategy encourages each primitive feature $f_n$ to\nbe similar to its assigned prototype $P+$ and dissimilar to all other $K(M+N)\u22121$ irrelevant prototypes\n$P-$. It means that the $K-1$ prototypes belonging to the same primitive but with different assignments are treated as negative samples in the same way as prototypes  $K(M+N-1)$ of other primitives. \nDoes this have a  impact on representation learning?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}