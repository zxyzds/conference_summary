{
    "id": "KEqerdxOBG",
    "title": "MRFNet: Multi-Receptive Field  Network for Multivariate Time-Series Prediction",
    "abstract": "Time series forecasting is a critical topic in machine learning. Although existing deep learning methods have demonstrated outstanding performance and currently dominate this field, the latest state-of-the-art (SOTA) models are increasingly encountering the same limitations: the blockneck of performance. We believe this convergence is due to these models being based on the same mathematical foundations. To address this issue, we draw inspiration from the universal approximation theorem (UAT) and show that most commonly used deep learning models for time series forecasting are specific implementations of UAT. Based on UAT theory and the characteristics of time series data, we propose a new forecasting model called the Multi-Receptive Field Network (MRFNet). This architecture integrates linear, sparse matrix, convolutional, and Fourier transform modules, resulting in an interpretable model with multiple receptive fields that can capture both global and local information. The MRFNet model has been tested extensively on several popular time series forecasting datasets and has achieved superior results.",
    "keywords": [
        "time series forecasting"
    ],
    "primary_area": "learning on time series and dynamical systems",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=KEqerdxOBG",
    "pdf_link": "https://openreview.net/pdf?id=KEqerdxOBG",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces MRFNET \u2014 a new architecture for long sequence time series forecasting, using a mixture of linear, sparse matrix, convolutional, and Fourier blocks. They also express CNNs and transformers in matrix vector form, providing a more direct link to the universal approximation theorem."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "While transformer based forecasting models have demonstrated large improvements in Long Sequence Time Series Forecasting (LSTF) tasks, improvements have largely been empirical in nature \u2014 with little formal analysis to understand the inner workings of the models."
            },
            "weaknesses": {
                "value": "However, I do have some fundamental concerns surrounding the motivations of the paper itself.\n\nFirstly, while universal approximation is the cornerstone of function approximation and that building blocks (FFNs, CNNs, transformers) can be expressed in UAT form -- the inductive biases provided through architecture (and how they are aligned with data characteristics) can make a big impact on performance. This has been seen frequently outside of time series datasets (e.g. transformers for LLMs, CNNs for computer vision), and also in the way deep neural networks have evolved beyond simple MLPs (which are also universal function approximators) . As such, the conjecture that performance bottlenecks are due to limitations under UAT would require a lot more evidence than supplied in the paper.\n\nSecondly, assuming this is the case, it is not immediately clear how/why the architecture allows MRFNET to overcome the performance limitations described. Furthermore, the building blocks described have all been utilised in other forecasting architectures, so it would also be important to describe why the current configuration is expected to improve performance."
            },
            "questions": {
                "value": "1. Is MRFNet a UAT based, and if not how is it different and how do differences result in performance improvements?\n2. Are there any concrete examples of a purely cnn-based time series forecasting model bottle necking at the same performance as a similar transformer-based model? Would we expect the performance of a simple CNN/naive Transformer model to match PatchTST?\n3. How significant are performance improvements over PatchTST (e.g. confidence intervals around improvements)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "## Summary of the Paper\nThe paper introduces MRFNet, a multivariate time-series forecasting model designed to capture patterns by integrating four components: linear, convolutional, sparse matrix, and Fourier transform blocks."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "## Strong Points\n1.\t**Clear Presentation**\nThe paper is well-organized, making it easy to follow the transition from problem statement to proposed solution. \n2.\t**Introduction of UAT to Time-Series Forecasting**\nThe application of the Universal Approximation Theorem (UAT) in time-series forecasting adds an interesting theoretical perspective."
            },
            "weaknesses": {
                "value": "## Weak Points and Concerns\n1.\t**Insufficient Experiment Details and Missing State-of-the-Art References (Ref 1 and Ref 2 below)**\nThe experimental setup lacks details, such as the size of weight matrices, learning rates, training epochs, and batch sizes, which are essential for reproducibility. This missing information makes it difficult to replicate the experiments or understand how hyperparameter choices might affect the results. Additionally, comparisons with recent state-of-the-art methods are absent. \nThe improvement seems marginal. \n \nRef 1 (ICML 2024): SparseTSF: Modeling Long-term Time Series Forecasting with 1k Parameters \nhttps://arxiv.org/pdf/2405.00946\nRef2 (ICLR 2024) :CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting\nhttps://openreview.net/pdf?id=MJksrOhurE\n\n2.\t**Lack of Motivation for Selecting the Four Specific Blocks**\nWhile MRFNet includes linear, convolutional, sparse matrix, and Fourier transform modules, there is no clear justification of using these four components over others. \n \n3.\t**Limited Theoretical Justification for UAT Application**\nAlthough UAT is referenced as a motivating factor, the paper does not fully explain how each component in MRFNet contributes to leveraging UAT in time-series forecasting. This weakens the theoretical foundation."
            },
            "questions": {
                "value": "## Questions for Authors\n1.\tCan you provide more details on the experiment setup, specifically weight matrix sizes, learning rates, and training epochs?\n2.\tWhat motivated the selection of these four specific modules? Could alternative components potentially yield similar or improved results?\n3.\tHow does MRFNet compare with recent state-of-the-art methods in the references?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "MRFNet is a novel multivariable time series prediction model, which is designed based on universal approximation theorem (UAT) and integrates linear, sparse matrix, convolution and Fourier transform modules. The model performs well on multiple popular data sets and achieves better prediction performance. The study also found that current state-of-the-art time series prediction models tend to have similar performance bottlenecks because they share the same mathematical foundation. MRFNet provides a new perspective to understand and improve time series forecasting by capturing both global and local information."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The MRFNet model combines multiple deep learning techniques, including linear, convolution, and Fourier transform, to accommodate the complexity of time series data. The design is based on the general approximation theorem, which ensures that the model can capture global and local information and improve the prediction accuracy."
            },
            "weaknesses": {
                "value": "MRFNet's module consolidation, while enhancing model functionality, is limited in innovation and relies primarily on a portfolio of existing technologies. This increases the complexity of the model."
            },
            "questions": {
                "value": "1. Capturing global and local features seems to be widely studied, so please identify the innovations in this article\n[1] Dai, T., Wu, B., Liu, P., Li, N., Bao, J., Jiang, Y., & Xia, S. T. (2024). Periodicity decoupling framework for long-term series forecasting. In The Twelfth International Conference on Learning Representations.\n2.MRFNet has limited performance improvements on some datasets. Do authors think this is mainly due to data characteristics or limitations of the model itself?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper is inspired by the universal approximation theorem (UAT) to solve the time-series forecasting problem. It shows that most time-series forecasting models can be expressed in the matrix-vector form thus satisfying the UAT. It also proposes the multi-receptive field network (MRFNet) for time-series forecasting problems. MRFNet consists of four blocks linear, sparse matrix, convolutional and Fourier transform blocks claimed to be interpretable and to capture both global and local information."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) The problem of time-series forecasting is important because it has many real-world applications.\n2) the concept of universal approximation theorem is theoretically sound."
            },
            "weaknesses": {
                "value": "Motivation \n\nmotivation of this work is rather unclear. It does not point out a specific issue to be addressed in the paper. Rather, the use of UAT is a common issue. In addition, please clarify the fact that neural network is a universal approximator. On the other hand, there is no figures at all justifying the motivation of this paper. \n\nLiterature Survey\n\nliterature review is rather outdated. There are more recent works uncovered in the literature survey.\n\nNovelty \n\nThe novelty of this work might be rather limited because the UAT2LLM has proved the uat of the transformer network.\n\nExperiments\n\n1) Numerical results are not convincing. The performance differences are very small such that it is not conclusive to say that the MRFNET is better than other methods.\n\n2) Statistical tests need to be conducted to understand whether the performance differences are statistically significant or not.\n\n3) Complexity analysis is absent. It is interesting to know the complexity of the proposed method compared to SOTA algorithms.\n\nConclusion\n\nlimitation of this method should be discussed in the conclusion section."
            },
            "questions": {
                "value": "1) I wonder the complexity of the proposed method. \n2) I wonder the novelty of this paper provided that the UAT of various modules of neural networks have existed in the literature."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}