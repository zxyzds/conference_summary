{
    "id": "qucdAPZfar",
    "title": "Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemmanian Geometry Finds It",
    "abstract": "The concept of sharpness has been successfully applied to traditional architectures like MLPs and CNNs to predict their generalization.\n  For transformers, however, recent work reported weak correlation between flatness and generalization. We argue that existing sharpness measures fail for transformers, because they have much richer symmetries in their attention mechanism that induce directions in parameter space along which the network or its loss remain identical.\n  We posit that sharpness must account fully for these symmetries, and thus we redefine it on a quotient manifold that results from quotienting out the transformer symmetries, thereby removing their ambiguities.\n  Leveraging tools from Riemannian geometry, we propose a fully general notion of sharpness, in terms of a geodesic ball on the symmetry-corrected quotient manifold. In practise, we need to resort to approximating the geodesics. Doing so up to first order yields existing adaptive sharpness measures, and we demonstrate that including higher-order terms is crucial to recover correlation with generalization.\n  We present results on diagonal networks with synthetic data, and show that our geodesic sharpness reveals the correlation for real-world transformers on ImageNet.",
    "keywords": [
        "generalization",
        "symmetry",
        "sharpness",
        "flatness",
        "riemannian geometry",
        "loss landscape"
    ],
    "primary_area": "learning theory",
    "TLDR": "We introduce a new, geodesic-based sharpness that can operate on a quotient manifold where neural network parameter symmetries have been factored out, revealing strong correlation with generalization in transformers.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=qucdAPZfar",
    "pdf_link": "https://openreview.net/pdf?id=qucdAPZfar",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a more general notion of sharpness measurement based on a geodesic ball on the symmetry-corrected quotient manifold, which accounts for the symmetry equivalence of the original network. Experiments with Diagonal Networks on synthetic data and transformers on the ImageNet dataset show that Geodesic Sharpness has a stronger correlation with the model\u2019s generalization performance compared to Adaptive Sharpness."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper introduces a novel approach to sharpness by leveraging quotient manifolds, reflecting the symmetry of the parameter space. This effectively addresses a gap in previous work that has not considered network symmetry.\n- The methodology is theoretically well-founded, employing tools from Riemannian geometry to incorporate network symmetry to the sharpness measure in a principled way.\n- Geodesic sharpness is shown to achieve a higher Kendall Tau correlation with the relevant metrics than Adaptive sharpness in both synthetic and ImageNet experiments."
            },
            "weaknesses": {
                "value": "The experimental section should be strengthened. Assessing the correlation between the proposed sharpness and the generalization of transformers trained on other tasks, such as time series forecasting or language modeling, would further support the findings."
            },
            "questions": {
                "value": "- Could you include additional experiments on real-world data beyond vision transformers? This would enhance the experiment effectiveness and demonstrate the predictive capacity of the proposed Geodesic sharpness across a broader range of tasks.\n- Could you provide a time complexity analysis of the proposed method relative to Adaptive sharpness?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method for measuring the sharpness of neural networks, called geodesic sharpness, which takes into account the symmetries present in the network architecture. The authors argue that previous sharpness measures fail to accurately capture the sharpness of transformers because they do not account for the rich symmetries present in the attention mechanism. The authors clearly motivate the need for a new sharpness measure that is invariant to these symmetries. However, the paper need to be polished more to fix typo and clearer explanation, especially experiments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "From theoretical aspects, the authors' main theoretical contribution is the application of Riemannian geometry to the study of neural network parameter space symmetry. They propose to use the geometry of the quotient manifold, which is obtained by removing the symmetries from the parameter space, to define a sharpness measure that is invariant to these symmetries. This approach is general and can be applied to a wide range of symmetries. The authors show that ignoring the curvature introduced by the symmetries leads to traditional adaptive sharpness measures. \n\nFrom experiment aspects, yo validate their approach, the authors conduct experiments on both synthetic and real-world data. They analytically derive the geodesic sharpness for diagonal networks and show that it correlates strongly with generalization. They also apply their method to large vision transformers and find that geodesic sharpness has a stronger correlation with generalization than any previously reported measure, both for in-distribution and out-of-distribution settings.\n\nThe main strength of the paper is its novel and principled approach with the use of Riemannian geometry to account for symmetries in sharpness measures, which can apply to more problem like equivariant neural functional network."
            },
            "weaknesses": {
                "value": "The paper, while presenting a promising theoretical approach to measuring sharpness, suffers from certain shortcomings related to the experimental validation of the proposed method and the potential computational cost involved:\n\n-   **Limited empirical support:** The experiments conducted on real-world transformers lack breadth.It would be good if the authors can demonstrated in the natural language task too, like language modeling with wikitext103.\n\n-   **Effect of assumptions:** The paper makes an assumption regarding the full column rank of weight matrices in attention layers. A relaxation parameter is introduced to handle potential violations of this assumption, but the impact of this parameter on the results is not thoroughly investigated.\n\n-   **Computational burden:** The paper acknowledges the potential computational demands of calculating geodesic sharpness, especially for large models. However, it lacks a detailed analysis of the computational cost, including aspects like time complexity, memory requirements, and actual runtime measurements. Such an analysis would enable a better understanding of the feasibility of employing geodesic sharpness in practical scenarios, particularly when dealing with large-scale models.\n\nAddressing these weaknesses would bolster the paper's contributions and enhance the understanding of the interplay between sharpness and generalization in the context of transformer models. I willing to increase the score more if the authors can provide more convincing analysis on these weaknesses."
            },
            "questions": {
                "value": "1. \"RIEMMANIAN\" -> \"RIEMANNIAN\" in title\n2. \",and\" -> \", and\" in line 39\n3.  In my opinion, the contributions can be collated, where (b)-(c) and (d)-(e)-(f) are collated into two contributions: the development of geodesic sharpness and experiments for it.\n4. Diagonal network experiment:  it is not clear to me what Figure 3 is showing. What is the meaning of the x axis and y axis? What is the ideal result? Why only show 50 data points when you have 200 model trained? Why the points in adaptive average case aligned in different direction in comparison with two other cases? I suggest adding more detailed captions and axis labels to Figure 3, and include explanations for these points in the corresponding text.\n5.  Assumption 5.1: Does Assumption 5.1 are too strong? What if the assumption is violated? Can we still calculated the result but with wrong value, or not able to calculate it at all? It would be good if the author can provide the evident and explanation of effect of adding $\\epsilon I_h$ into $GH$ since there have not any for the assumption. Also, including a discussion of the implications of violating Assumption 5.1 and provide empirical evidence for the effects of adding the $\\epsilon I_h$ term.\n6. Can the authors describe in detail how you treat the multi-layer schema of transformers model? It is not clear at this time. It would be good if the author can provide the diagram illustrating the approach for multi-layer transformers.\n7. Experiment diversity: it would be good if we can demonstrated in the natural language task too, like language modeling with wikitext103, to ensure that it works across domains.\n8.  In order to find the geodesic approximation, you need to solve the optimization using SGD, what is the quantitative performance, i.e. wall clock time or time/memory complexity of this approach in comparison with adaptive sharpness? How does it scale with large models like LLMs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces a new approach to measuring model sharpness using Riemannian geometry. This approach takes into account the symmetries in model parameters, removing ambiguities that these symmetries can cause. As a result, it provides a clearer and more reliable sharpness measure compared to previous methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This work takes a broader view of parameter symmetries and introduces a more robust metric for measuring sharpness.\n\n2. The theoretical framework and assumptions are well-grounded, and the experimental results are both strong and consistent."
            },
            "weaknesses": {
                "value": "1. $\\textbf{Geodesic sharpness}$ in section 5.2 is abbreviated. Providing a clear, explicit formula for geodesic sharpness would improve comprehension.\n\n2. The discussion of geodesic sharpness in transformers (Section 5.3) is brief. Including a description of geodesic sharpness for transformers, or a brief explanation of how adaptive sharpness could be applied to each layer, would make the analysis more thorough.\n\n3. The paper aims to propose a metric that surpasses previous methods. Therefore, I would expect comprehensive experimental results demonstrating both the effectiveness of the proposed approach and its superiority over existing methods. While the experiments provide sufficient evidence of the method\u2019s effectiveness, the comparative analysis with previous methods seems limited.\n\nMinor points:\n\n$\\bullet$ Example 3.2 \"(Self-attention Vaswani et al. (2017))\" $\\to$ \"Example 3.2 (Self-attention (Vaswani et al., 2017))\".\n\n$\\bullet$ $\\textbf{Geodesics}$ in section 5.2: \"... the geodesics of metric 15\" $\\to$ \"... the geodesics of metric (15)\"."
            },
            "questions": {
                "value": "1. In Case A), the second-order term in Equation (12) is omitted because it is considered small compared to the first-order term. However, I wonder if this omission might be overly convenient. Since there is no indication of how small $\\rho$ can be, I\u2019m unsure about the relative scale of the first and second orders. Would it be possible to retain the second-order term and, perhaps, combine the results of both cases to reach the conclusion?\n\n2. Could you provide further clarification on why \"adaptive sharpness is more appropriate\" in Section 5.3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel analysis of sharpness in machine learning, with a particular focus on its implications for generalization. The authors argue that existing sharpness measures are inadequate due to their failure to account for the symmetries which arise in parameter space, especially the complex symmetries inherent in transformer architectures. To address this limitation, they leverage tools from Riemannian geometry to propose a refined definition of sharpness (their so-called geodesic sharpness) that explicitly removes these symmetries by instead focusing on the quotient space. This construction draws upon concepts from the theory of quotient manifolds. The authors validate their theoretical framework through experiments on both toy models and vision transformer models trained on ImageNet."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "I found this to be an interesting paper. The authors explore the notion and role of sharpness in machine learning and shed light on how sharpness is affected by the symmetries which arise in parameter space for these large machine learning models. They use interesting ideas from Riemannian geometry and provide a clear, detailed analysis of difficult ideas. The ideas are original and they provide a creative way and mathematically sound way to define a new notion of sharpness (i.e., geodesic sharpness) which mitigates this issue of symmetry in parameter space."
            },
            "weaknesses": {
                "value": "Based on my understanding of the author's work, here are the weaknesses I see\n\nThere are a few conceptual gaps for me. While the use of quotient spaces to address parameter symmetries is conceptually nice, certain aspects of their construction are unclear to me. In particular, the choice of Riemannian metric on the total space $\\bar{\\mathcal{M}}$ appears to be crucial, as exemplified by the metric defined in equation (15) for attention layers.  This metric is not unique or canonical. Would similar results hold for any metric, except I suppose for the standard Euclidean one? It is unclear whether the proposed sharpness measure is invariant under different choices. One could conceive of a metric on $\\bar{\\mathcal{M}}$ that yields a different value for geodesic sharpness. Is that right? Or should all measures for geodesic sharpness be invariant under the R. metric of the total space as well? This technique is marketed in the introduction/conclusion as a \"one-size-fits-all\" technique for appropriately measuring sharpness but this choice of total R. metric doesn't feel that way to me. To address this concern could the authors\n 1. Explain the rationale behind choosing the specific metric in equation (15)\n 2. Provide some discuss around how sensitive the results are to different choices of Riemannian metrics on the total space\n 3. Clarify if there's a principled way to select an \"optimal\" metric for a given architecture.\nThese points would help evaluate whether the method is truly \"one-size-fits-all\" as claimed.\n\nAlso the details of how to actually compute the geodesic sharpness for the attention layer example (Sec 5.2) is lacking, see line 468-469. It's not clear to me what that means to \"...plug Eq. 16 into Eq. 17 and solve the resulting optimization problem using SGD\". Would it be possible to include the details for that computation and optimization solution details/setup? To address this concern, could the authors\n 1. provide the explicit form of the optimization problem after plugging Eq. 16 into Eq. 17 and clarify the specific SGD algorithm used to solve it and hyperparameters used, and\n 2. provide any additional constraints or modifications needed to ensure the optimization remains on the manifold\n\nIt would be nice to see more experiments or at least some more computational examples. The paper only addresses, in a careful way, very simple diagonal networks and attention layers in transformers. Nothing in between. The experiments are limited to correlational studies. It would be good to have more architectures and datasets to help convince the reader of this new technique. To address this, the authors could\n 1. test this measure of geometric sharpness on intermediate architectures between diagonal networks and transformers, such as MLPs or CNNs; or ideally, architectures that are more closely comparable with other measures of sharpness in the literature.\n 2. apply the technique to different datasets beyond ImageNet\n 3. conduct ablation studies to isolate the impact of different components of the 'geodesic sharpness' measure\n\nAlso, the final takeaway message from Figure 4 (see line 488) is that the \"...geodesically sharpest models studied on ImageNet are those that generalise best.\" This seems counter to the typically held belief that less sharp or more flat models generalize better. It would be nice to have more experiments or theory to explain why we see the opposite behavior here than previously in the literature. Or it would be nice to recreate the experiments in the literature which demonstrate that less sharp models generalize better (e.g. the original SAM paper and followups) and show that the geodesic sharpness behaves in the opposite way. To address this concern, could the authors\n 1. provide a theoretical explanation or justification as to why 'geodesic sharpness' might behave differently from traditional sharpness measures\n 2. conduct a direct comparison with previous sharpness measures on the same models and datasets. This, in particular, would be very nice. And\n 3. discuss potential implications of this result for providing better understanding of generalization in deep learning\n\nThere are also some parts of the exposition that I found confusing or misleading (in either the concepts or lack of details in plots) and quite a large number of typos which made the paper hard to follow at times. I've outlined these points in the questions section below."
            },
            "questions": {
                "value": "- line 112. in contribution (d) you claim that Figure 1 shows that there is a strong correlation between generalization and sharpness. Is this a typo? Can you better explain the connection between Figure 1 and generalization?\n- In general, the paper appears to only address symmetries that arise as group actions of GL. Is it obvious that this captures all possible symmetries in the parameter space? What is the effect of your construction of the geodesic sharpness when not all symmetries are removed? \n- in contribution (f) and in the paper you make a comparison with the CLIP  experiments from Andriushchenko et al. However, those models were not trained to convergence and one could argue that the role of sharpness in generalization is only evident for well-tune and converged models. Does that also apply to your measure of geodesic sharpness?\n- line 279, why denote the points in total space by $\\bar{x}^{(')}$. I'm confused by this notation.\n- line 280, is this a typo? Do you mean x,y for points in the quotient space?\n- line 297. Can you clarify the details in the section \"Linear embedding space\". When you say \"On the outer most layer, we are given a linear Euclidean space E\u2026\" what does this mean? Do you mean the $d$ parameters relating to the outermost layer of the network? Also, why define the loss $\\overline{\\overline{\\ell}}$ just on these outer layer parameters? How are $\\overline{\\overline{\\ell}}$ and $\\overline{\\ell}$ related to each other?\n- then on line 304, you reference the \"Riemannian generalization\" The R. generalization of what? The gradient?\n- line 318, i mentioned this above, but here you reference endowing the total space $\\overline{\\mathcal{M}}$ with a smooth inner product. Yes. it is possible to endow any smooth manifold with a Riemannian metric. However, this R. metric is not unique. You reference defining it in Appendix B.4 but that just points to a definition of what a Riemannian metric is. This is confusing and crucial aspect of this work. \n- Section 4. When defining the geodesic sharpness, I'm surprised to not see mention of the exponential map to define geodesics in the manifold using vectors in the tangent space. Would it not be possible to reformulate your construction looking only at vectors in the tangent space? And restrict yourself to vectors of a certain size in order to keep them within a fixed ball when projected to the manifold. \n- In Figure 3, you plot sharpness vs test loss for diagonal models. But only for 50 of the 200 models from the experiment setup? Why only 50 and why those?\n- How natural or reasonable is Assumption 5.1? There is a low-rank bias in deep learning when training overparameterized models. Can you provide a reference that this assumption is usually satisfied in multi-head attention layers for default choices of $d_v, d_k$?\n- line 453: Is it possible to endow the total space with any smooth Riemannian metric? Why this one? Admittedly I'm less familiar with the reference (Absil et al 2008) but it would be nice to see a computation verifying this is indeed a Riemannian metric and why this inner product was chosen.\n- line 514: Can you clarify what you mean when you say \"..attention weights approach being singular\" here? How are you defining singular. Also you mention a relaxation parameter but I'm not clear on the role this 'relaxation parameter' plays. You indicate that \"..in practise we found out results were robust to this parameter\". Can you explain more what robustness analysis you conducted to justify this claim.\n\ntypos/nits\n - (typo) Do you mean $L_{\\mathbb{S}}$ not $L_{S}$  in equations (1) and (2)? same in equation (3)\n - (nit/personal preference) := is more common that :- for definitional equivalence\n - (typo) line 229. Do you mean $\\overline{\\overline{f}}$ is symmetric\u2026?\n - the Figures have been resized and the font is very small, difficult to read\n - line 434: what do you mean that the GL(h) symmetry is 'dealt' by geodesic sharpness?\n - line 463: 15 should be (15)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper generalizes the (adaptive) sharpness concept by considering both the first-order perturbation and the (second-order) curvature of the loss landscape, presented under a Riemannian geodesic framework. It aims at solving the inconsistency in the literature on the correlation between sharpness and generalization, and addresses the failure of existing sharpness in measuring the generalization of Transformers with larger symmetry, explained by the scaling/rescaling symmetry of the parameter space. The symmetry is formalized as the quotient group. Experiments on both a toy diagonal network and fine-tuned vision transformers show that the geodesic sharpness has a significant correlation with the generalization gap."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The motivation is strong, the theoretical discussion is rich and sound, and the curvature-aware sharpness significantly depends on the generalization gap. I appreciate the insights of the Attention symmetry and the strong theoretical connections."
            },
            "weaknesses": {
                "value": "- My main concern is the practical effectiveness of the proposed method: does it really improve existing adaptive sharpness? In Figure 4 the improvements are not quite visible, and the parameter $\\tau$ is neither explained nor aligned by column.\n- The experiments are not described in detail, which affects reproducibility. For self-containedness, the method used in the experiment from Wortsman et al. (2022) could be explained better in detail. For example, what are the hyperparameters, how are the models trained, what is the precise algorithm, etc.?\n- It is questionable whether the attention's symmetry argued by the author is indeed the practical reason rather than a hypothesis. It would be helpful if the author could give a stronger argument or some illustrations. To give an example, ensure that the scaling symmetry causes irregularity in pre-trained models by measuring the conditional number, and modulating out this symmetry indeed corrects the sharpness---or any other way you prefer.\n- I believe the paper's writing could benefit greatly by being more concise. Many sentences in the introduction seem to wander around and are not precisely to the point.\n- Minor issues: Figures 2, 3, and 4 are not referenced."
            },
            "questions": {
                "value": "- I don't understand the role of the $\\tau$ variable in the result figures. For example, could you explain how it is chosen, and how it relates to the results?\n- I don't understand why in Figure 3 (left), the average-case adaptive sharpness is claimed to reveal a correlation with the test loss (generalization gap). To me, it looks not obvious, and the dependency is reversed.\n- $c$ inconsistently appears in Appendix D. Do the experiments of geodesic sharpness also choose a vector $c$ by taking $c=|w|$ to normalize each parameter tensor? If not how to guarantee fair comparison? In Appendix D $c$ is preset, but I don't understand whether the geodesic is invariant over scaling?\n- I wonder if normalizing QK embeddings will fix the concern in the paper that Transformers have GL group symmetry? It is shown in practice that it stabilizes training (such as [1]). [2] also uses spherical projection for theoretical convenience. Or if not, are there alternative ways to address the scaling symmetry?\n\n[1] Scaling rectified flow transformers for high-resolution image synthesis. Esser et al. 2024.\n[2] The emergence of clusters in self-attention dynamics. Geshkovski et al. 2024."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}