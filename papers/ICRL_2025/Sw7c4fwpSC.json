{
    "id": "Sw7c4fwpSC",
    "title": "Assessing Open-world Forgetting in Generative Image Model Customization",
    "abstract": "Recent advances in diffusion models have significantly enhanced image generation capabilities. However, customizing these models with new classes often leads to unintended consequences that compromise their reliability. We introduce the concept of *open-world forgetting* to emphasize the vast scope of these unintended alterations, contrasting it with the well-studied *closed-world forgetting*, which is measurable by evaluating performance on a limited set of classes or skills.\nOur research presents the first comprehensive investigation into open-world forgetting in diffusion models, focusing on semantic and appearance drift of representations. We utilize zero-shot classification to analyze semantic drift, revealing that even minor model adaptations lead to unpredictable shifts affecting areas far beyond newly introduced concepts, with dramatic drops in zero-shot classification of up to 60\\%. Additionally, we observe significant changes in texture and color of generated content when analyzing appearance drift.\nTo address these issues, we propose a mitigation strategy based on functional regularization, designed to preserve original capabilities while accommodating new concepts. Our study aims to raise awareness of unintended changes due to model customization and advocates for the analysis of open-world forgetting in future research on model customization and finetuning methods. Furthermore, we provide insights for developing more robust adaptation methodologies.",
    "keywords": [
        "generative models",
        "diffusion",
        "open-world forgetting",
        "semantic drift",
        "appearance drift"
    ],
    "primary_area": "generative models",
    "TLDR": "This paper identifies \"open-world forgetting\" in diffusion models, where customization causes unintended changes beyond new classes. Quantifies semantic and appearance drift, proposes mitigation, and advocates awareness in model adaptation research.",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Sw7c4fwpSC",
    "pdf_link": "https://openreview.net/pdf?id=Sw7c4fwpSC",
    "comments": [
        {
            "summary": {
                "value": "This paper investigates the issue of \u201copen-world forgetting\u201d in generative image model customization, highlighting how fine-tuning models for new classes can inadvertently degrade performance on previously learned classes. The authors systematically analyze open-world forgetting through the introduction of semantic and appearance drift concepts, using zero-shot classification to measure semantic drift. To mitigate this issue, they propose a \u201cdrift correction\u201d method, designed to reduce the model's tendency to forget prior knowledge when learning new concepts. Experiments demonstrate that drift correction significantly reduces semantic and appearance drift, enhancing the stability and reliability of customized models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The introduction of open-world forgetting is a novel perspective in the domain of diffusion model customization. While previous research often focuses on task-specific performance, this paper broadens the scope of forgetfulness evaluation, bringing strong innovation."
            },
            "weaknesses": {
                "value": "1. The paper\u2019s structure is confusing. For instance, lines 513-532 discuss contributions to open-world forgetting before defining it clearly, and these lines largely repeat lines 108-119, adding unnecessary redundancy.\n\n2. Key metrics lack basic explanation in the main text, with details only in supplementary materials. This makes it hard for readers to grasp the evaluation approach without prior knowledge.\n\n3. The paper focuses on how fine-tuning degrades original model capabilities but doesn\u2019t assess how the proposed method impacts performance on the fine-tuning tasks."
            },
            "questions": {
                "value": "1. Were alternative metrics for measuring semantic drift considered? For instance, could user evaluations on the semantic consistency of generated images be feasible?\n\n2. Has the drift correction method been tested on more complex or diverse concepts beyond the simple categories presented? For example, in Figure 2a, \u201ca sampled pair from the most dissimilar outputs (purple triangle) shows a complete change in content, colors, and scene composition that no longer matches the prompt.\u201d, What happens if drift correction is applied in this case, do the colors and scene composition match the prompts better?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the concept of \"open-world forgetting\" to emphasize the vast scope of these unintended alterations during the model customization of foundation generative models (i.e., Stable Diffusion). The authors conduct a comprehensive investigation of the semantic and appearance drift of representations. To address these issues, this paper proposes a mitigation strategy based on functional regularization which preserves original capabilities while accommodating new concepts. The contribution of the paper can be summarized as follows:\n\n1. $\\textbf{Introduction of Open-World Forgetting Concept:}$ The paper defines open-world forgetting in pre-trained foundation generative image models and systematically assesses its impact, focusing on how models lose previously learned concepts after adaptation.\n\n2. $\\textbf{Semantic and Appearance Drift Analysis:}$ It introduces two evaluation approaches:\nSemantic Drift: Uses zero-shot classification to measure changes in a model's semantic understanding.\nAppearance Drift: Examines shifts in visual attributes like color and texture after customization, introducing the \"Color Drift Index\" (CDI) as a metric for quantifying these changes.\n\n3. $\\textbf{Mitigation Strategy:}$ The paper proposes a functional regularization technique aimed at reducing open-world forgetting, enabling models to integrate new concepts while retaining prior knowledge. This method proved effective in maintaining both semantic and appearance integrity in fine-tuned models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The concept of open-world forgetting represents a novel extension to the field of model adaptation and customization, particularly in generative models. While catastrophic forgetting has been explored in closed-world contexts, applying it to open-world scenarios in text-to-image models is original and fills an important gap in understanding how fine-tuning affects broad model knowledge.\n2. The proposed Color Drift Index (CDI) for assessing appearance drift is a new and creative metric tailored to the nuances of generative models. This provides a fresh approach to evaluating visual consistency, which goes beyond typical performance metrics in generative model research.\n3. By providing quantitative results with the CDI and zero-shot classification performance across multiple models and concepts, the authors present strong empirical evidence for their findings, which enhances the reliability of their conclusions.\n4. The use of functional regularization as a mitigation strategy is well-executed and shows practical effectiveness, backed by solid data on how it mitigates both semantic and appearance drift.\n5. By proposing methods to measure and mitigate unintended model alterations, the work establishes a foundation for future research on safeguarding foundational knowledge in generative models, which will inspire other researchers to work in this direction in the future.\n6. The proposed method is simple yet effective and the writing of the paper is clear and easy to follow."
            },
            "weaknesses": {
                "value": "The authors have mentioned some of the limitations in the paper:\n1. The analysis is limited to a small subset of concepts and may not capture all potential instances of forgetting. 10 concepts are apparently not enough to reflect the effectiveness of the proposed method comprehensively. The scale is recommended to be scaled up to at least a hundred to thousand level.\n2.  This study has mainly focused on evaluating the impact of diffusion model customization and only focuses on evaluating two very representative but not new (DB was proposed in 2022) works. The results would be more convincing if the authors evaluated their methods on more SOTA methods. For instance, as the author mentioned in the related works:\n\n[1] Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar, Dimitris Metaxas, and Feng Yang. Svdiff:\nCompact parameter space for diffusion fine-tuning. ICCV, 2023b.\n\n[2] Wenhu Chen, Hexiang Hu, Yandong Li, Nataniel Rui, Xuhui Jia, Ming-Wei Chang, and William W\nCohen. Subject-driven text-to-image generation via apprenticeship learning. arXiv preprint\narXiv:2304.00186, 2023b.\n\n[3] Jing Shi, Wei Xiong, Zhe Lin, and Hyun Joon Jung. Instantbooth: Personalized text-to-image\ngeneration without test-time finetuning. arXiv preprint arXiv:2304.03411, 2023a.\n3. The results in Table 1 and Table 2 are not significant enough."
            },
            "questions": {
                "value": "1. Is the customization method used in Figure 3 DB? Please clarify it in the revised version,\n2. I recommend the author to increase the number of concepts in the evaluation. 10 concepts might be a \"cherry pick\".\n3. Add more images generated by the model before and after applying your methods which would be intuitive and easy to understand.\n\nOverall, I believe this paper is valuable to the community and I would be happy to raise the score if my concern can be well addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a study on open-world forgetting during the customization of generative image models, specifically focusing on diffusion models like Stable Diffusion. The authors define open-world forgetting as the unintended changes in model behavior when adapted to new classes or content, distinguishing it from the more limited scope of closed-world forgetting. They explore how fine-tuning models with even small sets of data  can lead to significant drifts in both the semantic understanding and appearance of images generated by the model. Key methodologies discussed include using zero-shot classification to measure semantic drift and assessing changes in appearance through color and texture analysis. The paper also introduces a mitigation strategy through functional regularization to minimize these drifts while incorporating new concepts."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper successfully highlights the issue of open-world forgetting, which is less studied compared to closed-world scenarios, providing a valuable framework for further research in model customization.\n2. The use of zero-shot classification to quantify semantic drift and the introduction of novel metrics for appearance drift offer robust tools for understanding model behavior post-customization."
            },
            "weaknesses": {
                "value": "1. While the study provides detailed insights into open-world forgetting, the generalizability of the findings across different types of generative models or broader sets of data remains unclear.\n2. The mitigation strategy's effectiveness is potentially limited by the quality of the data used for fine-tuning and the subjective nature of assessing image quality and drift.\n3. How does the model perform when fine-tuned with highly diverse or noisy datasets? Does the regularization technique maintain its effectiveness across such variations?\n4. What is the long-term stability of models customized using these techniques? Do they continue to maintain reduced levels of forgetting with continued use or additional rounds of customization?\n5. How do quantitative assessments of drift align with qualitative evaluations from human observers? Is there a significant disparity, and how can it be addressed?"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper delves into open-world forgetting in diffusion models,. Unveiling semantic and appearance drift, this paper proposes functional regularization to maintain original capabilities. Besides, this paper supports studying open-world forgetting and offers insights for stronger adaptation methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.The paper is well-written and easily comprehensible.\n\n2.The proposed method is simple and straightforward.\n\n3.The motivation for addressing both Appearance Drift and Semantic Drift is commendable."
            },
            "weaknesses": {
                "value": "1. This paper solely analyzes Appearance Drift and Semantic Drift in the context of OPEN-WORLD FORGETTING, leaving uncertainties about their occurrence in closed-world scenarios. \n\n2. The analysis in this paper focuses on two methods, Dreambooth and CustomDiffusion, overlooking recent approaches like BLIP-Diffusion [1] and HyperDreamBooth [2]. Do Appearance Drift and Semantic Drift commonly appear in these diffusion-based methods?\n\n3. While this paper claims to mitigate Appearance Drift and Semantic Drift using a mitigation strategy, the relevant qualitative results are missing, and the effectiveness needs to be intuitively demonstrated.\n\n4. The related work section requires updating. For instance, [2] and [3] in relation to this paper should be discussed and analyzed.\n\n[1] BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing. In Neurips2023 (pp.30146-30166).\n\n[2] Hyperdreambooth: Hypernetworks for fast personalization of text-to-image models. InCVPR2024 (pp. 6527-6536. 2024).\n\n[3] Customization assistant for text-to-image generation. InCVPR2024 (pp. 9182-9191)."
            },
            "questions": {
                "value": "Please see the above Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}