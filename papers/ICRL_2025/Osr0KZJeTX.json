{
    "id": "Osr0KZJeTX",
    "title": "Unlocking the Potential of Model Calibration in Federated Learning",
    "abstract": "Over the past several years, various federated learning (FL) methodologies have been developed to improve model accuracy, a primary performance metric in machine learning. However, to utilize FL in practical decision-making scenarios, beyond considering accuracy, the trained model must also have a reliable confidence in each of its predictions, an aspect that has been largely overlooked in existing FL research. Motivated by this gap, we propose Non-Uniform Calibration for Federated Learning (NUCFL), a generic framework that integrates FL with the concept of model calibration. The inherent data heterogeneity in FL environments makes model calibration particularly difficult, as it must ensure reliability across diverse data distributions and client conditions. Our NUCFL addresses this challenge by dynamically adjusting the model calibration objectives based on statistical relationships between each client's local model and the global model in FL.  In particular, NUCFL assesses the similarity between local and global model relationships, and controls the penalty term for the calibration loss during client-side local training.  By doing so, NUCFL effectively aligns calibration needs for the global model in  heterogeneous FL settings while not sacrificing accuracy. Extensive experiments show that NUCFL offers flexibility and effectiveness across various FL algorithms, enhancing accuracy  as well as model calibration.",
    "keywords": [
        "Federated Learning",
        "Model Calibration"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Osr0KZJeTX",
    "pdf_link": "https://openreview.net/pdf?id=Osr0KZJeTX",
    "comments": [
        {
            "summary": {
                "value": "The paper addresses the issue of model calibration in federated learning (FL), with a specific focus on heterogeneous scenarios, characterized by distribution shifts across clients. The paper argues that most works have focused on improving the accuracy of the proposed methods so far, but almost no attention has been given to the model's confidence in its predictions. This highlights a gap in the current literature: FL models should hava reliable confidence in their predictions to be deployed in real-world use cases. To fill this gap, this work introduces Non-Uniform Calibration for Federated Learning (NUCFL), a novel method to integrate FL with model calibration, that can be easily combined with existing approaches.\n\nThe work discusses the various benefits of NUCFL, studying its application with several calibration approaches and FL methods, showing its effectiveness in improving the model's confidence in its predictions, according to multiple metrics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper underlines a gap in the current FL research and proposes an effective method to address it\n-  NUCFL can be easily added on top of existing methods\n- The paper extensively shows the efficacy of NUCFL across various settings, model architectures and methods\n- NUCFL is extensively studied through in-depth and well-carried analyses\n- NUCFL does not increase communication costs"
            },
            "weaknesses": {
                "value": "- Difficulties in proving NUCFL's convergence and theoretical properties, as also pointed out by the authors\n- The paper argues that works like Zhang et al. [2022] and Luo et al. [2021] misuse the term \"calibration\" and do not further analyze the comparison with those methods. However, I believe it would still be relevant to the FL community to understand how NUCFL compares to them. \n- The application of NUCFL seems limited to supervised scenarios\n\nComments (did not affect my rating):\n- I believe the paper would benefit from the outlined Algorithm of NUCFL for better understanding\n- Please modify the citation style to improve the paper's readibility (the citation are not enclosed in brackets)\n- Line 136: typo \"..\""
            },
            "questions": {
                "value": "- Could the authors provide a comparison between NUCFL and Zhang et al. [2022] and Luo et al. [2021], according to the introduced metrics?\n- Does NUCFL increase computational costs on the client-side?\n- How could NUCFL be adapted to unsupervised/semi-supervised settings?\n- How sensible if NUCFL to the hyperparam $\\beta$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a model calibration method for federated learning, which adaptively adjusts penalties based on the relationship between local and global models."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The motivation makes sense.\n\nThe paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "The contribution of this paper is limited. The proposed method seems a simple incremental work of the existing FL model calibration method.\n\nAlthough I understand the author's motivation, I need the author to explain why the proposed metric is more important than accuracy. The proposed metrics are not intuitive enough. Typically, accuracy and the proposed metric are positively correlated. The author should add some detailed experiments to validate its motivation.\n\nThe experimental results show that The proposed method is only slightly optimized for federated learning. In addition, the proposed method may cause a decrease in accuracy in some scenarios.\n\nLake of comparison with SOTA FL optimization methods [1-5]. These methods achieve better model performance by guiding the model to optimize towards the flat region. I think these methods can still reduce the measures proposed by the author. I wonder if the author can compare these methods or integrate the proposed method into them.\n\n[1] FedSpeed: Larger local interval, less communication round, and higher generalization accuracy ICLR 2023\n\n[2] Is Aggregation the Only Choice? Federated Learning via Layer-wise Model Recombination, KDD 2024\n\n[3] Generalized Federated Learning via Sharpness Aware Minimization, ICML 2022\n\n[4] Dynamic regularized sharpness aware minimization in federated learning: Approaching global consistency and smooth landscape. ICML 2023\n\n[5] FedCross: Towards Accurate Federated Learning via Multi-Model Cross-Aggregation, ICDE 2024"
            },
            "questions": {
                "value": "Please see the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to ensure the reliability of FL in real-world applications. It proposes Non-Uniform Calibration for Federated Learning (NUCFL) that integrates FL with model calibration to achieve the goal. NUCFL dynamically adjusts the model calibration objectives by measuring the relationships between the local and the global model. Experiments show the superiority of NUCFL compared with existing FL methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "[1] The paper takes an important step to explore FL from the perspective of model calibration, which is important to various decision-making scenarios. \n\n[2] Extensive experiments are carried out to show that NUCFL can seamlessly integrate with existing FL methods and improve the original performance of those methods."
            },
            "weaknesses": {
                "value": "[1] It is unclear whether there is a trade-off between accuracy and reliability. If so, please give a detailed illustration of this aspect. If not, the advantage of not sacrificing accuracy seems an irrelevant contribution. \n\n[2] The relation between model calibration and enhancing the confidence of FL outputs is weak. It requires further demonstration and analysis of why model calibration can realize that. \n\n[3] It is better to provide a further investigation into how existing centralized calibration methods can adapt to the FL setting, for example, simply combining them with FedAvg framework. Empirical studies can also involve this part."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper contributes to a well-established line of research that adapts standard machine learning (ML) techniques for federated settings by leveraging the similarity between global and local models to weight client contributions. Here, the ML technique under adaptation is model calibration, achieved through an auxiliary loss function. The paper\u2019s primary contribution is a proposal to weight this auxiliary calibration loss based on a customizable similarity metric between global and local models, such as cosine similarity or other advanced measures. In this context, the \u201clocal\u201d model refers to the locally trained replica of the global model. The authors provide an extensive empirical evaluation on standard federated learning datasets for computer vision, using LDA to generate non-IID partitions for IID datasets and some naturally heterogeneous datasets as well (FEMNIST). Their results indicate improved performance over baseline methods across all datasets, models, and levels of data heterogeneity."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Comprehensive Evaluation: Experiments are extensive and demonstrate consistent improvements across datasets, models, and non-IID settings.\n- Writing and Presentation: The paper is well-written, with clear diagrams and formatting that aid readability.\n- Practical Relevance: The method holds strong practical implications, bringing effective calibration methods to FL."
            },
            "weaknesses": {
                "value": "I must mention that I am much more familiar with FL than model calibration and thus focus on this side of the work. \n\n- Limited Novelty in Core Insight: Although the similarity-based weighting approach is practical, it is not particularly novel, e.g.,[1,2,3]. The authors do acknowledge the influence of prior FL works that leverage model similarity metrics. \n- Potential Sensitivity to Hyperparameters: The method might be sensitive to local training hyperparameters like learning rate and epoch count, which could impact the similarity measure\u2019s effectiveness. In cases closer to FedSGD with only one or a few steps performed, data heterogeneity may minimally impact the model replica, potentially diminishing the relevance of the similarity function. Similarly, scenarios involving extensive local training or very high learning rates may affect the similarity measure\u2019s utility as all models may diverge very far from the global model regardless of the degree of local data heterogeneity. \n- No Exploration of Alternative Similarity References: Using only the client\u2019s local model replica as the similarity reference could limit the applicability; other approaches (e.g., auxiliary persistent local models or specific personalized layers) might better capture client-specific characteristics.\n\n\n\n\n[1] Tian Li, Shengyuan Hu, Ahmad Beirami, Virginia Smith:\nDitto: Fair and Robust Federated Learning Through Personalization. ICML 2021: 6357-6368\n\n[2] Tao Yu, Eugene Bagdasaryan, Vitaly Shmatikov:\nSalvaging Federated Learning by Local Adaptation. CoRR abs/2002.04758 (2020)\n\n[3] Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei, Yong Zhang:\nPersonalized Cross-Silo Federated Learning on Non-IID Data. AAAI 2021: 7865-7873"
            },
            "questions": {
                "value": "1. Can the authors provide any insight on how would the proposed approach perform under different local training conditions? For example with minimal local training (\u2264 1 epoch or with very low learning rates) or extensive local training (e.g., training the local model to convergence or near convergence every round).\n2. Have the authors considered the use of auxiliary local models or personalized layers, to compute similarity? \n3. Why did the authors decide to use raw similarity/relevance values rather than a softmaxed version with a normalization factor constructed based on the entire distribution of client similarities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}