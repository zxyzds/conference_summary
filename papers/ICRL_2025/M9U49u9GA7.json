{
    "id": "M9U49u9GA7",
    "title": "SiDyP: Simplex Diffusion with Dynamic Prior for Denoising Llama-Generated Labels",
    "abstract": "The traditional process of creating labeled datasets is not only labor-intensive but also expensive. Recent breakthroughs in open-source large language models (LLMs), such as Llama-3, have opened a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks to provide an alternative to such expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from such noisy labels, the model's generalization is likely to be harmed as it is prone to overfit those label noises. In this paper, we propose the \\textbf{Si}mplex Diffusion with a \\textbf{Dy}namic \\textbf{P}rior (\\textbf{SiDyP}) model to calibrate incorrect labels, thus enhancing classifier robustness to noisy labels. While diffusion models have largely been overshadowed by transformer architectures for NLP, our work shows that combining diffusion with transformers can further improve text-based tasks. Our framework leverages simplex diffusion model to iteratively correct noisy labels conditioned on training dynamic trajectories. The potential true label candidates, obtained by neighborhood label distribution in embedding space, progressively based on the feedback of the diffusion model. Our SiDyP model can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot Llama-3 generated noisy label datasets by an average of 5.33\\% and 7.69\\% respectively. Our extensive experiments, which explore different LLMs, diverse noise types (real-world and synthetic), ablation studies, and multiple baselines, demonstrate the effectiveness of SiDyP across a range of NLP tasks. We will make code and data publicly (under a CC BY 4.0 license) available on GitHub upon publication of the work.",
    "keywords": [
        "Diffusion Model",
        "Learning from Noisy Labels",
        "Soft Labels"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=M9U49u9GA7",
    "pdf_link": "https://openreview.net/pdf?id=M9U49u9GA7",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes applying simplex diffusion to denoise annotations generated by large language models (LLMs). The core idea is to first obtain noisy annotations from LLMs and then iteratively refine these labels with a simplex diffusion model, which maps labels to a continuous probability space. The main experiments are conducted across four common text classification datasets using Llama 3.1-70b. Overall the results show that the proposed method achieves competitive performance in both zero-shot and few-shot settings. Additionally, the authors explore the method\u2019s robustness by testing with different 4 LLM backbones and different types of label noises."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Overall, I think this paper is well-written and relatively easy to follow. The results are very competitive and clearly show the advantage of the proposed method. I think the construction of experiments is correct.  Additionally, the authors clearly communicate the problem and the potential impact of their approach on improving LLM-generated annotations, which would be a valuable contribution to the field."
            },
            "weaknesses": {
                "value": "= The comparisons with Mixtral models might not be entirely fair. If the authors used the base Mixtral-8x22b model, which is not instruction/chat-finetuned, it may not perform comparably to other models that have been finetuned on instruction data. For a fairer comparison, using Mixtral-8x22b-Instruct-v* or similar instruction-tuned models would better align with the capabilities of the other models tested.\n\n= Insufficient literature coverage: Overall, this paper aims to solve the problem of LLM for data annotation and reduce annotation noise. I think it would be justifiable to have a better coverage of related work especially on LLM for data annotations. Give the limitation in space for the initial submission, I expect the authors to conduct a more rigorous literature survey of related work.\n\n= Although the approach is novel for this specific problem of denoising llm annotaions, the method largely adapts simplex diffusion for signal denoising directly to noisy label refinement. This may raise questions regarding the technical novelty, as the adaptation itself does not appear to involve significant theoretical modifications."
            },
            "questions": {
                "value": "It would be helpful if the authors could clarify the following:\n\n= For missing labels, why was a random label assignment chosen? Given the low failure rate, might it be preferable to disregard these cases instead?\n\n= Were any specific system prompts or chat templates used when applying the prompts for LLM label generation? If so, could the authors provide details?\n\n= In the few-shot experiments, the authors selected one example per label. Were these demonstration examples sampled from the training set or the validation set?\n\n= For the 20News dataset, is there a reason why no results are reported for the few-shot experiments?\n\n= Since the validation set is used for model selection, as an exploratory experiment, have the authors considered prompting the LLM with a larger few-shot sample (e.g., 50+ examples) from the validation set, given the support for long contexts in the LLMs used? It would be interesting to see how the efficiency of this approach compares with the proposed diffusion-based denoising pipeline."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel approach using a simplex diffusion model for denoising labels generated by large language models (LLMs). The method aims to address the inherent noise in LLM-generated labels by leveraging an iterative denoising process within a continuous probability simplex space. The approach is motivated by the high cost and time demands of manual labeling, coupled with the practicality of LLMs for fast, albeit noisy, label generation. The paper introduces several key assumptions, including the local consistency of embedding spaces and the ability of diffusion models to gradually refine noisy labels into accurate representations. Experiments across different noise types, including symmetric, asymmetric, and instance-dependent noise, demonstrate the model's robustness. The results suggest that the method effectively reduces noise without requiring additional labeled data, making it a potentially valuable contribution to applications reliant on large-scale automatically generated labels."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper has several notable strengths across originality, quality, clarity, and significance:\n\nOriginality: The approach is innovative in applying a simplex diffusion model to iteratively denoise noisy LLM-generated labels. Using the probability simplex space to handle label noise is a creative application, enabling a gradual refinement of noisy labels, which is distinct from traditional denoising methods. This method also addresses the growing need for handling noise in labels generated by LLMs, making the approach highly relevant and timely.\n\nQuality: The paper presents a structured approach with a combination of techniques, such as embedding-based candidate selection, to effectively manage noise. The experiment setup is comprehensive, covering multiple noise types (symmetric, asymmetric, instance-dependent), which reflects the robustness of the method. By comparing the proposed model to various baselines, the paper demonstrates a clear performance advantage in multiple scenarios, supporting the claim that the simplex diffusion model can enhance accuracy in noisy data environments.\n\nClarity: The overall structure of the paper is clear, with a logical flow from the problem formulation to the model design and experimental results. The motivation for the proposed method is well-presented, with a clear description of how each component of the simplex diffusion process contributes to the final denoised output.\n\nSignificance: The work is significant for applications that rely on LLM-generated labels, which often contain noise. By introducing a method that reduces noise without needing additional labeled data, the paper addresses a practical challenge, potentially improving the scalability and quality of labeling in real-world scenarios. This could be valuable across fields where large-scale data labeling is a bottleneck, such as natural language processing, computer vision, and medical imaging."
            },
            "weaknesses": {
                "value": "While the paper is promising, several areas could benefit from further improvement:\n\nThe paper lacks in-depth theoretical discussion regarding why the simplex diffusion model is particularly well-suited to the task of LLM label denoising. For example, the rationale behind using iterative denoising in the simplex space could be strengthened by exploring why this approach may perform better than existing denoising methods in managing specific types of noise common to LLM-generated labels.\n\nKey Assumptions Verification: The paper is based on several assumptions, such as the local consistency of embeddings and the relationship between training dynamics and sample quality. However, these assumptions are not directly validated in the experiments. For instance, the assumption that noisy labels will have larger mean and standard deviation distances in the embedding space could be tested and quantified to provide stronger empirical support.\n\nThe paper could provide a more detailed analysis of the noise characteristics specific to LLM-generated labels. The motivation would be more convincing if it explained how these labels differ from other types of noise and why standard denoising methods are insufficient. Understanding these nuances would clarify why the simplex diffusion model is a more suitable choice.\n\nAlthough the experiments include different noise types, they do not explore the method\u2019s limitations in scenarios where noise is highly complex or includes extreme cases. Additionally, there is a lack of quantitative analysis regarding the training dynamics feature assumption, which would help validate the model\u2019s robustness and provide further insights.\n\nThe paper lacks a failure analysis that would highlight the model's limitations. Discussing scenarios where the model underperforms could provide readers with a more realistic understanding of its applicability and suggest areas for future improvement."
            },
            "questions": {
                "value": "Noise Characteristics in LLM Labels: Could the authors provide more insights into the specific noise patterns in LLM-generated labels that this model targets? Understanding these patterns would clarify why traditional denoising methods might struggle with this type of noise.\n\nEmbedding Space Consistency Assumption: Can the authors validate the assumption that the local consistency of embeddings allows clean and noisy labels to be differentiated? This could be demonstrated by visualizing the embedding space to show the distribution differences between noisy and clean labels.\n\nTraining Dynamics Validation: Could the authors conduct a more detailed analysis of the training dynamics related to noisy samples? Quantifying the mean and standard deviation differences in distances for noisy versus clean samples would strengthen the paper\u2019s empirical foundation.\n\nApplication Scenarios and Limitations: In which specific scenarios would the simplex diffusion model be most applicable or potentially limited? Additional examples would help readers understand the practical applicability of the method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method called SiDyP to address the learning-from-noisy-labels problem.  \nIn the experiments, the authors validated the effectiveness of the proposed method using noisy data generated from the zero-shot and few-shot inference of Llama-3."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors conducted experiments using noisy labels generated by LLM Llama and demonstrated the effectiveness of the proposed method, which is one of the contributions of this paper."
            },
            "weaknesses": {
                "value": "1)\tOn the novelty of introducing LLMs for generating noisy data for learn-from-noisy-labels methods.  \nThe authors claimed in the Introduction that, this is the first time that LLMs-generated datasets have been introduced in the realm of learning from noisy labels.\nActually, this statement is not rigorous. \nThere are already some works that focus on learning from noisy labels generated by LLMs [1,2,3].\nThese works concern the topic of Weak Supervision, which can be seen as a subset of the learning-from-noisy-labels problem; even though Weak Supervision considers the context of each one sample with multiple noisy labels, the learning-from-noisy-labels problem often refers to the context of one sample with one label.\nAnyway, the authors should take these prior works into account while writing.\n\n[1] Alfred: A System for Prompted Weak Supervision. ACL-2023 (demo).  \n[2] Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents. Artificial Intelligence and Law, 2024.  \n[3] https://snorkel.ai/blog/few-shot-learning-large-language-models/. Blog from Snorkel.\n\n\n2) On the core research motivation and contributions.  \nRelated to the first issue mentioned above, and more importantly, the core research motivation and contributions of this paper are not sufficiently clear:  \n\n    &emsp;2.1) If the designed method is more specifically tailored to noisy labels generated by LLMs (rather than noisy labels in the general learning-from-noisy-labels works), or in other words, if the proposed method is specifically designed for noisy labels generated by LLMs, then:\n    The authors should analyze from theoretical or experimental perspectives whether noisy labels generated by LLMs have different characteristics compared to noisy labels in the traditional sense, and why the designed method is well-suited to handle these characteristics.\n\n    &emsp;2.2) If the designed method is not specifically aimed at noisy labels generated by LLMs, then this paper essentially presents a new typical learning-from-noisy-labels method.    \n\n    &emsp;2.3) In summary, the authors do not clarify in the paper whether noisy labels generated by LLMs have different characteristics compared to traditional noisy labels, nor do they specify whether their contributions are specifically designed for noisy labels generated by LLMs."
            },
            "questions": {
                "value": "Please refer to the above Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a work on learning with noisy labels in datasets annotated by LLMs. The proposed framework, SiDyP, is based on a noisy-supervised model called PLC and a simplex diffusion model. In this framework, the PLC model, fine-tuned with the noisy labeled data, is used to obtain dynamic training trajectories and induce a prior distribution, while the diffusion model serves as a posterior to iteratively calibrate PLC\u2019s prior. Specifically, this paper introduces a true label candidates retrieval algorithm and a prior dynamic distillation\nalgorithm to mitigate the negative impact brought by noisy labels. Extensive experiments demonstrate that the proposed framework achieves competitive classification performance on multiple tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Denoising LLM-generated labels may be a promising direction and is worth further investigation.\n2. Experimental results are good, which shows that the proposed method is a state-of-the-art one."
            },
            "weaknesses": {
                "value": "1.The novelty of this paper is limited, capturing the label prior distribution based on training dynamics and using the simplex model for iterative refinement are the technical contributions of DyGen and TESS, respectively. The contributions of this paper seem like engineering innocations.\n\n2.The proposed method introduces a few more hyperparameters. In practice, when we don't have a clean validation set, these hyperparameters can be difficult to set.\n\n3.Writing needs to be improved. the dynamic prior needs to be clearly explained in the abstract and introduction, which can easily be confused with training dynamics. Additionally, the organization of Section 3 is not reasonable.\n\n4.A more detailed ablation study would have been desirable, such as the number of candidate labels in Algorithm 1 and the number of iterations in Algorithm 2."
            },
            "questions": {
                "value": "1.Compared to DyGen, what are the main contributions of SiDyP? It seems that SiDyP just replaces the VAE part in DyGEN with a simplex diffusion model. There are no insightful innovations.\n\n2.Line 165, why do we only consider the two candidate categories with the highest probabilities? In fact, the types and distributions of labels vary significantly across different tasks.\n\n3.Some descriptions and settings of hyperparameters can be confusing. Does the estimated error rate refer to the noise ratio? What are the bases for setting these hyperparameters?\n\n4.The symbols in Figure 1 are inconsistent with those in the main text.\n\n5.Section 4.5, the effectiveness of the proposed label candidate retrieval algorithm has not been validated."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}