{
    "id": "l11DZY5Nxu",
    "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
    "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is a pressing problem in today's cloud services and industrial operations. Effective root cause diagnosis calls for identifying nodes whose disrupted local mechanisms *cause* anomalous behavior at a target node. We propose IDI, a novel algorithm that predicts root cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes should take on anomalous values; 2) **Fix:** had the root cause nodes assumed usual values, the target node would not have been anomalous. Prior methods of assessing the fix condition rely on counterfactuals inferred from a Structural Causal Model (SCM) trained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs  yield unreliable counterfactual estimates. IDI overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. Our theoretical analysis demonstrates that IDI's in-distribution intervention approach outperforms other counterfactual estimation methods under mild assumptions about the data-generating process. Experiments on both synthetic and Petshop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. We release the anonymized code at https://anonymous.4open.science/r/petshop-BB8A/.",
    "keywords": [
        "Root Cause Diagnosis",
        "Causal Inference",
        "Interventional RCD"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "Identifying root cause of anomalies using interventions rather estimated from a learned SCM",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=l11DZY5Nxu",
    "pdf_link": "https://openreview.net/pdf?id=l11DZY5Nxu",
    "comments": [
        {
            "summary": {
                "value": "This paper focuses on addressing the issue of performance degradation caused by OOD problems in previous methods when localizing root cause curves through causal interventions. It proposes the IDI method and demonstrates its advantages over existing SCM-based root cause localization methods through multi-level experiments."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The presence of hidden confounding factors makes the OOD problem both prevalent and significant.\n2. The writing of this paper is clear and easy to read.\n3. The paper provides proof that the IDI method's in-distribution sampling has a bounded error, scaling with the distance between anomalies and normality."
            },
            "weaknesses": {
                "value": "See the following questions."
            },
            "questions": {
                "value": "1. The paper uses intervention methods to identify the root cause curve from multiple anomalous KPI curves. MicroCause uses Granger causality. Can there be a comparative result between the two? [1].\n2. On line 345, it is mentioned that to eliminate the impact of OOD, modeling needs to be performed on all subsets of candidates. What is the computational overhead when a fault is associated with many anomalies?\n\n[1] Meng, Yuan, et al. \"Localizing failure root causes in a microservice through causality inference.\" 2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS). IEEE, 2020."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes an approach: IDI that identifies root causes based on two criteria: (1) the node exhibits anomalous behavior (anomalous condition), and (2) if the node had normal values, the target node would not be anomalous (fix condition). It contrasts this approach with the pre-existing methods that use counterfactuals from Structural Causal Models (trained on historical data)\u2014often unreliable for rare anomalies (as they are OOD). IDI relies on interventional estimates within the training distribution (in reality the validation distribution)."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The three strengths of the paper are: \n1. Whatever is presented in the paper is technically sound. Although I believe some clarifications are needed and the contribution is not enough (i.e., more content can be added). \n2. **Main Strength:** The experiment section is very impressive. It is thorough and the ablation studies are performed well. \n3. The main research question addressed in this paper i.e., counterfactual estimates can push SCMs to OOD regions, and sampling from in-distribution to intervene to circumvent this issue, is an important contribution to the community. However, originality of this idea is unclear. \n4. Monitoring cloud KPIs for anomalies and root cause diagnosis in them is an important application. Showing the experiments on \"Petshop\" is impressive. In a way the paper is written to cater the root cause diagnosis needs of Petshop. However, the authors need to provide some insights on cloud KPIs either in Introduction or Preliminary to make the paper even stronger for engineers."
            },
            "weaknesses": {
                "value": "The methodological contribution of the paper is a major weakness. There are some weaknesses in the experiment section as well. \n1. Sampling the latent exogenous variable from the (validation set) distribution as opposed to inverting the function $f_i$ (abduction) is important but a minor methodological tweak that might not warrant a full research paper. It is also unclear if \"in-distribution intervention\" approach is novel or has been proposed in the literature. The authors must show an analogy of the abduction step as a probability distribution. And then they should show how sampling from that distribution is different from the proposed approach. \n\n2. Most parts of the papers are pre-existing knowledge except the two theorems. Even the difference between the two theorems is the abduction step, which is intuitive from the definitions of counterfactual vs intervention (equation 4, 5, 6). \n\n3. Section 5 is over-explained (especially for the unique root cause case). The definitions of \"anomaly condition\" and \"fix condition\" is well established before that section. The only contribution I see in section 5 (i.e., the paper's approach) is \"Assumption 1\" and \"Multiple root causes explained using Shapley values\". \n\n4. \"Low variance of exogenous variables $\\epsilon_i$ is the most important assumption of this paper. It should have been reflected in the title, and the abstract. Furthermore, the variance of $\\epsilon_i$s are not mentioned for the experiments, thus not providing transparency if the experiments satisfied this assumption. \n\n5. No experiment is done for \"high variance\" of exogenous variable. Therefore a reader cannot get insights if counterfactual method is better for such cases (as opposed to IDI). Please conduct a study to compare IDI and counterfactual methods for a range of variances (of latent exogenous variable) -- clearly showing the boundary cases where counterfactual outperforms IDI. \n\n6. In table 2 and table 4, a lot of the recall values for the proposed IDI approach seems 1.00, which raises questions on the data itself. The authors must provide insight if the data is biased towards their methodology. Just mentioning IDI outperforms the baseline is not enough, since the results are too good to be true. Please do the following -- (1) provide details on the data generation process including the randomness in the graph generation, (2) do multiple replications of the study and report the standard deviation of the recall values. If the authors have a reason to believe that the dataset might be biased for their proposed approach, they must provide reasons and mention the experimental limitations explicitly. \n\n7. The authors must provide examples or case study to show that their assumption of low variance of latent exogenous variable is true. In page 2, authors mentioned that they are \"typically small in practice\" without any references, or examples. This is not acceptable for a technical publication. The authors are required to provide specific examples and/or case studies to support their claim of low variance of exogenous variables. The authors must also show how these claims are true in the experimental dataset (both synthetic and Petshop). \n\n8. The paper is too verbose. The authors repeat the two conditions (anomaly and fix) over and over again, in multiple sections without new content. I suggest the authors to reduce the length of the current version of the paper. Add a few explanations to weakness pointed out be me and other reviewers. The authors need to understand that SCMs and causality might be jargon for a lot of readers. They need to explain everything using simpler notions of either probability or graphs like Figure 1 or Figure 2. \n\n9. The paper's formatting is not acceptable. Page 5, Page 6 mentions theorem numbers are 5 and 6 and in supplementary they are written as theorems 10, 11 respectively. Similarly Theorem 6 is referring to Theorem 10, which is not a real thing in the main text of the paper. Similarly, in page 4, under \"training setup\", the symbol $D^{trn}$ is used which is not defined at all. The paper uses a lot of abbreviations and do not expand it. Some abbreviations like IDI are used even in abstract. These are incorrect formatting. I will assume the authors can make changes in rebuttal phase to these issues. \n\n10. In section 3.3., for \"1. Anomaly Condition\", the authors write \"prior methods....\". Without references, such statements must be avoided and in my honest opinion unacceptable for a technical manuscript. \n\n11. Remark on page 6 is not comprehensive. The authors must remove the \"CIRCA\" reference and explain only their method. Otherwise, it digresses from the context. \n\n12. The authors mentioned in page 7 that their work uses \"Z-score\". Please provide some preliminary knowledge on Z-score and highlight where is it used ?"
            },
            "questions": {
                "value": "1. Why did the authors used the phrase \"auto-regressively\" at multiple places in the paper ? Is the data assumed to be time series ? Is the author referring to topological order as \"auto-regressive\" ? \n\n2. In page 9, for non lin non-invertible SCMs, the authors wrote \"but without additive noise\". Is non-additive noise the only way to induce non-invertibility in SCMs ? \n\n3. In page 7, under multiple root causes it is mentioned \"However, one problem is that applying fixes to any subset $\\alpha$ of ....\". This statement is not clear. This statement is the main reason behind using Shapley values and also the primary contribution of your multiple root cause subsection. Please rephrase this statement and explain it in simpler words. \n\n4. I understand that literature uses the phrase \"disrupted local causal mechanism\" and/or \"abnormal $\\epsilon_j$ for \"Anomaly Condition\". How are they all the same thing? Is it because under anomalous $x_j$, $\\epsilon_j$ is OOD ? The authors must provide explanation to this in the paper. \n\n5. **Important Question:** If I take the sample mean of $\\tilde{\\epsilon_{j+1}}$ for a large enough sample size, will it or will it not converge to the $\\hat{\\epsilon}_{j+1}$ ? -- equation 4, 5, 6\n\n6. In page 9, in the paragraph mentioning \"Generating the Oracle SCM $\\mathcal{S}$\", it is mentioned that the \"Cloud KPIs are usually positive\". Why ? If thats a fact, give references. If thats an assumption, mention it explicitly. \n\nI will wait for the rebuttal. Please address both weaknesses and questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an algorithm for diagnosing the root causes of anomalies in cloud-based systems. It addresses limitations in traditional counterfactual-based approaches by using in-distribution interventions on structural causal models to identify root causes with enhanced robustness and accuracy. By avoiding out-of-distribution issues common in counterfactuals, it achieves better performance in terms of robustness and root cause accuracy, as validated through experiments on synthetic and benchmark datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper provides a solid theoretical foundation for IDI, including error bounds and conditions where IDI surpasses counterfactual methods.\n\n- Experimental results consistently show that IDI outperforms baselines, highlighting its effectiveness and robustness in root cause diagnosis."
            },
            "weaknesses": {
                "value": "- The presentation is complex and may be challenging to follow, particularly in Section 3, due to the heavy use of notation. Adding examples to clarify key concepts would improve readability.\n\n- While IDI demonstrates strong performance on synthetic and benchmark datasets, further validation in diverse, real-world industrial systems would strengthen its practical applicability.\n\n- The focus is on accuracy, but runtime and latency evaluations are limited. A discussion of computational overhead and potential optimizations for large-scale deployment would increase its relevance."
            },
            "questions": {
                "value": "- Could counterfactual methods still be preferred over IDI in certain cases or types of systems? If so, can you give insights on how to choose between these approaches? \n\n- Is IDI sensitive to variations in anomaly detection thresholds?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the In-Distribution Interventions (IDI) method to address the problem of RCD. The authors highlight two critical conditions in the RCD problem: the anomaly condition and the fix condition. The authors demonstrate that intervention-based approaches outperform counterfactual reasoning when tackling RCD problems, particularly by avoiding OOD errors commonly associated with counterfactual estimation. The proposed RCD algorithm uses an intervention-based approach to handle both conditions simultaneously. The evaluation results show the effectiveness of the IDI algorithm and its robustness in handling complex anomaly environments."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Strengths:\n- This paper proposes a novel in-distribution intervention algorithm to address the RCD problem, which simultaneously considers both the fix and anomaly conditions in RCD, demonstrating strong robustness in complex failure scenarios.\n- A well-supported theoretical proof. The authors demonstrate the advantages of the intervention method over counterfactual reasoning when dealing with OOD scenarios and apply this method to the fixed condition in the IDI method.\n- Based on the evaluation results, IDI demonstrates better performance and robustness than the existing baseline algorithms across different datasets.\n- Good reproducibility. The authors have open-sourced the code, data, and detailed instructions."
            },
            "weaknesses": {
                "value": "Weaknesses:\n- The OOD problem is not clearly presented. The OOD problem in RCD is an important motivation for the paper. However, I could not find a formal definition of OOD or in-distribution in RCD in the paper. The authors should provide a formal definition of OOD in the context of RCD early in the paper, e.g., in the introduction or background. Additionally, the authors should include an illustrative diagram contrasting OOD and in-distribution scenarios to help clarify this concept for readers.\n- More details about the construction of the SCM are necessary. In the paper, the authors directly apply an Oracle SCM rather than constructing it in an automated way, which is uncommon in existing RCD algorithms. The authors should carefully explain how the Oracle SCM was obtained and discuss whether this method can be generalized.\n- The description of CIRCA may have some minor issues. In CIRCA, the authors use the Descendant Adjustment technique to handle the anomaly scores of downstream nodes in the CBN from the root cause. Therefore, Descendant Adjustment can mitigate the issue with CIRCA, as mentioned in line 276 of the paper. The authors should describe this technique in the paper.\n- The authors need to provide a more precise overview of the IDI algorithm. Currently, the proof in Section 4 takes up too much space, while the description of the IDI algorithm in Section 5 needs to be more brief and mainly presented in text. The authors should include an overview figure in Section 5 to help readers understand the overall workflow of the IDI algorithm.\n- Lack of explanation of the Petshop dataset. In Table 1, the authors evaluate the results across three categories: Low, High, and Temporal. However, the paper needs to explain why these categories are separated for comparison or what observation in each category is meant to reflect. The authors should briefly explain these categories in the Petshop dataset, including why they are relevant to RCD and what insights they provide about the performance of different methods.\n- In Section 6.3, cases of Assumption 1 violations are evaluated. However, the paper does not explain the motivation for this evaluation or whether such violations occur in real-world scenarios. The authors should explain the real-world relevance of these violations and how common they might be in practice.\n- Lack of discussion on some existing counterfactual reasoning methods. Sage [1] proposed using CVAE to generate counterfactuals for RCD. The authors should discuss and compare this method in the paper.\n- Lack of case studies on IDI with OOD data. Although the experiments show promising results, the authors should at least present a case study where IDI is applied for RCD in an OOD scenario (e.g., step-by-step results of applying IDI to the OOD cases with intermediate outputs, a comparison of how IDI performs on OOD cases v.s. other methods) to validate its effectiveness on OOD data. \n- Shapley values are used for multiple root causes, possibly introducing high time complexity. The paper does not discuss the impact of this on scalability. The authors should discuss the computational complexity of their Shapley value approach and its implications for scalability in large-scale RCD scenarios, provide empirical runtime analysis, or discuss potential optimizations for improving efficiency.\n\n[1] Gan, Yu, Mingyu Liang, Sundar Dev, David Lo, and Christina Delimitrou. \"Sage: practical and scalable ML-driven performance debugging in microservices.\" In Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 135-151. 2021."
            },
            "questions": {
                "value": "- Can you provide a clear and formal definition of OOD in the context of the RCD problem?\n- How will the performance of IDI be affected if an Oracle SCM cannot be obtained? How can this algorithm be applied in real-world scenarios where an Oracle SCM is unavailable?\n- Will using the Shapley value reduce algorithm efficiency in large-scale RCD scenarios?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}