{
    "id": "mhCNUP4Udw",
    "title": "Graph Vision Networks for Link Prediction",
    "abstract": "Traditional message-passing neural networks (MPNNs) face challenges regarding limited expressive power and coarse-grained structural awareness in link prediction tasks. While heuristic structural features (SFs) have been instrumental in enhancing MPNNs' performance in these aspects, they typically offer insights from a fixed structural perspective, lacking adaptability to diverse real-world scenarios. In response to this need for flexible structural insights, we introduce Graph Vision Networks (GVNs). By integrating vision awareness into MPNNs for link prediction, GVN models can adaptively extract learnable visual structural features (VSFs), leading to significant performance improvements across seven commonly used link prediction datasets.",
    "keywords": [
        "Graph Neural Networks\uff1bLink Prediction\uff1bMultimodality"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "We propose Graph Vision Networks, which first incorporate visual structural features as novel structural features, to enhance message passing GNN for link prediction",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=mhCNUP4Udw",
    "pdf_link": "https://openreview.net/pdf?id=mhCNUP4Udw",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes the Graph Vision Networks (GVN) for link prediction, which is designed to deal with the potential limitation of HSFs that it can only be derived based on the pre-defined structural prior and thus lacks sufficient adaptability to diverse real-world scenarios.\n\nThe core idea of GVN is very simple, it interprets either a link-centered subgraph or a node-centered subgraph as visual images and then extracts visual features from them as the structure features."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The idea is simple and the experiments show the effectiveness."
            },
            "weaknesses": {
                "value": "1. The technical novelty is limited. \n2. The method is not convincing. It first transforms the graph data to visual modality and extracts the visual features as the structural features, which is expected to be more effective than the HSFs learned based on structural priors in graph modality. Intuitively,  the visual features are more capable of learning appearance features or semantic features. In contrast, the graph data should have more expressive power than the visual modality in terms of the structural features."
            },
            "questions": {
                "value": "It is suggested to given more theoretical analysis and qualitative comparison to show why the method can learn more effective structure features from the visual modality than the graph modality."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper focuses on the link prediction task. The authors introduce Graph Vision Network (GVN). By integrating vision awareness into MPNNs for link prediction, GVN models can adaptively extract learnable visual structural features (VSFs). Moreover, the authors propose two models under GVN framework: GVN-Link and GVN-Node. Experimental results demonstrate that the proposed method establishes new SOTA for link prediction."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1 The writing and the organization of this paper are generally OK.\n\n2 Integrating vision modality into MPNNs for link prediction sounds interesting."
            },
            "weaknesses": {
                "value": "1 The motivation for incorporating vision modality into MPNNs for link prediction should be better clarified and discussed. Why is this design effective? Any theoretical evidence? Maybe a dedicated section for this discussion could be valuable.\n\n2 The counterpart methods used for experimental comparison seem not SOTA enough. The authors should compare some 2024 SOTAs.\n\n3 Minor Issues:  Ln 32 on Page 1, \u2018Empiically\u2019 should be \u2018Empirically\u2019"
            },
            "questions": {
                "value": "See above weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a Graph Vision Networks (GVN) framework aimed at improving the expressive power of Message Passing Neural Networks (MPNNs) in link prediction tasks by integrating structural visual modalities. Extensive experiments on multiple datasets show that the framework exhibits potential in improving prediction accuracy and model robustness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Originality: The idea of embedding local structural information of graphs using visual models is innovative. \n\nQuality: The author has demonstrated good performance across multiple datasets, particularly in challenging large-scale graph datasets."
            },
            "weaknesses": {
                "value": "1. While the idea of using visual modalities to model local neighborhoods is novel, the techniques utilized in this manuscript are very simple. For instance, the use of simple attention mechanisms to integrate node and neighborhood features. \n\ufeff\n2. The author employs the graph visualizer (GV) to generate image modalities of subgraph structures. So what distinguishes the image modalities generated by GV for two isomorphic subgraphs? Are they random or identical? It appears that the improvement in representation learning performance is highly dependent on the effectiveness of GV.\n\ufeff\n3. The title and abstract of this manuscript are overly concise. It's hard to understand the work's significance and contributions.\n\ufeff\n4. The manuscript lacks a framework diagram to illustrate the proposed methodology, which could enhance clarity and comprehension.\n\ufeff\n5. The presentation of equations in the manuscript is uneven. For example, formulas in the PRELIMINARIES section are numbered, while those in the GRAPH VISION NETWORKS section are not, leading to potential confusion.\n\ufeff\n6. The writing quality of the manuscript requires improvement, with multiple errors. For instance, in the third paragraph of the INTRODUCTION, the quotation marks around \u201cidentity\u201d are incorrectly used."
            },
            "questions": {
                "value": "Please see the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The author noticed that the MPNN model based on message passing can only obtain coarse-grained structural feature information, which makes the model unable to adaptively model fine-grained structural features, which limits the expressive power of the model. Therefore, inspired by Das et al., the author proposed to use the visual modality of the graph to provide fine-grained structural features for the model, and proposed the GVN model. The model first generates edge-oriented k-order subgraphs and node-oriented k-order subgraphs based on the query node pairs, and visualizes these subgraphs as 2D images. Then the cross-attention model is used to fuse the image features with the node features of the graph, and finally the readout module is used to implement the downstream prediction task."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Well-written, clearly organized, and easy to read and understand\n2. The motivation of the article is clear. It is timely and necessary to use image modality for link prediction task on graphs.\n3. Evaluating the model's effectiveness on multiple datasets with different scale and types."
            },
            "weaknesses": {
                "value": "1. The innovation of the method proposed in the article is relatively neutral. The main innovation of this article is to classify and discuss link images and node images. The remaining designs are just stacking existing modules (GNN, cross-attention, ResNet). First, inspired by the prior work, the authors use images to express the local structure of the graph. Secondly, the article uses the existing pre-trained visual encoding model to extract image features. Finally, the fusion of visual features and graph structure features utilizes the existing cross-attention. \n\nI think the authors can further explore this idea in the following aspects. First, how to construct image representations of graph structures, such as the color and shape of nodes, etc. can be further explored. Secondly, how to construct effective image encodings of graphs instead of using existing pre-trained ResNet models can be explored. For example, can the features extracted by the visual encoder be used to reconstruct the local structure of the graph (regression graph adjacency matrix)?\n\n2. The article claims to construct an adaptive fine-grained structure feature. However, the article only uses the image modality of the graph structure (which may be considered a fine-grained graph structure representation, but I have doubts about this), and cannot express adaptability.\n\n3. There are some typos in the article, such as the period in line 025, the singular form of produce, and the misspelling of Empirical in line 032."
            },
            "questions": {
                "value": "1. What does $lO(\\cdot)$ mean in Section 4.3?\n2. There is already a projector in the formula on line 215, and there is another projector in the formula on line 220. The expressiveness of two linear projectors put together is the same as that of one projector because the product of two matrices is equivalent to one matrix.\n3. Why are there no mapping matrices $W_Q, W_K, W_V$ in cross-attention?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}