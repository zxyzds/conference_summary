{
    "id": "ga4LyaucKr",
    "title": "Learning-based Mechanism Design: Scalable, Truthful, and Continuum Approaches for Utility Maximization",
    "abstract": "Mechanism design is a crucial topic at the intersection of computer science and economics. \nThis paper addresses the automated mechanism design problem by leveraging machine learning and neural networks. \nThe objective is to design a **truthful**, **expressive** and **efficient** mechanism that maximizes the platform's expected utility, given that the players' types are drawn from a pre-specified distribution.\n\nWe present a general mechanism design model that captures two critical features: hidden information and strategic behavior. \nSubsequently, we propose the **PFM-Net** framework, which parameterizes the menu mechanism class by function approximation and identifies an optimal mechanism through ingenious optimization techniques. \nWe also provide both theoretical and empirical justifications for the advantages of our approach. \nExperimental results demonstrate the effectiveness of PFM-Net over traditional and learning-based baselines, \nenabling the PFM-Net framework to serve as a new paradigm for automated mechanism design.",
    "keywords": [
        "automated mechanism design",
        "differential economics",
        "function approximation",
        "mechanism representation"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "We propose a neural-network based automated mechanism design framework that is not only intrinsically truthful, but also behaves well when the problem size is large.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ga4LyaucKr",
    "pdf_link": "https://openreview.net/pdf?id=ga4LyaucKr",
    "comments": [
        {
            "summary": {
                "value": "This paper uses the MenuNet (Shen et al., 2018) idea to optimize a general quasi-linear objective over multiple players and multiple items. In particular, the feasible allocation set X is the product of the feasible allocation set for each individual player i, which implies that there is no constraint on the total supply of each item (each item could potentially allocate to multiple players).\n\nThe results are compared with other mechanisms empirically."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Unless I misunderstood the feasible allocation set, I didn\u2019t see much strength."
            },
            "weaknesses": {
                "value": "The problem being solved in this paper is a trivial extension of the MenuNet (Shen et al., 2018) to multiplayer setting with individual-wise allocation constraints. The key challenge of extending MenuNet to general multi-bidder setting is to handle the feasibility constraint properly (i.e., each item can only be allocated to at most one bidder). \n\nThis challenge is referred to as \u201cmenu compatibility\u201d and first solved by GemNet (Wang et al, 2024b), who solve the compatibility issue through a combination of a price adjustment and MIP (mixed integer program).\n\nThis paper, however, drops the only challenge of generalizing MenuNet to the multi-bidder setting. So I cannot see any real contribution to the literature (unless I misunderstood this part)."
            },
            "questions": {
                "value": "Please properly mention the key result of MenuNet in your second paragraph, and explicitly compare your approach with theirs."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "There has been a lot of recent research on designing revenue-optimal, strategy-proof auctions through the use of neural networks and machine learning tools. However, existing approaches often fall short of meeting all desired properties: exact truthfulness, expressiveness, and efficiency. For instance, RegretNet does not ensure exact truthfulness, AMA mechanisms lack expressive power, and MenuNet can be computationally inefficient. This paper presents PFM-Net, a framework designed to address all three objectives through a learning-based approach.\n\nThe authors propose a full-menu mechanism that uses neural networks to parameterize pricing functions\u2014determining how much agents are charged for specific bundles based on their valuations. This framework incorporates insights from economic theory, such as agent independence, convexity and monotonicity, to achieve incentive compatibility and a no-buy-no-pay rule to satisfy individual rationality. The optimization is an alternating process: first, allocations are optimized for the players given fixed pricing functions; then, the neural network parameters are adjusted to optimize revenue for the auctioneer.\n\nThe framework is initially evaluated in a single-bidder, multiple-goods setting. It is adaptable to other objectives, such as social welfare maximization. To demonstrate this flexibility, the authors include an experiment with a social planner setting involving multiple agents and multiple goods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1. PFM-Net leverages insights from economic theory, including agent independence, convexity, and monotonicity, to ensure incentive compatibility and no-buy no-pay rule to satisfy individual rationality. These designs seem to be an improvement over architectures presented in RegretNet\n\nS2. Avoidance of Explicit Menu Enumeration  \nTraditional menu-based mechanisms often require enumerating all possible menu options, which can be computationally prohibitive, especially as the number of items grows. For instance, even a deterministic mechanism for a single buyer with $m$ items would need $2^m$ menu options, creating scalability challenges. PFM-Net, however, avoids this by not requiring explicit enumeration of the menu. For each auction instance, it optimizes the agent's objective directly based on the pricing functions. This means allocations are determined dynamically by maximizing the agent\u2019s utility under the current pricing function, allowing the model to handle large settings without incurring the overhead of menu enumeration."
            },
            "weaknesses": {
                "value": "W1. Missing Baselines  \nRochetNet, the current state-of-the-art for single-buyer settings, should be included as a benchmark, as other methods generally reduce to RochetNet in this context, making it a sufficient point of comparison. Additionally, the optimal mechanism for up to six items is given by the SJA mechanism (referenced in the paper as Giannakopoulos and Koutsoupias). Please include this under OPT for $S_5$. This mechanism can be extended for larger m using a recursive formula, with results available up to m = 10 in the RegretNet paper, where it is also conjectured to be optimal. This makes SJA an essential baseline for evaluating the proposed approach.\n\nMoreover, it would be interesting to test the model\u2019s performance in a setting with a single additive bidder and two items, where the bidder's values are independently drawn from a Beta distribution (\u03b1=1, \u03b2=2). Prior work [2] has shown that the optimal mechanism in this setup involves an infinitely sized menu, providing a valuable test case. Additionally, including settings where randomization is essential would show how well this approach performs for non-deterministic settings.\n\nW2. Lack of Moderate/Large-Scale Experiments  \nThe paper currently lacks experiments involving moderate to large-scale settings. RegretNet already performs well with very low regret for the small scale settings shown in the paper. For smaller settings at least, one could consider Regretnet to be potentially exactly truthful. To fully demonstrate PFM-Net's advantages over regretnet, it would be beneficial to include tests with multiple agents and items (e.g., n,m\u22652) \n\nW3. Writing and Clarity  \nThe writing is generally clear and accessible until Section 4. I found myself frequently switching between the appendix and the main paper to fully understand the methodology. Including the learning algorithm or a pseudo-code in the main paper would improve readability. Additionally, clearly noting in the main text when specific technical details, such as the handling of over-allocations, are explained in the appendix would be helpful as well.\n\n---\n\n### References\n[1] Yiannis Giannakopoulos and Elias Koutsoupias. Duality and optimality of auctions for uniform\ndistributions. In Proceedings of the fifteenth ACM conference on Economics and computation,\npp. 259\u2013276, 2014.\n\n[2] Daskalakis, C., Deckelbaum, A., and Tzamos, C. (2017). Strong duality for a multiple-good monopolist. Econometrica, 85:735\u2013767"
            },
            "questions": {
                "value": "This approach shares notable similarities with RegretNet. Rather than having separate networks for allocation and payment, PFM-Net combines these into a single payment network with hardcoded constraints like convexity and monotonicity. The training process is also comparable: the proposed approach alternates between computing the allocation (the analogous step is finding the misreport in regretnet) and optimizing the payment function (updating the weights of RegretNet). Equation 11 is the also the same as RegretNet's objective (with the missing L2 penalty term). \n\nFor larger settings, it\u2019s likely that PFM-Net would encounter similar issues to RegretNet with gradient-based allocation computation. Testing the proposed approach's exact violation (i.e., the term involving ReLU in Equation 11) at test time, preferably with multiple initializations of x, would be informative. For smaller settings, RegretNet incurs very low regret (and recovers optimal solutions wherever known). For larger configurations, further evaluation is needed to verify that PFM-Net\u2019s allocation computation can overcome these scaling challenges that RegretNet faces in computing the misreports."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores deep learning methods applied to mechanism design, focusing on multi-buyer, multi-item scenarios where $ n $ represents the number of buyers and $ m $ the number of items. The primary focus is on menu mechanisms. For example, in a single-buyer context, a menu mechanism is defined by a set $ X \\subseteq [0,1]^m $, where each allocation vector $ \\vec{x} \\in X $ indicates the probability that the buyer will receive each item. This mechanism is coupled with a pricing function $ p(\\vec{x}) $, and the buyer selects the allocation vector that maximizes their utility.\n\nThe authors attempt to establish that the class of truthful mechanisms is equivalent to the class of menu mechanisms with convex pricing functions (I found this proof somewhat difficult to follow, as I elaborate in the Weaknesses section.)  Building on this theoretical foundation, the authors design a neural architecture. While the main text does not provide details on the architecture or algorithm, the core idea is to use a convex function to represent the payment function, which is optimized during training."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper's experiments suggest that the authors may be onto something promising with their architectural design. The revenue results in Table 1 indicate strong performance relative to baselines like UM-GemNet, showcasing the potential effectiveness of their approach."
            },
            "weaknesses": {
                "value": "- I found the proof of the main theoretical result, Theorem 3.4, challenging to follow. This theorem claims that the class of truthful mechanisms is equivalent to the class of menu mechanisms with convex pricing functions, but several parts of the proof were confusing:\n  - On line 1018, it\u2019s unclear what is meant by treating $ x_i^d $ and $ p_i^d $ as free variables $ x_i $ and $ p_i $. First, since these are functions, it\u2019s confusing to call them variables, and second, because they are defined by the input mechanism $ M^d $, it\u2019s even more confusing to refer to them as \u201cfree\u201d variables.\n  - On line 1022, I\u2019m unsure what is meant by saying $ \\tilde{u}_i(t) $ is constant with respect to $ x_i $ and $ p_i $. By definition, $ \\tilde{u}_i(t) $ depends on $ x_i^d $ and $ p_i^d $, so it doesn\u2019t appear to be constant with respect to these terms.\n  - In Equation (5), the supremum is taken over $ t_i $, but the line before mentions $ p_i $ should be minimized. The connection between this minimization and the supremum in Equation (5) is unclear.\n  - The paragraph titled \u201cProve the first statement\u201d on line 1049 is also difficult to interpret. Since $ \\tilde{u}_i(t) $ is a function of $ x_i^d $ and $ p_i^d $, whether $ \\tilde{u}_i(t) $ is convex should depend on the properties of $ x_i^d $ and $ p_i^d $ (e.g., whether or not they themselves convexity).\n- Section 4 would benefit from more information on the algorithm.\n- In terms of experiments, prior work (e.g., UM-GemNet) evaluates performance on a wider range of distributions beyond $ U([0,1]) $. This paper should expand its set of benchmarks to allow for a more comprehensive comparison.\n- There are also numerous grammatical issues throughout the paper. I recommend using a tool like Grammarly to identify and correct these. Lastly, it\u2019s advisable to avoid terms like \u201cingenious\u201d in the abstract when describing one\u2019s own method."
            },
            "questions": {
                "value": "Could you please address my confusions regarding the proof of Theorem 3.4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "There has been much recent progress in using neural networks for mechanism design. Current successful approaches are either not fully expressive, are restricted to a single agent, can't guarantee strategyproofness, or require costly postprocessing. The authors of this paper present a new method that is fully expressive and works in general settings, and is strategyproof, yet is claimed not to require costly postprocessing. The key idea is rather than searching for allocation/payment rules as functions of types, they work in the dual space and compute a pricing function over each possible allocation of the mechanism. They show that truthfulness is equivalent to a convexity property of this pricing function. There are many good methods for enforcing convexity of neural networks, so the authors use these to train neural networks representing the pricing function on a couple mechanism design problems, and achieve good performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper tackles a key problem in mechanism design and tries to push things forward in a very creative way. The core idea is clever and original. The authors do have some successful experiments and successfully prove many important mechanism design properties for their method."
            },
            "weaknesses": {
                "value": "# Presentation\n\nThe biggest weakness of this paper is in its presentation.\n\nThere are frequent grammar and usage errors, and it might be good to fix them, but these errors don\u2019t harm comprehension, so this is not so important.\n\nHowever, the organization and structure of the paper is extremely difficult to follow, far beyond the usual problems of space-limited conference papers. The definitions are unusual and non-standard, many points jump around frequently, the proofs are not well-organized, and I find myself trying to guess at what the authors are doing based on my knowledge of mechanism design, rather than learning it from the paper itself.\n\nOverall the presentation is confusing enough that I have a hard time following the paper, even though I completely understand all background work. There are many good aspects to this work but the poor presentation makes it hard to really tell what\u2019s going on.\n\n# Experiments\n\nOne of the main exciting things about automated mechanism design is its use in solving the wide-open problem of revenue-maximizing DSIC auction design. There are many auction design benchmark problems in the papers the authors cite (GemNet, RegretNet, AMA) but the authors choose to compare to none of these benchmarks, instead picking only two problems, one of which is less interesting (single buyer) and one of which is not standard.\n\nIf the authors could run their method on some of the same benchmarks as in the RegretNet/GemNet papers, and hopefully produce similar plots visualizing the learned mechanisms, it would significantly increase confidence that their method works well. I think any claimed competitor to GemNet must tackle some of those problems shown in the GemNet paper (e.g. recover the Yao auction, or 2x2 uniform additive buyers, at the very least).\n\n# Full Expressiveness and Supply Constraints\n\nThe authors claim their method is fully expressive, which seems to be true as far as I can tell. It is also true of GemNet (their main point of comparison).\n\nThe main weakness they point out with GemNet is that it requires a costly post-processing step on a discrete grid. The purpose of this post-processing step is to achieve \u201cmenu compatibility\u201d \u2014 during learning GemNet may choose menus such that when all bidders choose their favorite menu item, some items are oversold, and the post-processing step adjusts prices to prevent this.\n\nSo the key point is the post-processing step is only required for problems where menu compatibility is an issue. But in both of the problems studied in the experiments in this paper, menu compatibility would not be an issue \u2014 GemNet also is fully expressive and requires no postprocessing!\n\nAlthough they don\u2019t deal with it in experiments, in principle their method can deal with supply constraints of the sort that show up in auctions. This is discussed quite briefly in section F.1 (I think it belongs in the main body or at least should be mentioned more prominently as it is very important). However there are unresolved issues to make this work in practice. Perhaps these issues can be overcome more efficiently than the GemNet postprocessing, but the paper gives no evidence one way or the other. (Also, side note \u2014 equation 13 seems not to \u201ctype check\u201d \u2014 a vector proj(x, X) is subtracted from a scalar)\n\nOverall as it stands, the authors seem to have pursued a clever idea with some partial success, but this is not a good paper as a paper. I think the authors should significantly rewrite it, as well as pushing experiments much further, and deal more straightforwardly with the issue of handling supply constraints."
            },
            "questions": {
                "value": "Although this review is somewhat harsh, I do want to give the authors encouragement for pursuing a clever and original idea, and I think in the future this could become a great paper.\n\nThe authors are welcome to respond to any points in my review they want to, and to correct any errors or misunderstandings of mine. I would be happy to engage in discussion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}