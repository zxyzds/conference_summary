{
    "id": "TKuYWeFE6S",
    "title": "PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization",
    "abstract": "Reinforcement learning-based methods for constructing solutions to combinatorial optimization problems are rapidly approaching the performance of human-designed algorithms. To further narrow the gap, learning-based approaches must efficiently explore the solution space during the search process. Recent approaches artificially increase exploration by enforcing diverse solution generation through handcrafted rules, however, these rules can impair solution quality and are difficult to design for more complex problems.  In this paper, we introduce PolyNet, an approach for improving exploration of the solution space by learning complementary solution strategies. In contrast to other works, PolyNet uses only a single-decoder and a training schema that does not enforce diverse solution generation through handcrafted rules. We evaluate PolyNet on four combinatorial optimization problems and observe that the implicit diversity mechanism allows PolyNet to find better solutions than approaches that explicitly enforce diverse solution generation.",
    "keywords": [
        "neural combinatorial optimization",
        "learning to optimize",
        "reinforcement learning",
        "routing problems"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "A novel approach for neural combinatorial optimization that uses a single-decoder model to learn multiple complementary solution strategies.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=TKuYWeFE6S",
    "pdf_link": "https://openreview.net/pdf?id=TKuYWeFE6S",
    "comments": [
        {
            "comment": {
                "value": "Thank you very much for reviewing our paper and providing helpful feedback! We are happy that you find the performance comparison on different CO problems solid and convincing.\n\nPlease let us address your two remaining weaknesses.\n\n> a) Related works are not well-organized. As a important part to let readers aware the background, the motivation and the priority of this paper, Neural CO methods should be organized in a way that these points are clearly outlined.\n\nWe agree that giving a good overview on the related work is of critical importance. As such we are very motivated to address this weakness and improve the literature review. Could you kindly provide some more details on how we can improve the related work section? Do you think that the related work section does not provide enough details? Are there works that we missed to include? Is the high-level structure of using 3 paragraphs (NCO, Diversity mechanisms in RL, Diversity mechanisms in neural CO) insufficient?\n\nWe are confident that we will be able to improve the related work section during the rebuttal based on your feedback!\n\n> b) Fow now, the scale of the CO problems PolyNet could address is no more than 300, which makes me curious about the performance of PolyNet on larger instances (#nodes > > 300). From my angle, the exploration ability is especially needed in large scale problems.\n\nThe version of PolyNet presented in this paper is not well suited to scale to very large instances without additional modifications, however our approach is nonetheless a significant contribution in its current form despite this limitation for two reasons: 1) A large number of real-world scenarios exit that require solving CVRP(TW) instances with fewer than 500 nodes. In fact, even more recent state-of-the-art, hand-crafted approaches from the operations research literature [1, 2] focus only on problems with 100 to 1000 nodes. On these medium-sized problems, our approach offers state-of-the-art performance and outperforms all other machine learning-based approaches. 2) Going forward, our method can be integrated into divide-and-conquer approaches that divide larger instances into smaller subproblems (see e.g., [3]). For these approaches, our method could function as a powerful subsolver, resulting in improved performance even on very large-scale instances.\n\n[1] Vidal, T. (2022). Hybrid genetic search for the CVRP: Open-source implementation and SWAP* neighborhood. Computers & Operations Research, 140, 105643. \\\n[2] Christiaens, J., & Vanden Berghe, G. (2020). Slack induction by string removals for vehicle routing problems. Transportation Science, 54(2), 417-433. \\\n[3] Ye, H., Wang, J., Liang, H., Cao, Z., Li, Y., & Li, F. (2024, March). Glop: Learning global partition and local construction for solving large-scale routing problems in real-time. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 38, No. 18, pp. 20284-20292)."
            }
        },
        {
            "summary": {
                "value": "PolyNet introduces a novel approach to enhancing exploration in neural combinatorial optimization (CO). Unlike traditional methods that enforce diversity via handcrafted rules, PolyNet employs a single-decoder model that inherently learns multiple strategies, facilitating more effective search and solution quality. The paper demonstrates PolyNet's superior performance across several benchmark CO problems, such as TSP, CVRP, and CVRPTW, outperforming state-of-the-art methods both in speed and solution quality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The use of a single-decoder model that can learn multiple strategies simplifies the training pipeline and reduces computational overhead compared to multi-decoder systems.\n\n- The model's training schema, which emphasizes inherent diversity, makes it adaptable to various CO problems beyond simple routing tasks.\n\n- The authors provide useful insights into the impact of their design choices, such as the effectiveness of not forcing diverse first moves."
            },
            "weaknesses": {
                "value": "- While starting from pre-trained models boosts training efficiency, this reliance could limit applicability in cases where such pre-training is not feasible or available.\n\n- While PolyNet demonstrates strong results in routing tasks, its effectiveness in other CO problem domains (e.g., scheduling or knapsack) has not been deeply explored.\n\n- The paper does not discuss how PolyNet handles instances where input data is noisy or incomplete, a common occurrence in practical applications.\n\n- The impact of different hyperparameter settings on model performance is not fully analyzed, which could be critical for real-world applications requiring fine-tuning."
            },
            "questions": {
                "value": "1. How would PolyNet perform when extended to non-routing CO problems, such as job scheduling or knapsack problems?\n\n2. Can you elaborate on the potential methods for improving PolyNet\u2019s scalability to handle larger problem instances?\n\n3. What are the specific limitations of PolyNet\u2019s inherent diversity mechanism when applied to problem instances with different statistical properties?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To facilitate learning complementary solution strategies, this paper avoids forcing the initial action step. Instead, it enhances exploration by embedding it into the decoder as a bit vector. While experiments demonstrate performance improvements, the approach lacks novelty."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper is well-structured, presenting its content in a clear manner.\n2. A wide range of experiments are conducted to assess solution diversity."
            },
            "weaknesses": {
                "value": "1. The method of inserting additional vectors in the decoder is very similar to the idea of COMPASS [1], lacking sufficient innovation to significantly advance the field.\n2. The description of bit vectors is minimal, and there is no detailed analysis of how varying vector representations might impact performance.\n3. The fairness of comparing COMPASS with PolyNet+EAS in an experimental context is questionable.\n4. In [1], there is a big difference between COMPASS and EAS runtimes, but in this paper, PolyNet+EAS time is similar to COMPASS, please specify the reason.\n\n[1] Combinatorial optimization with policy adaptation using latent space search. NeurIPS 2023."
            },
            "questions": {
                "value": "1. The advantages of using bit vectors as supplementary vectors for insertion should be thoroughly analyzed, particularly in comparison to previous continuous potential vectors.\n2. In the experimental section, a more comprehensive explanation and analysis of performance concerning runtime are necessary."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This study, grounded in the POMO framework, introduces a straightforward yet impactful component: PolyNet. The component takes as input the concatenation of a set of binary vectors and the output from the decoder's multi-head attention layers. After processing through a series of linear layers and activation functions, the output is directly added to the output of the decoder's multi-head attention layers, thereby directly influencing the probability distribution of node selection. Analysis from the paper indicates that the newly added module helps to enhance solution diversity without the need for mandatory starting point selection as in POMO. Additionally, the authors assert that PolyNet can be integrated with EAS, and significant performance improvements can be achieved by updating only the newly added modules."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The authors have clearly articulated the framework and implementation of the method, with smooth writing.\n2. The tables and figures are presented clearly, and the experiments are comprehensive.\n3. Testing PolyNet on various combinatorial optimization problems (TSP, CVRP, CVRPTW, FFSP) demonstrates the good generality of the method.\n4. (As claimed by the authors) their method performs exceptionally well on instances of scale 100, 200, and 300 (Tables 1-3)."
            },
            "weaknesses": {
                "value": "PolyNet can enhance the diversity and optimality of solution sets, but the authors seem to lack an in-depth discussion on the principles behind the additional layers of PolyNet. This leaves me somewhat puzzled. The training process described in the paper adopts a method similar to Poppy, and the added linear layers, activation functions, and residual connections are common components in the Transformer architecture. The motivation for significant improvements by merely concatenating an additional binary array is not very clear."
            },
            "questions": {
                "value": "1. What is the design motivation behind the additional concatenated binary array $v$? Why can it significantly enhance diversity and optimality? If it were replaced with a column of random numbers, or if random perturbations were directly added to the input of the \"added layer,\" would the same effect be achieved?\n\n2. In Appendix Figure 6, a comparison is made between \"PolyNet w/o Added Layers\" and \"POMO with Added Layers.\" It would be better if a \"POMO\" without additional additions could be included for comparison. My question is, why does \"PolyNet w/o Added Layers\" perform significantly better than \"POMO with Added Layers\"? Is it due to differences in training methods? If so, it would be best to compare POMO with the new training method.\n\n3. Which contributes more significantly, the training method or the new structure?\n\n4. In combinatorial optimization, there is a class of problems specifically focused on diversity optimization, where multiple solutions need to be found simultaneously. Relevant papers include \u201cComputing Diverse Shortest Paths Efficiently: A Theoretical and Experimental Study\u201d and \u201cA Niching Memetic Algorithm for Multi-Solution Traveling Salesman Problem.\u201d The work presented in this paper seems particularly suited for such scenarios, and I hope to see more discussion on this topic."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes PolyNet, which aims to reinforce the exploration training and testing of Nueral CO methods. In particular, a representive NCO method POMO is used as the playground in this paper. The idea behind this paper is quite simple: adding a neural network module which contains MLP layers besides the  main structure of POMO, termed PolyNet layer. PolyNet layer  provide exploration ability by letting its input as the node embeddings and a binary context coding. Using different binary context codings, the output of PolyNet layer add different information to the output of POMO hidden layers. By training on moderate instances, PolyNet show state-of-the-art performance on several CO problems (#nodes < 300). Besides, the authors demonstrate the exploration ability of PolyNet during the training and testing is different from the common practice in existing works: forcing diverse first action selection."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea behind PolyNet is simple yet effective. The methodology part is easy-to-follow. The experimental results for performance comparison on different CO problems are solid and convincing. The ablation studies that explain the solution diversity in PolyNet are with good demonstration."
            },
            "weaknesses": {
                "value": "There are two major weaknesses:\n\na) Related works are not well-organized. As a important part to let readers aware the background, the motivation and the priority of this paper, Neural CO methods should be organized in a way that these points are clearly outlined. \n\nb) Fow now, the scale of the CO problems PolyNet could address is no more than 300, which makes me curious about the performance of PolyNet on larger instances (#nodes > > 300). From my angle, the exploration ability is especially needed in large scale problems."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}