{
    "id": "tpGkEgxMJT",
    "title": "Improving Large Language Model Planning with Action Sequence Similarity",
    "abstract": "Planning is essential for artificial intelligence systems to look ahead and proactively determine a course of actions to reach objectives in the virtual and real world. Recent work on large language models (LLMs) sheds light on their planning capability in various tasks. However, it remains unclear what signals in the context influence the model performance. In this work, we explore how to improve the model planning capability through in-context learning (ICL), specifically, what signals can help select the exemplars. Through extensive experiments, we observe that commonly used problem similarity may result in false positives with drastically different plans, which can mislead the model. In response, we propose to sample and filter exemplars leveraging plan side action sequence similarity (AS). We propose GRASE-DC: a two-stage pipeline that first re-samples high AS exemplars and then curates the selected exemplars with dynamic clustering on AS to achieve a balance of relevance and diversity.  Our experimental result confirms that GRASE-DC achieves significant performance improvement on various planning tasks (up to ~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on average). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a validator, we are able to even boost the performance by 18.9% more.\nExtensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.",
    "keywords": [
        "planning with LLM",
        "in-context learning (ICL)",
        "action sequence"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "We propose GRASE-DC, an iterative exemplar re-sampling method to boost LLM planning performance using in-context learning (ICL). It achieves ~10-30 absolute points of accuracy improvement on various tasks and different LLMs.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=tpGkEgxMJT",
    "pdf_link": "https://openreview.net/pdf?id=tpGkEgxMJT",
    "comments": [
        {
            "summary": {
                "value": "The authors propose GRASE-DC, an approach to enhance planning capability in LLMs by improving ICL exemplar selection. Unlike traditional methods relying on semantic similarity, which can lead to false positives, GRASE-DC utilizes AS similarity to identify exemplars with closely aligned plan structures. The GRASE-DC pipeline comprises two stages: re-sampling high-AS exemplars and dynamically clustering them to balance relevance and diversity, yielding more accurate planning guidance with fewer exemplars. An iterative variant, GRASE-DC*+VAL, further boosts performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The proposed approach is both intuitive and shows good empirical performance as it selects exemplars based on AS similarity, providing the similar types of exemplars as the test task.\n2. The empirical evaluation is extensive, spanning four PDDL tasks and a natural language planning task, and it tests the method across different base models, showcasing the robustness of the approach."
            },
            "weaknesses": {
                "value": "1. The effectiveness of GRASE is highly dependent on the quality of initial plans generated by the LLM with randomly selected exemplars; poor initial plans can lead to compromised AS-based exemplar selection.\n2. For setups with validator access, a baseline comparison with rejection sampling could improve the analysis. E.g., under a similar validator query budget, the validator can be used to reject the invalid plans and select the better plan generated by the approach with random exemplars."
            },
            "questions": {
                "value": "Refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes GRASE-DC, which is a new 2-stage pipeline for selecting examples for in-context learning of planning tasks based on action sequence similarity. In the \u2018Generative Re-sampling of Action Sequence Similar Exemplars\u2019 stage, GRASE-DC ranks and selects ICL exemplars with high action sequence similarities. In the \u2018Dynamic Clustering\u2019 stage, GRASE-DC performs AS-based clustering to further curate improved dynamic sets of examples that strikes a good balance between diversity and relevance to further improve the LLM\u2019s planning ability. This paper also reports comprehensive experiment results on four PDDL tasks to empirically show the performance gain brought by GRASE-DC to different LLMs."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- **Originality**: This paper has good originality in that it proposes to focus on action sequence similarity instead of the traditional criteria based on the semantic similarity between task descriptions when performing example selection for LLM in-context learning of planning tasks.\n- **Quality**: This paper has high overall quality. Most of the steps in the proposed GRASE-DC pipeline are very clearly described and discussed in the methodology section, and Section 3 as well as the appendix also provide comprehensive empirical results and analysis to support the main claim of the paper.\n- **Clarity**: This paper is generally well-written and the ideas are generally well-presented in the paper. The clarity of both the writings and the figures are good. Please see the Weaknesses section in this review for things to improve.\n- **Significance**: The main intuition behind GRASE-DC is relatively simple and straightforward, but its performance gain shown in the empirical evaluations is solid."
            },
            "weaknesses": {
                "value": "1. In the formula on Line 141, shouldn\u2019t there be a \u2018|      |\u2019 symbol around \u2018LCAS(A_i, A_j)\u2019? According to the previous description, LCAS(A_i, A_j) is a sequence, not a number.\n2. The notation and definition of the core concept \u2018Action Sequence Similarity\u2019 should be defined more clearly and strictly in the paper. Currently some mentions of AS are a little vague and confusing."
            },
            "questions": {
                "value": "In Figure 3, why on some tasks the planning accuracies of GRASE+VAL are higher than those of AS for certain numbers of examples? Is there any intuition behind this observation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the action sequence as a key signal to measure the similarity between exemplars in planning tasks. Based on this finding, the paper introduces a two-stage pipeline, GRASE-DC, to select similar in-context examples while maintaining diversity and relevance. Experiments on both PDDL and natural language planning tasks show the promising performance of the proposed exemplar selection strategy. Further analysis includes OOD generalization and some options to replace AS when considering efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This paper breaks away from traditional task similarity and instead utilizes action sequence similarity to select exemplars for ICL, enhancing the model's planning performance, which is simple yet effective.\n- The GRASE-DC shows great generalization performance on more complex tasks.\n- Endeavors have been made to pursue the efficiency of the exemplar selection process."
            },
            "weaknesses": {
                "value": "1. The method of using clustering algorithms to improve the relevance and diversity of the selected exemplars has been proposed by other paper [1] before.\n2. The selected evaluation datasets lack some real world simulated tasks such as ALFWorld, Mind2Web, ScienceWorld, etc.\n3. Though the VAL mechanism is referenced from other paper, the authors are suggested to introduce it briefly in the paper to enhance the readability as VAL appears frequently in the paper.\n\n[1] Automatic Chain of Thought Prompting in Large Language Models, ICLR 2023"
            },
            "questions": {
                "value": "- Why are MLP and BPE-Proxy more efficient than LCAS, as encoding the action sequence to embeddings itself requires inference time?\n- Why is Sim$_{AS}$ designed as shown in line 141, whereas based on experience LCAS($A_i$, $A_j$) should be squared?\n- How is the decision made for the iterative version of GRASE-DC on whether to iterate? Since we do not have test data trajectories and answers, based on efficiency, iteration is only needed in case of errors."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes GRASE-DC, a two-stage selection algorithm designed to identify effective and diverse exemplars from candidate plans, thereby enhancing in-context learning effectiveness. In the first stage, GRASE calculates the Action Similarity (AS) between different plans based on their sequence of actions. In the second stage, DC refines the selected exemplars using dynamic clustering based on AS, ensuring a balance between relevance and diversity. The effectiveness of GRASE-DC is demonstrated through extensive experiments, which show significant performance improvements over baseline methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "[+] The overall structure is compact and clear.\n\n[+] The use of four benchmark domains provides convincing results.\n\n[+] The analysis section effectively discusses the efficiency of different methods for calculating Action Similarity (AS)."
            },
            "weaknesses": {
                "value": "[-] My concern is that such methods may be difficult to adopt in real-world applications. I feel that in-context learning is not the optimal solution for improving the planning capabilities of LLMs, especially considering the existing o1. In-context learning is more suitable for quickly adapting the model to output desired formats or providing it with hints to follow, rather than using very long in-context prompts to enhance the model's capabilities.\n\n[-] The paper should at least compare some baseline approaches that use the similarity between plans. In the LLM-agent area, there are papers that employ similar ideas, using a similarity metric to select trajectories from the memory module. Implementing such a simple baseline would not be difficult and could provide a better complement to the experiments, enhancing their convincingness."
            },
            "questions": {
                "value": "1. How do you justify that only the sequence of actions is important for capturing the plan properties? Have you considered including intermediate states (i.e., the object states and information) in the plan?\n\n2. Could you provide a detailed pseudocode for GRASE-DC? I am a bit confused with the steps in Diversity Clustering."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}