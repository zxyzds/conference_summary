{
    "id": "XK5jYtLMXl",
    "title": "Convergence Of Consistency Model With Multistep Sampling Under General Data Assumptions",
    "abstract": "Diffusion models accomplish remarkable success in data generation tasks across various domains. However, the iterative sampling process is computationally expensive. Consistency models are proposed to learn consistency functions to map from noise to data directly, which allows one-step fast data generation and multistep sampling to improve sample quality. In this paper, we study the convergence of consistency models when the self-consistency property holds approximately under the training distribution. Our analysis requires only mild data assumption and applies to a family of forward processes. When the target data distribution has bounded support or has tails that decay sufficiently fast, we show that the samples generated by the consistency model are close to the target distribution in Wasserstein distance; when the target distribution satisfies some smoothness assumption, we show that with an additional perturbation step for smoothing, the generated samples are close to the target distribution in total variation distance. We provide two case studies with commonly chosen forward processes to demonstrate the benefit of multistep sampling.",
    "keywords": [
        "Consistency models",
        "diffusion models",
        "learning theory"
    ],
    "primary_area": "learning theory",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=XK5jYtLMXl",
    "pdf_link": "https://openreview.net/pdf?id=XK5jYtLMXl",
    "comments": [
        {
            "summary": {
                "value": "This paper gives the convergence of the consistency model multistep sampling procedure. The authors establish guarantees on the distance between the sample distribution and data distribution in terms of both Wasserstein distance and total variation distribution. The established upper bound requires only mild assumptions on the data distribution."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The theoretical results seem solid\n2. This manuscript is well-written and easy to follow"
            },
            "weaknesses": {
                "value": "1. The primary contribution stems from the utilization of a modest assumption. Nevertheless, this mild assumption still appears to have limitations in practical applications.\n2. There is no empirical evaluation to verify the theoretical findings."
            },
            "questions": {
                "value": "1. It would be beneficial if the authors could illustrate the main contribution through a table.\n2. Assumption 1 also relies on the distribution $P_{\\tau_i}$ . It still seems to have limitations in practical applications. What advantages does it offer over other theoretical assumptions?\n3.  It would be better if the authors could offer empirical evaluations to validate these theoretical findings.\n4. The primary challenge lies in how to translate the approximate self-consistency measured under the training distribution into the quality of the generated samples. What technical breakthrough has been achieved to address this challenge?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper analyzes the distribution generated from the consistency model. It studies the upper bound of the total variation distance and Wasserstein distance between the generated distribution to true data distribution when the consistency model is approximately self-consistent. It then provides two examples that illustrate the main results."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper provides the upper bounds for the consistency model and discusses two examples to give the exact bounds. It studies the analytical aspect of the diffusion models and uses the results to provide insights into optimal choices for sampling. It contributes to the development of diffusion models."
            },
            "weaknesses": {
                "value": "The major concern is the tightness of the upper bounds discussed in the paper. It seems to me that given $R$ is never zero, the right-hand side of Equation (7) will be bounded away from zero. This might be because either $\\hat{P}^{(N)}_0$ will not be asymptotically close to the true date distributions or the bound can be further tightened. Or is there a non-trivial condition that the right-hand side of Equation (7) would be small?"
            },
            "questions": {
                "value": "a. It would be nice to also discuss the bounds when self-consistency holds. \n\nb. The authors have provided two examples of case studies with specific upper bounds. It would be great to run the simulation on these two examples and see if the upper bound of calculated distance $W_2(\\hat P_{t_{N}}, P_{\\text{data}})$ matches the theories.\n\nc. Is there a general rule of choosing optimal $N$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the convergence of consistency models when the training process is approximately self consistent under the training distribution. This analysis involves mild data assumptions and applies to multi-step sampling for a family of forward processes. Sample quality guarantees are provided in terms of Wasserstein distance and total variation distance for target distributions that have particular properties. Finally, two multi-step sampling case studies are presented to demonstrate the implications of the results in this paper for two common forward processes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper provides a good overview of background and related work on score-based diffusion models and consistency models.\n- The contributions in this paper regarding sample quality guarantees in Wasserstein distance and total variation distance appear to be novel and technically sound.\n- The high-level ideas for the proofs of the main results in this paper are presented reasonably well in Section 4."
            },
            "weaknesses": {
                "value": "- While some of the implications and benefits of the results in this paper are presented as case studies from a theoretical standpoint in Section 3.3, there are no empirical/experimental results to accompany this discussion. The lack of such empirical results detracts somewhat from this paper, and adding these results would help to further validate the benefits of the authors\u2019 results.\n- To connect the results in this paper to real-world scenarios, it would be help for the authors to connect the data distribution properties used in Theorems 2 (bounded support) and 3 (light tail) and the data distribution smoothness assumption in Theorem 4 with some examples of real-world datasets commonly used to train consistency models that satisfy these properties/assumptions."
            },
            "questions": {
                "value": "It would be helpful for the authors to respond to the weaknesses pointed out above. If the authors don\u2019t currently have experimental results that they can share, I suggest that they add such results to a future draft of this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper studies the convergence of consistency models theoretically. They provide bounds on the Wasserstein distance between target and estimated data distribution using such models for as most general assumptions as they can (specifically, for bounded density support and light tail density). They transfer this to total variation distance under smoothness assumption, giving convergence guarantee. Moreover, they also derive theoretically the benefit of an additional sampling step in the specific case of Ornstein-Uhlenbeck process. They provide advance in the theoretical understanding of empirical observations about consistency models which are (i) an additional step can significantly improve the quality of the sample and (ii) more steps only bring limited gains."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The will of bringing theoretical claim about convergence of a method + analytical explanation of empirical observations is highly welcomed. It allows better understanding of flaws and successes of a method. Especially in the field of diffusion models, and specifically here consistency models which are SOTA methods for generative modeling. Consistency models aim to improve over classical diffusion, tackling the sampling efficiency. Bringing theory and explainability in convergence of such method is valuable.\n\n- The paper base their claims on previous observations in the literature and try to improve in several ways. \n\n- It is welcomed to see work that tries to provide theoretical claim with light assumptions, making them as most general as possible.\n\n- Interpretability (in the case of multi-step sampling) is thrilling."
            },
            "weaknesses": {
                "value": "As a general comment, I found the goal laudable. However, the paper is really hard to follow and lacks clarity in its presentation and writing. I will try to pack similar remarks in thematic groups here below.\n\n**General confusion**\n\nThe introduced notations are overly complex and sometimes confused. \n- Line 50-71 : The inline paragraphs bold titles are weird. Why not using clear separated paragraphs? (I know that you may lack space, I propose getting rid of useless repetition below).\n \n- Score-based generative model notations are hard to follow.\n\n    - Is the switch between $P_t$ and $p_t$ needed?\n\n    - Operator $\\mathcal{D}$ is not useful and can be simplified by just using the noise schedule kernel and the distribution defined line 143.\n\n    - Why $x_{t_i}$ and not just $x_i$? e.g. : line 165 where we have $x_{t_0} = x$, usually denoted $x_0$ in the literature. But on the other hand, you define a $\\Delta \\tau$ accounting for step between consecutive time, ... all of that can be simplified. I understood the paper but found it hard due to intertwined overly complex notations (at least understandable but making it hard to follow without making tons of back and forth in the text to check each piece). The time subscript is sometimes omitted, confusing also the reader concerning what we are talking about.\n\n- The paper lacks structure and the reader is too often referred to other part of the paper. The authors introduce a lot of preliminaries 'useful for later', 'used in theorem x'... leading to a lot of repetition in the main text (in the abstract, the contributions, the theorem in themselves,...). It would be better to have more structured blocks. E.g. : Contributions can be shortened, more summarized, leaving the reader to the proofs in the main text.\n\n- The consistency function introduced line 167-168 is used on distribution line 211. Of course the author precise **after** that the operation is now on distributions, but this further confuse the notations and highlight again a general confusion.\n\n- It would be nice to introduce Wasserstein distance and total variation somewhere. Even in Appendix, it's ok. Indeed, In theorem 2 you use $W_2$ and then make a sort of connection with the KL line 187 that pops from nowhere. It lacks proper explanation.\n\n- Lines 246-255 repeats a lot with preceding text.\n\n**Results**\n\nAnalytical results are interesting. However they stick to theory and it's hard to identify their contribution in practice. Could you add, even for small toy problem, experiments that illustrate your findings. Indeed, you derive bounds given several assumptions. Use those for a toy example. It is crucial to link theory to practice to motivate the worth of your work. Experiments might also help identify potential yet to study problems/questions. Your results are sometimes specific (e.g. you stick to VP and VE SDE in case study 2) which is normal for theoretical derivations, please extend the scope of your work a bit. Even if you show that your conclusions do not hold at all in other setup, it might be valuable as later study can try to understand why? Or in the opposite, if your claims extend in other setup, it might raise the question of generalization of your work.\n\n**Found typos**\n\nI list below typos I detected, just to correct them (I might have missed some).\n\n- Uppercase in contributions (lines 76-92).\n\n- Space after a point line 169 **. At a high level ...**.\n\n- Line 262: ~insteading~ -> instead of.\n\n- Where is Theorem 1? At the beginning of page 6 you directly have Theorem 2 but there are no Theorem 1. Keep separated counting between Assumptions, Lemmas and Theorems.\n\n- Line 367: ~forawrd~ -> forward.\n\n- Line 368: ~nosie~ -> noise.\n\n- Line 377: Without loss of generality preferred to not clear *W.l.o.g.*.\n\n- Line 450: ~samling~ -> sampling.\n\n**Suggestions**\n\n- Remove the references to theorems in your contributions. Focus only to the key message of each of them and the rest will follow in the main text.\n\n- line 165: remove the 'as a function of t'.\n\n- Remove parenthesis around 'ground truth' line 166.\n\n- Putting ':' inside a sentence often make it long and hard to follow (can be more structured). E.g. : lines 170-172\n\n- Combine Theorem 2 and 3. Can't we see theorem 2 as a specific case of 3 when $C \\to 0$?\n\nFor me, the paper is not ready yet. The main causes being the presentation and lack of illustrations."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}