{
    "id": "D1gKsJagiq",
    "title": "Dual-Stream Adapters for Anomaly Segmentation",
    "abstract": "Anomaly segmentation aims to identify pixels of objects not present during the model\u2019s training. Recent approaches address this task using mask-based architectures, but these methods have high training costs due to the large transformer backbones involved. While vision adapters can help reduce training costs, they are not specialized for this task, leading to inferior performance. In this work, we propose Dual-Stream Adapters (DSA), a vision adapter tailored for anomaly segmentation. DSA extracts both in-distribution and out-of-distribution features via (i) an anomaly prior module that produces separate initial embeddings for the two streams; and (ii) a dual-stream feature refinement that implicitly guides the separation of in-distribution from out-of-distribution features. We train DSA using a novel hyperbolic loss function that provides supervised guidance for differentiating in-distribution and out-of-distribution features. Experiments on various benchmarks show that dual-stream adapters achieve the best results while reducing training parameters by 38\\% w.r.t. the previous state-of-the-art.",
    "keywords": [
        "Adapters",
        "Anomaly Segmentation"
    ],
    "primary_area": "applications to robotics, autonomy, planning",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=D1gKsJagiq",
    "pdf_link": "https://openreview.net/pdf?id=D1gKsJagiq",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a ViT adapter designed specifically for anomaly detection in semantic segmentation. The approach begins by extracting multi-scale features using a ResNet convolutional stem. Two distinct sets of learnable encodings are added to these features to specialize them for in-distribution (ID) and out-of-distribution (OOD) learning. These initial features are then fused with ViT backbone activations through a series of cross-attention layers and feed-forward networks, maintaining separate streams for ID and OOD features throughout the entire downstream path. The model is trained using an uncertainty-based hyperbolic loss function, where features are projected into hyperbolic space: OOD features are attracted towards the origin of the Poincar\u00e9 ball, while ID features are repelled away from it.\n\nThe authors evaluate their dual-stream adapter on road-driving anomaly detection benchmarks, comparing its performance to other ViT adapters and alternative outlier detection methods. Additionally, they conduct an ablation study to assess the impact of individual components of their proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1) Method is simple and more parameter efficient than existing outlier detection methods.\n2) The method preserves ID performance well."
            },
            "weaknesses": {
                "value": "1) Mixed results in terms of OOD detection on different datasets, both in comparison to fully fine-tuned models, but also different adapter types.\n2) I do not agree that using void/background class makes this training self-supervised, as there is explicit supervision in terms of labelling pixels into this additional class. Furthermore, the method could not be used on datasets that do not have ignore regions. It would maybe be better to follow the convention of using the term \"auxiliary data\". It  would be useful if this was reflected in the organization of Table 3. \n3) Missing methods in ood-detection tables. e.g. [a] is the current leader on SMIYC-RA\n4) Some things about the method are still not clear -> see questions.\n\n[a] Delic et al., Outlier detection by ensembling uncertainty with negative objectness, BMVC 2024"
            },
            "questions": {
                "value": "1) How are the encoder and adapter features integrated before being passed to the decoder as described in Equation 3?\n2) Is the background class utilized in the computation of L_{mask} and L_{class}\u200b?\n3) Is the convolutional module within the anomaly prior module also fine-tuned? Was it pretrained, and if so, how? What specific ResNet variant is used?\n4) Can you provide detailed specifications of the Cross-Attention and Feed-Forward Network (FFN) modules used in the adapters?\n5) How is the void/background class incorporated into L_{ubhl}? At what stage is the ground truth label applied?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper aims to reduce the high training cost of the transformer-based anomaly segmentation model. The authors introduce the Dual-Stream Adapter (DSA) to tackle this issue, specifically designed for anomaly segmentation tasks. The DSA comprises two main components: an anomaly prior module and a dual-stream feature refinement module. The anomaly prior module is responsible for learning both in-distribution and out-of-distribution features through separate feature-level encodings. Meanwhile, the dual-stream feature refinement module enhances and integrates these features with the robust representations derived from a frozen Vision Transformer backbone. Additionally, the architecture employs a hyperbolic loss function to guide the learning process effectively. The authors carried out extensive experiments across five datasets, demonstrating their proposed model's effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "+ The paper is clearly structured, featuring well-organized paragraphs and accessible figures that enhance comprehension.\n+ The design of the proposed Dual-Stream Adapter is sound and well-motivated."
            },
            "weaknesses": {
                "value": "- The experiments conducted were compared to several competitors; however, the values reported in Table 3 do not align with those in the original publications. This inconsistency raises questions about the validity of the experimental outcomes. It is highly advisable for the authors to verify the accuracy of the reported experiments to ensure reliable results.\n\n- It appears that there is an inconsistency between Figure 3 and equations (6) and (7). It would be beneficial to verify their accuracy.\n\n- It would be interesting to analyze the amount of training time that can be saved due to the reduction in trainable parameters.\n\n- There are some related papers [A-B] that have not yet been cited in the current version.\n\n    [A]  Yuanpeng Tu, Yuxi Li, Boshen Zhang, Liang Liu, Jiangning Zhang, Yabiao Wang, Cairong Zhao: Self-Supervised Likelihood Estimation with Energy Guidance for Anomaly Segmentation in Urban Scenes. AAAI 2024: 21637-21645\n\n    [B] Tom\u00e1s Voj\u00edr, Jir\u00ed Matas: Image-Consistent Detection of Road Anomalies as Unpredictable Patches. WACV 2023: 5480-5489"
            },
            "questions": {
                "value": "This paper is well-structured and has a clear motivation. However, a significant concern arises from the experiments reported, as the values presented appear inconsistent with those in the original publications. At this stage, I prefer to take a cautious approach to the rating and await the author's response before reaching a final conclusion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel adapter architecture for anomaly segmentation. The architecture incorporates two key architectural components: anomaly prior modules and dual-stream feature refinement tailored to improve anomaly segmentation. The anomaly prior\nmodule learns to extract the initial ID and OOD features that are refined and improved by passing through a set of dual-stream feature refinement blocks. It introduces an uncertainty-based hyperbolic loss to explicitly learn the ID and OOD features. The results on several datasets in terms of some metrics show the effectiveness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "+ a novel adapter architecture for anomaly segmentation. It designs anomaly prior modules and dual-stream feature refinement tailored to improve anomaly segmentation. \n+ The results on several datasets in terms of some metrics are the SOTA."
            },
            "weaknesses": {
                "value": "- The definaton of this task is unclear. How to define the Anomaly regions. For example, I put the first input of Fig. 5 into the ChatGPT and ask it to indicate the abnormal regions. It responses: \"\nFrom the image, it appears to show a traffic checkpoint or roadblock scene with a few police officers, some cones marking the road, and vehicles either being stopped or passing through the checkpoint. To analyze any potential abnormal regions, I would need specific criteria for identifying abnormalities, such as:\nTraffic flow: Are there any unusual movements or traffic behavior?\nObjects: Are there any misplaced cones, vehicles, or people?\nSecurity concerns: Is there anything out of place, like suspicious behavior or unmarked vehicles?\nIf you're looking for more detailed insights, could you clarify what type of abnormality you're focused on\u2014whether it's safety, traffic irregularities, or something else?\"\nThis answer is more reasonable, since the anomaly regions can be different in different settings.\n\n-The above example gives another question. The current multimodal large language model already achieves better responses.\n\n- The preposed method lacks novelty, and it is mainly combined by Vit adaptors with cross-attention."
            },
            "questions": {
                "value": "Based on the above the weaknesses, I have the following questions: \n\n- What are the key criteria or benchmarks used to evaluate anomaly detection in your scenario?\nDefining the task clearly with precise criteria is critical. How do you plan to measure the model's success in detecting abnormal regions?\n\n- What are the distinguishing features of your method compared to existing multimodal models?\n\n- How does the model handle the contextual differences in anomaly definitions?\nSince anomalies are highly context-dependent, is your model trained to recognize such context? How does it deal with shifting or ambiguous definitions of normalcy versus anomaly?\n\n- Are there plans for improving the generalization and adaptability of the model?\nFor instance, using domain adaptation techniques or fine-tuning the model on specific datasets related to the task could improve its performance in different scenarios."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}