{
    "id": "yfkvUJEY6i",
    "title": "Learning Disease Progression Models That Capture Health Disparities",
    "abstract": "Disease progression models are widely used to inform the diagnosis and treatment of many progressive diseases. However, a significant limitation of existing models is that they do not account for health disparities that can bias the observed data. To address this, we develop an interpretable Bayesian disease progression model that captures three key health disparities: certain patient populations may (1) start receiving care only when their disease is more severe, (2) experience faster disease progression even while receiving care, or (3) receive follow-up care less frequently conditional on disease severity. We show theoretically and empirically that failing to account for disparities produces biased estimates of severity (underestimating severity for disadvantaged groups, for example). On a dataset of heart failure patients, we show that our model can identify groups that face each type of health disparity, and that accounting for these disparities meaningfully shifts which patients are considered high-risk.",
    "keywords": [
        "fairness",
        "equity",
        "bias",
        "health disparities",
        "disease progression",
        "bayesian model"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We propose an interpretable Bayesian model that captures and accounts for three types of multiple health disparities, and we prove that failing to account for disparities leads to biased estimates of disease severity.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=yfkvUJEY6i",
    "pdf_link": "https://openreview.net/pdf?id=yfkvUJEY6i",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a disease progression model that uses observed symptoms to model the progression of a patient's latent severity. Compared with previous research, it accounts for three types of health disparities: initial severity, disease progression rate, and visit frequency. The proposed method is identifiable and shows good performance on a private dataset."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper studies the important topic of predicting disease progression by capturing the disparities between patients."
            },
            "weaknesses": {
                "value": "1. The proposed method appears to be a variant of a hidden Markov model (HMM). Instead of using transition probabilities in HMM, it employs simple functions to describe transitions between states and outcomes. This simplification might limit the model's ability to capture the complex dynamics of disease progression.\n2. The directed acyclic graph, the selection of functions between observed and hidden variables, and the specific types of disparities incorporated in Section 3 seem overly simplistic and heuristic. The paper lacks detailed reasoning or motivation for these design choices. Providing justifications or empirical evidence supporting these decisions would enhance the credibility of the model.\n3. The paper adopts a linear representation solely because \"it provides an interpretable characterization of the trajectory.\" However, real-world disease progression often involves intricate, nonlinear relationships between variables. Relying solely on a linear model may lead to suboptimal performance and may not capture the true underlying patterns, potentially undermining the trustworthiness of the explanations. Exploring nonlinear models could offer better performance and more reliable interpretations.\n4. The empirical results are based on a private dataset with a relatively small number of subjects (n=2,942) and only four features. This raises concerns about the model's generalizability to other datasets. I recommend validating the model on public EHR datasets such as MIMIC or UK Biobank to assess its broader applicability. Furthermore, the comparisons are limited to simple baselines like linear regression, quadratic regression, principal component analysis, and factor analysis. Evaluating the model against state-of-the-art methods, including neural networks, RNNs, and transformers, would provide a more comprehensive assessment.\n5. Insufficient Evidence of Superior Performance:\n   - The model's explainability is only qualitatively assessed using medical knowledge. Incorporating quantitative evaluations or user studies could strengthen the claims about interpretability.\n   - The model does not show (significant) improvements over the baselines in reconstruction and predictive tasks. Additionally, the absence of error bars or statistical significance tests makes it challenging to determine if the differences are meaningful. If the authors can include the code, my confidence in the results will be higher."
            },
            "questions": {
                "value": "1. Regarding function $f$ in line 135, is it a stationary function over the progression of severity -- that is, is it the same for every $Z_t$? If so, can you provide a justification for this assumption?\n2. There are hundreds, if not more, types of disparities among patients. Why do you believe that the three disparities used in your paper are the most significant or important?\n3.  In the methodology section, the author mentions the need to pin a group $a_0$ first. How did you choose this particular group, and does selecting a different $a_0$ affect the performance of your model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this work, the authors propose a Bayesian disease progression model that explicitly accounts for 3 types of disparities concerning health. The model contains several subgroup-specific parameters to account for inequalities in health. The authors provide a strong theoretical analysis of the model, as well as analyses of simulated data and a real application for heart failure patients."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper has several interesting ideas\n- the addressed problem is very important\n- the model is well explained, and the theoretical analysis seems strong\n- the authors provide an extensive empirical analysis, with interesting insights"
            },
            "weaknesses": {
                "value": "However, the paper suffers from several flaws. I am really willing to increase my grade if those points are addressed, but as it is, the contribution of the model compared to existing strategies, in terms of performance is really unclear.\n- the baselines seem quite weak. The authors report that several indicators are important, like the visit frequency. I am not sure to understand from the manuscript which features the baselines include, in particular do they include demographics information? and not sure either that PCA or FA are the best tools to do feature engineering. In particular all those approaches are linear, so they can not model interactions between demographics and other features. Maybe considering tree-based methods would be relevant here, with an appropriate feature engineering process. I know that prediction is not the end-goal of the model, but this constitutes the only \"measurable\" performance indicator.\n- the ablation studies are interesting, but they should also be conducted on the real-data application, to assess the variation in predictive performance, because it is not very convincing that data simulated with a model would be less accurately represented by a different model. \n- additional baselines to consider, both on simulated and real data it would be interesting to compare the performances with models that account for demographics characteristics differently (with one type of disparity for instance)"
            },
            "questions": {
                "value": "- can the authors add stronger baselines, both from classical machine learning and from the literature of disease progression with health disparities? With a better description of the feature engineering and alternative feature engineering strategies. As it is, the paper shows measurable health disparities of several types, but it is not clear that it is really important for the overall disease understanding\n- can the authors extend the ablation study to the real dataset? or to datasets simulated with alternative data generation processes?\n- can you describe more clearly the metrics used? there are several variables in Xt, how is the RMSE and MAPE aggregated over all of them?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a Bayesian hierarchical, linear model of disease progression that captures well known disparities in an interpretable way, while maintaining identifiability. The authors show on a simulated data set that the model can correctly identify the relevant parameters and that accounting for disparities is important to correctly estimate progression. They then demonstrate the utility on a real world data set, showing predictive ability, reconstruction compared to factor analysis and PCA and consistency with medical knowledge."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Alleviating health disparities and fairness w.r.t. clinical algorithms is an important aspect of machine learning for health and the impact of disparities on disease progression modeling is important\n- Interpretability and estimating effects of disparities and covariates on disease progression is clinically meaningful"
            },
            "weaknesses": {
                "value": "- While the model is interesting from a clinical perspective, I am not sure this is the right venue for this publication due to limited technical novelty\n- Very limiting disease progression trajectory due to linear assumption in time. A patient can therefore not experience worsening and improvement on their disease trajectory\n- The proofs show that not taking into account disparities will bias the result, however other (non-linear) disease progression models can take \"baseline\" covariates like ancestry, effectively conditioning the probability of the latent progression $z$ on $A$ as well. Comparisons to models like these are necessary to underline the claims.\n- The authors need to compare the disease progression modeling with other state of the art methods of inferring latent disease trajectories. It is not clear how well more realistic disease trajectories are captured and how the model compares to SOTA models on this task.\n- For the synthetic data it would be helpful to also use data not sampled from the same architecture as the model under consideration, but more complex disease progressions to examine how well the model can infer these despite the relatively simple assumptions"
            },
            "questions": {
                "value": "- For a continuous A, does there have to exist a reference value a_0 for which $\\mu(a_0) = 0, \\sigma(a_0) = 1$?\n- Is the second disparity mentioned a disparity because there might be worse clinical care for each ancestry group? Or is this supposed to capture biological differences? Wouldn't the point of any disease progression model with ancestry as a covariate be to infer disparities in disease progression rates?\n- What happens if some of the disparities are unmeasured? How well can the model infer the correct disease progression e.g. in simulations where some of the disparity variables are not shown to the model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a Bayesian modelling strategy to model disease evolution while accounting for three sources of biases present in medical data."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is well written, easy to read and tackles an important problem: improving modelling when disparities mark model. The paper presents theoretical justification and thoroughly evaluates the proposed methodology on both synthetic and real-world data."
            },
            "weaknesses": {
                "value": "The model makes assumptions upon the expression of disparities while being identifiable. The underlying process must verify the assumptions. It would be beneficial to discuss further how realistic and/or common these assumptions are. An analysis of a misspecified model when the underlying generating process does not meet these assumptions would be valuable."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}