{
    "id": "FGSgsefE0Y",
    "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents",
    "abstract": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for their potential to deliver emotional value and facilitate sociological research.\nHowever, existing studies are primarily confined to the textual modality, unable to simulate humans' multimodal perceptual capabilities.\nTo bridge this gap, we introduce the concept of Multimodal Role-Playing Agents (MRPAs), and propose a comprehensive framework, MMRole, for their development and evaluation, which comprises a personalized multimodal dataset and a robust evaluation method.\nSpecifically, we construct a large-scale, high-quality dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single or multi-turn dialogues.\nAdditionally, we present a robust evaluation method, MMRole-Eval, encompassing eight metrics across three dimensions,\nwhere a reward model is trained to score MRPAs with the constructed ground-truth data for comparison.\nMoreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of MMRole-Agent and highlight the primary challenges in developing MRPAs, emphasizing the need for enhanced multimodal understanding and role-playing consistency.\nThe data, code, and models will all be available.",
    "keywords": [
        "Multimodal Role-Playing Agents",
        "Large Multimodal Models"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "We propose MMRole, a comprehensive framework for developing and evaluating Multimodal Role-Playing Agents, comprising a personalized multimodal dataset and a robust evaluation method.",
    "creation_date": "2024-09-20",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=FGSgsefE0Y",
    "pdf_link": "https://openreview.net/pdf?id=FGSgsefE0Y",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a multimodal role-playing agent data collection and training framework. The authors use a wide range of images with different prompts to prompt GPT for image-text role-playing data, and fine-tune a QWen-VL-Chat model on the dataset after some automatic filtering."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* Simple, straightforward method that clearly works well given the model size and achieves the desired outcome.\n* Create a specialized Multimodal Role-Playing Agent is a novel idea.\n* Experiments demonstrate good performance given the finetuned model size.\n* Comprehensive evaluation."
            },
            "weaknesses": {
                "value": "* The major technical contribution seems to come from the MM roles dataset collection process. However, there does not seem to be much data curation beyond automated filtering.\n* Analysis seems to be mostly numbers and high-level results, with little technical/detailed insight."
            },
            "questions": {
                "value": "* The abstract and introduction highlights the \"specialized MRPA\" idea. Do we know much improvement comes from the specialized reward model vs. no specialized reward model?\n* Do the authors have any insight on the results generated by a finetuned MM role playing model? What works, what doesn't work, and what works better/worse than just prompting gpt?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a new dataset and evaluation framework for multimodal role-playing agents. They present several complementary evaluation metrics.\nThe authors evaluate several recent general purpose multimodal LLMs within this framework. In addition they evaluate a specialized model fine-tuned on their dataset."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is well-written and easy to follow.\nThe evaluation framework is highly relevant and potentially very impactful. The evaluation metrics are meaningful and the SOTA evaluation itself is comprehensive, providing a relevant set of baselines for future users of the dataset/framework."
            },
            "weaknesses": {
                "value": "I am not sure whether I could fully follow the approach to evaluation.\nImo it would be important to run a (at least limited) evaluation with human participants scoring the output. Building models that automatically evaluate outputs seems to be a circular approach.\n\nFurthermore, evaluting the MAE to compare between different evaluators might not adequately model differences between evaluators that are not visible in MAE."
            },
            "questions": {
                "value": "no questions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the concept of Multimodal Role-Playing Agents (MRPAs), develops a multimodal dataset (MMRole-Data) and evaluation framework (MMRole-Eval), and creates a specialized MRPA model, MMRole-Agent, achieving improved multimodal understanding and role consistency."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper constructs a complete multimodal dataset (MMRole-Data) and evaluation framework (MMRole-Eval).\n2. Testing across multiple LMMs lends credibility to the experimental results."
            },
            "weaknesses": {
                "value": "1.Overreliance on GPT-4 for Evaluation: While MMRole-Eval provides a stable evaluation mechanism, it heavily relies on GPT-4, introducing a degree of bias. The authors validated the MAE between GPT-4 (humans) and Reward Model (humans), demonstrating consistency between the reward model and GPT-4. However, comparing two MRPAs to see which performs better does not substitute for genuine human judgment on the quality of MRPA responses. While this reward model may help MMRole-Agent approach GPT-4\u2019s performance, its potential to surpass GPT-4 or elevate MRPAs to human-level capabilities remains debatable.\n2.Lack of Performance Comparison with Single-Modality RPAs: Although the concept of MRPAs is appealing, the absence of specific experimental comparisons makes it difficult to understand exactly where MRPAs improve upon performance or accomplish tasks that single-modality RPAs cannot achieve."
            },
            "questions": {
                "value": "Why are only 320 samples used as the validation set out of 23,520 samples, with the remainder used for training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a concept of Multimodal Role-Playing Agents (MRPAs), expanding traditional role-playing agents to tackle multimodal interactions. The paper introduce a framework (MMRole) including MMRole-Data and MMRole-Eval. The MMRole-Data is a large-scale, high-quality dataset with 85 characters, 11,000+ images, and 14,000 dialogues. The MMRole-Eval is a robust evaluation method with eight metrics across three dimensions: conversational skills, multimodal understanding, and role-playing qualities."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper first introduces the concept of Multimodal Role-Playing Agents (MRPAs), extending traditional role-playing agents to the multimodal domain, filling a gap in existing research.\n\n2. The MMRole framework includes both the construction of a dataset (MMRole-Data) and the design of an evaluation method (MMRole-Eval), covering eight metrics across dimensions such as fundamental conversational skills, multimodal understanding, and role-playing quality.\n\n3. The proposed MMRole-Agent demonstrates strong performance.\n\n4. The writing is good and easy to understand."
            },
            "weaknesses": {
                "value": "1. The paper lacks case studies, which could help illustrate MMRole-Agent's performance across diverse roles and dialogue scenarios.\n\n2. The paper mentions that character profiles undergo \"rigorous manual quality control,\" it does not provide detailed quality control standards or processes."
            },
            "questions": {
                "value": "1. Could you provide specific cases to analyze MMRole-Agent\u2019s performance under In-Test and Out-Test conditions? \n\n2. Could you explain the \"rigorous manual quality control\" process in character profile generation\uff1f\n\n3. Has the sensitivity of MMRole-Agent to different prompt templates been tested?\n\n4. Could you discuss the primary limitations of MMRole-Agent, especially in terms of challenges encountered in practical applications and possible directions for future improvements?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}