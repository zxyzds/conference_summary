{
    "id": "kpL66Mvd2a",
    "title": "Tree Search for Language Model Agents",
    "abstract": "Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation. However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks. \nTowards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments. \nOur approach is a form of best-first tree search that operates within the actual environment space, and is complementary with most existing state-of-the-art agents. \nIt is the first tree search algorithm for LM agents that shows effectiveness on realistic web tasks. \nOn the challenging VisualWebArena benchmark, applying our search algorithm on top of a  GPT-4o agent yields a 39.7\\% relative increase in success rate compared to the same baseline without search, setting a state-of-the-art success rate of 26.4\\%. On WebArena, search also yields a 28.0\\% relative improvement over a baseline agent, setting a competitive success rate of 19.2\\%. \nOur experiments highlight the effectiveness of search for web agents, and we demonstrate that performance scales with increased test-time compute.\nWe conduct a thorough analysis of our results to highlight improvements from search, limitations, and promising directions for future work.",
    "keywords": [
        "agents",
        "web navigation",
        "multimodal models"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "We develop an inference time tree search algorithm that improves the relative performance of LLM web agents by up to 39.7% on VisualWebArena and 28.0% on WebArena.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=kpL66Mvd2a",
    "pdf_link": "https://openreview.net/pdf?id=kpL66Mvd2a",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a tree search algorithm for improving the performance of language model agents. By implementing a best-first search approach that operates in the environment's actual state space, the authors enable LM agents to achieve multi-step planning and exploration during inference. Experiments are conducted on VisualWebArena and WebArena benchmarks with improved performance, showing that introducing search allows agents to perform better on complex tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Experiments are conducted on several practical benchmark datasets such as VisualWebArena and WebArena, showcasing its effectiveness in web-based tasks.\n\n2. The search algorithm is compatible with a variety of LM agents and does not require fine-tuning or retraining.\n\n3. Extensive hyper-parameter analysis is provided."
            },
            "weaknesses": {
                "value": "1. The search algorithm demands significant computational resources due to the increased number of environment interactions. This may limit its practical applicability in real-time or resource-constrained environments.\n\n2. The success of the best-first search depends heavily on the quality of the value function. Although self-consistency techniques were used, further improvements in the value function are needed for optimal performance.\n\n3. The paper briefly addresses the issue of destructive actions in search trajectories but lacks a comprehensive solution. This is a critical consideration for deployment in real-world web environments where irreversible actions are possible."
            },
            "questions": {
                "value": "1. How does the search algorithm perform on tasks with very high action complexity or longer required sequences? Are there any indications that increasing the search budget might lead to diminishing returns in such cases?\n\n2. Can the authors provide more details on how the environment resets are managed during backtracking? Specifically, what challenges arise, and how might these affect the agent\u2019s efficiency?\n\n3. What were the key considerations in selecting the self-consistency technique for the value function? How does this compare to alternative approaches like reinforcement learning-based value functions?\n\n4. Are there any safeguards or heuristics incorporated to prevent the agent from becoming stuck in specific repetitive or irrelevant actions during search?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a tree search algorithm for web agents.\n\nThe search algorithm expands states using best first search where the value of the state comes from LLM self-evaluation. Specifically, the value comes from self-evaluation of the parent state. This proceeds up to a max depth and search budget after which the algorithm linearly rolls out to complete the task. \n\nTheir results show that tree search can significantly improve LLM-based web agents. \n\nThey claim to be the first tree-search algorithm for web agents."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality: This paper proposes an original tree search algorithm for LLM based web agents. The paper also claims to be the first such algorithm.\n\nQuality: The paper is of high quality. The results are pretty strong and clear. \n\nClarity: The paper is generally clear and easy to follow. However, there could be some improvement here. \n\nSignificance: There has been a trend of applying tree search and test time compute across many applications LLMs can be applied to. So it is not surprising to see a tree search algorithm for LLM web agents. However, in a first to the flag sense, it is significant. \n\nThe results show that this is a meaningful route to improved performance and seems likely to inspire other works. It clearly clears the bar for publication significance. \n\nValue function approach seems smart: Multi-modal, Last d screenshots. Scores in 0, 0.5, 1 and averaging over multiple reasoning. This could be a source of a lot of noise but this seems to be a way of reducing that. The trade-off is more compute so the further balance is by only evaluating states when expanded, not when generated. \n\n\u201cwe generate 20 outputs from the model by prompting it with CoT reasoning (Wei et al., 2022), and aggregate the count of the action candidates. We use the top-b actions with the highest counts for branching.\u201d \u2028- This is a good way to generate distinct action candidates"
            },
            "weaknesses": {
                "value": "WebArena results do not look strong relative to other modern works. However, some of those works seem to be a bit over-optimized for the benchmark, whereas this work is more general. \n\nThere are some clarity issues to work out with the writing. \n\nThe section on destructive actions, seems highly speculative. This is a major weakness of the approach in that in real world settings it is difficult to conduct search with lots of back tracking required. It is not even clear to me how backtracking could be conducted in these situations even excluding destructive actions. \n\nAnother weakness of this method is that it involves more inference time compute."
            },
            "questions": {
                "value": "1)\nAlgorithm 1 has \u201cBacktrack and execute new actions to get to state s_p\u201d\n- How is this done in your implementation?\n\n2)\nAlgorithm 1 has \u201c\u201d\u201d\nfor i \u2190 1 to b \ndo: \n\tExecute a_ip to get to state s_ip\n\u201d\u201d\u201d\n- How do you execute multiple actions from the same state in a web environment? This is similar to the above question. Essentially, how is backtracking done?\n\n3)\nTab 2 shows GPT-4o gets 18.9% across the whole VWA benchmark. On the 200 question subset, the results without search are 24.5%. And with b=5, d=5 the results are 37% compared to 26.4% in table 2. This seems like a large discrepancy. Can this be attributed to the sampled questions? \n\n4)\nLine 405: \u201c(which is a sparse reward signal that returns either 0 or 1)\u201d\n- What about just showing the accuracy of the value function when the ground truth is available? I.e. Something like mean square error of the value function in cases when ground truth is available. \n\n5) \nHow is tie-breaking done? Seems like it would make sense to break ties by depth and/or by the number of \"votes\" during generation. \n\nSuggestions:\n\nAlgorithm 1 should be in main section of paper. It is easier to be able to refer to it in the method section. \n\n\u201cFor example, a search budget of 10 indicates that at most 10 nodes will be expanded, after which the agent will commit to and execute the trajectory with the highest value\u201d - This needs to be part of the algorithm. \nThe reader needs a place to be able to refer to and understand how the algorithm works. They should not need to comb through ablation results to know how the method works. \n\nLine 404: \u201cprompted zero-shot (with just the current observation)\u201d\n- Maybe note this is because LLaVa only accepts one screenshot\n\nThis is maybe nit-picky but wouldn't all the children of a state have the same value? In figure 1, (7) and (9) have different values. \n\n\u201cAlloted\u201d -> \u201callotted\u201d\n\nLine 483: backtrack -> backtracks\n\nFigure 1 should be referred to in the text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses a critical limitation of language models (LMs) used in autonomous Web agents, particularly their difficulty in performing multi-step reasoning, planning, and utilizing environmental feedback in decision-making tasks. The authors propose an inference-time search algorithm that enhances the decision-making capabilities of LM agents by incorporating a best-first tree search method. To handle the challenge of lacking clear cut rewards in the diverse environments of Web, they propose a model-based value function to guide best-first search. The proposed approach allows the agents to effectively explore and evaluate multiple action paths within interactive web environments, thereby improving their performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper adeptly addresses several critical challenges faced by LLM agents in real-world web environments: the difficulty in obtaining clear rewards, the accumulation of errors, and the complexity of multimodal interactive web environments. The motivation for this research is both meaningful and reasonable.\n2. The study introduces a tree search algorithm specifically tailored for LLM-based multi-step planning in web environments. This framework is both clear and straightforward.\n3. The authors provide qualitative examples of agent trajectories in Section 5.3, which significantly aids in understanding the operational principles and effectiveness of the proposed method.\n4. The paper is well-written, with clear and readable presentation of formulas, visualizations of figures and tables, and experimental results."
            },
            "weaknesses": {
                "value": "1. Lack of technical contribution. The integration of tree search techniques with LLM planning is not entirely novel, as there is existing research in this area, e.g., [1, 2, 3, 4]. Thus, the contribution of this paper in terms of technique novelty may need to be reconsidered, as it incrementally applies existing tree search-based LLM planning frameworks to the web agent domain.\n\n[1] Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models (Released in 6 Oct 2023)\n\n[2] When is Tree Search Useful for LLM Planning? It Depends on the Discriminator (Released in 16 Feb 2024)\n\n[3] LLM Self-Training via Process Reward Guided Tree Search (Released in 6 Jun 2024)\n\n[4] LiteSearch: Efficacious Tree Search for LLM (Released in 29 Jun 2024)\n\n\n2. Lack a specially designed evaluation method for value function. The authors evaluate the impact of different value functions on the success rate of the entire framework in order to select a best value function, as mentioned between lines 401 and 412. However, assessing value functions based solely on the overall framework's outcome might be indirectly influenced by various potential factors. It would be beneficial for the authors to propose a dedicated evaluation method for value functions, essentially allowing for a more stable and accurate selection process.\n\n\n3. The performance and credibility of the proposed framework seems limited, as observed in Table 2 (lines 324-341):\n- The use of different baselines across two different datasets raises questions about the credibility of the experiments.\n- On the WebArena benchmark, the authors only report the performance of two base LLMs augmented by their method, without the performance of the SOTA baselines augmented by their method, suggesting that the method may not universally integrate with diverse models or scenarios as claimed.\n- Since the base LLMs already perform sub-optimally, the observed improvements after involving the proposed method are not surprising.\n- The highest success rate achieved by the framework is 19.2% on the WebArena benchmark, which is considerably lower than multiple baselines, raising doubts about its efficacy.\n\n\n4. Some mentioned future works should have been addressed in this paper:\n- Integrating proposed search strategies into domain-specific SOTA baselines (mentioned as future work on lines 274 and 349).\n- Experiments with larger search budgets (mentioned as future work on line 377).\n- Mitigating the time cost of tree search-based LLM planning (mentioned as future work on line 502).\n\nFor instance, the study should report the performance of the domain-specific SOTA baselines augmented by the proposed method under the maximum step constraint setting used in the reported baselines, instead of just using the base LLMs and a small step constraint. Furthermore, addressing the time consumption of tree search for LLM planning is crucial for the feasibility of practical applications, making this an essential consideration.\n\nSimply involving these crucial issues into future work may lead to skepticisms about the credibility and robustness of this study."
            },
            "questions": {
                "value": "Please refer to the 'Weaknesses' section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a search-based approach to improve the performance of language model (LM) agents on realistic web automation tasks. Existing LM agents struggle with multi-step reasoning, planning, and using environmental feedback, which is crucial for success on open-ended web tasks. The authors introduce a best-first tree search algorithm that operates within the actual environment space and is complementary to existing state-of-the-art LM agents. The search procedure allows agents to explore a larger number of potentially promising trajectories at test time, reducing uncertainty through explicit exploration and multi-step planning. The authors evaluate their approach on the challenging VisualWebArena and WebArena benchmarks, demonstrating significant improvements over baseline LM agents and setting new state-of-the-art success rates."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The methodology presented in this paper is robust, as the application of tree search methods within a network environment proves to be an effective solution.\n2. The structure of the paper is logically organized, beginning with an examination of existing issues and specifically addressing the challenge of implementing multi-step reasoning in network environments.\n3. The authors propose a novel method, conduct rigorous testing, and perform comprehensive ablation studies.\n4. The explanations are articulated clearly and are easily comprehensible; the combination of diagrams and text effectively illustrates the improvements achieved by the proposed method.\n5. The experimental section is meticulously detailed, ensuring the reproducibility of the experiments, which enhances the credibility of the findings."
            },
            "weaknesses": {
                "value": "1. The authors' central concept is to apply tree search methods within a network environment to achieve enhanced performance. However, as tree search techniques are commonly used in other systems, this approach exhibits limited innovation. \n2. In Section 5.4, the authors acknowledge that this method may result in slow execution, a significant drawback often associated with tree search. Nevertheless, the paper does not present a comparison of execution times between this method and other approaches, nor does it provide an in-depth discussion of the temporal challenges involved. The discussion primarily revolves around the search budget c, yet c does not accurately reflect the time expenditure. Readers are more concerned with the issue of temporal efficiency rather than the selection of hyperparameters."
            },
            "questions": {
                "value": "1. In Figure 2, it can be observed that there is a noticeable improvement as the search budget c increases from 15 to 20. Have the authors attempted to experiment with a larger c? This might yield better results.\n2. The parameter c is set as the maximum search budget. Have the authors tested the average number of searches conducted for both successful and unsuccessful cases? It might be beneficial to use a larger search budget during testing and observe how the training performance improves as c increases."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}