{
    "id": "gqC0egRfWq",
    "title": "Theoretical Analyses of Hyperparameter Selection in Graph-Based Semi-Supervised Learning",
    "abstract": "Graph-based semi-supervised learning (SSL) is a powerful paradigm in machine learning for modeling and exploiting the underlying graph structure that captures the relationship between labeled and unlabeled data. A large number of classical as well as modern deep learning based algorithms have been proposed for this problem, often having tunable hyperparameters. We initiate a formal study of hyperparameter tuning from parameterized algorithm families for this problem. We obtain novel $O(\\log n)$ pseudo-dimension upper bounds for hyperparameter selection in three classical label propagation based algorithm families, where $n$ is the number of nodes, implying bounds on the amount of data needed for learning provably good parameters. We further provide matching $\\Omega(\\log n)$ pseudo-dimension lower bounds, thus asymptotically characterizing the learning-theoretic complexity of the parameter tuning problem. We extend our study to hyperparameter selection in modern graph neural networks. We bound the Rademacher complexity for tuning the self-loop weighting in recently proposed Simplified Graph Convolution (SGC) networks. We further propose a novel tunable architecture that interpolates graph convolutional neural networks (GCN) and graph attention networks (GAT) in every layer, and provide Rademacher complexity bounds for tuning the interpolation coefficient.",
    "keywords": [
        "graph-based semi-supervised learning",
        "hyperparameter selection",
        "sample complexity",
        "pseudo-dimension",
        "Rademacher complexity"
    ],
    "primary_area": "learning theory",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=gqC0egRfWq",
    "pdf_link": "https://openreview.net/pdf?id=gqC0egRfWq",
    "comments": [
        {
            "summary": {
                "value": "This paper delves into the theoretical analysis of hyperparameter selection in graph-based semi-supervised learning, specifically focusing on label propagation algorithms and modern graph neural networks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper presents a novel theoretical analysis of hyperparameter selection in graph-based semi-supervised learning, particularly for GNNs.\n- The theoretical guarantees can guide the design of efficient and robust hyperparameter selection methods in practice."
            },
            "weaknesses": {
                "value": "- The experiment in the main body of the paper is limited.\n- Considering the proposed GCAN is part of the central contribution of this paper, the comparison between GCAN and baselines should be included in the main body instead of the appendix."
            },
            "questions": {
                "value": "How do the proposed methods compare to existing hyperparameter tuning techniques, such as grid search and Bayesian optimization, in terms of efficiency and accuracy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies hyperparameter tuning in GNN frameworks through Rademacher complexity analysis."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The theoretical approach to studying hyperparameter tuning is interesting."
            },
            "weaknesses": {
                "value": "- The core Rademacher complexity analysis largely builds upon work from [1]\n- The paper's positioning is unclear - whether it aims to propose a new framework competing with GAT and GCN, or purely offers theoretical analysis of hyperparameter tuning\n\n- Results in Table 1 show minimal practical significance:\n\n  - Many means are identical with only slight interval differences \n  - Where differences exist, they appear negligible\n\n- The definition of $n$ is inconsistent between lines 140-145 (instances per problem) and line 295 (total labeled/unlabeled datapoints)\n- The independence of bounds from $n$ in Theorems 4.2 and 4.3 requires explanation\n- The rationale for GCAN's additional hyperparameter search isn't justified given the marginal improvements"
            },
            "questions": {
                "value": "**More Questions:**\n\n- Does this analysis extend to node classification or graph classification in GNNs?\n- Can this approach generalize to other hyperparameter tuning scenarios beyond GNNs?\n- Please clarify how CIFAR-10 is treated as a graph dataset\n- Could you elaborate on your work's relationship to [2]?\n- What justifies the additional complexity of GCAN's hyperparameter search?\n\n---\n\n**References:**\n\n- [1]: Vikas Garg, Stefanie Jegelka, and Tommi Jaakkola. Generalization and representational limits of graph neural networks. In Hal Daum\u00e9 III and Aarti Singh (eds.), Proceedings of the 37th In- ternational Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 3419\u20133430. PMLR, 13\u201318 Jul 2020. \n\n- [2]: Hsu, Kelvin, Richard Nock, and Fabio Ramos. \"Hyperparameter learning for conditional kernel mean embeddings with rademacher complexity bounds.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10\u201314, 2018, Proceedings, Part II 18. Springer International Publishing, 2019."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper takes a theoretical examination of hyperparameter tuning for graph-based semi-supervised learning (GSSL) algorithms, focusing on label propagation methods and graph neural networks (GNNs). New pseudo-dimension upper bounds and matching lower bounds for hyper-parameter tuning are proved, and the Rademacher complexity bound for tuning the weight of SGC is provided, together a new model, GCAN, that interpolates between GCNs and GATs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper offers a rigorous theoretical analysis with novel insights into hyperparameter tuning complexities. To the best of the reviewer\u2019s knowledge, this is the first to provide generalization guarantees to the problem of hyperparameter selection.\n\n2. It presents a unified approach to analyze different GSSL algorithms, which is commendable. The introduction of the GCAN model is innovative and empirical results support its potential effectiveness."
            },
            "weaknesses": {
                "value": "1. It is unclear about the practical usefulness of the theoretical studies. This paper only considers tuning the single real-valued hyperparameter; it is unclear whether or not the proposed theoretical guarantees and models are able to apply to learning multiple hyper-parameters. \n\n2. The analysis is specific to certain algorithms (i.e., SGC), and it is unclear how these findings generalize to other models."
            },
            "questions": {
                "value": "1. How do the theoretical bounds scale with different dataset sizes and graph structures?\n\n2. Can the GCAN approach be extended to interpolate between other GNN architectures?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the problem of hyperparameter selection in graph-based semi-supervised learning. The theoretic analysis starts from three classical label propagation algorithms: local and global consistency algorithm, smoothing-based algorithm and normalized adjacency matrix-based algorithms. For each of them, the authors show that the upper and lower bound of the pseudo-dimension is of order $\\log (n)$, where $n$ is the number of nodes in graph. Then the authors turn to some modern GNN models including SGC, GCN and GAT. Concretely, the authors propose a GNN model named GCAN that linearly combines the update of GCN and GAT via a hyperparameter $\\eta$. For the case that $\\eta=0$ and $\\eta=1$, the GCAN degenerates to GCN and GAT, respectively. For SGC and GCAN, the authors analyze the upper bounds for the Rademacher complexity of tuning the interpolation coefficient. Both of them are of order $\\sqrt{\\log m/m}$, where $m$ is the number of training nodes with labels. Finally, the authors conduct experiments to demonstrate that GCAN has a matched or better performance compared to GAT and GCN."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The problem studied in this paper is significant, i.e., analyzing the sample complexity of selecting a proper hyperparameter for graph-based semi-supervised learning algorithms, since the selection of hyperparameter has a significant effect on the performance of learning algorithms. From my own perspective, the main contribution of this paper is the analysis for three classical label propagation algorithms, where the authors present both upper and lower sample complexity bounds for each of them. Particularly, the upper and lower bounds are matched, which makes the theoretic results convinced. And, the proof technique of deriving the lower bounds is novel and interesting, where the authors carefully construct a hard learning example.  I believe that these results could bring some new insights to the community."
            },
            "weaknesses": {
                "value": "- The theoretic analysis in this paper only consider single real-valued hyperparameter, e.g., the one control the trade-off between the\n local and the global consistency or the interpolation between two update rules. This significant limits the application of the theoretic results. Particularly, this kind of analysis is less sufficient for modern GNN models. There exist many hyperparameters in the optimization algorithm used for training, e.g., the learning rate and the weight decay in Adam, and they also have significant impact on the performance of model. It seems that the technique used in this paper could not be easily extend to these cases since the Rademacher complexity could not directly reflect the impact from learning algorithms. Also, I think that the title of this paper seems to exaggerate its actual workload.\n- The analysis for SGC and GCAN seems to rely on the technique and assumption used in (Garg et al., 2020), i.e., treating each node as a computation tree and requiring that these trees are independent to each other. This assumption seems too strong for GNN models and raises a gap between theory and practice. Indeed, the training and evaluation of model GNNs follows the transductive learning setting [1,2], i.e., some nodes are sampled without replacement from the graph and their labels are revealed to the GNN model. Therefore, the training and test nodes are dependent. I think that using the transductive learning setting [3,4,5] to conduct the theoretic analysis could be better. \n\n[1] Gilmer et al., Neural message passing for quantum chemistry. ICML 2017.\n\n[2] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. ICLR 2017.\n\n[3] Cong et al., On provable benefits of depth in training graph convolutional networks. NeurIPS 2021.\n\n[4] Esser et al., Learning theory can (sometimes) explain generalisation in graph neural networks. NeurIPS 2021.\n\n[5] Kenta Oono and Taiji Suzuki. Optimization and generalization analysis of transduction through gradient boosting and application to multi-scale graph neural networks. NeurIPS 2020."
            },
            "questions": {
                "value": "Q1: It seems that the experiments result in this paper only demonstrate the performance of the proposed GCAN model, and there are no other ones about the bounds you derived. Could you provide some experiments to verify your theoretic results ?\n\nQ2: I am concerned about some steps in the proof of Lemma C.1. In line 1004-1010, it seems that you have used the following inequalies\n$$\n\\frac{1}{\\sqrt{(d_i+\\beta)(d_j+\\beta)}} = \\frac{1}{\\sqrt{d_i d_j + \\beta (d_i + d_j) + \\beta^2}} \\leq \\frac{1}{\\sqrt{C^2_{dl} + 2\\beta C_{dl} + \\beta^2}} = \\frac{1}{C_{dl}+\\beta},\n$$\nwhere the inequality comes from $d_i, d_j \\leq C_{dl}$. However, the following could not be true\n$$\n\\left\\\\Vert \\frac{1}{\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}} - \\\\frac{1}{\\sqrt{(d_i+\\beta')(d_j+\\beta')}} \\right\\Vert \\\\leq \\left\\\\Vert \\\\frac{1}{C_{dl}+\\\\beta} - \\frac{1}{C_{dl}+\\beta'} \\right\\\\Vert\n$$\nsince the sign of the second term is negative. I think that the right one should be derived as follows:\n\\begin{equation}\n\\begin{aligned}\n& \\left\\\\Vert \\frac{1}{\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}} - \\\\frac{1}{\\sqrt{(d_i+\\beta')(d_j+\\beta')}} \\right\\Vert  \\\\\\\\\n= & \\left\\Vert \\frac{(d_i+\\beta)(d_j+\\\\beta) - (d_i+\\beta')(d_j+\\\\beta')}{\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}\\\\sqrt{(d_i+\\beta')(d_j+\\\\beta')}[\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}+\\\\sqrt{(d_i+\\beta')(d_j+\\\\beta')}]} \\right\\Vert \\\\\\\\\n= & \\left\\Vert \\frac{(d_i+d_j+\\\\beta+\\\\beta')(\\\\beta-\\\\beta')}{\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}\\\\sqrt{(d_i+\\beta')(d_j+\\\\beta')}[\\\\sqrt{(d_i+\\beta)(d_j+\\\\beta)}+\\\\sqrt{(d_i+\\beta')(d_j+\\\\beta')}]} \\right\\Vert \\\\\\\\\n\\leq & \\left\\Vert \\frac{2(C_{dh}+C_{dl})}{(\\beta+C_{dl})(\\beta'+C_{dl})[(\\beta+C_{dl})+(\\beta'+C_{dl})]} (\\beta - \\beta') \\right\\Vert \\\\\\\\\n\\leq & \\\\frac{C_{dh}+C_{dl}}{C^3_{dl}}\\Vert \\beta - \\beta' \\Vert.\n\\end{aligned}\n\\end{equation}\nAnd other results should be revised accordingly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}