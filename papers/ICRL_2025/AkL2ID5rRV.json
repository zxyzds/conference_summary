{
    "id": "AkL2ID5rRV",
    "title": "PRM:  Photometric Stereo based Large Reconstruction Model",
    "abstract": "We propose PRM, a novel photometric stereo based large reconstruction model to reconstruct high-quality meshes with fine-grained local details.\nUnlike previous large reconstruction models that prepare images under fixed and simple lighting as both input and supervision, PRM renders photometric stereo images by varying materials and lighting for the purposes, which not only improves the precise local details by providing rich photometric cues but also increases the model\u2019s robustness to variations in the appearance of input images. \nTo offer enhanced flexibility of images rendering, we incorporate a real-time rendering method and mesh rasterization for online images rendering.\nMoreover, in employing an explicit mesh as our 3D representation, PRM ensures the application of differentiable PBR, which supports the utilization of multiple photometric supervisions and better models the specular color for high-quality geometry optimization.\nOur PRM leverages  photometric stereo images to achieve high-quality reconstructions with fine-grained local details, even amidst sophisticated image appearances. Extensive experiments demonstrate that PRM significantly outperforms other models.",
    "keywords": [
        "3D reconstruction",
        "feed-fowared reconstruction model",
        "photometric stereo"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-21",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=AkL2ID5rRV",
    "pdf_link": "https://openreview.net/pdf?id=AkL2ID5rRV",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes a variation of the large reconstruction models for reconstructing objects (geometry and albedo) from single or multi-view input images. By incorporating physically based rendering pipeline for image synthesis in training, as well as ground truth images rendered under sampled BRDF and lighting conditions, the model is able to utilize additional supervision based on diffuse and specular color maps, in an attempt to improve the generalization ability of the model to images of diverse and complex materials and lighting combinations. The model is evaluated against baselines include InstantMesh, and additional ablation is provided on losses related to PBR, as well as robustness to materials, number of views and field of view."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "[1] The paper is able to improve on a line of work around LRMs, by incorporating PBR related insights into training, and showcases by incorporating ground truth and supervision from sampled complex materials and lighting conditions, the model better handles images of those conditions, and additionally gains improvement on geometry estimation due to the improved modeling of physics.\n\n[2] The speed up of PBR rendering with split sum approximation enables efficient on-the-fly view synthesis and ground truth generation in a large parameter space of materials and lighting. Mostly as a technical contribution, but it will enable efficient data generation and augmentation on-the-fly when modeling complex parameter space of PBR.\n\n[3] Extensive evaluation. The model is able to compare on standard benchmarks against baseline models in this task, but additionally provides extensive ablation study to justify the design choices by ablating the PBR-related losses, as well as robustness to number of input views and FOVs."
            },
            "weaknesses": {
                "value": "[1] Clarification. Several details need to be clarified to better understand the model and the training strategy.\n\n(a) What does the model estimate w.r.t. the PBR parameters? Does it only estimate albedo? \n\n(b) With sampled metallic, roughness and lighting envmaps, do we apply the metallic and roughness globally? If yes: 1)what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps? 2) And if applied globally, does this strategy diminish the model's generation ability towards real images with complex SV materials? 3) Given a good portion of Objaverse models are assigned with PBR materials, does it benefit the training to also predict ground truth BRDF (roughness, metallic) without manually sampling and enforcing global roughness and metallic?\n\n(c) Is the split-sum approximation only applied to synthesizing estimated image from estimated representations, or it is also used to render ground truth images? Are ground truth images rendered on-the-fly for each batch in training?\n\n[2] Writing. Language issues are abundant and need to be fixed for a polished version. Examples:\n\n(a)  L015: for what purposes?\n\n(b) L020: Need to introduce the full name of PBR before first use of the abbreviation.\n\n(c) L050, L235: Need to clarify 'dependence on images rendered under fixed and simple lighting conditions' of previous methods. Mostly previous methods use PBR materials and envmap base lighting similar to this paper, so it would be important to clarify this assertion.\n\n(d) L186: functionalities -> downstream applications of ...\n\n(e) L283: what is 'a richer set of equations'?\n\n[3] Additional evaluation results on images of complex lighting and materials. The paper is able to showcase the robustness towards complex lighting and materials in Fig. 9, however one scene is too few, and comparison with baselines on this setting is necessary to further justify the claim."
            },
            "questions": {
                "value": "Please see Weakness section for comments and questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This submission addresses the multi-view photometric stereo task and proposes a large reconstruction model (LRM) specifically leveraging photometric stereo. Unlike previous LRM models, in this work the authors train the model on data with varying illumination, material, etc. and instead of the usual triplane representation, they leverage a traditional mesh as the output 3D representation. This allows them to incorporate physically based rendering priors into the training objective. The idea of split-sum approximation from the physically based rendering community is leveraged to speedup the training data setup.\n\nThe approach is able to generate 3D models with fine geometric detail, handle a very wide variety of shapes, materials, lighting. Both qualitative and quantitative results are very convincing. However this is large transformer based architecture and training costs are prohibitively high."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The experimental results reported in the paper are very convincing. The performance of the model is quite impressive both from the point of view of the reconstructed 3D geometry, the large range of objects, materials that can be handled as well as the ability to handle a fairly small number of multi-view images.\n\nThe quantitative results reported in Tables 1 and 2 on the GSO and Omni3D datasets are quite convincing. A large improvement can be seen compared to prior LRM based baselines.\n\nThe method builds on top of the InstantMesh (Xu et al. 2024) model in terms of architecture and the training procedure. However, the model is extended to solve the photometric stereo problem. Leveraging mesh representations for geometry allows additional priors to be incorporated such as depth maps and normal maps (which are available for meshes)."
            },
            "weaknesses": {
                "value": "This is a well written paper but the technical details were difficult to follow in certain sections. The section describing the use of the split-sum approximation was difficult to understand because it was quite brief. I was also unable to appreciate to what extent this approximation is needed. Is this a standard solution that is used in real-time rendering nowadays and what assumptions or requirements does this method have, which could potential make it inapplicable."
            },
            "questions": {
                "value": "How were the hyperparameters tuned and to what extent do the authors think that they matter, or specifically which ones matter more than the others? Given the high training cost, it is infeasible to carefully tune so many hyperparameters. \n\nI am curious to know what happens on scenes with real, non-trivial backgrounds? Can the proposed model be run on multi-view images of non segmented real objects with natural backgrounds? Will the model reconstruct the object as well as the background? or would it be expected to automatically ignore the backgrounds because of how it was trained."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concerns."
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduced a new LRM method that improves the output quality. The method addressed the limitation of LRMs that they rely on simple lighting and material assumptions as input. The paper integrates photometric stereo principles into large reconstruction models. The key innovations are: (1) using varied materials and lighting conditions during training to improve detail reconstruction and robustness, (2) incorporating real-time rendering with split-sum approximation for flexible online image generation, and (3) utilizing explicit mesh representation with differentiable physically-based rendering (PBR) for better geometry optimization."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Novel integration of photometric stereo principles into large reconstruction models\n- Comprehensive ablation studies that validate each component's contribution\n- Practical applications demonstrated through relighting and material editing capabilities\n- Impressive handling of specular surfaces, which are traditionally challenging"
            },
            "weaknesses": {
                "value": "- Limited discussion of computational overhead compared to simpler approaches\n- The 50% probability threshold for material/lighting consistency seems arbitrary\n- Results appear sensitive to multi-view diffusion model quality\n- Some failure cases (e.g., with lacking depth information) could be analyzed more thoroughly"
            },
            "questions": {
                "value": "- How does the computational cost of online rendering compare to traditional offline approaches?\n- What is the rationale behind the 50% probability threshold for material/lighting consistency?\n- Have you considered incorporating depth estimation to improve reconstruction quality for challenging cases?\n- How does the method perform on real-world images with unknown lighting conditions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper \"PRM\" presents a high-quality 3D mesh reconstruction model with fine-grained local details from sparse image input. Unlike previous large reconstruction models (LRMs) that were trained using data rendered with fixed lighting and without material changes, PRM utilizes photometric stereo images with varied materials and lighting during training, enhancing detail accuracy and robustness. By incorporating split-sum approximation and mesh rasterization for online rendering, PRM effectively captures multiple photometric cues\u2014such as diffuse and specular lighting\u2014making it resilient to complex image appearances. Experiments demonstrate that PRM  outperforms existing models in both 3D geometry accuracy and 2D visual fidelity across public datasets like GSO and Omni3D."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper focuses on an often overlooked yet crucial factor affecting the performance of prior work --- training data. Unlike prior approaches that relied on data rendered with fixed lighting and without material variations, this method leverages data rendered under varied materials and lighting conditions to enhance both 3D geometry accuracy and 2D visual fidelity.\n\n2. The paper shows better performance than the selective baselines."
            },
            "weaknesses": {
                "value": "1. One key motivation of this paper is unconvincing --- why would the online rendering of training data be necessary? The authors argue that offline preparation of training data is challenging due to the \"infinite number of potential combinations of materials and lighting\" and the high sample counts required for rendering high-quality images. However, for the first reason, one could randomly sample finite combinations of materials and lighting offline, as the model will only be trained on a finite set of combinations given the limited training iterations. For the second reason, if online rendering is not strictly necessary, as suggested, the offline rendering costs without using split-sum approximation would be acceptable, and using default rendering engines would yield better image quality than the split-sum approximation used in this paper.\n\n2. The paper does not compare with some stronger baselines, such as Mesh-LRM, which has released an online demo from its first author before the ICLR submission deadline.\n\n3. The ablation studies are incomplete. The authors provide only qualitative comparisons on 1-2 selected objects, which is quite limited. And the quantitative tables are missing"
            },
            "questions": {
                "value": "See my weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}