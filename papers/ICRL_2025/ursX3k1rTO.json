{
    "id": "ursX3k1rTO",
    "title": "Wyckoff Transformer: Generation of Symmetric Crystals",
    "abstract": "We propose Wyckoff Transformer, a generative model for materials conditioned on space group symmetry. Most real-world inorganic materials have internal symmetry beyond lattice transition. Symmetry rules that atoms obey play a fundamental role in determining the physical, chemical, and electronic properties of crystals. These symmetries form energy configurations, determine stability, and influence key material structural and functional properties such as electrical and thermal conductivity, optical and polarization behavior, and mechanical strength. And yet, despite the recent advancements, state-of-the-art diffusion models struggle to generate highly symmetric crystals. We use Wyckoff positions as the basis for an elegant, compressed, and discrete structure representation. To model the distribution we develop a permutation-invariant autoregressive model based on Transformer and absence of positional encoding. Our experiments demonstrate that Wyckoff Transformer has the best performance in generating novel diverse stable structures conditioned on the symmetry space group, while also having competitive metric values when compared to model not conditioned on symmetry. We also show that it is able to predict formation energy and band gap within DFT accuracy.",
    "keywords": [
        "material design",
        "machine learning",
        "crystal generation",
        "space group symmetry",
        "Transformer",
        "Wyckoff position",
        "generative model",
        "autoregressive model",
        "permutation invariance"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "A generative Transformer for crystals conditioned on space group symmetry; based on Wyckoff positions.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ursX3k1rTO",
    "pdf_link": "https://openreview.net/pdf?id=ursX3k1rTO",
    "comments": [
        {
            "title": {
                "value": "Response to quick question"
            },
            "comment": {
                "value": "Yes, are there other methods apart from CHGNet that could be used?"
            }
        },
        {
            "title": {
                "value": "Quick question"
            },
            "comment": {
                "value": "Thank you very much for the detailed and to-the-point review! We will address the issues in the upcoming two weeks. Could you please elaborate, what did you mean in\n> Are there methods apart from CHGNet that improve crystal structure generation?\n\nWhether it's possible to use another method in place of CHGNet?"
            }
        },
        {
            "summary": {
                "value": "The paper focuses on the tasks of de novo materials generation and materials property prediction. The main contribution is a Wyckoff representation tokenization and model training strategy. For de novo generation, once the transformer generates a Wyckoff position then PyXtal and CHGNet are used to generate/relax the structure. In particular, the model is good at generating materials with the proper space group."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The application of ML to materials discovery is interesting and timely. \n- The Wyckoff representation builds in crystal symmetries in a natural way. \n- Good empirical results for template novelty, P1, and Space Group metrics.\n- The paper is written well"
            },
            "weaknesses": {
                "value": "- Little improvement in standard de novo generation metrics. SUN actually goes down compared to DiffCSP.   \n- Additionally, de novo generation metrics were computed with a ML potential instead of DFT.  \n- The property prediction benchmark is not particularly compelling because there are better benchmarks out there with other more recent models as baselines (e.g. CHGNet), such as Matbench discovery. \n- If not there, it would be good to include this citation (https://arxiv.org/abs/2106.11132)."
            },
            "questions": {
                "value": "- You found a nice way to tokenize a Wyckoff representation, would it be better to fine-tune a LLM with this representation than train a transformer from scratch? The CrystalLLM paper (https://arxiv.org/abs/2402.04379v1) had some nice results that could potentially be improved with your representation. \n- Another important axis is the inference speed or cost of de novo generation, how does WyFormer or WyForDiffCSP++ compare to DiffSCP/FlowMM? \n- Is there a way to more concretely show the benefit template novelty?\n- Can you plot the distribution of space groups generated from WyFormer compared to MP-20 distribution?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a transformer-based approach that leverages Wyckoff positions to encode material symmetries efficiently. This is done by primarily encoding the discrete symmetries of space groups without using atomic coordinates. The discussion on WyFormer, including tokenization and (extensive) metrics, is detailed. Their main contribution is to represent a crystal as an unordered set of tokens and make de novo material and property predictions. Furthermore, four new metrics are proposed (P1, Template Novelty, Space Group, and S.S.U.N.) to judge the ability to reproduce symmetry properties accurately. Results indicate that WyFormer outperforms other methods in terms of template novelty, space group distribution, and fraction of asymmetric structures.\n\nOverall I think the paper could be a good step in the direction of using symmetries for property prediction, provided certain clarifications on experimental details and broader evaluations are addressed."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Crystal representation for tokenization.\n- Material property prediction results are surprisingly good when compared against neural nets trained for energy prediction.\n- Four new metrics provide a new way of looking at models' ability to generate symmetry properties.\n- Justification in the appendix for the selected two structure generation methods."
            },
            "weaknesses": {
                "value": "- The scope of material property prediction- authors focus on just two (energy and band gap). If feasible, can the authors provide some insight on which other properties could be predicted, purely from a correlation with crystal structure perspective?\n- The proposed method is evaluated on a single dataset, MP-20, and makes it hard to judge the generalizable nature of WyFormer from it. Are there other datasets on which performance can be evaluated?"
            },
            "questions": {
                "value": "1. In section 1.3, line 138, \"...our main differences are listed in the discussion of our contributions 1.2.\"  where are the main differences listed in section 1.2? Or am I missing something?\n\n2. Can the authors explain why the Space Group value for WyForDiffCSP++ is high while the S.S.U.N. value is similar to WyCryst in Table 1a? \n\n3. A discussion on computational cost would be good to have, given that the authors mention that the entire dataset fits into GPU memory (training time and memory requirements)\n\n4. Are there methods apart from CHGNet that improve crystal structure generation?\n\n5. Have the authors tried other property prediction experiments besides energy and band gap?\n\nAdditional Feedback:\n1. line 280: \"they to be\" -> \"they are\"?\n2. line 282: percetage -> percentage?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper highlights the problem of generative models for crystals not generating symmetric crystals, which is an important property of these materials. This results in less realistic materials as well as inability to model some properties of crystals correctly. The authors propose to address this limitation by generating materials in a two-stage process. First, they train a Transformer model to output occupied Wyckoff positions in the crystal. Then either a method based on DiffSCP++ or PyXtal is used for atomic coordinates. The authors verify experimentally that this allows to generate more symmetric and diverse crystals."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The work tackles an important limitation of generative models for crystals\n- The proposed solution is simple and sound\n- The experimental evaluation shows that the method addressed the limitation. The evaluation metrics for symmetry and novelty of structures based on Wyckoff templates is also valuable."
            },
            "weaknesses": {
                "value": "- Just using the Wyckoff positions is not a complete representation, especially for atoms in the general position. The sentence \"reducing the number of parameters by an order of magnitude without information loss\" is false. I also don't think that statement that desired properties can be obtained from the discrete values alone is accurate or substantiated by enough evidence. I therefore encourage the authors to substantially nuance that section. The experiments on property prediction indicate a degradation of performance in property when discarding coordinates.\n- The model is claimed to be invariant with respect to the choice of coset representative and to permutations. This formulation is too strong, since this is achieved through data augmentation. A correct statement would be that the model is encouraged to be invariant.\n- The proposed representation for Wyckoff positions is universal across space groups but might not allow proper generalization since the \"enumeration\" variable is not grounded on physical information but on an arbitrary convention. Therefore, if a group is rare in the training data (this is indeed the case for datasets like MP20), there is no reason that the model will learn to capture that variable correctly. The authors should discuss this limitation appropriately. \n- I did not find the discussion of the related works to be sufficient. The authors should expand that discussion so that the readers understand the differences and similarities with the proposed method better.\n- I find that the explanation of Wyckoff position in the third paragraph of the introduction is not easy to understand. It may be too early in the paper to go into such an explanation.\n- There are some typos and mistakes that the authors should look into correcting. For example, \"lattice transition -> lattice translation\" or \"   Cordiality -> Cardinality\"."
            },
            "questions": {
                "value": "- I don't see what the footnote 1 adds to the discussion, I find it more confusing than anything. Could the authors clarify it, or consider simply removing it?\n- I don't understand the expression in the abstract \"These symmetries form energy configurations\". What is meant there?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a transformer-based architecture to generate symmetric crystals conditioned on space groups in a two-stage process. Initially, it generates tokens representing elements and their site symmetries, followed by lattice and coordinate predictions for these tokens with existing methods. The results include comparisons with multiple baselines, showing competitive performance across established proxy metrics. Finally, the paper also proposes metrics to assess the symmetry of the generated crystals and highlights further gains over baseline approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper emphasizes the importance of generating symmetric crystals and highlights challenges with existing methods.\n- The evaluation methods, including the newly proposed methods for evaluating symmetry, form a compelling discussion section.\n- The method demonstrates effective gains for the symmetry metrics and is competitive for widely-used proxy metrics.\n- The paper proposes a novel representation of crystal symmetry that could facilitate learning of crystal symmetry with deep learning approaches."
            },
            "weaknesses": {
                "value": "- **Presentation and writing**: Essential concepts (site symmetry, wyckoff positions, space groups) are not appropriately introduced, which would create difficulty for readers unfamiliar with the field. Several works are cited in the related works section, but neither described nor highlighted the difference from their approach. Figures for architecture and pseudo-code to describe the training and generation pipeline would greatly benefit the understanding of the work.\n\n- **Generalization of the approach**: \n  - The paper heavily focuses on the MP-20 dataset and does not provide any experiments with other datasets. For instance, it states permutation invariance was achieved because the number of WPs in the MP-20 dataset is small. How can this method be extended (or how does it fare in terms of performance) for crystals with a very high number of WPs?\n   - There are no precise details on how many tokens were formed from the MP-20 dataset after tokenization. It would be interesting to discuss this number and other statistics about the tokens, e.g., which tokens are present more often (for some of the high symmetry space groups) and how the distribution of tokens affects training. \n   - It is also important to add how many new tokens the method generates or if it just predicts the fixed set of tokens in different combinations (and these combinations result in more template novelty than just sampling existing templates from training data). For instance, naively thinking about it, how will your model generate tokens that are not present in its dictionary? \n  - Finally, in Table 1a, please also provide the number of novel templates as absolute numbers instead of percentages.\n\n- **Architecture**:\n  - Please provide at least a pseudo-code of the training/generation algorithm and a figure explaining the training/generation process with a sample crystal example. The central algorithm is not clear from the text. \n  - Please mention the size of the model and computational and memory consumption (training time, memory required during training and generation). The paper lists that it is trained for $150k$ epochs, which seems to be a very long training process compared to existing methods (~$1k$ epochs). Can you explain this behaviour along with the set of hyperparameters used?\n\n- **Evaluation**:\n  - Can WyCryst be considered a fair baseline for comparison since it supports a limited number of unique elements per structure? For instance, it wouldn't compare with other methods that generate an arbitrary number of methods because it would result in poorer metrics (as seen in Table 1).\n  - Is CHGNet used both to relax the generated structures and determine the energy in Table 1? \n  - Please mention the percentage of novel but structurally invalid generations from your method."
            },
            "questions": {
                "value": "- **Two-stage approach**: Can you explain the benefits of a two-stage approach instead of a one-shot (such as DiffCSP) prediction of the site symmetries, elements, their positions and lattice parameters? If problems exist with a one-shot prediction, please explain and motivate the need for a two-step approach. For instance, can we (as an example) predict all the tokens (with elements, site symmetry, enumeration) followed by the lattice parameters and the fractional coordinates of the tokens or are there inherent issues with this approach? This question becomes more necessary since the generation of crystals would be slow for the proposed \"sequential two-stage\" approach. \n- **Crystal Structure Prediction (CSP)**: The paper focuses on generating crystals conditioned on space group. How could this method be extended to the CSP task, which is also crucial and could potentially benefit from using crystal symmetry?\n- **Dataset fragmentation**: Although the tokens can be shared across different space groups, there will still be dataset fragmentation when the approach is conditioned on the space group. Is the training (and then generation) not affected by how many samples are present within each space group?\n\nSome of the other questions are listed in the Weaknesses section. I will be happy to improve the score if the authors address the questions and weaknesses with supportive evidence during the discussion phase."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes the **Wyckoff Transformer**, a generative model designed for creating highly symmetric crystal structures by leveraging **space group symmetry**. Recognizing that most inorganic materials exhibit inherent symmetries, the authors develop a model that encodes these symmetries to influence key material properties such as stability, conductivity, and optical behavior. The Wyckoff Transformer uses **Wyckoff positions** as a discrete, permutation-invariant representation of atomic locations, eliminating the need for explicit positional encoding and improving the model\u2019s efficiency and alignment with crystal symmetries.\n\nKey contributions of the paper include:\n\n1. **Tokenization of Crystals**: The authors represent crystals as an unordered set of tokens, merging information on chemical elements and their Wyckoff positions, enabling symmetry-based generation.\n2. **Permutation-Invariant Encoding**: The model encodes Wyckoff positions based on symmetry-defined point groups, allowing for the generation of stable structures without positional encoding.\n3. **Transformer Architecture**: The Wyckoff Transformer combines **autoregressive probability factorization** with permutation invariance, enhancing diversity and stability in generated structures.\n4. **Empirical Outperformance**: The model outperforms existing methods, generating novel, stable structures that adhere to space group symmetry.\n5. **Predictive Accuracy**: Despite limited input information, the model accurately predicts formation energy and band gap values comparable to DFT (Density Functional Theory) standards.\n\nThe model demonstrates superior performance in symmetry-conditioned generation, creating a diverse set of stable crystal structures that respect the underlying physical symmetries. This approach addresses limitations in prior methods, which struggled to produce symmetry-compliant structures, and shows promise for accelerating material discovery in fields requiring stable, symmetric crystals. However, the model inherits typical dataset limitations in generative models, as it learns distributions only within the scope of the training data, which may omit some stable but out-of-domain structures."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Strengths\n\n1. Originality: The Wyckoff Transformer introduces a novel approach to crystal generation by utilizing Wyckoff positions to encode symmetries explicitly, making it unique among generative models. Unlike traditional methods, it avoids positional encoding and uses permutation-invariant tokenization tailored to space group symmetries, a creative and effective innovation for materials science.\n\n2. Quality: The paper includes rigorous experimental results, showing the model\u2019s success in generating symmetric crystal structures while achieving competitive accuracy in formation energy and band gap predictions. The evaluation is thorough, comparing the model\u2019s performance to state-of-the-art methods across multiple metrics, demonstrating its robustness and effectiveness in real-world scenarios.\n\n3. Clarity: The authors provide clear explanations of the technical background (e.g., Wyckoff positions and space group symmetries) and detailed descriptions of the model architecture and training process. Visual aids and structured explanations make complex concepts accessible and support a deeper understanding.\n\n4. Significance: This work is impactful for both machine learning and materials science. By generating materials that are symmetric and physically plausible, the Wyckoff Transformer can accelerate material discovery for applications requiring stable, symmetric structures (e.g., in semiconductors and optoelectronics). The model\u2019s potential for symmetry-conditioned generation highlights a promising direction for future research in material informatics and generative modeling."
            },
            "weaknesses": {
                "value": "I observed the follwoing weakness in the paper and my recommendations towards constructively improving this paper:\n\n1. The write-up does not qualify for the levels of ICLR acceptance, it has too many inconsistent notation, typing errors, vague statements and hypothesises without proofs. Following is a non-exhaustive list: Line 174 WP 4a becomes (m-3m, 0), what does this line mean? later in Figure 4 the authors mention m-3m without any tuple, and later again in Figure 5 where the authors mention similar symbols as 1a = [m-3m] just to show and example of inconsistency in this paper, in Line 51 , ``atom position'' use correct quatotation marks, Figure 1 is vague no details on how it is constructed or taken from other source, line 227 coset (closest) representative (if you wish to mention grouping theory coset, then kindly use proper mathematical notations), Section 3.1 line 269, 270, 308, 315, 327, 329 no enumeration. Kindly go through the paper again, and correct all of them.\n\n2. The paper revolves around Wyckoff Transformer, but no explanation of the model architecture either in writting or in schematic has been given in the paper, section 2.2 mentions the title Model architecture but did not mention anything other than the Transformer paper by Vaswani et el which was used for Neural machine translation, moreover the authors are wrong in stating it to be an encoder only architecture. The authors seem to be lacking the knowledge about Encoder only, Decoder only and Encoder-Decoder models. This confusion seem to prpogate through the training section (2.3) where they mention (a) De novo generation , (b) Property prediction , where they are unable to state the difference between these two tasks and how a single kind of model cannot handle these two separate taks without any further layers (some hints of this is mentioned on Line 222, but still vague while following the whole paragraph.). Please attend to all these points, this would make the paper more readable and understandable.\n\n3. The paper does not include any structural schematic of the generated structure, if any. The paper does inlcude a few figures on Wyckoff positions and Wyckoff representation of a toy 2D Crystal and SrTiO3 in Figure 2 and 5 respectively. But none for their actually generated structures (if generated any). Claims on generative capability stand weak when figures are not included (kindly refer to the papers which they've cited, they have shown a wide set of generated structures with their corrosponding inductive biases.) Since the authors mention about their novel representation, they should support the validity of those representations and inductive biases (representational consistency) in their outputs. If possible I would like this point to be addressed in the revision.\n\n4. The section covering related work is weak. The authors must do a good survey of the past work in cystal generations particularly in the field of crystal genration in the representaion space. Some of which I was able to find by searching for representation based genrative model in citations to CDVAE (Xie et. al.) paper are: 1. https://arxiv.org/abs/2306.04510, 2. https://arxiv.org/abs/2403.10846,  3. https://arxiv.org/abs/2408.07213 (kindly read and search for more). I request the authors to kindly include papers which are in the same field to address the concerns in this paper and how your research aligns or complements with these papers, so that this work becomes complete. Kindly include a paragraph discussing how their approach compares to or builds upon these specific papers mentioned in the comments."
            },
            "questions": {
                "value": "The following are my questions and suggestions for this paper:\n\n1. The structure of the network, inputs, outputs and loss function (including tokeization, loss function computation needs to be defined properly with proper mathamtical notation and schematics). Kindly include a schematic diagram of their Wyckoff Transformer architecture, clearly showing how it differs from standard Transformer models. Additionally, kindly clarify how their model handles both de novo generation and property prediction tasks, possibly by explaining any additional layers or modifications to the base architecture.\n\n2. How did the authors plot Figure 1? Kindly include other generated structures in Figure 2, it will be best to show how the generated structures also follow these symmetris and where do ther lie in terms of space group number. Kindly provide a clear caption explaining the source and construction of the figure. Kindly include a figure showing examples of structures generated by their model, possibly comparing them to real structures or those generated by baseline models. This would help demonstrate the model's capabilities and the effectiveness of their novel representation.\n\n3. In section 2.2 clearly mention the assumtpions for your model, as of now the reviewer was not able to find the assumptions which the authors have taken. These need to be mentioned in a list.\n\n4. What was the training objective, were they two different models for task of De novo genration and Property prediction? If so, then how were they both trained? (Objective funvtion, optimiser hyper-parameters, Input data, valdiation metrics, regularisers, hardware specifications etc.)\n\n5. The algorithm explained for (i) Tokenization, (ii) De-nove generation, (iii) Structure genration and (iv) Metric computation is vaguely defined. These need to be defined propely in algorithm sections. As of now they don't make any sense and are without mathematical notation.\n\n6. Which DFT calculation has been used in the paper? Did the authors perform DFT of their own or are using previously reported results, if yes, then it will still need to be described and also how are they reporting."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}