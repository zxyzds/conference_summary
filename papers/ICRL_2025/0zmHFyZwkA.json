{
    "id": "0zmHFyZwkA",
    "title": "Hierarchical Graph Learners for Cardinality Estimation",
    "abstract": "Cardinality estimation -- the task of estimating the number of records that a database query will return -- is core to performance optimization in  modern database systems. Traditional optimizers used in commercial systems use heuristics that can lead to large errors. Recently, neural network based models have been proposed that outperform the traditional optimizers. These neural network based estimators perform well if they are trained with large amounts of query samples. In this work, we observe that data warehouse workloads contain highly repetitive queries, and propose a hierarchy of localized on-line models to target these repetitive queries. At the core, these models use an extension of Merkle-Trees to hash query plans which are directed acyclic graphs. The hash values can divisively partition a large set of graphs into many sets, each containing few (whole) graphs. We learn an online model for each partition of the hierarchy. No upfront training is needed; on-line models learn as the queries are executed. When a new query comes, we check the partitions it is hashed to and if no such local model was sufficiently confident along the hierarchy, we fall-back onto a default model at the root.  Our experimental results show that not only our hierarchical on-line models perform better than the traditional optimizers, they also outperform neural models, with robust errors rates at the tail.",
    "keywords": [
        "Cardinality Estimation",
        "Many small models",
        "Graph Hash",
        "Group-by-template",
        "Fast Learning"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "Given many labeled graphs, each representing database query, where graph label is cardinality, we group graphs by graph-structure and learn simple model per group (within group, feature dimension is constant).",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=0zmHFyZwkA",
    "pdf_link": "https://openreview.net/pdf?id=0zmHFyZwkA",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a workload-driven approach for cardinality estimation aiming at workloads containig repetative queries. The proposal utilizes multiple templatizer to derive hierarchical cardinality estimation models, taking a query plan tree as input and obtaining data with different granularity. It employs general predictors like PostgreSQL to perform cardinality estimation at the lowest level."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- S1: The evaluation experiments used six types of workloads, including up to five-table join queries, and achieved a higher Q-error than MSCN (CIDR2019). It was confirmed that the fine-grained model, H1, achieved the fastest convergence in training and the highest accuracy.\n\n- S2: Since machine learning-based methods often underperform in high-percentile cases, the fallback mechanism is beneficial in practice. As shown in Table 4, the deeper hierarchical fallback mechanism achieves a higher Q-error.\n\n- S3: As a query-driven approach, the featurizer\u2019s ability to characterize predicates is useful."
            },
            "weaknesses": {
                "value": "- W1: In addition to Q-error, P-error should be also evaluated, which is becoming a standard metric.\n\n- W2: As shown in Table 3, H1 demonstrates the highest performance, so a structure of H1 -> PostgreSQL seems optimal, making the multiple hierarchy setup (in Equation 15) unnecessary. The authors should clarify the benefit of using multiple hierarchy levels. \n\n- W3: Although the proposal adopts a workload-driven approach, recent trends favor data-driven or hybrid approaches. Notably, data-driven approaches have the advantage of robustness for unknown queries. Combining a workload-driven approach with data-driven methods could enhance accuracy in cases where prediction errors are large. While a workload-driven approach has the advantage of faster inference time, it is not obvious workload-driven approach alone is useful. \n\n- W4: In Section 2.5, the statement \"All graphs whose templates are isomorphic share the same model\" is based on graph isomorphism as defined in Definition 1, relying on edge information only. The templatizer, H1, thus does not use graph attribute information. However, Section 3.1 states, \"Hence, query graphs found in the same H1 template differ only by the constant values,\" which appears contradictory.\n\n- W5: Section 3.3 includes a calculation for the hash size, such as s(#T1), but according to Equation 6, the hash length is fixed at h, so the case distinction in Equation 10 does not seem valid.\n\n- W6: Although Cardbench is used as the evaluation benchmark, it is proposed in an arXiv paper and is not yet a standard benchmark. It would be better to use the widely accepted join order benchmark or explain the strong justification for using Cardbench."
            },
            "questions": {
                "value": "- It is unclear how the plan tree is constructed. For example, is it correct to interpret that (A ? B) ? C and A ? (B ? C) are non-isomorphic plans?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a supervised cardinality estimation method that enhances accuracy for workloads with repetitive queries (i.e., queries repeated in templates with only the constant parameters changed) by leveraging hierarchical, online localized models. This approach transforms each SQL query into a Directed Acyclic Graph (DAG) representation, groups isomorphic DAGs into the same partition, and trains an online model for each partition as queries are executed. Grouping is conducted hierarchically at multiple levels of granularity, ranging from fine-grained (i.e., queries varying only in constant terms are placed in the same partition) to coarse-grained (e.g., queries varying only in constants, operator types, and column names are placed in the same partition). During runtime, given a query, the method begins with the fine-grained model and moves to coarser-grained models until it finds a confident model for the query. If no suitable model exists, it defaults to a learned or traditional model. Using the CardBench benchmark, the authors demonstrate that this method yields more accurate cardinality estimates compared to competitors such as PostgreSQL and MSCN."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "S1. The authors tackle an important issue in analytical databases: cardinality estimation for repetitive queries.\n\nS2. The authors propose a cardinality estimator, which leverages hierarchical localized models that are trained online."
            },
            "weaknesses": {
                "value": "W1. The Experiments section needs to be improved.\n- The authors should compare their method with state-of-the-art (SOTA) data-driven cardinality estimation methods such as [1]. Currently, the comparison is limited to MSCN, a query-driven method proposed in 2019 [2], and PostgreSQL, a traditional estimator.\n- The \u201cImperfect Admission Experiments\u201d in Section 4 seems unfair, as the q-error percentiles of each method are reported on different query subsets: PostgreSQL is evaluated on the entire query set, MSCN on a subset excluding disjunctions, while the proposed method seems to be evaluated on a subset of simple queries (e.g., repetitive queries varying only in constant terms).\n- The authors should report end-to-end time (including both planning and query execution time), as shown in [1,3], along with its breakdown for further clarity.\n- Reporting training time and model size would provide further insights into the method\u2019s practical feasibility.\n- The authors should clarify why the q-error is higher in certain intervals with larger training sample sizes in Figure 4.\n- The experimental setup requires a more thorough explanation, particularly regarding how query repetitiveness was generated and its extent.\n\n\nW2. Motivation is inadequate.\n- The authors should explain why existing learned estimators struggle with repetitive workloads to highlight the necessity for their proposed method.\n- The authors should clarify why a hierarchical model structure is effective in improving the accuracy of cardinality estimation.\n\nW3. The presentation needs to be improved.\n- The process of generating a DAG from a query needs further explanation. If the DAG refers to a query plan, the authors should specify which query plan is used, as multiple plans can exist for a single query.\n- There are some undefined terms, such as d_{\\psi} in Section 2.\n- There are inconsistent notations throughout the paper. For instance, \u201cquery graph\u201d and \u201cquery plan\u201d are used interchangeably.\n- Numerous typos appear throughout the paper, such as \u201cgeoping\u201d and \u201chases\u201d in Section 5.\n\nW4. There are some misstatements regarding existing work\n- The authors seem to overstate the limitations of existing methods. They claim that \u201cNN-based estimators perform well if they are trained with large amounts of query samples,\u201d which is true specifically for query-driven learned estimators, not all NN-based methods.\n- The authors state that \u201c50% of the real world clusters have more than 90% queries repeated in templates (only changing the constant parameters),\u201d citing [4]. However, according to [4], the correct value is 80%, not 90%.\n\n[1] Kim, Kyoungmin, et al. \"Asm: Harmonizing autoregressive model, sampling, and multi-dimensional statistics merging for cardinality estimation.\" Proceedings of the ACM on Management of Data 2.1 (2024): 1-27.\n[2] Kipf, Andreas, et al. \u201cLearned cardinalities: Estimating correlated joins with deep learning.\u201d In Biennial Conference on Innovative Data Systems Research, 2019.\n[3] Wu, Ziniu, et al. \"FactorJoin: a new cardinality estimation framework for join queries.\" Proceedings of the ACM on Management of Data 1.1 (2023): 1-27.\n[4] van Renen, Alexander, et al. \"Why tpc is not enough: An analysis of the amazon redshift fleet.\" Proceedings of the VLDB Endowment 17.11 (2024): 3694-3706."
            },
            "questions": {
                "value": "Please refer to W1-W4."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To address the issue of repeated queries in cardinality estimation, this paper proposes an on-line cardinality estimation method. Unlike traditional cardinality estimation approaches that rely on a single model, this study introduces a hierarchical cardinality estimation framework. Queries are categorized into three levels, with different structural classifications applied at each level. For each level, distinct estimator models are trained based on various classification templates, and evaluations are conducted hierarchically. Additionally, these models utilize an extension of Merkle-Trees to hash directed acyclic graph (DAG) query plans. Finally, an ensemble learning method is used to statistically aggregate the results and produce the final cardinality estimates. Compared to traditional cardinality estimators and the query-based cost estimation method MSCN, this approach achieves superior results."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1. Hierarchical cardinality estimation methods have significant advantages for cardinality estimation methods in the presence of a large number of repeated queries. They allow for the training of separate cardinality estimators for each query type, thereby saving training costs and improving the accuracy of cardinality estimation.\nS2. The method presented in this paper demonstrates strong cardinality estimation performance, and it also exhibits good convergence stability through hierarchical training.\nS3. Compared to traditional cardinality estimators, the method proposed in this paper achieves faster convergence speed with lower overhead, making it suitable for practical industrial applications."
            },
            "weaknesses": {
                "value": "W1. This paper employs only the Q-Error as an evaluation metric, which can assess the stability of the cardinality estimator but does not provide an intuitive measure of its accuracy. The addition of mean absolute error (MAE) and relative prediction error (RPE) would allow for a more comprehensive evaluation of the accuracy of different cardinality estimators.\nW2. This paper compares only with two relatively outdated query-based cardinality estimation methods, MSCN and MSCN+. It should include a broader variety and greater number of baseline methods by introducing more advanced cardinality estimation approaches. Adding comparisons with data-driven cardinality estimation methods or experiments against paradigmatic methods like QueryFormer would enhance the analysis.\nW3. The experimental workload in this paper lacks clarification regarding query redundancy. It should include comparative experiments under different workloads. Additionally, experiments on cardinality estimation with lower query redundancy should be added to provide a more comprehensive evaluation."
            },
            "questions": {
                "value": "Q1. The addition of mean absolute error (MAE) and relative prediction error (RPE) would allow for a more comprehensive evaluation of the accuracy of different cardinality estimators.\nQ2. It should include a broader variety and greater number of baseline methods by introducing more advanced cardinality estimation approaches. Adding comparisons with data-driven cardinality estimation methods or experiments against paradigmatic methods like QueryFormer would enhance the analysis.\nQ3. It should include comparative experiments under different workloads. Additionally, experiments on cardinality estimation with lower query redundancy should be added to provide a more comprehensive evaluation.\nQ4. Could you clarify what specific models are used at each level of cardinality estimation in this paper? This detail is not adequately explained in the manuscript."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}