{
    "id": "KW8yzAOIZr",
    "title": "To Tackle Adversarial Transferability: A Novel Ensemble Training Method with Fourier Transformation",
    "abstract": "Ensemble methods are commonly used for enhancing robustness in machine learning. However, due to the ''transferability'' of adversarial examples, the performance of an ensemble model can be \nseriously affected even it contains a set of independently trained sub-models. To address this issue, we propose an efficient data transformation method based on a cute  ''weakness allocation'' strategy, to diversify non-robust features.\nOur approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.\nMoreover, our approach enjoys several other advantages, e.g., it does  not require any communication between sub-models and the construction complexity is also quite low.\nWe  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods, and meanwhile preserve high clean accuracy.",
    "keywords": [
        "robustness",
        "diversity",
        "ensemble training",
        "Fourier transformation"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "A  Fourier transformation based method to enhance adversarial robustness",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=KW8yzAOIZr",
    "pdf_link": "https://openreview.net/pdf?id=KW8yzAOIZr",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a Fourier-based ensemble training method to counter adversarial transferability by diversifying non-robust frequency components across sub-models. Using random noise and targeted attack transformations, the method achieves improved robustness and competitive accuracy on datasets like CIFAR-10, outperforming current ensemble techniques."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The use of Fourier transformations to manipulate frequency components for adversarial robustness is innovative and less explored in ensemble methods.\n- The proposed method addresses the transferability of adversarial attacks more effectively by diversifying non-robust features across sub-models.\n- Unlike simultaneous training methods, the approach\u2019s independent training of sub-models reduces GPU memory requirements and simplifies the training pipeline."
            },
            "weaknesses": {
                "value": "- The proposed targeted-attack transformation method, while effective, introduces a layer of complexity to the training pipeline. By replacing specific non-robust frequency components in the data with adversarially targeted features, the transformation becomes computationally intensive and intricate to implement, especially when scaling to larger datasets or real-time applications. This additional complexity may limit the ease of adoption for other researchers or practitioners looking to implement this technique without substantial computational resources.\n- The experiments are primarily conducted on smaller architectures, like ResNet-20, with limited exploration on larger or more complex models. Without extensive testing across a variety of architectures, it\u2019s unclear whether the proposed Fourier-based transformations are universally effective or if they are more suitable for specific model types."
            },
            "questions": {
                "value": "Refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Ensemble training is a commonly used technique to enhance a model's adversarial robustness. However, recent studies suggest that this approach may not be as effective, as adversarial examples can often affect multiple sub-models due to a phenomenon called \"transferability.\" This limitation arises because all sub-models are typically trained on the same dataset, leading them to share similar vulnerabilities. To address such issue, the author propose an effective data transformation framework to improve the diversity of training\ndata used by different sub-models for robust ensemble training. In the end of the paper, they present empirical results demonstrating the effectiveness of their method against common adversarial attacks, while also maintaining clean accuracy."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed framework is innovative, intuitively reasonable, and easy to understand. \n- The method comes with solid theorical backing\n- The experiments are comprehensive and well-supported their findings"
            },
            "weaknesses": {
                "value": "- The paper's readability is poor. I\u2019ve provided specific feedback in the following sections and strongly recommend improvements in clarity and structure.\n- The ensemble learning with proposed method still shows limited competitiveness with adversarial training, which restricts its practical applicability. Although the appendix shows that this method maintains higher clean accuracy than popular adversarial training (AT) methods, it still falls significantly short in robust accuracy compared to these approaches."
            },
            "questions": {
                "value": "Here are few questions and suggestion I want to provided for your paper:\n\n1. No detailed explanation of the feature extractor. In Definition 3.1, you provide a detailed definition of what a \"useful detail extractor\" is. However, the feature extractor itself is only given as $\u03b8: X \u2192 \\mathcal{R}^k$. Based on the information provided, I can't see how it differs from a standard classification model. I hope you can add more details to improve the readability of the paper\n\n2. $\\hat{y}$ is not an appropriate mathematical symbol in my opinion. $\\hat{y}$ is typically used to denote the prediction of y by convention, but in your paper, you are using it to denote the one-hot vector of y, which is quite confusing.\n\n3. In your Definition 3.2, I am confused by the second formula you provided. The first formula indicates that the feature extractor is robust if the expectation $ y^t \\cdot \\theta(A(x)) > \\frac{1}{k} $, but the second formula does not contain $y^t$ at all. I'm not sure whether I misunderstood your formula or if there is a mistake here.\n\n4. The format of your formula 8 doesn\u2019t seem correct to me. The equation is broken in the middle, leaving part of it followed after the plain text and the other part in equation mode.\n\n5. I am curious how you find the \"high-amplitude frequency features\" from your image. I think I am having this question since I didn't understand how your feature extractors work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an ensemble training approach to tackle the adversarial transferability problem by leveraging Fourier transformation and a weakness allocation strategy to diversify non-robust features across sub-models. The authors introduce a novel data transformation framework involving frequency selection and frequency transformation, aiming to improve the ensemble model\u2019s robustness against adversarial attacks without sacrificing clean accuracy. Experimental results show that their method, particularly the FDT-hybrid, outperforms several existing ensemble methods in robust accuracy on benchmark datasets like CIFAR-10 and CIFAR-100\u200b."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper addresses a critical challenge in adversarial machine learning, focusing on enhancing ensemble robustness without excessive overhead.\n2. The frequency-based approach for diversifying non-robust features is innovative and leverages insights from signal processing.\n3. Experimental results are thorough, showcasing improved robustness across various adversarial attacks and comparison with multiple baseline methods."
            },
            "weaknesses": {
                "value": "1. The paper\u2019s complexity may hinder reproducibility, especially given the intricate weakness allocation and frequency transformation processes.\n2. The dependency on specific frequency thresholding could limit adaptability across different datasets or tasks."
            },
            "questions": {
                "value": "1. Could the authors elaborate on how the choice of frequency thresholds (\u03c41 and \u03c42) affects robustness and clean accuracy?\n2. Is the computational efficiency of the proposed approach scalable to larger models or more complex datasets, given the Fourier transformations applied?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a data transformation method aimed at improving the adversarial robustness of ensemble models. Instead of reducing the influence of non-robust features, the authors propose to reduce the transferability of attacks by increasing the diversity of non-robust features. The robust and non-robust features are identified by frequency selection. The weakness set is allocated to sub-models for training to increase diversity. Through the experiments on various datasets, the results demonstrate the superiority of the proposed method over other baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to follow.\n2. The motivation of diverse non-robust features seems natural for a better trade-off between clean and robust accuracy.\n3. The comparison with other baselines shows the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. The motivation of amplitude-based selection is not well explained. There is no theoretical or empirical evidence to support this design in this paper.\n2. There is no ablation study to verify the effectiveness of all the components, such as weakness set allocation, amplitude-based selection, new dataset construction, etc.\n3. The results of baselines seem strange. For example, the results in Table 2 differ from those in Table 1 of TRS."
            },
            "questions": {
                "value": "1. Please clarify the motivation of amplitude-based selection.\n2. Please provide more ablation studies of the proposed method.\n3. Please clarify the difference in the result in Table 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}