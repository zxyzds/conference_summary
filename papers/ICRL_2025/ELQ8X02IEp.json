{
    "id": "ELQ8X02IEp",
    "title": "Learning Reliable Rules by Re-generating Deep Features",
    "abstract": "Improving the interpretability and reliability of deep learning models is essential for advancing machine learning applications, though it remains a significant challenge. One promising approach is the integration of logical reasoning into deep learning systems. Previous works have demonstrated that SATNet, a differentiable MaxSAT solver, can learn interpretable and reliable rules from input-output examples in puzzle domains. In this work, we propose *Visual SATNet* (Vi-SATNet), an extended version of SATNet capable of learning logical reasoning rules in more general and complex domains, such as the feature space of real-life images. We find that, given a pre-trained deep convolutional neural network (CNN) architecture, a Vi-SATNet layer can be integrated and trained efficiently to learn a set of reasoning rules on the deep features, guiding the classifier\u2019s decision. Vi-SATNets are trained to perform feature re-generation tasks for a given image dataset, where the re-generated features maintain high accuracy when used for image classification, proving their quality. In our experiment on the Imagenette dataset with a pre-trained VGG19 model, masking out 10\\% to 80\\% of the features results in classification accuracy ranging from 98.50\\% to 93.92\\% with Vi-SATNet re-generation, compared to 97.07\\% to 9.83\\% without re-generation. Furthermore, we introduce a visualization method to illustrate the rules learned by Vi-SATNets, thereby enhancing the interpretability of the pre-trained CNN model.",
    "keywords": [
        "Interpretable ML",
        "Neuro-symbolic AI",
        "SATNet",
        "Logical Reasoning"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ELQ8X02IEp",
    "pdf_link": "https://openreview.net/pdf?id=ELQ8X02IEp",
    "comments": [
        {
            "summary": {
                "value": "This paper extends SATNet by enabling it to learn logical rules from the complex feature space of real-life images, allowing it to regenerate masked features while maintaining high classification accuracy. \nExperimental results on the features from some pre-trained models show that the learned reasoning rules allow Vi-SATNet to re-generate missing feature vectors accurately.\nFinally, the authors present a visualization technique to illustrate the rules learned by Vi-SATNet models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Experiments on MNIST and Imagenette datasets demonstrate the effectiveness of Vi-SATNet in feature regeneration and classification, showing impressive results even under high masking ratios.\n\nThe visualizations of the learned rules offer an intuitive understanding of feature dependencies."
            },
            "weaknesses": {
                "value": "The visualization of the learned rules is not very clear. Whether in the foreground or background, MSF tends to pay more attention to the position around the target, which is a rather trivial result."
            },
            "questions": {
                "value": "As mentioned in the weaknesses section, the visualization of the learned rules indicates that the target-related MSF pays more attention to its surrounding features, which is a trivial finding. Since CNN features are derived from convolutions with neighboring pixels, the features at each position are inherently closely related to those in the surrounding area. Could you provide some more meaningful rules from different perspectives?\n\nThe features in the paper appear to be derived from the last layer of the convolutional module in the model. What would happen if features from other convolutional layers were used? Could different layers with varying depths extract distinct rules?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This manuscript introduces Visual SATNet (Vi-SATNet), an innovative extension of SATNet aimed at learning logical rules within complex feature spaces, particularly those generated by convolutional neural networks (CNNs). By employing Vi-SATNet for feature regeneration, the study illustrates its capacity to improve interpretability in CNNs during image classification tasks. Experiments conducted on datasets such as MNIST and Imagenette reveal promising classification outcomes across different levels of feature masking."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tVi-SATNet extends the capabilities of the original SATNet by enabling the learning of logical reasoning rules within the feature spaces of convolutional neural networks (CNNs). This generalization allows it to operate effectively on complex datasets beyond simple logical puzzles.\n2.\tThe study presents a new method for feature regeneration that leverages learned logical rules derived from deep features, thereby enhancing the interpretability and reliability of convolutional neural networks (CNNs).\n3.\tVi-SATNet can be seamlessly integrated as a drop-in layer within existing CNN architectures, requiring no retraining or fine-tuning."
            },
            "weaknesses": {
                "value": "1.\tThe manuscript effectively outlines the architecture of Vi-SATNet and establishes an evaluation framework through feature regeneration tasks, employing cosine similarity and Vi-C agreement as measurable metrics for assessing feature quality. However, it could enhance clarity regarding the Vi-SATNet training process, especially concerning hyperparameter selection.\n2.\tThe manuscript describes visualization through minimal significant feature sets (MSFs) and their corresponding receptive fields. However, a more in-depth explanation of how MSFs correlate with specific learned rules would be advantageous. Without clear criteria for evaluating rule quality, the reader may find it challenging to interpret the rules\u2019 significance. \n3.\tTo enhance the study's rigor, it is recommended to include additional datasets, such as CIFAR-10 or other complex real-world datasets.\n4.     Some related works are needed to discuss in the manuscript, such as [1-2].\n\n[1] Wei J, Garrette D, Linzen T, et al. Frequency effects on syntactic rule learning in transformers[J]. arXiv preprint arXiv:2109.07020, 2021.\n[2] Zhang W, Mo S, Liu X, et al. Learning robust rule representations for abstract reasoning via internal inferences[J]. Advances in Neural Information Processing Systems, 2022, 35: 33550-33562."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the author proposed Visual SATNet (Vi-SATNet) which targets learning logic reasoning rules in a general domain. Specifically, the author trains and evaluates Vi-SATNet on deep feature re-generation and the experiment results show the effectiveness of the proposed methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The experiment results are convincing, showing the effectiveness of the proposed method.\n2. The author provides detailed definitions and algorithm processes to demonstrate their ideas and contributions."
            },
            "weaknesses": {
                "value": "1. The author proposes a method to learn logical reasoning rules in a more general domain. However, different from the original SATNet, which targets solving Sudoku, a task has a clear logic process, how can we understand the logical reasoning for the real-life images? The author should provide more explanation and analysis.\n2. In Table 1, the author obtained the best results with regeneration with a 30% mask ratio. However, without regeneration, the model's performance will drop with a higher maks ratio.  Why does the model have the best performance with a 30% mask ratio? The author should provide more analysis."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}