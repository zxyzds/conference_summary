{
    "id": "BapOwAzicb",
    "title": "HOGT: High-Order Graph Transformers",
    "abstract": "Inspired by the success of transformers on natural language processing (NLP) and computer vision (CV) tasks, graph transformers (GTs) have recently been proposed to boost the performance of graph learning. \nHowever, the attention mechanisms used in existing GTs face certain limitations in capturing crucial topological information or scaling to large graphs, due to their quadratic complexity. \nTo address these limitations, in this paper, we propose a high-order information propagation strategy within the transformer architecture to simultaneously learn the local, long-range, and higher-order relationships of the graph. \n\\textcolor{blue}{We first propose a flexible sampling method to extract communities from the graph, and create new community nodes and in particular a learnable community sampling method with reinforcement learning.} We then propose a three-step message-passing strategy dubbed \\emph{HOGT} to capture the local and higher-order information in the communities and propagate long-range dependency information between the community nodes to finally obtain comprehensive node representations. Note that as structural information has been flexibly integrated into our designed community-based message-passing scheme, HOGT discards the positional encoding which was thought to be important for GT.",
    "keywords": [
        "Graph representation learning",
        "Graph Transformer"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=BapOwAzicb",
    "pdf_link": "https://openreview.net/pdf?id=BapOwAzicb",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces HOGT (High-Order Graph Transformer), a new architecture that tackles key issues in existing graph transformers, especially around capturing topology and scaling to large graphs. The authors use a three-step message-passing process: sampling communities from the graph, creating community nodes as information bridges, and enabling message flow between graph and community nodes. This design removes the need for positional encoding, embedding structure naturally through communities. HOGT shows strong performance across different types of graphs, with impressive computational efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper introduces a well-founded architecture with a three-step message-passing strategy that effectively captures multi-scale information in graphs, handling local, global, and higher-order details. Theoretically, it\u2019s shown that HOGT can approximate global attention and unify existing models, while the community-based design removes the need for positional encoding.\n\n2. HOGT also demonstrates strong versatility, performing well on various graph types (homophilic, heterophilic, and hypergraphs) and adapting to different community sampling methods, which enhances scalability across graph sizes. Efficiency is greatly improved, with computational complexity reduced from O(N\u00b2) to O(m\u00b2 + N), validated by experiments that show strong results over state-of-the-art methods, especially on challenging datasets."
            },
            "weaknesses": {
                "value": "1. The strict hierarchy in the three-step message-passing mechanism could introduce bottlenecks in information flow. By requiring all long-range communication to route through community nodes, the model risks distorting or weakening critical direct relationships between nodes\u2014especially in tasks where pairwise connections hold essential information. The assumption that this hierarchical structure is universally beneficial may be too broad, as the paper offers little discussion on cases where direct node-to-node communication might better capture necessary details.\n\n2. The approach to initializing community nodes also feels underdeveloped and could pose challenges. Starting with random initialization may lead to instability and slower convergence, particularly in early training stages. Additionally, there's no clear strategy for aligning community node dimensionality with original node features, which seems like a significant gap. Given that these community nodes are crucial bridges for information flow, their initial setup could substantially impact the quality of the representations learned."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a high-order graph transformer (HOGT) for graph learning tasks. HOGT introduces a flexible sampling method to extract communities from the graph and a three-step message-passing strategy to capture local, long-range, and higher-order relationships of the graph. The paper demonstrates the effectiveness of HOGT on node classification tasks and shows its superiority over other graph models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) The paper introduces a novel approach, HOGT, that combines community-based sampling and message-passing to capture comprehensive information in graph learning.\n\n(2) HOGT achieves competitive results on various graph datasets, demonstrating its effectiveness in node classification tasks.\n\n(3) The paper provides a theoretical analysis of HOGT, showing its approximation capabilities and the relationship with other graph models."
            },
            "weaknesses": {
                "value": "(1) Domain Limitation of Datasets. Expanding the evaluation to include diverse domains, such as those in the TEG-DB datasets [1], which feature rich node and edge text, would strengthen the findings.\n\n(2) Narrow Applicability. The model\u2019s applicability is somewhat restricted to specific tasks within graph domains, such as node classification. The authors should consider its potential for other important tasks, like link prediction.\n\n[1] \"TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs.\" NeurIPS 2024."
            },
            "questions": {
                "value": "See weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents HOGT, a graph transformer that uses community-based processing to handle graph topology and computation complexity issues.\nThe method consists of three parts: Community sampling using reinforcement learning, Message-passing within communities and information propagation between community nodes. HOGT achieves highly competitive results\nacross node and graph classification tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The technical part of the paper is good -- the method is of careful design and implementation."
            },
            "weaknesses": {
                "value": "1. The problems of node classification and graph classification are well-studied in the past 10 years.\nYou can find the old baselines like GAT are very competitive.  Due to task saturation, HOGT shows relatively small improvements compared to these simple algorithms.\n2. The theoretical part of the paper seems like mainly from a related work. Further analysis about HOGT is needed.\n3. The method is too complex."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a unique approach to graph learning by integrating high-order information propagation within the transformer architecture. The paper empirically shows that HOGT achieves competitive results on node and graph classification tasks, especially on heterophilic datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The idea of using a learnable community sampling method with reinforcement learning for graph representation is novel. It combines the advantages of community detection and adaptive sampling.By addressing the limitations of existing graph transformers in terms of capturing topological information and scalability, this work contributes to the advancement of the field and opens up new research directions for further exploration."
            },
            "weaknesses": {
                "value": "Analysis on the sensitivity of the HOGT model's performance to its hyperparameters such as walk length, hidden dimension, and dropout.\n\nFurther exploration of the sampling method's performance in graphs with irregular or sparse structures would enhance the understanding of the model's robustness.\n\nA more detailed comparison of HOGT's computational complexity, including training time and memory usage, with other state-of-the-art models is needed."
            },
            "questions": {
                "value": "Could the authors provide more insights into how HOGT scales with graph size, especially in terms of memory usage and training efficiency?\n\n\nCan the authors elaborate on the theoretical analysis of the model's expressiveness and how it relates to the approximation of global attention?\n\nHow sensitive is HOGT to its hyperparameters, particularly the number of communities and the reinforcement learning-based sampling method?\n\nCould the authors discuss how HOGT captures long-term dependencies in the graph and compare this with other methods that focus on long-range interactions?\n\nHow sensitive is the performance of HOGT to changes in hyperparameters such as the hidden dimension and dropout rate? \nHave the authors experimented with different optimization algorithms for hyperparameter tuning, and if so, what were the results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}