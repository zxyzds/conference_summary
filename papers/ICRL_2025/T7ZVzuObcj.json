{
    "id": "T7ZVzuObcj",
    "title": "Interpretable point cloud classification using multiple instance learning",
    "abstract": "3D image analysis is crucial in fields such as autonomous driving and biomedical research. However, existing 3D point cloud classification models are often black boxes, limiting trust and usability in safety-critical applications. To address this, we propose PointMIL, an inherently locally interpretable point cloud classifier using Multiple Instance Learning (MIL). PointMIL offers local interpretability, providing fine-grained point-specific explanations to point-based models without the need for post-hoc methods, addressing the limitations of global or imprecise interpretability approaches. We applied PointMIL to popular point cloud classifiers, DGCNN and PointNet, and proposed a transformer-based backbone to extract high-quality point-specific features. PointMIL transformed these models to become inherently interpretable while increasing predictive performance on standard benchmarks (ModelNet40, ShapeNetPart) and achieving state-of-the-art mACC ($97.3\\%$) and F1 ($97.5\\%$) on the IntrA biomedical data set.",
    "keywords": [
        "Multiple instance learning",
        "point cloud",
        "interpretable"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "We propose an interpretable point cloud classification framework using multiple instance learning",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=T7ZVzuObcj",
    "pdf_link": "https://openreview.net/pdf?id=T7ZVzuObcj",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces PointMIL, an inherently locally interpretable point cloud classifier using Multiple Instance Learning (MIL). It addresses a gap in existing classification methods, which either employ post-hoc interpretability techniques or focus on global interpretability. PointMIL comprises a feature encoder, implemented using either 3D transformers, DGCNN, or PointNet, to capture per-point features. A MIL pooling layer provides interpretability, with several types of MIL pooling methods explored, including Instance, Attention, Additive, and Conjunctive pooling.  A contextual prior is also injected into attention mechanism to learn local information. Experiments are conducted on medical dataset IntrA and general 3D object dataset ModelNet40."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow.\n2. It claims to be the first work to achieve locally interpretable point cloud classification on a per-point basis.\n3. The visual results are compelling, highlighting important regions for classification. Quantitative results on multiple classification benchmarks, such as IntrA and ModelNet40, and part segmentation benchmarks, including IntrA and ShapeNetPart, demonstrate performance improvements over baselines."
            },
            "weaknesses": {
                "value": "The technical contribution appears somewhat limited, as it primarily involves combining various typical point cloud encoders with existing MIL pooling methods for point cloud classification. I would have expected a deeper exploration of this combination. For example, were any modifications made to the MIL pooling methods to better adapt them to point cloud data? What specific challenges were encountered and addressed when applying MIL to this domain? Providing more insights into these aspects could help strengthen the contribution and highlight the distinctiveness of the approach.\n\nFurthermore, in Tables 4, 5, and 6 in Appendix A.1, the paper presents varying performance across different MIL pooling methods. However, there is a lack of analysis explaining why certain methods perform better than others, and how these insights could guide the selection or adaptation of pooling methods in future work. Simply presenting the empirical results without such analysis misses an opportunity to make the work more insightful and inspiring.\n\nThe backbones used for evaluation are somewhat limited, as more recent and widely adopted models, such as Point Transformer (ICCV 2021) and sparse convolutional architectures, are not included. Evaluating PointMIL with these modern architectures would provide a more comprehensive comparison. I would appreciate it if the authors could discuss how PointMIL might be adapted to work with these newer backbones.  Additionally, a side-by-side comparison of the interpretability outputs for the same representative examples using different backbones would be valuable to determine if they highlight the same local regions of interest."
            },
            "questions": {
                "value": "1. In Lines 195-197, the paper claims to use five MIL pooling methods, but only four are listed: Instance, Attention, Additive, and Conjunctive. Could the authors please clarify whether a fifth pooling method was intended and omitted, or if this is a typo that should be corrected?\n2.  In Table 2,  PointNet is reported to achieve 86.0 mACC, whereas the original paper cites 86.2 mACC. Could the authors please verify this discrepancy and explain? I wonder if this difference is due to variations in the implementation, experimental setup, or evaluation criteria.\n3. Could the authors provide visual results for segmentation similar to Figures 2-5? Specifically, it would be interesting to include side-by-side comparisons of classification and segmentation interpretability outputs for a the same representative examples."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces PointMIL, the first framework to apply MIL to point cloud classification. PointMIL provides fine-grained point-specific interpretability without post-hoc techniques."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThis paper is well-written, and the organization is great.\n2.\tThe motivation is clear enough."
            },
            "weaknesses": {
                "value": "1.\tThe backbones and compared methods are limited. There are lots of methods that have been proposed for point cloud classification and segmentation. It is recommended to compare with them, including Point-MAE and PointTransformer V3.\n2.\t\u201cGroup features through k-nearest neighbours\u201d, \u201cLearned relative positional encoding\u201d, and \u201cAttention on the augmented features\u201d are also widely used in point cloud processing, including PoinTr, Point-BERT, or DGCNN. It is recommended to move these parts into appendix and focus on your interpretation. \n3.\tThe logic in L90-L94 is puzzling. \u201cPost-hoc or inherently interpretable\u201d and \u201clocal or global approaches\u201d could be organized better.\n4.\tThe citation in L100 should be (Tan & Kotthaus, 2022). The remaining part should also be carefully checked."
            },
            "questions": {
                "value": "1.\tIt is claimed that \u201cmost local interpretability methods for point cloud classification are post-hoc\u201d and \u201cno one has yet offered an inherently locally interpretable model for point cloud classification\u201d seems conflict.\n2.\tLocal and global features are widely studied in point cloud classification. Why your local approach is effective than others?\n3.\tMIL pooling has been widely used in 2D images. Please clarify the main difference between these methods. And it is also recommend to exploit the specific design for point cloud.\n4.\tThe main contribution of this paper is the interpretation. However, the discussion about the interpretation is limited and the discussion about the network design has a great portion.\n5.\tThe performance gain on ModelNet40 and ShapeNetPart is marginal. Moreover, more newly proposed backbones should be included as your backbone."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method for generating point-level importance in point cloud classification, aiming to interpret the contribution of each point to the classification outcome. A modified Transformer is introduced to extract point-level features, with MIL pooling applied to determine each point's importance. The paper presents a strong motivation and is well-organized."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The motivation is innovative, focusing on the interpretability of point cloud models and aiming to address the issue of poor interpretability in existing models."
            },
            "weaknesses": {
                "value": "1. The authors aim to propose a general interpretability method; however, they add a Transformer-based feature extractor to existing models as an additional modification to the backbone network. This modification can be seen as an alteration to the backbone, which may impact the original performance of the point cloud network. Consequently, conducting interpretability analysis on this modified version may not align with the original motivation.\n\n2. The novelty is limited: the authors' contributions primarily include (1) the feature extractor and (2) MIL pooling. However, the core iead of the feature extractor is merely a straightforward combination of existing Transformer and DGCNN approaches, lacking significant originality. In the MIL pooling, existing ideas are directly applied without any improvements tailored to the inherent characteristics of point cloud data. These factors restrict the paper's novelty, as it largely reflects a simple combination and adaptation of existing methods.\n\n3. The performance improvements are likely attributed mainly to the additional feature extraction network."
            },
            "questions": {
                "value": "Although the authors provide visualizations of points deemed important for classification in the figures, these points are derived from the final pooling output. Why are these highlighted red points considered more important\u2014just because they have higher importance scores? The current conclusions remain insufficiently convincing. Are there alternative methods that could offer supplementary validation? One possible approach could involve removing the red points and observing a significant accuracy drop, while removing the gray points leads to no substantial accuracy decrease. However, this is an intuitive idea and may not hold in actual experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces multiple instance learning to provide local interpretability for point cloud classification models. Experiments are conducted on several popular point cloud classification models and classification benchmarks, demonstrating the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper is the first to introduce multiple instance learning for interpretable learning in the 3D domain. It can be integrated as a simple module into existing point cloud classification models, effectively enhancing classification performance while also improving interpretability."
            },
            "weaknesses": {
                "value": "1.The point cloud classification models applied in PointMIL appear to be relatively outdated, as more advanced models such as PointNeXt and PointMLP, as well as more classic models like PointNet++, have not been included in the experiments.\n\n2.The practicality of PointMIL in real-world applications remains questionable, as it lacks experiments on real datasets such as ScanObjectNN, or robustness tests against noise, rotation, and other transformations.\n\n3.There are some minor errors in the details: $\\textbf{(a)}$. it seems that $\\hat{y}$ in Equation 8 is not defined. $\\textbf{(b)}$. there is an error in Table 4 of the appendix"
            },
            "questions": {
                "value": "1.Is the performance comparison on classification tasks fair? If I understand correctly, PointMIL eliminates downsampling to achieve point-level predictions, whereas the other methods compared, such as PointNet++, still employ downsampling. The authors should consider the impact of downsampling on performance.\n\n2.I recommend that the authors include experimental results for PointMIL on ScanObjectNN and test the interpretability on more advanced point cloud models such as PointNeXt and PointMLP.\n\n3.Is PointMIL also applicable to scene-level tasks, such as scene segmentation that requires generating point-level predictions? This could effectively demonstrate the applicability of PointMIL.\n\n\n4. I hope the authors can provide a detailed explanation of the results, for example, why $\\textbf{Additive}$ and $\\textbf{Conjunctive}$ achieve better results compared to other MIL pooling methods in Figure 2. Such an exploration would be beneficial for understanding how to choose MIL pooling methods under different circumstances."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}