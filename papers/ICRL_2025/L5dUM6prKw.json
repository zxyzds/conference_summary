{
    "id": "L5dUM6prKw",
    "title": "Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension",
    "abstract": "As neural language models achieve human-comparable performance on Machine Reading Comprehension (MRC) and see widespread adoption, ensuring their robustness in real-world scenarios has become increasingly important. Current robustness evaluation research, though, primarily develops synthetic perturbation methods, leaving unclear how well they reflect real life scenarios. Considering this, we present a framework to automatically examine MRC models on naturally occurring textual perturbations, by replacing paragraph in MRC benchmarks with their counterparts based on available Wikipedia edit history. Such perturbation type is natural as its design does not stem from an arteficial generative process, inherently distinct from the previously investigated synthetic approaches. In a large-scale study encompassing SQUAD datasets and various model architectures we observe that natural perturbations result in performance degradation in pre-trained encoder language models. More worryingly, these state-of-the-art Flan-T5 and Large Language Models (LLMs) inherit these errors. Further experiments demonstrate that our findings generalise to natural perturbations found in other more challenging MRC benchmarks. In an effort to mitigate these errors, we show that it is possible to improve the robustness to natural perturbations by training on naturally or synthetically perturbed examples, though a noticeable gap still remains compared to performance on unperturbed data.",
    "keywords": [
        "Natural Perturbations",
        "Robustness Evaluation",
        "Machine Reading Comprehension"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=L5dUM6prKw",
    "pdf_link": "https://openreview.net/pdf?id=L5dUM6prKw",
    "comments": [
        {
            "title": {
                "value": "Answer question"
            },
            "comment": {
                "value": "> line 334-337: I have trouble understanding this long sentence with too many clauses. can you explain that?\n\nYes, sure, and sorry for the confusion. In Section 5.4, our aim is to zoom in on the errors of encoder-only models as much as possible and examine whether these errors transfer to Flan-T5 and LLMs. Therefore, we propose an exhaustive search algorithm to create a challenging natural perturbed test set:\n\nGiven a matched reading passage \\( P \\) from a prior version, its counterpart \\( P' \\) from the current version, and the associated questions:\n\n1. **First Scenario:** We treat \\( P \\) as the original passage and \\( P' \\) as the perturbed one. We then evaluate, for each associated question, how many encoder-only models demonstrate the lack of robustness phenomenon, i.e., succeed on \\( P \\) but fail on \\( P' \\). We obtain the total number of models that demonstrate the lack of robustness phenomenon across all questions, denoted as \\( N \\). Questions on which none of the models demonstrate the lack of robustness phenomenon are removed, leaving \\( Q \\) questions.\n\n2. **Second Scenario:** We treat \\( P' \\) as the original passage and \\( P \\) as the perturbed one. We repeat the evaluation process as described in the first scenario and obtain the total number of models demonstrating the lack of robustness phenomenon across all questions, denoted as \\( N' \\). Questions on which none of the models demonstrate the lack of robustness phenomenon are removed, leaving \\( Q' \\) questions.\n\nIf \\( N > N' \\), we consider \\( P \\) as the original passage and \\( P' \\) as the perturbed version.  \nIf \\( N < N' \\), we consider \\( P' \\) as the original and \\( P \\) as the perturbed.  \nIf \\( N = N' \\), we compare \\( Q \\) and \\( Q' \\):  \n- If \\( Q > Q' \\), we consider \\( P \\) as the original passage and \\( P' \\) as the perturbed version.  \n- If \\( Q < Q' \\), we consider \\( P' \\) as the original and \\( P \\) as the perturbed.  \n- If \\( Q = Q' \\), the order does not matter, and we randomly decide which one should be the original and which should be the perturbed.\n\nWe will add this explanation to the paper.\n\nWe hope our response addresses the reviewer\u2019s concern, and we are happy to discuss if there is anything unclear."
            }
        },
        {
            "title": {
                "value": "Address weaknesses"
            },
            "comment": {
                "value": "We appreciate the reviewer for the time spent in reviewing our work and address the proposed concerns below.\n\n> It is unclear whether stronger model, e.g. gpt-4o would still suffer from this challenge. While weaker models like BERT suffers from the natural perturbations, it is important to show that it is still a challenge for recent stronger LLMs. The performance drops on non-SQuAD datasets like DROP are relatively small, e.g. LLaMA-2 only exhibits less than 2 points drop, which could also potentially be remedied by adversarial training. Again, I'm concerned that this benchmark is not super challenging for recent LLMs anymore.\n\nAs one of the strengths recognised by the reviewer, our work show that natural perturbation is a powerful attack to not only encoder-only and Flan-T5 models, but also to the recent Large Language Models (LLMs), including Google\u2019s Gemma (2B and 7B), Meta\u2019s Llama 2 (7B and 13B) and Llama 3 (8B), Mistral 7B and Falcon (7B and 40B). To further evidence its harmfulness, we experimented with GPT-4o. Table 1 shows the results.\n\n#### Table 1: IM changes (%) of GPT-4o on naturally perturbed test sets of five MRC datasets.\n| Dataset  | SQuAD V1 | SQuAD V2 | DROP   | HotpotQA | BoolQ  |\n|----------|----------|----------|--------|----------|--------|\n| **GPT-4o** | -13.06   | -13.39   | -12.68 | -2.67    | -7.47  |\n\nIt can be seen clearly from Table 1 that GPT-4o still suffers from natural perturbations, with quite noticeable performance drops. This further demonstrates the harmfulness of natural perturbations to the contemporary powerful LLMs.\n\nAlso, we indeed notice that the performance decrease of some models on certain datasets (e.g., Llama 2 on DROP) is not that significant. However:\n\n1. Our aim/contribution is more to raise awareness within the community about models\u2019 vulnerabilities to the quite under-explored natural perturbations, rather than mitigate it.\n2. The effectiveness of adversarial training for LLMs remains uncertain. Our work shows that while it can help encoder-only models address natural perturbations, it falls far short of effectively mitigating them, warranting future study.\n\n> The perturbation method relies on Wikipedia edit history, limiting its applicability to non-Wikipedia based datasets.\n\nIn this paper, our goal is to show the behaviour of neural language models (e.g., LLMs) on natural perturbations. These are by no means limited to Wikipedia, but occur in any kind of text that evolves over time, e.g., company-internal files, software documentation, etc. Wikipedia happens to allow us to track changes and automatically construct a benchmark to test the behaviour, but the phenomenon of natural perturbations is by no means limited to Wikipedia. Our work serves as an initial step to address this critical challenge, and future work is needed to explore alternative natural perturbation approaches, as mentioned in Conclusion."
            }
        },
        {
            "summary": {
                "value": "This paper contributes to understanding and improving the robustness of Machine Reading Comprehension models by introducing a new evaluation framework based on naturally occurring text variations. Rather than relying on synthetic perturbations, the authors leverage Wikipedia edit history to generate realistic test cases that reflect how the text changes in the real world."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Proposes a framework using Wikipedia edit history to generate natural perturbations in MRC benchmarks\n\n- Evaluate model performance across encoder-only, encoder-decoder, and decoder-only architectures\n\n- Shows that natural perturbations can degrade performance and these errors transfer to larger models\n\n- Demonstrate that adversarial training with both natural and synthetic perturbations can help mitigate these issues"
            },
            "weaknesses": {
                "value": "I am generally optimistic about the paper, and I have the following minor concerns. \n\nThe analysis section could be more in-depth\n1. Permutations and models\n\n- No investigation of how perturbation magnitude affects performance and why certain permutations affect the model more than others;\n\n- Missing analysis of the interaction between model size and robustness is extremely important as we see that some observations might not always be predictable and transferrable on smaller model sizes. \n\n- I am wondering why authors didn't consider ablation studies on the impact of Wikipedia edit types.\n\n2. Wikipedia edit history\n\nIt feels to me that Wikipedia's edit history might suffer from being less realistic and potentially data contamination."
            },
            "questions": {
                "value": "- why certain permutations affect the model more than others;\n\n- Are certain types of changes over/under-represented?\n\n- whether different pretraining approaches affect models' robustness to natural perturbations?\n\n- the effectiveness of adversarial training vary with model size and architecture?\n\n- the effectiveness of adversarial training vary with model size and architecture?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces perturbed sets of several machine-reading comprehension datasets including SQuAD, using Wikipedia edits to create natural perturbations. Results show that encoder-only, decoder-only and encoder-decoder LMs suffer from this challenge. Adversarial training with perturbation is an effective defense strategy."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. It is interesting to use Wikipedia edit history to construct perturbation.\n2. The perturbed set is verified by human to ensure that the perturbed examples are still valid.\n3. Results show that natural perturbation is a powerful attack to LMs."
            },
            "weaknesses": {
                "value": "1. It is unclear whether stronger model, e.g. gpt-4o would still suffer from this challenge. While weaker models like BERT suffers from the natural perturbations, it is important to show that it is still a challenge for recent stronger LLMs.\n2. The perturbation method relies on Wikipedia edit history, limiting its applicability to non-Wikipedia based datasets. \n3. The performance drops on non-SQuAD datasets like DROP are relatively small, e.g. LLaMA-2 only exhibits less than 2 points drop, which could also potentially be remedied by adversarial training. Again, I'm concerned that this benchmark is not super challenging for recent LLMs anymore."
            },
            "questions": {
                "value": "line 334-337: I have trouble understanding this long sentence with too many clauses. can you explain that?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors study the impact of real world perturbations on MRC performance for various Transformer-based architectures. They propose a framework to create naturally-perturbed test sets from popular QA datasets using the revision history of Wikipedia. They perform experiments and analyses on the abovementioned models, followed by adversarial training of encoder-only models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* Comprehensive evaluation across multiple architecture types rather than only decoder models and multiple models of each type: encoder, decoder, encoder-decoder models\n* Somewhat comprehensive evaluation across multiple QA datasets, with caveats: see below\n* Paragraphs are generally well-written and easy to understand"
            },
            "weaknesses": {
                "value": "**TLDR**\n\nThe authors pose an interesting question, but the execution of the study contains unexpected design decisions that are not well-justified. The exact improvement of their claimed methodology over existing work is also unclear.\n\n**Details:**\n* The authors call out the similarities between their method and Belinkov & Bisk (2018), do not make clear the differences and improvements over the latter, if any. The claimed contribution (\"novel Wikipedia revision history-based framework\") also does not highlight the exact improvements over simply applying Belinkov & Bisk (2018)'s method to the MRC setting, and is therefore running the risk of over-claiming. I recommend the authors revise the framing to highlight the exact contribution over Belinkov & Bisk (2018) and other prior, similar work [1, 2].\n* The encoder-only models were only evaluated on SQuAD datasets to draw conclusions, with no clear justification even though the authors are aware that they are no longer challenging benchmarks.\n* The transition to experiments on the other architectures and datasets was a little strange (only evaluating on questions that the encoder models failed on) with no clear justification. There is then a transition back to encoder-only models and SQuAD for adversarial training, also without clear justification for excluding other datasets and architectures. \n* The authors appear to have missed relevant work on robustness evaluation in QA/MRC [3, 4] and other types of synthetic perturbations [5].\n\n\n**Missing References:**\n1. Mining Naturally-occurring Corrections and Paraphrases from Wikipedia\u2019s Revision History. Max et al. 2010.\n1. Robust Systems for Preposition Error Correction Using Wikipedia Revisions. Cahill et al. 2013.\n1. It\u2019s Morphin\u2019 Time! Combating Linguistic Discrimination with Inflectional Perturbations. Tan et al. 2020.\n1. Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. Tan et al. 2021.\n1. From Hero to Z\u00e9roe: A Benchmark of Low-Level Adversarial Attacks. Eger et al 2020."
            },
            "questions": {
                "value": "> Questions on which none of the encoder-only models fail under the perturbation are then removed.\n\nWhy was this decision made, rather than studying the effect of all perturbed questions on each architecture type? An analysis of the overlaps between architectures is good to have, but I would have preferred to see the former if I had to choose one. I may have missed a strong justification, if one has already been included."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}