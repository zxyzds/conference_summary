{
    "id": "m0ddLnNvXS",
    "title": "Automatic Task-aware Instruction Optimizer for Black-box LLMs",
    "abstract": "Large Language Models (LLMs) have demonstrated superior capabilities in terms of solving various real-world tasks. However, their performance and generated content quality heavily depend on task-relevant instructions, which makes instruction optimization a challenging but critical direction to explore. In particular, as practitioners generally cannot access black-box (or API) LLMs' internal parameters and gradient information, it consequently makes instruction optimization for black-box LLMs especially non-trivial. Existing methods for optimizing black-box LLM instructions mainly focus on in-context learning using manually designed or heuristic disciplines, which can be insufficient due to the extreme complexity of modern black-box LLMs that can contain hundreds of billions of parameters. \nTo address these challenges, we propose a novel automatic instruction optimization framework named Automatic Instruction Optimizer (AIO). AIO is designed to perceive target task information and adaptively adjust its task-aware instructing strategy for a task-solver black-box LLM. \nBy leveraging a white-box LLM with parameter fine-tuning for enhanced representation power, AIO can automatically update its instructing strategy based on the feedback from task-solver black-box LLM. \nTo achieve this goal, AIO adopts a novel LLM parameter fine-tuning process powered by zeroth-order gradient approximation and Contextual Bandit techniques, which can effectively and efficiently help address the challenge of inaccessible black-box LLM internal parameters and gradients, as well as help alleviate expensive API cost concerns by flexibly reusing collected black-box LLM feedback.\nExtensive empirical evaluations are presented to demonstrate properties of our proposed AIO, and its effectiveness in comparison with strong baselines.",
    "keywords": [
        "Large Language Models; Instruction Optimization"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=m0ddLnNvXS",
    "pdf_link": "https://openreview.net/pdf?id=m0ddLnNvXS",
    "comments": [
        {
            "summary": {
                "value": "This work proposed to fine-tune a white-box LLM to generate optimal instruction for the black-box LLM for downstream tasks. Under the assumption of linear optimization landscape of $\\phi$, a zero-order gradient approximation approach was leveraged to update the parameters, in conjunction with a decision-making process that employed contextual bandits to select the most informative directions of gradient perturbation. Experiments of $15$ instruction induction and reasoning tasks showed the superior performance of the proposed algorithm."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The idea of automatic instruction optimizer is important to domain experts who do not have enough experience in prompting engineering. An added benefit would be increased transparency and trustworthiness between human and LLM agents.\n\n2. The zero-order optimization framework with gradient approximation and decomposition is reasonable when involving many parameters."
            },
            "weaknesses": {
                "value": "1. The structure can be significantly improved for better clarification and illustration. There are many re-defined notations and formulations, such as $\\phi$, $Theta_t$ and $\\mathbf{z} \\sim \\mathcal{N}(0, I)$. Showing the trivial calculation process makes it difficult to grasp the core structure of the algorithm. It is suggested to first give the overall framework of the algorithm and then briefly present the calculation details.\n\n2. The motivation of introducing Thompson sampling, in consideration of the zero-order gradient approximation, is confused. In addition, additional hyperparameters $\\beta$ and $B$ were introduced without enough sensitivity analysis in experiments.\n\n3. There is missing legend in Figure 3."
            },
            "questions": {
                "value": "1. Is the task context known by the white-box LLM? How can domain expert be involved in the design of instruction?\n\n2. Does the Thompson sampling introduces bias of gradient estimation? What is the influence of hyperparameters $\\beta$ and $B$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes an instruction optimization framework called Automatic Instruction Optimizer (AIO) for black-box Large Language Models (LLMs). LLMs often rely on precise, task-relevant instructions to achieve high-quality outputs, but manual optimization is challenging, especially for black-box models where internal parameters are inaccessible. AIO addresses this by employing a white-box LLM, which can be fine-tuned to generate optimized instructions based on task-specific information and feedback from the black-box LLM. The optimization process involves a novel zeroth-order gradient approximation method, aided by Thompson Sampling, which bypasses the need for direct access to gradients, enabling effective fine-tuning. Extensive experiments demonstrate that AIO not only improves task performance but also reduces API token costs. Compared to existing methods, AIO achieves better performance on various tasks and maintains efficiency through the adaptive reuse of feedback. This framework represents a significant advancement in automating instruction generation, enhancing the usability and adaptability of black-box LLMs across diverse tasks\u200b"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "+ The paper introduces a unique framework, Automatic Instruction Optimizer (AIO), that optimizes instructions for black-box LLMs without requiring access to internal parameters, which is a critical advantage in real-world applications where only API-based models are available.\n+ AIO\u2019s use of zeroth-order gradient approximation with Thompson Sampling is innovative, as it enables effective instruction fine-tuning without direct gradient access, thereby overcoming a major limitation in black-box model optimization.\n+ The framework significantly reduces API token consumption by reusing black-box LLM feedback adaptively, making it a cost-effective solution compared to existing in-context learning or manual tuning methods.\n+ The paper also explores lightweight PEFT variants (e.g., LoRA and Linear Probing) that maintain performance with fewer parameters, showcasing AIO\u2019s flexibility for different fine-tuning needs."
            },
            "weaknesses": {
                "value": "+ The experiments mainly use llama+API pairing, which may not fully represent the framework\u2019s effectiveness across a broader range of LLMs. I suggest the authors do more combinations of white-box LLMs, e.g., Mistral, for making the study of the method more comprehensive."
            },
            "questions": {
                "value": "The paper focuses on optimizing instructions based on task-specific feedback from a black-box LLM; how well does the optimized instruction generalize to related tasks or domains, especially in cases where task-specific data is sparse?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a task-aware instruction optimization for black-box LLMs. This method leverages both white LLM and black LLM. AIO adopts the parameter fine-tuning process with gradient approximation and contextual bandit techniques."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper proposes the AIO for the instruction optimization. The AIO provides some theoretical analysis and demonstrations."
            },
            "weaknesses": {
                "value": "1.\tThe evaluation benchmarks in this paper are not very common. The proposed improvements should be demonstrated in the general benchmarks, including the instructions for the following benchmarks.\n2.\tThe proposed method is unlike other task-aware instruction optimization methods. As there are many methods and literatures in this field, it would be beneficial to compare the proposed methods with other baselines.\n3.\tAlthough the white box LLM and black box LLM show improvements, it is obvious that this combination will perform better than the white box LLM and black box LLM individually. So the more analyses on these component designs are needed."
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper mainly focuses on optimizing task-aware instructions in the absence of task-solver LLMs\u2019 internal parameters and gradient information. Finding that the current instruction optimization methods based on in-context learning are insufficient to match the extreme complexity of modern black-box LLMs, this paper proposes a novel framework, called Automatic Instruction Optimizer (AIO), which fine-tunes a white-box LLM and enables it to adaptively adjust its instructing strategy for a particular task-solver black-box LLM. To address the optimization challenges, AIO adopts zeroth-order gradient approximation and Contextual Bandit techniques, eliminating the need for internal parameters and gradient information."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This paper demonstrates that fine-tuning a white-box LLM into the instruction optimizer is able to have better instruction generation performance due to a stronger representation power.\n- This paper addresses the optimization challenges using zeroth-order gradient approximation and manages to reduce the API cost by reusing historical records.\n- It conducts comprehensive experiments to verify the effectiveness of the proposed method, including different combinations of white-box and black-box LLMs, instruction optimization trajectory results, comparison to CoT."
            },
            "weaknesses": {
                "value": "- A minor point: study the transferability of fine-tuned instruction optimizers across different black-box task-solver LLMs.\n- The right-hand side of equation 1 misses a right parenthesis.\n- Figure 3 lacks proper legends for different instruction optimization methods."
            },
            "questions": {
                "value": "Kindly refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}