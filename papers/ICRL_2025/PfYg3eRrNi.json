{
    "id": "PfYg3eRrNi",
    "title": "Agent Workflow Memory",
    "abstract": "Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.",
    "keywords": [
        "agent",
        "web navigation",
        "memory augmentation",
        "online"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "AWM significantly improves agent performance by continually inducing workflows from past experiences, integrating into agent memory, and applying them to solve future tasks.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=PfYg3eRrNi",
    "pdf_link": "https://openreview.net/pdf?id=PfYg3eRrNi",
    "comments": [
        {
            "summary": {
                "value": "The paper presents the Agent Workflow Memory method for extracting and using task workflows for web navigation task.\nThe proposed memory is a collection of subroutines each of which is comprised from a task description and a set of actions generated by the agent or taken from the training dataset.\n\nAWM is implemented with GPT-3.5 and GPT-4 and evaluated on WebArena and Mind2Web datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed method enables online and offline variants of generating the task workflows to use both high-quality train data and past experiences of the agent.\n- The authors conduct the ablation study and evaluations on two web navigation datasets.\n- The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "- The paper would benefit from the descriptions of how the agent was implemented and tested. The authors provide the model prompt and example workflow prompts in appendix, but considering that the agent is based on the closed-source models, the lack of implementation details impedes reproducibility.\n- It is not clear how the workflows are extracted from memory to improve the task solving or the whole memory content is always provided as a part of the prompt."
            },
            "questions": {
                "value": "- How many past experiences can be stored in memory?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Agent Workflow Memory (AWM), a method for improving language model agents in complex, long-horizon tasks by learning and reusing task workflows. AWM flexibly supports both offline and online applications, showing strong improvements on web navigation benchmarks Mind2Web and WebArena. Results demonstrate notable gains in task success rates, efficiency, and cross-domain generalization."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Using reusable routines from agent trajectories is a fresh and effective idea for complex task management.\n2. Extensive evaluations, including ablation studies, validate AWM\u2019s effectiveness across online and offline settings.\n3. The concept of workflows is well-explained in Introduction, making AWM\u2019s approach easy to understand."
            },
            "weaknesses": {
                "value": "1. Figure 4 could be refined to better illustrate the workflow in the online setting.\n\n2. In WebArena, if AWM leverages test set tasks to build workflows, it could cause data leakage and compromise fairness.\n\n3. The paper does not show AWM\u2019s sensitivity to task exploration order, which could affect its performance. For example, which task should be explored first? Task sequence could impact the quality of workflows induced\u2014precisely, whether exploring tasks from difficult to easy (or vice versa) could degrade performance. Analyzing how task order affects workflow quality and overall results would provide valuable insight into AWM's robustness.\n\n4. In Table 1, \u201c# steps\u201d is unclear. Reporting tokens or time would better reflect agent efficiency.\n\n5. Section 5's description of \u201cwrapping each workflow into a high-level function\u201d needs more explanation and details.\n\n6. In Table 4, MindAct consistently achieves a higher AF1 score than AWM. It would be helpful if the authors could explain this."
            },
            "questions": {
                "value": "AWM\u2019s high performance in domains like Maps deserves more detailed analysis to explain these gains, which can help to understand methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposes agent workflow memory as an approach to building web agents that accumulate knowledge from their experiences as workflows. Specifically, it converts each successful trajectory it obtains to a workflow, which consists of a workflow description and workflow trajectory. It stores those workflows on a per-website basis. For inference, the corresponding workflows are incorporated into the agent's input and used for solving the tasks. The authors conduct experiments on WebArena and Mind2Web and demonstrate that their approach outperforms the compared baseline methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Acquiring domain-specific knowledge in a re-usable form can be useful and the proposed approach is reasonable. Especially, the authors try to acquire shorter chunks of re-usable skills as workflows, which could be important for inceasing the utility of such workflows.\n- Overall, the writing is easy to follow, especially with the well-visualized figures.\n- They perform additional empirical analyses, such as the form of workflows and how useful those acquired workflows are. These kinds of analyses can be helpful in constructing a deeper understanding of the proposed approach."
            },
            "weaknesses": {
                "value": "- The proposed approach accumulates experiences as workflows on a website basis (L196). While this can be effective in focusing on a specific set of websites, it also comes with a limitation in terms of generalization to different websites. This may also become a practical limitation, as there are myriad websites available and preparing various scenarios for most of them could be quite challenging. On benchmarks, this can be a factor that makes the empirical evaluation of the generalization capabilities of this approach difficult. Although this work tests the proposed approach in the online setting, existing benchmarks are based on pre-defined sets of websites.\n- Although the online acquisition of workflows in a continual manner can be helpful in practice, comparing only the online version with the baseline approaches on the benchmark tasks can be unfair or misleading. Usually, getting information about other test tasks can bring noticeable improvement in the performance in most benchmarks, mainly because of the similarities in the tasks and the bigger data size. For a fairer comparison without the knowledge about the \"held-out\" test tasks, one can try gathering experiences (and thus workflows) without access to any of the tasks from the test set and evaluating on each of the test tasks without updating the set of workflows.\n- In Table 4 for the Mind2Web results, the numbers for MindAct in the cross-domain split are the GPT-3.5 results, not the GPT-4 results."
            },
            "questions": {
                "value": "Please take a look at the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose an agent workflow memory that induces, augments and uses the most common functions as part of an existing library that the agent can take advantage of. This can be operated in both offline and online scenarios i.e. in the presence or absence of labeled samples. They evaluate the approach on two challenging  web navigation benchmarks mind2web and web arena and show that this simple and effective approach generalizes well across web navigation benchmarks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "#### Strengths:\n1. **IMemory Utilization:**\n   - AWM's ability to integrate workflows into the agent\u2019s memory, allowing for more sophisticated task handling and adaptation over time, is noteworthy. This is an advancement in making agents more autonomous and capable\n\n2. **Empirical Validation:**\n   - The empirical results showing AWM's performance boosts of 24.6% and 51.1% in relative success rates on the Mind2Web and WebArena benchmarks respectively are impressive. These results provide evidence of the workflow memory working to some level of competency.\n\n3. **Generalization across Domains:**\n   - The method's robustness across tasks, websites, and domains, particularly in environments where no annotated examples exist, highlights its potential for real-world applications and its adaptability."
            },
            "weaknesses": {
                "value": "#### Areas for Improvement, please take this with a pinch of salt:\n1. **Writing and Clarity:**\n - the paper needs a good amount of work on writing to meet the publication standards.  Can avoid unnecessary floating images and tables. Perhaps can save space by removing much of the unnecessary text and allowing natural space. More importantly, the overall story and clarity and motivation at places need improvement on why something is being discussed.\n\n2. **Workflow Induction Clarity:**\n   - The work could benefit from a more detailed explanation of the workflow induction process, particularly how the workflows are selected and refined during the induction phase. More insights into the criteria for choosing particular workflows over others would enhance the reader's understanding of the method's inner workings.\n\n3. **Discussion on Limitations:**\n   - While the paper discusses the success of the AWM model, a more thorough exploration of its limitations, especially in scenarios where the agent encounters completely novel tasks or domains not covered by the workflows, would provide a balanced view of its applicability.\n\n4. **Comparison with State-of-the-Art Methods:**\n   - Expanding the comparison with current state-of-the-art methods, not just in terms of task success rates but also considering factors like computational efficiency and scalability, would provide a clearer picture of standings."
            },
            "questions": {
                "value": "In the feedback from fellow reviewers and the authors, I would appreciate a discussion or clarity on the terminology used in the paper. The approach described appears to be a knowledge-retaining technique, akin to the reuse of skills stored in a skills library for related tasks, as seen in other literature such as Voyager (Wang et al., 2023) or works on counterfactual reasoning. These sources typically refer to reused routines as \"skills\" rather than \"workflows,\" and use \"library\" instead of \"memory\" for storage. It would be beneficial for the paper to acknowledge its inspirations from prior works, especially in the context of web navigation applications. This acknowledgment could help clarify the rationale behind the choice of terminology right from the start."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}