{
    "id": "d23EVDRJ6g",
    "title": "MotionDreamer: One-to-Many Motion Synthesis with Localized Generative Masked Transformer",
    "abstract": "Generative masked transformer have demonstrated remarkable success across various content generation tasks, primarily due to their ability to effectively model large-scale dataset distributions with high consistency. However, in the animation domain, large datasets are not always available. Applying generative masked modeling to generate diverse instances from a single MoCap reference may lead to overfitting, a challenge that remains unexplored. In this work, we present MotionDreamer, a localized masked modeling paradigm designed to learn motion internal patterns from a given motion with arbitrary topology and duration. By embedding the given motion into quantized tokens with a novel distribution regularization method, MotionDreamer constructs a robust and informative codebook for local motion patterns. Moreover, a sliding window local attention is introduced in our masked transformer, enabling the generation of natural yet diverse animations that closely resemble the reference motion patterns. As demonstrated through comprehensive experiments, MotionDreamer outperforms the state-of-the-art methods that are typically GAN or Diffusion-based in both faithfulness and diversity. Thanks to the consistency and robustness of quantization-based approach, MotionDreamer can also effectively perform downstream tasks such as temporal motion editing, crowd motion synthesis, and beat-aligned dance generation, all using a single reference motion. Our implementation, learned models and results are to be made publicly available upon paper acceptance.",
    "keywords": [
        "motion synthesis",
        "generative masked modelling",
        "vector quantization",
        "single instance learning"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We present MotionDreamer, a localized masked modeling paradigm designed to learn motion internal patterns from a given motion with arbitrary topology and duration.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=d23EVDRJ6g",
    "pdf_link": "https://openreview.net/pdf?id=d23EVDRJ6g",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces a novel method for intrinsic generation for motion, i.e., augmenting a single input motion sequence into multiple versions. The paper employs an underexplored generative approach - the masked transformer - and presents SOTA performance. To improve diversity and overall quality, the paper also offers a simple KL-divergence based loss to encourage full usage of the latent space, to mitigate mode collapse. The paper reports a complete evaluation, including comparisons, ablation studies, quantitative evaluation, qualitative evaluation and a user study."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Paper is well written and easy to follow.\n- Proposed method is simple and elegant\n- The mask transformer mechanism is a refreshing approach\n- Codebook distribution regularization is interesting\n- Evaluation is rigorous, including all conventional metrics"
            },
            "weaknesses": {
                "value": "- The application is a niche one \n- The method, being simple, is also limited in contribution\n- Qualitative evaluation is limited"
            },
            "questions": {
                "value": "As stated above, I believe that paper presents interesting ideas, and I would like to see this player out there with the other methods. \n\nMy main concern is the scope of impact. Perhaps these ideas can and should be examined in a wider scope:\n- can the codebook regularization loss improve other VQ methods off the bat? \n- More ambitiously, can this method be combined with others, for example can the masked transformer be applied in the bottle neck of a diffusion process? or perhaps instead of the VAE?\n- similarly, some more discussion regarding the regularization could benefit the paper. What other alternatives could have been employed?\n\nIn addition, I would have liked to see some more qualitative results \n\nMinor concerns:\n- Swin is already rather widely adopted and known for shifting windows (Swin-Transformer), I recommend using another name for the sliding window approach (which I find simple and elegant for reducing the receptive field)\n- \"Crowd motion synthesis\" can also be misinterpreted here, as an algorithm to avoid collisions, I would also find a different name here.\n- I find figures 1 and 2 a bit exaggerated. The right side of Fig 2 depicts little information for its size. Figure 1 is also rather overwhelming, half of the amount of characters would probably go a long way."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes Motiondreamer, a framework for one-to-many motion synthesis. The paper aims to learn the underlying motion pattern in a given sequence and leverage the motion pattern to generate natural and diverse motions.\nThe general idea of the paper is to first quantize a motion sequence into tokens, and then train a masked transformer to generate these motion tokens. \nThere are two core technical contributions,  one lies in regularising motion tokenization to encourage more coverage, and the other one lies in injecting localality into the makes transformer to encourage motion decomposition."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The model is well-designed. Given the scarcity of motion data in this one-to-many setting, the inductive bias in the model design is particularly important. The overall framework follows a masked transformer architecture which is simple, but multiple practical techniques have been contributed to balance the motion faithfulness and the motion diversity, including\n    - A KL term is added to the quantizer training besides the standard commitment loss to encourage coverage.\n    - A sliding window attention that adds locality to the transformer to encourage diversity.\n    - A differentiable dequantization loss that helps to compute loss on the motion space.\n    \n    All of them are well-motivated and make sense to me.\n    \n- The ablation study is very comprehensive. Although the above techniques, like KL regularisation, are quite standard and empirical, the paper provides detailed experiments to support their importance to the final results. I find those experiments convincing.\n- The paper shows qualitative results on a webpage, which generally looks good to me. Compared to SinMDM, the proposed method reduces unnatural motions. Compared to SinMDM, the generated motion seems more diverse."
            },
            "weaknesses": {
                "value": "- Table 1 and Figure 3 are inconsistent in the comparison between GenMM with Ours. Table 1 shows that GenMM has much better coverage than Ours. However, in Figure 3, the failure mode of GenMM is missing a part of the reference motion.\n- The beat-aligned dance synthesis application does not convince me. The generated dances have a clear mismatch with the tempo. Most importantly, the application (including implementation details) is not well documented in the paper so I am not fully sure what is happening there, for example, what is a \u201clight-weight encoder-decoder\u201d? To my understanding, the beat-aligned dance is like an extension of the \u201csubpart generation\u201d task while keeping predefined keyposes on the music beats. That is not sufficient to produce a beat-aligned dance in my opinion.\n- Some of the techniques could be a little niche to be presented as part of the method. For example, AttnFuse could better fit into implementation details.\n- Minor\n    - L281: by progressively fill \u2192 by progressively filling.\n\n----\nThe overall framework makes sense to me. The proposed techniques are simple, but they are well-motivated and are supported by solid ablation experiments. I am convinced that they contribute to the overall performance. My concerns are about the comparison between GenMM and the dance generation application part. The presentation can be improved as well. I am slightly inclined to accept."
            },
            "questions": {
                "value": "Please address the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a localized masked modeling paradigm designed to learn motion internal patterns from a given motion with arbitrary topology and duration. It introduces the codebook distribution regularization and sliding window local attention (SwinAttn) mechanism to avoid codebook collapse and overfitting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The codebook distribution regularization effectively prevents codebook collapse. The sliding window local attention mechanism in the Local-M transformer captures local dependencies and ensures smooth transitions across overlapping windows, enhancing the fidelity and diversity of generated motions."
            },
            "weaknesses": {
                "value": "This paper applies some recent advancements from the image domain to motion synthesis, which is a commendable attempt. However, the contribution feels somewhat limited. As a work focused on enhancing the VQVAE structure for motion synthesis, the authors might benefit from incorporating insights and experiments from NCP, rather than simply adapting the network architecture.\n# Added after AC's comment\nI'm grateful for the feedback and suggestions. To clarify, the aspects of the contribution that feel limited include the novelty in adapting image domain advancements without significant modification or integration specific to motion synthesis. Additionally, while some metrics have been provided, they may not fully reflect the method's advantages. I believe visualizations of the latent space could be helpful in demonstrating its effectiveness. Regarding NCP, I apologize for the oversight\u2014it refers to Neural Categorical Priors for Physics-Based Character Control. Thank you for the guidance."
            },
            "questions": {
                "value": "In the final section of the paper, the authors mention several other applications. Could the authors elaborate on how the network architecture performs and what advantages it offers for these tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a generative masked model (MotionDreamer) for motion synthesis domain based on the motivation \"large datasets are not always available\". MotionDreamer designs a local masked modeling paradigm to learn motion internal patterns from a given motion with a key sliding window local attention module. Experiments demonstrate various motion tasks, including crowd motion synthesis, temporal editing and beat-aligned dance synthesis."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is well-written and is easy to follow. \n\n- Qualitatively results look impressive. Ablation studies prove the effectiveness of the designs.\n\n- The authors introduce various applications of motion synthesis and achieve great performance."
            },
            "weaknesses": {
                "value": "- Generative masked modeling for motion synthesis has been investigated in many recent works, such as MMM, Momask, MotionGPT, as described in paper. On the other hand, single motion synthesis is also not new, such as SinMDM. It seems that MotionDreamer integrates the techniques of generative masked modeling into the task of single motion synthesis, including motion tokenization and codebook distribution regularization.\n\n- Capturing local dependencies of motion features is quite important for single motion synthesis. SinMDM introduces QnA layers that allow local attention with a temporally narrow receptive field. And MotionDreamer incorporates sliding window local attention to achieve this. Besides, another key design of codebook distribution regularization has been explored in single image synthesis domain. Therefore, I think the technical contribution of the paper is somewhat limited.\n\n-  In Ablation Studies (Sec. 4.4), it's better to use QnA layers in SinMDM to replace sliding window local attention and show the comparison of the performance. Due to the same task, the paper should demonstrate its unique effectiveness."
            },
            "questions": {
                "value": "See Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}