{
    "id": "d4gu2XgccF",
    "title": "MEMREASONER: A MEMORY-AUGMENTED LANGUAGE MODEL ARCHITECTURE FOR MULTI-HOP REASONING",
    "abstract": "Recent benchmarks suggest that there remains significant room to improve large language models\u2019 ability to robustly reason across facts distributed in extremely long documents. In this work, we propose MemReasoner, a new memory-augmented LLM architecture that is trained to perform temporal reasoning, along with multiple computational steps,  over the context stored in the memory. Experiments show that MemReasoner trained on the core reasoning facts generalizes better, when compared to off-the-shelf large language models and existing recurrent models, on a test distribution  where  the required facts are scattered across long natural text up to 128k tokens. Further, MemReasoner demonstrates robust reasoning performance relative to the baselines, when the answer distribution in test samples  differs from that in the training set.",
    "keywords": [
        "reasoning",
        "multi hop",
        "memory",
        "large language models",
        "generalization"
    ],
    "primary_area": "generative models",
    "TLDR": "A memory-augmented LLM shows robust multi-hop reasoning on a challenging long-context benchmark",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=d4gu2XgccF",
    "pdf_link": "https://openreview.net/pdf?id=d4gu2XgccF",
    "comments": [
        {
            "summary": {
                "value": "MemReasoner is a novel encoder component of an encoder-decoder transformer architecture. On top of a transformer encoder stack, it uses a recurrent component to write memory and read memory.\n\nThe readout is fed into the decoder similar to key-value cache to improve performance on question-answeringe tasks.\n\nThe paper benchmarks their method on BABILong. Their method solves the task as shorter contexts but does not seem to length generalize. However, their method does do better than the baselines when symbolically manipulating locations."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The hypothesis and method are well motivated. The experiments are well done and the model well in short contexts and is robust to symbolic manipulation of the locations."
            },
            "weaknesses": {
                "value": "I don't think I entirely understand the comparisons. The model does much worse than the models that are finetuned on long context data. We should see if MemReasoner also benefits from this?"
            },
            "questions": {
                "value": "The encoder and memory components have some cost and overhead. What are they?\n\nHow does it compare to just give the decoder more parameters?\n\nCan MemReasoner augment existing decoder-only LLMs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces MemReasoner, a memory-augmented LLM designed to improve temporal and multi-hop reasoning over extremely long contexts. MemReasoner integrates an episodic memory module and introduces a novel mechanism for explicitly learning temporal relationships between events and for iteratively reading and updating queries, aiming to address the limitations of existing LLMs in processing and reasoning across long documents. The proposed model is evaluated on the BABILong benchmark, demonstrating superior generalization compared to existing LLMs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The authors present an architecture that uses a memory module for capturing temporal relationships and enabling multi-hop reasoning, which adds a valuable improvement over standard LLMs.\n- MemReasoner demonstrates a robust ability to reason across contexts of up to 128k tokens, outperforming existing LLMs and memory-augmented architectures on the challenging BABILong benchmark."
            },
            "weaknesses": {
                "value": "- The experiments are largely based on synthetic datasets like BABILong, which, while controlled, may not fully reflect the complexities of real-world language tasks. Extending evaluations to diverse, natural datasets would strengthen the validity of the model\u2019s utility.\n- The architecture involves multiple components like GRU-based temporal encoding and iterative query updates, which might increase computational complexity, potentially making it less scalable for broader applications."
            },
            "questions": {
                "value": "- What improvements does MemReasoner have compared to Larimar?\n- Has the model been tested on other multi-hop reasoning datasets or more general NLP tasks?\n- How does MemReasoner compare to traditional, non-LLM memory networks? Are there any experiments comparing it to these earlier methods, and what would the outcomes likely be?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes MemReasoner, a method that augments language models with memory and is designed to perform reasoning over long contexts. The authors aim to enable models trained on short sequences to generalize and work effectively on longer sequences without retraining. To achieve this, they build on the Larimar model, which augments language models with episodic memory, and enhance it with two key modifications: 1. An iterative mechanism to read information from memory and update the query accordingly. 2. Adding explicit information about temporal ordering of facts within the context (via position embeddings or BiGRU). The approach is evaluated on the bAbI dataset and its long sequence variant BABILong, demonstrating the ability to perform on longer sequences while being trained on short ones, and improving performance over existing methods in this setup."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- General idea of iterative reading from memory for multi-hop tasks is clear and reasonable.\n- The motivation to address the challenge of generalizing from short to long sequences without extensive retraining is strong and relevant, and addresses a key limitation of current methods.\n- Results show that the proposed approach is indeed able to generalize to longer sequences being trained on short only.\n- The evaluation setup, using the bAbI dataset and its longer version, is clear and suitable for testing the ability of the method to solve inference tasks over varying sequence lengths."
            },
            "weaknesses": {
                "value": "- Giving that idea is clear, unfortunately Section 3 that describes the proposed method is hard to read and lacks clarity. I believe clarity of presentation of the proposed method should be largely improved. Details are provided in the suggestions section. \n- Lack of comparison with Transformer models. The authors do not evaluate the performance of transformer-based LMs that support long contexts (e.g., LLama-3.2, Phi-3.5, or Qwen-2.5). These models could be fine-tuned on bAbI and evaluated on BABILong, providing relevant baselines for comparison. Including such evaluations would contextualize the performance of MemReasoner relative to current state-of-the-art models.\n- Generalization of the proposed method to tasks other than bAbI is not supported. There are other datasets that require multi-hop reasoning, such as MultiHopQA, MuSiQue, HotPotQA. Their context could be extended by extracting relative paragraphs from e.g. Wikipedia.\n- The paper does not provide empirical evaluations of the method\u2019s inference time or memory consumption compared to other methods. However, authors provide theoretical time complexity in Appendix A.2."
            },
            "questions": {
                "value": "Suggestions on improving presentation:\n- Figure 2 is hard to comprehend \u2013 it is not clear where to start from. I would suggest making two schemes: 1. conceptual scheme of the method. 2. a detailed one with how the memory module and the query are iteratively updated.\n- Similar problem with Section 3 - overloaded preliminary section hindering comprehension. Section 3.1 contains too many details on how memory read/write operations are constructed, making it challenging to grasp the overall picture. Splitting the explanation into two parts \u2013 a conceptual overview and detailed descriptions of the memory module and reasoning within it \u2013 would help readers understand the main ideas before diving into technical specifics. As the method is based on the Larimar model, a dedicated section describing Larimar would greatly improve clarity.\n- L292-296 present formulas for the loss components that are difficult to match with their explanations. Defining each loss component separately and explaining their roles can improve clarity and comprehension.\n- How do P_a and P_s look like in L270\u2013271? P_a is later defined in L371\u2013372. Providing these definitions earlier would help improve clarity.\n- Typos and Minor Issues\n  - L315: \"facts from bAbI is distributed\" -> are\n  - L318\u2013319: missing space \"tokens.For\"\n\nComments:\n- One of the results is that RMT being trained on short sequences (single segment) can not generalize to longer ones (multiple segments). RMT inherently can not generalize from 1 segment to multiple segments. To learn to use memory (to pass information sequentially) it needs at least 2 segments. It was shown in RMT paper and generalization to larger lengths is possible with curriculum learning procedure (\u201cBeyond Attention: Breaking the Limits of Transformer Context Length with Recurrent Memory\u201d). So this makes comparison with RMT not so fair.\n\nQuestions:\n- Table 1 and 2 miss results for RMT on 64k and 128k. Authors mention that it \u201cmeans unavailable due to out of memory errors or maximal input length constraints\u201d (L426). However, RMT has constant memory consumption as it is required to pass only memory states between segments, and there is no need to all keep intermediate outputs. So, it is not clear why these values are missing? However, I acknowledge that they would be low.\n- Is it possible to train MemReasoner on longer sequences and compare it with RMT/Mamba which has also been trained on longer sequences? Will the performance of MemReasoner continue to improve?\n- L182 - what does \u201cmimicking Bayesian inference\u201d mean here? How is it motivated and why is it mimicking? It is unclear how this concept is applied and whether it is key to constructing an effective memory module.\n- After the last readout operation, the z_i most similar to z_r is selected. Z_i, representing a single fact from bAbI, goes to a decoder. It seems to be sufficient for QA1-2 tasks to get the correct answer from bAbI, but would it be sufficient for general tasks to extract only one fact from memory? Why not to use z_r itself?\n- The paper does not clearly explain whether the number of memory read operations correlates with the number of fact hops required in reasoning tasks. For example, in QA2 tasks, a fixed number of two read operations is used. Is this number optimal? Would using only one read operation be insufficient to retrieve the answer? Providing an analysis or justification for the chosen number of read operations would clarify this aspect.\n\nPersonally, I like the idea and direction of the work and find it interesting. However, I think it could be improved a lot."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}