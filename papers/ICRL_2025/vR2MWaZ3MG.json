{
    "id": "vR2MWaZ3MG",
    "title": "Matchmaker: Schema Matching with self-improving compositional LLM programs",
    "abstract": "Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce --- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic, or suffer from poor zero-shot performance. To this end, we propose Matchmaker -  a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process.  Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.",
    "keywords": [
        "schema matching",
        "data-centric AI",
        "Large Language Models",
        "healthcare"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "schema matching across heterogenous data sources using compositional language model programs",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vR2MWaZ3MG",
    "pdf_link": "https://openreview.net/pdf?id=vR2MWaZ3MG",
    "comments": [
        {
            "summary": {
                "value": "The paper deals with schema matching, and old but very important problem in databases. The idea is that, given one starting (relational) schema and one target schema, to be able to match which attributes in the  starting schema correspond to attributes in target schema. The proposal in this paper is Matchmaker. This system uses a mix of retrieval using multi-vector representation and LLM-based reasoning to produce candidates for the matching, and then applies a final LLM-driven step to refine these candidates. Notably, the program also is built so that it can optimize the last step by providing examples from the databases. All together, the system shows quite an advantage over previous proposals."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Very well written \n- Addresses an importan tproblem that has ben recently identified as a target for the ML community\n- Provides a thorough experimental section, including a (very nice) ablation study to understand the impact of different strategies for candidate generation."
            },
            "weaknesses": {
                "value": "- While the paper is well writtend and scientifically sound, the algorithm itself (matchmaker) is not groundbreaking. Matchmaker resolves basically on building appropriate chain of thought prompts, as well as applying semantic similarity techniques. As such, I see this mostly as a paper describing a particular, LLM-based proposal, to address this problem. \n- There seem to be a lack of LLM-dirven alternatives to compare with, which is both good for the paper (because authors are the first to apply them in this context), but it also raises the question on whether any other similar approach would produce similar results. \n- The problem itself ( schema matching, or more generally data harmonization/interoperability) is not a core problematic of ICLR. I would imagine this paper would be more suitted to a database conference."
            },
            "questions": {
                "value": "Why haven't you submitted this to a database conference? It seems to me that the reception and impact there would be much higher."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a zero-shot schema matching approach by leveraging the multi-stage call of LLMs to generate, refine, and score the matchings.  Specifically, it introduces synthetic examples to guide the reasoning of LLMs for improving and optimizing the results of schema matching. The experiments on medical schema matching benchmarks demonstrate that the proposed approach outperforms the selected baseline methods on accuracy. \n\nThe paper does a great job of demonstrating the problem that they are solving and the methodology they presented. \nThe main contribution is decomposing the schema matching task into multi-stage sub-tasks that are completed by multiple calling of LLMs, with retrieval from contextual reasoning and prompt optimization based on in-context examples. However, the contribution of this work is limited, as they only introduce the muti-stage schema matching by extending the calling of LLMs from single to multiple."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1: The idea of leveraging the multi-stage LLMs for schema matching is novel.\n\nS2: The authors do a great job of demonstrating the challenges of schema matching in real-world scenarios that they are trying to address and the methodology they presented. \n\nS3: Several experiments on MIMIC-OMOP and Synthea-OMOP datasets are conducted to empirically investigate and demonstrate the performance of the presented method."
            },
            "weaknesses": {
                "value": "W1: The contribution of this work is limited, as they only introduce the muti-stage schema matching by extending the calling of LLMs from single to multiple.  \n\nW2: The accuracy@k is the only metrics that is reported in experimental results, the results on precision are missing. \n\nW3: The prompts are provided in the appendix, but the source code is not provided for reproducibility.\n\nW4: The GPT-4 (0613) is the only backbone model, the results of using llama as backbone are not reported."
            },
            "questions": {
                "value": "Q1: How does your approach work in terms of precision when compared with the baseline method?\n\nQ2: How confident when ranking the LLM-generated candidates with LLM-based scores? How much does this ranking contribute to the results?\n\nQ3: Could you provide the details of how the vector retrieval works in Sec 4.1?\nIf I understand well, you retrieve the top-k matching from the target schema attribute based on MaxSim between query embeddings and target schema embeddings. However, the granularity of the query embeddings and target schema embedding is different, query embedding is an attribute-level embedding while target schema embedding is a table-level embedding."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors considered the schema matching problem for\ntabular structured data. In particular, a schema is defined as a set\nof tables {T_1, ..., T_m}, where each table T_i has a set of\nattributes {A_{i,1}, ..., A_{i,n_i}}. Additionally, it is assumed that\neach table T_i is associated with some metadata describing its purpose\nand content, and each attribute A_{i,j} is associated with some\nmetadata describing its type and relational context. Then, given a\nsource schema S including a set of attributes A_S and a target schema\nT including a set of attributes A_T, the goal of schema matching is to\nfind a partial function f : A_S -> A_T such that if f(A) = B for\nattributes A in A_S and B in A_T, then B is the corresponding target\nattribute to the source attribute A.\n\nThe algorithm proposed in the paper for schema matching works as\nfollows. Given a source attribute A, the algorithm uses embeddings of\nA and the target attributes to retrieve the top-k matching target\nattributes. The generated set of target attributes is called the\nsemantic retrieval candidates for A. Then the algorithm generates a\nset of reasoning-based candidates using a reasoning LLM. The union of\nsemantic retrieval candidates with reasoning-based candidates\nconstitutes the set of candidates for A. Then the algorithm uses a\nrefiner LLM to reduce the number of candidates, and it finally ranks\nthe resulting candidates and filters out the non-suitable ones. If the\nresulting set of target attributes is not empty, then the top-scored\nattribute can be considered as the corresponding target attribute for\nA."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1) The schema matching problem is fundamental to generating large,\n    integrated, and interoperable datasets. In this sense, this paper\n    addresses a relevant and interesting problem.\n\nS2) The experimental evaluation shows that the proposed approach\n    outperforms other schema matching approaches in terms of accuracy."
            },
            "weaknesses": {
                "value": "W1) The approach proposed in the paper essentially disregards the\n    large body of work on schema matching that has been developed for\n    decades in the database field.\n\nW2) The schema matching problem is not properly formalized."
            },
            "questions": {
                "value": "General comments\n\nThe schema matching problem is fundamental to generating large,\nintegrated, and interoperable datasets. In this sense, this paper\nmakes a contribution by proposing a new method for this problem that\ntakes advantage of certain capabilities of LLMs. Besides, the\nexperimental evaluation provides evidence that the proposed method\noutperforms other schema matching approaches in terms of\naccuracy. However, I have two serious concerns about the contribution\nof this paper:\n\n- The schema matching problem is not properly formalized. The authors\n  provide a formal definition of this problem where they indicate that\n  mapping function f \"correctly\" assigns each attribute of the source\n  schema to an attribute of the target schema. How is the\n  \"correctness\" of f defined? What are the properties that a correct\n  mapping function f should satisfy? Does the algorithm proposed in\n  this paper compute a function f that satisfies such properties? None\n  of these questions is answer in the paper.\n\n- The authors disregard the large body of work on schema matching that\n  has been developed in the database area. I am not going to mention\n  here the relevant literature on schema matching, which is an\n  established area within databases, but I would like to note that one\n  can already find surveys on this topic from more than 20 years ago:\n\n  Erhard Rahm, Philip A. Bernstein: A survey of approaches to\n  automatic schema matching. VLDB J. 10(4): 334-350 (2001)\n\n  Notice that the problem considered in this paper is schema matching\n  for relational databases, which is exactly the scenario discussed in\n  this survey.\n\n  A first obvious step in considering the work on schema matching done\n  in databases is to compare the method proposed in this paper with\n  methods from the database field. But this is just the tip of the\n  iceberg and probably not the most fruitful way. The method proposed\n  in this paper can be improved by considering the more classical work\n  in schema matching. For example, the authors could leverage this\n  work in the generation of candidates, and they can address issues\n  with the formalization of the schema matching problem by reusing its\n  formalization from the database field.\n\n\nSpecific questions\n\nAll these questions refer to the definition of the schema matching\nproblem:\n\n- How is the notion of correctness of a mapping function f defined?\n\n- What are the properties that a correct mapping function f should\n  satisfy?\n\n- Does the algorithm proposed in this paper compute a function f that\n  satisfies such properties?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Matchmaker, a novel approach to schema matching using a self-improving compositional language model program. Schema matching is crucial for creating interoperable ML-ready data by finding correspondences between attributes across different databases. Matchmaker operates through three main components: multi-vector document creation, candidate generation (using both semantic retrieval and LLM-based reasoning), and confidence scoring. A key innovation is its ability to self-improve without labeled data through synthetic in-context examples. The method significantly outperforms existing approaches on real-world healthcare schema matching benchmarks (MIMIC-OMOP and Synthea-OMOP)."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Addresses a critical practical problem in data integration that has significant implications for ML development\n2. Novel technical approach combining retrieval and LLM reasoning in a compositional program\n3. Zero-shot learning capability through synthetic in-context examples, eliminating the need for labeled training data\n4. Comprehensive empirical evaluation against multiple baselines\n5. Practical considerations for deployment, including human-in-the-loop integration and uncertainty handling\n6. Strong quantitative results showing 15-20% improvement over baselines\n7. Well-documented implementation details and ablation studies"
            },
            "weaknesses": {
                "value": "1. Limited evaluation to two healthcare domain datasets, though the approach is claimed to be general\n2. The synthetic in-context example generation process could be explained more clearly\n3. The paper shows strong performance metrics but doesn't provide detailed analysis of where and why Matchmaker fails"
            },
            "questions": {
                "value": "1. How does the performance of Matchmaker scale with very large schemas (>1000 attributes)?\n2. Could the approach be extended to handle many-to-many mappings between schemas?\n3. How sensitive is the performance to the quality of attribute descriptions in the schemas?\n4. What strategies could be employed to reduce the number of LLM calls while maintaining performance?\n5. How might the system handle schemas in languages other than English?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}