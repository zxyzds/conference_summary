{
    "id": "OeKp3AdiVO",
    "title": "Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach",
    "abstract": "In the field of long-tailed recognition, the Decoupled Training paradigm has shown exceptional promise by dividing training into two stages: representation learning and classifier re-training.  While previous work has tried to improve both stages simultaneously, this complicates isolating the effect of classifier re-training.  Recent studies reveal that simple regularization can produce strong feature representations, highlighting the need to reassess classifier re-training methods.  In this study, we revisit classifier re-training methods based on a unified feature representation and re-evaluate their performances. \nWe propose two new metrics, Logits Magnitude and Regularized Standard Deviation, to compare the differences and similarities between various methods. \nUsing these two newly proposed metrics, we demonstrate that when the Logits Magnitude across classes is nearly balanced, further reducing its overall value can effectively decrease errors and disturbances during training, leading to better model performance. \nBased on our analysis using these metrics, we observe that adjusting the logits could improve model performance, leading us to develop a simple label over-smoothing approach to adjust the logits without requiring prior knowledge of class distribution.\nThis method softens the original one-hot labels by assigning a probability slightly higher than $\\frac{1}{K}$ to the true class and slightly lower than $\\frac{1}{K}$ to the other classes, where $K$ is the number of classes.\nOur method achieves state-of-the-art performance on various imbalanced datasets, including CIFAR100-LT, ImageNet-LT, and iNaturalist2018.",
    "keywords": [
        "Long-Tailed Recognition and Decoupled Training"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "In this study, we propose a new logits-based metric for classifier re-training in long-tailed recognition, introducing a simple retargeting method \"Label Over-Smooth\" that achieves state-of-the-art performance on imbalanced datasets.",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=OeKp3AdiVO",
    "pdf_link": "https://openreview.net/pdf?id=OeKp3AdiVO",
    "comments": [
        {
            "summary": {
                "value": "This paper revisits the two-stage learning paradigm in long-tailed recognition and proposes two metrics, Logits Magnitude, and Regularized Standard Deviation, to compare different classifier re-training methods. Moreover, it develops a label over-smoothing approach to improve model performance. Experimental results on multiple long-tailed datasets demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper reveals some shortages in previous metrics, such as the ignoration of feature magnitude.\n\n- The proposed label over-smoothing is interesting. Both theoretical and empirical results demonstrate the effectiveness.\n\n- The proposed LOS outperforms most compared methods on multiple datasets. The ablation studies are well done."
            },
            "weaknesses": {
                "value": "- Figure 1 is hard to follow. What do the red and blue lines mean? Why do they obey Gaussian distributions? More explanations are required.\n\n- Since the feature magnitude and the class weight norm both have effects on prediction results, why not directly use the Cosine classifier? The Cosine classifier is quite simple and effective, which calculates Cosine similarities between the normalized features and the normalized class weights, and then divides it by a temperature to obtain the final logits. Therefore, it can directly mitigate the impact of feature magnitude. (Well, maybe the logit magnitude is different from the feature magnitude, but I suggest the authors include the Cosine classifier as a baseline.)\n\n- Despite the superior performance. Some recent works are ignored and not compared. For example, RIDE, BCL, NCL, GML.\n\n- The references are outdated. Among the 50 cited papers, there are no papers from 2024, only 3 papers from 2023, and 4 papers from 2022.\n\n- Please pay attention to the format of the references. Some do not include the source (e.g. Peifeng et al., 2023); some have a URL (Huang et al., 2018) but others do not; some source names are inconsistent (e.g. \"Computer Vision-ECCV ...\" or \"Proceedings of ... (ECCV)\"? and \"arXiv preprint\" or \"ArXiv, abs/...\" or \"arXiv e-prints\"?)"
            },
            "questions": {
                "value": "See \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper revisits the paradigm of classifier re-training in the context of long-tailed recognition and proposes two metrics for analyzing the efficacy of classifiers: logits magnitude (LoMa) and regularized standard deviation. Various existing methods for LTR are re-evaluated with a unified feature representation and with respect to the proposed metrics. They further use a variant of label smoothing where very strong smoothing is used to achieve better performance. Results and ablation studies are reported on multiple benchmark LTR datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The performance of various methods seems to somewhat correlate to the proposed metrics.\n2. The proposed method outperforms prior arts on multiple benchmarks in most of the evaluated settings.\n3. The over-smoothing technique can be used as a plugin on top of existing methods."
            },
            "weaknesses": {
                "value": "1. The proposed LoMa metric is hard to understand due to ambiguous language and notation. The authors should use two indices in the subscript of the logits to differentiate between sample and class. In Fig. 2 it is unclear what true samples and non-true samples are. \n2. While the authors claim it is hard to optimize directly for LoMa or Regularized Standard Deviation, they don't propose any way to do this. The suggested label smoothing approach doesn't directly fit into the story of achieving uniform LoMa.\n3. There are wild claims made, for instance, that classifier weight norm cannot capture a method's efficacy due to potential arbitrary lengths (Proposition 2). It is relative weight norm that matters, not absolute, thus rendering Prop. 2 meaningless. Section 3.1 on the deep dive into LoMa seems like a rambling section without concrete takeaways. \n4. The math in the paper could be improved. For instance, in Eq. 9, the expectation can't be decomposed like that, it looks artificial. \n5. The proposed (over) label smoothing technique is just a minor variant of prior work."
            },
            "questions": {
                "value": "Please address the points in weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a simple but effective method for long-tailed problem. They base their method in decoupled ones and first propose two new metrics, Logits Magnitude and Regularized Standard Deviation, to compare the differences and similarities between various methods. Then, they propose a simple method by softening the original one-hot labels by assigning a probability slightly higher than $1/K$ to the true class and slightly lower than $1/K$ to the other classes, where $K$ is the number of classes. In the method, they also provide the detailed analysis how the method is designed. In the experiments, the results validate the effectiveness of proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) The structure of this paper is clear, starting from the definition of problem, the background motivation and analysis to the final implementation.\n\n(2) The experiments are good. By applying the proposed method to some existing methods, their performances can be further improved."
            },
            "weaknesses": {
                "value": "Although the structure is clear, the transition from last part to the next can be further improved. \n\nSome of the explanations are also missed. See below."
            },
            "questions": {
                "value": "I tried to understand the logic and the details of this paper, so some of the points in the paper require further clarification:\n\n(1) In Proposition 1. It is said \" In all cross-entropy based methods, the aforementioned conclusion remains valid\", in deep learning networks, the objective is always a non-convex optimization problem, how the conclusion is still valid in this case?\n\n(2) The Proposition 1 is used to exclude the effect of b and to introduce Proposition 2 which illustrates that the weight norm-based method may not be reliable in some cases, am I right? But how the equation (4) is obtained? from s' to s.\n\n(3) From line 313-314, how the assumption is determined\" Consider random perturbations \u2206i that independently affect each class zi and are proportional to the standard deviation of their logits, i.e., z\u2032\"?? It is said \"These perturbations \u2206 are commonly introduced during the training process, particularly due to factors such as overfitting in the initial stage of training and bias in the sampling of the training set.\", can you clarify more on this point?\n\n(4) if the point lies in $\\Delta$ and $\\sigma$ in section 3.1, what is the point to introduce definition 2?? The point in definition 2 shoule be $R_i$, right?\n\n(5) Figure 1 is also not easy to understand for the first time until figure 2 is given.\n\nTypo: (1) Is the parenthesis missed in line 107?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper revisits the classifier re-training in long-tailed recognition, proposing a simple label over-smoothing approach to balance the logits magnitude across classes. The method achieves state-of-the-art performance on various imbalanced datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The method is simple, using basic label smoothing to effectively reduce overfitting.\n1. Theoretical analysis and experimental validation are comprehensive, demonstrating the method's effectiveness across various datasets."
            },
            "weaknesses": {
                "value": "There are no significant methodological drawbacks. It is recommended that the authors include comparisons with the latest SOTA methods^[1] and discuss related works^[2,3].\n\n[1] Probabilistic Contrastive Learning for Long-Tailed Visual Recognition. TPAMI 2024.\n\n[2] Adaptive Logit Adjustment Loss for Long-Tailed Visual Recognition. AAAI 2022.\n\n[3] Long-Tailed Visual Recognition via Gaussian Clouded Logit Adjustment. CVPR 2022."
            },
            "questions": {
                "value": "See the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}