{
    "id": "57EjN072hl",
    "title": "COT Flow: Learning Optimal-Transport Image Sampling and Editing by Contrastive Pairs",
    "abstract": "Diffusion models have demonstrated strong performance in sampling and editing multi-modal data with high generation quality, yet they suffer from the iterative generation process which is computationally expensive and slow. In addition, most methods are constrained to generate data from Gaussian noise, which limits their sampling and editing flexibility. To overcome both disadvantages, we present Contrastive Optimal Transport Flow (COT Flow), a new method that achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models. Benefiting from optimal transport (OT), our method has no limitation on the prior distribution, enabling unpaired image-to-image (I2I) translation and doubling the editable space (at both the start and end of the trajectory) compared to other zero-shot editing methods. In terms of quality, COT Flow can generate competitive results in merely one step compared to previous state-of-the-art unpaired image-to-image (I2I) translation methods. To highlight the advantages of COT Flow through the introduction of OT, we introduce the COT Editor to perform user-guided editing with excellent flexibility and quality.",
    "keywords": [
        "generative models",
        "consistency models",
        "diffusion models",
        "optimal transport"
    ],
    "primary_area": "generative models",
    "TLDR": "Generative flow using optimal transport regularization",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=57EjN072hl",
    "pdf_link": "https://openreview.net/pdf?id=57EjN072hl",
    "comments": [
        {
            "summary": {
                "value": "This paper present Contrastive Optimal Transport Flow (COT Flow), a method that achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well-written"
            },
            "weaknesses": {
                "value": "1.The performance improvement of the paper is not significant.\n\n2.The comparison method is outdated; SDedit is a work from two years ago.\n\nThis paper has neither impressive results nor significant improvements. I did not find any highlights in this paper, leaning towards a rejection."
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes the COT Flow model by integrating neural optimal transport and consistency models. Based on the similarities between contrastive learning and consistency models, the authors introduce a new method for defining positive pairs. Furthermore, they demonstrate that the COT Flow can be applied to zero-shot image editing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed COT Flow model effectively enables unpaired image-to-image translation.\n2. The COT Flow model shows potential for various zero-shot image editing scenarios."
            },
            "weaknesses": {
                "value": "1. Comparison methods are limited.\n2. Quantitative evaluations are limited, relying solely on FID scores.\n3. Qualitative results lack visual impact."
            },
            "questions": {
                "value": "1. Does COT Flow truly address the generative learning trilemma? The comparison only includes FID scores, but if the model claims to tackle the trilemma, it should demonstrate comparisons in terms of sampling speed, quality, and diversity against existing methods.\n2. What is the training process for the neural optimal transport model?\n3. Comparison methods are limited. Numerous recent studies on diffusion-based unpaired image-to-image translation tasks should be included, such as [1], [2], and [3]. Additional comparisons with more recent or relevant baselines could strengthen the validity and impact of the findings.\n\n[1] Korotin, A., Selikhanovych, D., & Burnaev, E. Neural Optimal Transport. In The Eleventh International Conference on Learning Representations.\n[2] Su, X., Song, J., Meng, C., & Ermon, S. Dual Diffusion Implicit Bridges for Image-to-Image Translation. In The Eleventh International Conference on Learning Representations.\n[3] Zhao, M., Bao, F., Li, C., & Zhu, J. (2022). Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations. Advances in Neural Information Processing Systems, 35, 3609-3623."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work presents Contrastive Optimal Transport Flow (COT Flow), a new method that achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This work presents Contrastive Optimal Transport Flow (COT Flow), a new method that achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models."
            },
            "weaknesses": {
                "value": "1. Experiments are not enough only on handbag\u2192shoes (64\u00d764), CelebA male\u2192female (64\u00d764), and outdoor\u2192church (128\u00d7128). These tasks are unuseful.\n2. The images are too small and unclear.\n3. The comparison methods are too old. It should compare with at least some of the latest text-based image editing methods in 2024."
            },
            "questions": {
                "value": "1. How to use this flow to open-set text-based image editing? What is the source distribution and target distribution?\n2. What is the role of \\phi_\\omiga in Eq.10 and 11? Eq.10 and 11 confuse me.\n3. In Algorithm 1 COT Training, if the encoder learns to output all zero, the loss function will be zero, how to handle this problem?\n\nI will be happy to raise the rating if the response is good."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}