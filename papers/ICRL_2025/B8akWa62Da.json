{
    "id": "B8akWa62Da",
    "title": "Bridging General and Personalized Federated Learning through Selective Model Integration",
    "abstract": "Personalized federated learning (PFL) achieves high performance by assuming clients only meet test data locally, which does not meet many generic federated learning (GFL) scenarios. In this work, we theoretically show that PMs can be used to enhance GFL with a new learning problem named Selective FL (SFL), which involves optimizing PFL and model selection. However, storing and selecting whole models requires impractical computation and communication costs. To practically solve SFL, inspired by model components that attempt to edit a sub-model for specific purposes, we design an efficient and effective framework named Hot-Pluggable Federated Learning (HPFL). Specifically, clients individually train personalized plug-in modules based on a shared backbone, and upload them with a plug-in marker on the server modular store. In inference stage, an accurate selection algorithm allows clients to identify and retrieve suitable plug-in modules from the modular store to enhance their generalization performance on the target data distribution. Furthermore, we provide differential privacy protection during the selection with theoretical guarantee. Our comprehensive experiments and ablation studies demonstrate that HPFL significantly outperforms state-of-the-art GFL and PFL algorithms. Additionally, we empirically show HPFL's remarkable potential to resolve other practical FL problems such as continual federated learning and discuss its possible applications in one-shot FL, anarchic FL, and FL plug-in market. Our work is the first attempt towards improving GFL performance through a selecting mechanism with personalized plug-ins.",
    "keywords": [
        "Federated Learning"
    ],
    "primary_area": "infrastructure, software libraries, hardware, systems, etc.",
    "TLDR": "This work proposes a selective federated learning approach to integate personalized modules into general federated learning.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=B8akWa62Da",
    "pdf_link": "https://openreview.net/pdf?id=B8akWa62Da",
    "comments": [
        {
            "summary": {
                "value": "This article proposes a new federated learning framework called Hot-Pluggable Federated Learning (HPFL), which aims to solve the performance gap problem between general federated learning (GFL) and personalized federated learning (PFL). Traditional GFL cannot cope with the diversity of data distribution, while PFL is only suitable for scenarios where local data distribution is similar. When the client encounters test data that is different from local data, PFL's personalized model has difficulty maintaining efficient generalization performance. To this end, this paper proposes a new problem framework of Selective Federated Learning (SFL), which enhances the effect of GFL by selecting an appropriate personalized model for each client in the inference stage. The HPFL framework divides the model into shared backbone and personalized plug-in modules. The client trains and uploads plug-ins based on local data. During inference, it can select appropriate plug-ins to adapt to different data distributions, while protecting data privacy through differential privacy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Originality\uff1aThe HPFL framework proposed in this paper innovatively introduces a plug-in selection mechanism into federated learning, realizes the bridge between general models and personalized models, and solves the performance balance problem of traditional GFL and PFL. This is a new attempt in federated learning.\n\nQuality\uff1aThe experimental part is relatively comprehensive, covering a variety of data sets and model verification, and enhancing security through differential privacy. The overall design is rigorous, and the results demonstrate the advantages of HPFL in performance and adaptability.\n\nClarity\uff1aThe paper is well-structured, with clear background and problem descriptions, and clear algorithm design, framework details, and experimental procedures, making it easy for readers to understand its core contributions.\n\nSignificance\uff1aThis study proposed a new solution to the adaptability problem of federated learning under heterogeneous data distribution, which has practical application potential and provides a new direction for the future development of federated learning."
            },
            "weaknesses": {
                "value": "\u00b7Insufficient details of the selection mechanism (page 5, Section 3.3)\uff1aHPFL uses multiple distance metrics such as MMD, SVCCA, and CKA to select plug-ins, but the specific algorithm steps and implementation details are rarely described. The article can add mathematical expressions or pseudocodes for some of the selection methods to increase readability and make it easier for readers to understand the robustness of the selection process.\n\n\u00b7Selection of comparison methods (page 7&8, Table 2 and Table 3)\uff1aThe paper compares a variety of GFL and PFL algorithms, but lacks a comparison of newer solutions that focus on heterogeneous data distribution problems. It is recommended to add more to further highlight the advantages of HPFL in performance and adaptability."
            },
            "questions": {
                "value": "\u00b7How to balance the computational and communication overheads brought by the storage and selection of personalized plug-in modules in the HPFL framework to improve model efficiency?\n\n\u00b7Is it possible that differential privacy protection during model selection in this article, or when using other privacy protection methods, may significantly affect model performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel framework called Hot-Pluggable Federated Learning (HPFL) that aims to bridge the gap between generic federated learning (GFL) and personalized federated learning (PFL). The authors propose a new learning paradigm, Selective Federated Learning (SFL), which combines model optimization with model selection. HPFL addresses the challenges of storing and selecting whole models by designing an efficient framework that allows clients to train personalized plug-in modules and upload them to a server. During inference, a selection algorithm identifies suitable plug-in modules to enhance performance on target data distributions. The paper also incorporates differential privacy protection during the selection process. Comprehensive experiments demonstrate HPFL's effectiveness in improving GFL performance and its potential in addressing other FL challenges like continual learning and one-shot FL."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The authors identify a substantial gap between GFL and PFL, and formulate a new problem SFL to bridge them together to address this performance gap. Both optimization function of GFL and PFL are the special cases of it.\n\n2. The authors propose a general, efficient and effective framework HPFL, which practically solves SFL.\n\n3. Comprehensive experiments and ablation studies on four datasets and three neural networks demonstrate the effectiveness of HPFL."
            },
            "weaknesses": {
                "value": "1. It\u2019s adorable that the authors define a paradigm to bridge the gap between GFL and PFL, but the selective method are not novelty enough. For example, [1] allowed each client to choose the appropriate scale model to train. And the training process in HPFL are identical to the split federated learning, the authors only add another select process in inference process. \n2. The authors claim that they theoretically show PMs can be used to enhance GFL with a new learning problem named Selective FL (SFL), which involves optimizing PFL and model selection. But only the statement of the loss cannot totally evaluate the effectivess of the SFL. And in the Eq.4, the greater-than sign \\geq should be a less-than sign \\leq? The better one should gain the less loss?\n3. What\u2019s the originality in the analysis of the privacy protection? It seems that add Gaussian noise to the partial model or full model is identical. Thus I think it\u2019s only an existing result.\n4. The notations needs to be improved. For example, in section 2.4 the definition of Selective FL (SFL) problem, the introducing of auxiliary information is confused. And in Theorem2.3, the function s(\\dot) lacks description.\n5. The presentation in experimental section should be improved. For example, the Table 2 is hard to read. It\u2019s confused that the authors not only give the best result in grey, but also some second best result. And why the proposed HPFL does not gain the best result especially compared to the GFL FedSAM?\n\n[1] Cho, Yae Jee, et al. \"Heterogeneous ensemble knowledge transfer for training large models in federated learning.\" arXiv preprint arXiv:2204.12703 (2022)."
            },
            "questions": {
                "value": "As shown in the Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces Hot-Pluggable Federated Learning (HPFL), a framework aimed at bridging the gap between Generic Federated Learning (GFL) and Personalized Federated Learning (PFL) by proposing Selective Federated Learning (SFL). SFL optimizes PFL while allowing for the selection of personalized models (PMs) to enhance generalization performance across diverse test data. In HPFL, clients train personalized plug-in modules based on a shared backbone model, which are then uploaded to a server for selection during inference. This process also incorporates differential privacy to protect user data during the selection phase. Experimental results demonstrate that HPFL significantly outperforms traditional GFL and PFL methods, suggesting its applicability in various federated learning scenarios, including continual learning."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The introduction of SFL effectively addresses the limitations of existing PFL methods, allowing for better adaptation to real-world scenarios where test data may differ significantly from local training data.\n\n2. The HPFL framework\u2019s modular approach enables efficient communication and computation, making it suitable for practical applications in federated learning, including scenarios with resource-constrained clients."
            },
            "weaknesses": {
                "value": "1. The dependency on a common backbone model may lead to reduced performance if the backbone fails to generalize well across heterogeneous client data distributions.\n\n2. The plug-in selection process during inference could introduce additional computational delays, particularly for clients with limited resources, potentially hindering real-time performance.\n\n3. While the framework claims differential privacy protection, the effectiveness of this mechanism in preventing information leakage during plug-in selection remains to be empirically validated in diverse operational contexts."
            },
            "questions": {
                "value": "See the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In order to solve the selective FL (SFL) problem, this paper leverages the model components that attempt to edit a submodel for specific purposes to design a  framework referred to as Hot-Pluggable Federated Learning (HPFL). In HPFL, clients individually train\npersonalized plug-in modules based on a shared backbone, and upload them with a plug-in marker on the server modular store. During the inference stage, a selection algorithm allows clients to identify and retrieve suitable plug-in modules from the modular store to enhance their generalization performance on the target data distribution. This paper also provides differential privacy protection during\nthe selection with theoretical guarantee. Key contributions can be summarized as:\n-\tIdentifying a major gap between Generic FL (GFL) and Personalized FL (PFL), and formulate a new problem SFL to bridge this performance \n-\tDeveloping a general, efficient and effective framework HPFL, which practically solves SFL and adding noise on communicated markers to provide differential privacy protection with theoretical guarantee.\n-\tExperiments on four datasets and three neural networks to demonstrate the effectiveness of HPFL"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is well-written. It fairly cites prior works that it built on and shows how it leverages those solutions. It clarifies what is the problem and what are research questions to answer."
            },
            "weaknesses": {
                "value": "The originality of this paper is not clear. For instance, the following are two major claimed contributions according to the paper \u201cIdentifying a major gap between Generic FL (GFL) [e.g.,  (Karimireddy et al., 2019; Woodworth\net al., 2020; Tang et al., 2022b)'s works] and Personalized FL (PFL) [e.g.,  (Li & Wang, 2019; Chen & Chao, 2021; Li et al., 2021c):'s works], and formulate a new problem SFL to bridge this performance; and Developing a general, efficient and effective framework HPFL, which practically solves SFL and adding noise on communicated markers to provide differential privacy protection with theoretical guarantee.\u201d\nHowever, the methodology seems to be a combination of existing works on PFL while leveraging several existing work with minimal advances. It is not clear how the mentioned theorems add value to the literature, for example, this statement is vague and is not adequately explained: \u201csolving SFL means that clients achieve performance in GFL as high as in PFL.\u201d. It is not clear how plug-in marker can contribute to bridging the gap between GFL and PFL? It would be very helpful to explain elaborately. Specifically, please provide a more detailed explanation and concrete example of how the plug-in markers specifically help bridge the gap between GFL and PFL performance.\nWhile using differential privacy can add value to the method, it is not clear whether it can benefit from local DP, central DP, or both?  Please clarify which type(s) of differential privacy (local, central, or both) are used, and to provide a more detailed explanation of how the plug-ins interact with the DP mechanisms and what novel contributions are made in this area. Specifically it could be explained how plug-ins affect DP and what is the contribution in this part of the paper.\nFigure 2 should also include results of HPFL. The comparison should be expanded to cover more advanced PFL studies to showcase how HPFL performs compared to those methods. Currently is mainly focuses on basic PFL algorithms for comparison purposes. For instance, some key papers in this domain can help authors to provide a more compelling comparison among proposed method and existing PFL solutions, such as FedAlt/FedSim of Krishna et al, 2022@ICML and for the specific case of PFL with differential privacy, Hu et al, 2020 @ IEEE IoT Journal."
            },
            "questions": {
                "value": "Q1. What is the main contribution of the HPFL that makes it outperform existing PFL models? This could be described by adding a table with core update rule of existing PFLs [including more recent studies] and the proposed method;\nQ2. What is the difference of plug-in module and vanilla personalized model? Intuitively they seem to be the same and help considering the local model to personalize the local model of each client.;\nQ3. What is the novelty of integrating DP in the algorithm? How does it lead to advancing the proposed HPFL solution? Is it HPFL+DP or the integration has some challenges? If so, what are the challenges and how does this paper tackle them? Why can\u2019t we use other privacy preservation mechanisms? ;\nQ4. Detailed comparison with two types of studies: i. existing PFL algorithms and comparing with HPFL, ii. Existing privacy preserving algorithms and comparison with DP;\n5. How can the plug-in marker contribute to bridging the gap between GFL and PFL?\nQ6. Can you please clarify which type(s) of differential privacy (local, central, or both) are used, and to provide a more detailed explanation of how the plug-ins interact with the DP mechanisms and what novel contributions are made in this area?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}