{
    "id": "BoXyYnpUTh",
    "title": "Chinese Inertial GAN for Writing Signal Generation and Recognition",
    "abstract": "Disabled people constitute a significant part of the global population, deserving of inclusive consideration and empathetic support. However, the current human-computer interaction based on keyboards may not meet the requirements of disabled people.\u00a0The small size, ease of wearing, and low cost of inertial sensors make inertial sensor-based writing recognition\u00a0a promising human-computer interaction option for disabled people. However, accurate recognition relies on massive inertial signal samples, which are hard to collect for the Chinese context due to the vast number of characters. Therefore, we design a Chinese inertial generative adversarial network (CI-GAN) containing Chinese glyph encoding (CGE), forced optimal transport (FOT), and semantic\u00a0relevance alignment (SRA) to acquire unlimited high-quality training samples. Unlike existing vectorization focusing on the meaning of Chinese characters, CGE represents the shape and stroke features, providing glyph guidance for GAN to generate writing signals. FOT establishes a triple-consistency constraint between the input prompt, output signal features, and real signal features, ensuring the authenticity and semantic accuracy of the generated signals and preventing mode collapse and mixing. SRA constrains the consistency between the semantic relationships among multiple outputs and the corresponding input prompts, ensuring that similar inputs correspond to similar outputs (and vice versa), significantly alleviating the hallucination problem of generative models.\u00a0The three modules guide the generator while also interacting with each other, forming a coupled system. By utilizing the massive training samples provided by CI-GAN, the performance of six widely used classifiers is improved from 6.7%\u00a0to 98.4%, indicating\u00a0that CI-GAN constructs a flexible and efficient data platform for Chinese inertial writing recognition.\u00a0Furthermore, we\u00a0release\u00a0the first Chinese writing recognition dataset based on inertial sensors in GitHub.",
    "keywords": [
        "Inertial Sensors",
        "Handwriting Recognition",
        "Signal Generation",
        "Human-Computer Interaction",
        "Disabled People"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=BoXyYnpUTh",
    "pdf_link": "https://openreview.net/pdf?id=BoXyYnpUTh",
    "comments": [
        {
            "comment": {
                "value": "Thank you for your recognition of our work, especially your positive feedback on the motivation, experiments, and writing of our paper!  Regarding the two weaknesses you mentioned, we provide the following responses:\n\n1. **Weaknesses:** The dataset is relatively small and lacks comprehensive coverage of the Chinese character set.\n\n    **Response:** We would like to clarify that collecting high-quality inertial sensor (IMU) handwriting signals is inherently challenging due to the nature of IMU data. Unlike visual data, IMU signals are continuous time-series waveforms, making it difficult to segment and label individual characters without auxiliary tools like optical tracking devices. Despite these challenges, we successfully collected a dataset of 4500 IMU signal samples, covering \u201cCommonly Used Chinese Characters List\u201d published by the Chinese government.\n\n    While our dataset does not encompass every Chinese character, our model has learned the structural relationships and shape patterns between different character, as evidenced by the t-SNE visualizations where characters with similar structures and stroke patterns cluster closely together. As most complex Chinese characters are constructed by combining simple elements, our work represents a foundational step from 0 to 1 in this field. \n\n2. **Weaknesses:** The proposed method should be tested on other public available benchmarks with other SOTA methods, such as IAHCC-UCAS2016 and CASIA-OLHWDB.\n\n    **Response:** Our CI-GAN is designed to generate handwriting signals captured by **inertial sensors**. However, the IAHCC-UCAS2016 dataset and the CASIA-OLHWDB dataset were collected by entirely different sensors. The IAHCC-UCAS2016 dataset relies on the Leap Motion, a **vision-based optical device** that captures hand trajectories in the air, while the CASIA-OLHWDB dataset uses an Anoto **digital pen** to record pen-tip trajectories data on specialized paper. Given the fundamental differences in data modalities, these datasets are not suitable for evaluating CI-GAN tailored for inertial sensor signal generation. \n\n    In fact, there is currently no publicly available handwriting dataset based on inertial sensors, highlighting a significant gap in this field. Our work addresses this gap by creating CI-GAN to generate an infinite number of inertial-sensor-based handwriting signals.\n\nThank you for your insightful comment. We hope we have addressed your concerns."
            }
        },
        {
            "comment": {
                "value": "Thank you for your review of our paper. We have distilled your comments into four key points and addressed each one individually.\n\n1. **Review Comment:** Comparing CI-GAN with other high-performing classification models, such as in reference [1].\n\n    **Response:** CI-GAN is a generative model, not a classification model. CI-GAN can generate high-quality inertial measurement unit (IMU) signals for Chinese handwriting recognition, but can not classify or recognize handwriting characters. Therefore, comparing a **generative model** to **classification models** may be a methodological misunderstanding. We acknowledge that the classification and recognition methods you suggested are excellent, and we will cite these references to highlight their contributions. However, as a generative model, CI-GAN is fundamentally different from classification models, making a direct comparison with them highly impractical.\n\n2. **Review Comment:** CI-GAN generation effect can be verified on other open source datasets of Chinese character data, such as IAHCC-UCAS2016, CASIA-OLHWDB, and ICDAR 2013.\n\n    **Response:** The IAHCC-UCAS2016, CASIA-OLHWDB, and ICDAR 2013 datasets are used for handwriting recognition tasks, based on visual or pen-tip trajectory data. CI-GAN is designed for generating IMU handwriting signals rather than recognizing them, so it would be challenging to evaluate a generative model on a classification dataset. \n\n3. **Review Comment:** The dataset collected is small in scale, with data from only nine individuals and without full coverage of the complete Chinese character set.\n\n    **Response:** We would like to clarify that IMU signal data collection is inherently challenging and considerably more complex than collecting visual data. Handwriting signals are continuous, and therefore each segment corresponding to a specific character must be extracted from the continuous stream of handwriting signals. For images, videos, or pen trajectories, such segmentation is relatively straightforward due to visual cues. However, for IMU signals, which are time-series waveforms, it is extremely difficult to identify the start and end points of each character segment visually, requiring auxiliary optical equipment for precise annotation. \n\n    We invested significant time and effort to obtain the 4,500 handwriting signals presented in this study, creating the first IMU dataset of Chinese handwriting that covers the official set of commonly used characters in China. This effort underscores the value of our CI-GAN model, which eliminates the need for such labor-intensive annotation by directly generating IMU signals for each Chinese character. This dataset sufficiently supports the training of our generative model for the IMU signal generation task, and our experiments have validated the practical effectiveness of CI-GAN on this scale and quality of data.\n\n4. **Review Comment:** Comparing the CI-GAN with other generative models.\n\n    **Response:** It is important to highlight that this study is the first to propose a generative deep learning model for generating IMU handwriting signals. CI-GAN is specifically designed to address the unique challenges of IMU handwriting signal generation, with tailored modules and optimization strategies to suit IMU data. In the field of IMU signal generation research, there is currently no precedent or comparable model, meaning that no readily available generative model exists for direct comparison.\n\n    Therefore, we conducted a thorough comparison of CI-GAN with twelve commonly used data augmentation methods spanning five major categories. This comprehensive evaluation demonstrates the rigor of our approach and the scientific validity of our results. While you suggested that we use Diffusion models or other image-based generative models for comparison, these models were originally designed for image data. Applying them directly to IMU signal generation would involve technical and theoretical misalignment. Adapting such image-based generative models to IMU signal generation would require substantial modifications to both model structure and algorithms, along with re-training and validation on IMU data. This adaptation alone would justify an entirely new research paper, extending far beyond the scope of our current study.\n\nIn conclusion, we sincerely hope that our replies address your concerns satisfactorily. Your understanding and recognition of our efforts are of utmost importance to us."
            }
        },
        {
            "summary": {
                "value": "This paper tackles the challenge of data scarcity in Chinese writing recognition using inertial sensors by proposing the Chinese Inertial Generative Adversarial Network (CI-GAN). CI-GAN includes three innovative modules, Chinese Glyph Encoding (CGE), Forced Optimal Transport (FOT), and Semantic Relevance Alignment (SRA), to generate high-quality inertial signal samples. CGE captures the shape and stroke of Chinese characters, FOT ensures feature consistency to prevent mode collapse, and SRA aligns the semantic relevance of generated signals to their glyph structures. With CI-GAN, the authors establish a flexible data platform for Chinese writing recognition and claiming to release  the first inertial-sensor-based dataset on GitHub."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The introduction of CI-GAN is a novel approach for enhancing data availability in Chinese inertial writing recognition, with modules designed specifically to tackle challenges unique to Chinese characters.\n2. The improvement from 6.7% to 98.4% in classifier performance highlights the potential of CI-GAN-generated data to enhance recognition accuracy, indicating practical benefits for downstream applications."
            },
            "weaknesses": {
                "value": "1. In Figure 1, CI-GAN is presented as a framework overview, yet it lacks consistency in terminology, with CGE mislabeled as \"GER\" and FOT written in full without abbreviation. Additionally, SRA is not visually represented in the figure. This detracts from the clarity of the diagram and makes it harder for readers to grasp the full framework.\n2. The paper\u2019s theoretical foundation could be strengthened. The current theoretical analysis is minimal, with only a few formulas provided. More detailed mathematical explanations, particularly for FOT\u2019s role in preventing mode collapse, would lend greater credibility to the approach.\n3. The ablation studies are somewhat limited, and additional experiments testing more comprehensive combinations of CGE, FOT, and SRA would provide a clearer understanding of each module's contribution. More exhaustive ablation tests would validate the effectiveness of the modules individually and collectively.\n4. The example in Figure 1, intended to illustrate the framework's application for disabled individuals, doesn\u2019t effectively convey this purpose. Including a more relatable example that directly addresses accessibility for disabled users would better align with the stated motivation of the study."
            },
            "questions": {
                "value": "1. Can you clarify how Figure 1 relates to accessibility for disabled individuals, as the example seems disconnected?\n2. Could you provide more theoretical details on the FOT component to reinforce its foundation?\n3. Are more exhaustive ablation studies possible to validate the contributions of CGE, FOT, and SRA individually?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper propose CI-GAN, which enhances Chinese writing recognition for disabled users, generating high-quality samples and improving classifier performance significantly."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The article is clearly written and easy to understand. \n\n2. The motivation is clear: translating subtle movements of user\u2019s hand into written text can help disabled people of writing. \n\n3. Experiments demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. The dataset is relatively small and lacks comprehensive coverage of the Chinese character set, which may not support the generation of more complex Chinese characters.\n\n2. The proposed method should be tested on other public available benchmarks with other SOTA methods, such as IAHCC-UCAS2016 and CASIA-OLHWDB."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces CI-GAN, a generative adversarial network for Chinese writing recognition using inertial sensors, designed to aid disabled individuals. CI-GAN incorporates Chinese glyph encoding, forced optimal transport, and semantic relevance alignment to generate accurate signals. With these synthetic signals, classifier accuracy improved from 6.7% to 98.4%. The study also releases the first Chinese inertial sensor dataset for writing recognition, advancing accessible human-computer interaction."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tThe application of research has significant potential and creativity about addressing accessibility needs for disabled individuals.\n2.\tThe proposed dataset contributes valuable inertial sensor data for Chinese writing. And the research introduces a novel method using GAN for data augmentation, effectively addressing data scarcity and enhancing handwriting recognition research.\n3.\tThe experimental results show promising improvements in classifier accuracy."
            },
            "weaknesses": {
                "value": "1.\tThe concept of inertial data is introduced only in Section 4.2, making it somewhat difficult to understand when mentioned in the earlier parts of the paper. It is recommended to provide a brief introduction to this concept earlier on.\n2.\tThe first point in the summary of contributions mentions that it \"provides new tools for the study of the evolution and development of pictograms,\" which may not be suitable for the contributions summary, as it seems the research does not cover this aspect.\n3.\tThe description of CGE mentioned in Section 3.1 seems to be just an embedding? In my opinion, the current version of the introduction may be somewhat complex."
            },
            "questions": {
                "value": "1.\tAccording to my understanding, CGE can be divided into two parts: 1. converting one-hot encoding into dense features, and 2. using \u03b1-order R\u00e9nyi entropy regularization in GER. Therefore, in the ablation study in Section 4.4, what specific configuration is being ablated when CGE is removed? Which part of these two components is being eliminated? Additionally, can this ablation experiment validate the effects of the glyph encoding regularization (GER) proposed in Section 3.1?\n2.\tWhat is the difference between the pre-trained VAE mentioned in Section 3.2 and CGE in Section 3.1? It seems that both can extract glyph features. Can VAE replace CGE?\n3.\tWhat are h_G, h_T, and e in Section 3.2? It seems that e comes from the GAN input, h_G comes from the GAN output, but where does h_T come from during training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the author proposes a method of sensor-style Chinese character data generation based on GAN. It mainly consists of three modules CGE, FOT and SRA. CGE encodes Chinese characters according to glyphs. FOT uses a ternary consistency constraint to monitor the consistency of the predicted sample, the real sample, and the glyph encoding vector. The SRA module aligns glyph and semantic encoding. The author collected 4500 samples of 500 Chinese characters, including 1500 samples in the training set and 3000 samples in the test set. The author uses the proposed CI-GAN to generate additional training sets to augment the original data set. The validity of the generated data is proved by comparing the recognition effect of training with different data quantities. The effectiveness of the proposed module is verified by ablation experiments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper makes a strong contribution to research in accessible human-computer interaction, focusing on Chinese handwriting recognition for disabled individuals. It addresses an important issue by introducing CI-GAN, a generative model with unique modules\u2014Chinese Glyph Encoding, Forced Optimal Transport, and Semantic Relevance Alignment\u2014that effectively tackle the challenges of data scarcity and segmentation. According to the visualization results of Chinese glyph encodings, the module proposed in this paper is effective in encoding Chinese character shapes. The experimental results in Table 3 and Table 4 prove that the generated data has useful value."
            },
            "weaknesses": {
                "value": "The proposed method section does not provide sufficient comparisons and analysis. The collected real data and generated data are insufficient, and the quality of the constructed dataset is not high. The experimental section lacks important comparative experiments and analysis, making it difficult to demonstrate the effectiveness of the proposed method. The specific issues are as follows:\n\n1. **Methodology**: The authors propose a GAN-based generation method but do not compare its generation quality with other generative approaches, such as diffusion models or other GAN-based methods.\n\n2. **Dataset**: The dataset collected is small in scale, with data from only nine individuals and without full coverage of the complete Chinese character set. \n\n    (1) The complexity of different Chinese characters is very different, and the author only shows the generation and classification results of relatively simple Chinese characters in this paper, it is impossible to evaluate the model's generation effect on complex Chinese characters. \n\n    (2) Writing habits vary greatly among individuals, leading to significant differences in handwriting styles. With data from only nine participants, how can the authors ensure that the generated data quality aligns with real-world scenarios?\n\n3. **Experiments**: \n\n      (1) Comparative methods lack citations.\n\n      (2) The algorithm\u2019s performance has not been tested on other public datasets. Whether the CIGAN generation effect can be verified on other open source datasets of Chinese character data, such as IAHCC-UCAS2016, CASIA-OLHWDB (ICDAR 2013 Chinese Handwriting Recognition Competition).\n\n      (3) The authors did not compare their method with other high-performing algorithms for Chinese character recognition, such as the one mentioned in [1].  As far as I know, [1] achieved a recognition accuracy of 96.78% on the dataset of all Chinese characters in the Level 1 Character Set (IAHCC-UCAS2016) and 97.86% on ICDAR-2013. I suggest the authors compare their method with more state-of-the-art (SOTA) approaches.\n\n     (4) The experiments lack further analysis, such as individual-level performance testing and performance evaluation across characters with different stroke complexities. \n\nThese improvements would better support the effectiveness and applicability of the proposed approach.\n\n[1] Gan J, Wang W, Lu K. A new perspective: Recognizing online handwritten Chinese characters via 1-dimensional CNN[J]. Information Sciences, 2019, 478: 375-390."
            },
            "questions": {
                "value": "Repeat:\n1. **Methodology**: The authors propose a GAN-based generation method but do not compare its generation quality with other generative approaches, such as diffusion models or other GAN-based methods.\n\n2. **Dataset**: The dataset collected is small in scale, with data from only nine individuals and without full coverage of the complete Chinese character set. \n\n    (1) The complexity of different Chinese characters is very different, and the author only shows the generation and classification results of relatively simple Chinese characters in this paper, it is impossible to evaluate the model's generation effect on complex Chinese characters. \n\n    (2) Writing habits vary greatly among individuals, leading to significant differences in handwriting styles. With data from only nine participants, how can the authors ensure that the generated data quality aligns with real-world scenarios?\n\n3. **Experiments**: \n\n      (1) Comparative methods lack citations.\n\n      (2) The algorithm\u2019s performance has not been tested on other public datasets. Whether the CIGAN generation effect can be verified on other open source datasets of Chinese character data, such as IAHCC-UCAS2016, CASIA-OLHWDB (ICDAR 2013 Chinese Handwriting Recognition Competition).\n\n      (3) The authors did not compare their method with other high-performing algorithms for Chinese character recognition, such as the one mentioned in [1].  As far as I know, [1] achieved a recognition accuracy of 96.78% on the dataset of all Chinese characters in the Level 1 Character Set (IAHCC-UCAS2016) and 97.86% on ICDAR-2013. I suggest the authors compare their method with more state-of-the-art (SOTA) approaches.\n\n     (4) The experiments lack further analysis, such as individual-level performance testing and performance evaluation across characters with different stroke complexities. \n\nThese improvements would better support the effectiveness and applicability of the proposed approach.\n\n[1] Gan J, Wang W, Lu K. A new perspective: Recognizing online handwritten Chinese characters via 1-dimensional CNN[J]. Information Sciences, 2019, 478: 375-390."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents an innovative approach to addressing the limitations in performance of inertial sensor-based systems for Chinese character recognition, which traditionally rely on extensive manual data collection. By introducing a Chinese Inertial Generative Adversarial Network (CI-GAN), the study offers a solution that generates unlimited, high-quality training samples, thereby providing a flexible and efficient data support platform for classification models. This method significantly reduces the dependency on labor-intensive data gathering and enhances the overall performance and feasibility of using inertial sensors for HCI in the context of disability."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* **Clear Motivation and Feasible Approach**: The paper is driven by a well-defined goal\u2014to improve HCI for disabled individuals using inertial sensors. The proposed solution, a generative adversarial network (GAN) for data generation, is not only innovative but also practically feasible, as evidenced by the experimental results.\n\n* **Innovation and High Performance**: By introducing advanced techniques of CGE,  FOT and SRA, the study significantly enhances the recognition accuracy of Chinese characters, with performance improvements reported from 6.7% to 98.4%.\n\n* **Social Impact and Community Contribution**: The research addresses significant accessibility issues for disabled individuals and adds substantial value to the community by releasing the first Chinese writing recognition dataset based on inertial sensors, enabling further advancements in the field."
            },
            "weaknesses": {
                "value": "* **Visualization and Clarity of Diagrams**: The diagrams in the paper could be improved for better systematic representation and intuitiveness. Visualizing abstract constraints and regularization techniques more clearly would aid in understanding the complex interactions within the model. The task and symbols need a more detailed defination to improve the understanding.\n* **Detailed Justification of Model Constraints**: The paper could be improved by including more detailed exploration of the motivations and effectiveness of using specific constraints such as the Forced Optimal Transport (FOT). A deeper discussion on why aligning input stroke encoding features with generated signal features and real signal features; and why utilizing Wasserstein distance as regularization can mitigate mode mixing and mode collapse is necessary to validate the approach.\n* **Analysis of Robustness Under External Disturbances**: The paper lacks a thorough analysis of the system's robustness in the presence of external disturbances. Detailed insights into how these factors affect the system and recommendations for enhancing robustness would strengthen the paper.\n\nThese points should be addressed to enhance the overall comprehensibility and impact of the research."
            },
            "questions": {
                "value": "As shown in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}