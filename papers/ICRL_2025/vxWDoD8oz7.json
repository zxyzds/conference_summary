{
    "id": "vxWDoD8oz7",
    "title": "Distortion-free and GPU-compatible Tree Embeddings in Hyperbolic Space",
    "abstract": "Embedding tree-like data, from hierarchies to ontologies and taxonomies, forms a well-studied problem for representing knowledge across many domains. Hyperbolic geometry provides a natural solution for embedding trees, with vastly superior performance over Euclidean embeddings. Recent literature has shown that hyperbolic tree embeddings can even be placed on top of neural networks for hierarchical knowledge integration in deep learning settings. For all applications, a faithful embedding of trees is needed, with combinatorial constructions emerging as the most effective direction. This paper identifies and solves two key limitations of existing works. First, the combinatorial construction hinges on finding maximally separated points on a hypersphere, a notoriously difficult problem. Current approaches lead to poor separation, which degrades the quality of the corresponding hyperbolic embedding. As a solution, we propose maximally separated Delaunay tree embeddings (MS-DTE), where during placement, the children of a node are maximally separated through optimization, which directly leads to lower embedding distortion. Second, low distortion requires additional precision. The current approach for increasing precision is to use multiple precision arithmetic, which renders the embeddings useless on GPUs in deep learning settings. We reformulate the combinatorial construction using floating point expansion arithmetic, leading to superior embedding quality while simultaneously retaining their use on accelerated hardware.",
    "keywords": [
        "Hyperbolic Geometry",
        "Hyperbolic Tree Embeddings",
        "Representation Learning",
        "Hierarchical Learning"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "In this paper we propose a method for embedding trees in hyperbolic space by optimizing hyperspherical point separation and using floating point expansion arithmetic for maintaining GPU-compatibility.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vxWDoD8oz7",
    "pdf_link": "https://openreview.net/pdf?id=vxWDoD8oz7",
    "comments": [
        {
            "summary": {
                "value": "This paper refines an algorithm for tree embeddings via projected stochastic descent and improved floating point arithmetic. The authors identify an issue with an algorithm for uniformly sampling points on hyperplanes in the Poincare disk, which is a crucial part of a classical tree embedding algorithm. They then compare their approach to other well-known methods and obtain consistently improved performance."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Fast implementation using projected gradient descent.\n2. Empirical efficacy\n3. The solution to the floating point arithmetic degeneracy ailment is crucial due to calculations of the division of small numbers. I find it to be very interesting."
            },
            "weaknesses": {
                "value": "1. There are no claims of empirical results for downstream tasks, despite the introduction which claims the importance of tree embeddings for downstream tasks.\n\n2. Code isn't available."
            },
            "questions": {
                "value": "1. Can you explain Figure 1 (b)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles two key challenges in embedding tree-structured data using hyperbolic geometry, a mathmatical concept known for effectively capturing hierarchical relationships. Traditional combinatorial methods struggle with finding maximally separated points on a hypersphere, leading to poor separation and high distortion in embeddings. The authors introduce maximally separated Delaunay tree embeddings (MS-DTE), which optimize child node placement to reduce distortion. Additionally, they address the precision requirements for low-distortion embeddings, replacing multiple-precision arithmetic with floating-point expansion to ensure compatibility with GPU acceleration. MS-DTE offers a more accurate and hardware-compatible approach for hyperbolic embeddings, facilitating their use in deep learning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper tries to improve the hyperbolic embedding method for tree-like data in two aspects: lower distortion and higher precision. It demonstrates effectiveness through several experiments."
            },
            "weaknesses": {
                "value": "My primary concern with this paper lies in its limited exploration of embedding dimensions, as all experiments are confined to fixed dimensions of 8 or 10. Hyperbolic spaces are indeed well-suited for embedding tree-like structures in low dimensions with minimal distortion, as shown by prior work such as Sala et al. (2018), which evaluated dimensions from 2 to 200. The restricted range of dimensions examined here leaves questions about the method's robustness across different dimensional settings and its performance at lower dimensions, which could highlight the embedding quality and distortion more clearly.\n\nMoreover, in the specific experiment detailed in Table 1, the authors embed an 8-depth binary tree in a 10-dimensional space. Given the remark in lines 232-233 about point generation limitations in low-dimensional spaces, this experiment does not seem sufficient to validate these claims, as a binary tree should be well-represented in 10 dimensions without encountering major separation limitations. Additionally, as the node degree is 2 in this case, the proposed MHS in Equation 14 appears equivalent to Liu et al.\u2019s (2018) approach in Equation 13, raising concerns about the distinct advantage claimed for this setting.\n\nTo strengthen the paper, I recommend conducting experiments across a wider range of dimensions, particularly in low dimensions, which would not only enable visualization but also demonstrate the effectiveness of the proposed GPU-compatible floating-point expansion approach. This expanded experimentation would provide a more comprehensive evaluation of the proposed method\u2019s advantages and limitations."
            },
            "questions": {
                "value": "1. What is $s$ in Eq 13\n\n\n2. In lines 250-254, you discuss the limitation of Eq. 13. Is this a mere observation or a conclusion drawn from empirical analysis? Have you experimented with using Equation 13 as an objective function, and if so, what were the results?\n\n3. In Equation 14, is the objective minimizing the absolute angle value? Note this is equivalent to minimizing the geodesic distance between vectors. Why not instead minimize the cosine value between the angles?\n\n4. You note that the effective number of nodes is lower in practice due to the high frequency of low-degree nodes, allowing cached hyperspherical points to be reused (lines 271-272). Could you provide more context (statistics on dataset) on how frequently these caches are applied and their impact on computational efficiency?\n\n5. While the paper focuses on the embedding method itself, have you evaluated the utility of these embeddings in downstream tasks? For example, Nickel and Kiela (2017) demonstrated the effectiveness of their embeddings on link prediction. Any insights on potential downstream improvements would be helpful.\n\n\n6. Have you evaluated the proposed model on WordNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce maximally separated Delaunay tree embeddings to construct tree embeddings in hyperbolic spaces, particularly in the Poincar\u00e9 ball model. Empirically, they show that their method improves upon existing methods. Additionally, they present a method for the arithmetic expansion of floating-point numbers in tensors, allowing for increased calculation precision without losing the benefits of hardware acceleration."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The authors present a series of interesting theoretical results with clear and well-written proofs. These results serve as the fundamental backbone of the work, making it well-written and cohesive."
            },
            "weaknesses": {
                "value": "1. Line 855 is not clearly understandable; there is likely a typo. \n2. Theorems 3 and 5 seem more straightforward than presented. It would be better to state them as propositions and briefly comment on their proofs."
            },
            "questions": {
                "value": "1. Could it be possible to elaborate a bit more on the third limitation (line 236)? I may have missed something, but it doesn't seem entirely clear based on the current text.\n2. Can you use isometries between hyperbolic spaces to study another manifolds? I think maybe some properties will be preserved.\n3. Can you derive an extension of Theorem 1 changing MHS? The proof may be similar."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Embedding tree structures in hyperbolic space enhances knowledge representation, especially for hierarchies and ontologies. This paper addresses two key challenges: poor point separation and limited hardware compatibility. It proposes maximally separated Delaunay tree embeddings (MS-DTE) and floating-point expansion arithmetic, achieving lower distortion and efficient GPU use, which improves embedding quality in deep learning applications."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is well-structured.\n- The proposed method is well-justified.\n- The method demonstrates strong performance improvements."
            },
            "weaknesses": {
                "value": "- The experimental evaluation lacks comprehensiveness."
            },
            "questions": {
                "value": "- In the abstract, \"directly leads to lower embedding distortion\" is mentioned; if the method only reduces distortion, what justifies the use of \"distortion-free\" in the title?\n- The relationship between \"DISTORTION-FREE,\" \"GPU-COMPATIBLE,\" and performance in downstream tasks remains unclear.\n- The impact of finding maximally separated points on a hypersphere for downstream tasks needs clarification.\n- Experimental details are incomplete, as MHS requires training.\n- The paper should include an analysis of computational complexity and overhead.\n- Parameter analysis for the scaling factor $\\tau$ is needed, as different values are used across tasks.\n- Why is the MAP metric omitted from Table 3 and Table 4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new hyperbolic embedding algorithm for tree data. The authors propose a Delaunay tree embedding with maximum separation (MS-DTE), where during placement, the child nodes of the node directly result in lower embedding distortion by optimizing the maximum separation. To solve the problem of floating point precision at the edge of Poincare-ball space, a gpu multi-precision algorithm is proposed."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1.The motivation of this article is very natural. The tree structure embedding in hyperbolic space does have two problems mentioned .\n2.The paper is well written and is easy to understand.\nThe theory of the article is very solid, and the precision problem is explained very well."
            },
            "weaknesses": {
                "value": "1.This approach is aimed at hyperbolic embedding of tree structures, but does not seem to be able to handle general data (there is no explicit tree structure, but often there is an underlying tree structure).\n2. The author lacks a discussion of algorithm complexity. Especially for the accuracy problem, whether it will cause a greater amount of calculation."
            },
            "questions": {
                "value": "1. Can this precision processing method be applied to general hyperbolic neural networks? As we all know, hyperbolic machine learning has two problems, precision error and difficult optimization.\n2. See other questions in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}