{
    "id": "WoJzHQIIUk",
    "title": "MinMax Bayesian Neural Networks and Uncorrelated Representation",
    "abstract": "In deep learning, Bayesian neural networks (BNN) and dropout techniques provide the role of robustness analysis, and the minimax method used to be a conservative choice in the traditional Bayesian field. In this paper, we apply the minimax game to the BNN on the representation level  and formulate as a two-player game between a deterministic neural network $f$ and a sampling stochastic neural network $f + r*\\xi$, which can be seen as a Brownian Motion of $f$. Our simple experiments show that $r$ will be stable with enough dimension space, suitable activation function, and without bias with the minimax coding rate loss, which verify the statement \\cite{yu2020learning} in some sense. And we test the convolutional neural network without bias, with bias and with batch normalization on simple data set like MNIST, Fashion MNIST and others, and visualize the sampling radius as a bias-variance tradeoff study. At last, we also test how noise perturbation will affect radius in stable case.",
    "keywords": [
        "Minimax game",
        "Bayesian Neural Networks",
        "Brownian Motion",
        "Minimax coding reduction",
        "Uncorrelated representation"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "Apply minimax method with the minimax coding rate loss to Bayesian neural network to verify previous stament in previous paper and use sampling to visualize the bias-variance tradeoff.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=WoJzHQIIUk",
    "pdf_link": "https://openreview.net/pdf?id=WoJzHQIIUk",
    "comments": [
        {
            "summary": {
                "value": "I struggled to understand this work, my best interpretation is that instead of learning a neural network (NN) f(x, \u03bc), where \u03bc are the parameters, a stochastic perturbation of such NN is learned obtaining f(x, \u03bc) + r \u03be(\u03c1) where r is a positive scalar and \u03c1 parametrizes the distribution \u03be, which appears to be a Gaussian distribution."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "I could not understand enough of the present work to asses its strenghts."
            },
            "weaknesses": {
                "value": "To put it shortly, this work is not written to a publishable standard.\nThe method is not presented in a clear and precise manner, the phrasing is often confusing and of poor English level.\n\n**On the method:**\n\nFor instance, considering the supervised setting, the method is defined in (1).\nIt appears that the stochastic NN f(x, \u03bc) + r \u03be(\u03c1) is sometimes referred to as g() and sometimes as h().\nMoreover, \"pre()\" is never defined, and the other quantities defining (1) are actually introduced only after (2), which is the representation learning setting.\nThe noise \u03be *appears* to be Gaussianly distributed (it s not defined in Section 2, there is a mention to the Brownian Motion in the abstract, and quoting the authors \"normally we use Gaussian priors throughout the paper if without specification\").\nThen, in Section 3, the parametrization \u03c3 = log(1 + exp(\u03c1)) is employed, in which case there is no difference between changing \u03c1 and r.\n\n**On the confusing sentences:**\n\n> The minimax method or game theory has been used in deep learning for a long time. The most well-known work is the generative adversarial networks (GAN) Creswell et al. (2018) and Variational auto-encoding (VAE) Kingma & Welling (2013), which formulate the networks as a two-player game problem using the encoder and decoder.\n\nI do not see how it is possible to frame a VAE as a competitive or min-max game, surely not just having an encoder and a decoder suffices...\n\n> The contribution of this paper includes 2 points. First, the experiments of MinMax BNN verify that enough embedding dimension for CNN without bias term or Batch normalization layer for uncorrelated representation learning from a robustness perspective, and Batch normalization (BN) and bias, especially BN will have large impact on the robustness of simple CNN models trained by MNIST data. Second, a well-trained neural network can use stochastic sampling neural networks to find the suitable radius to do the out-of-distribution detection and estimate the data similarity both in representation learning and supervised learning with easier implementation and more intuitive in contrast to Bayesian Neural Networks.\n\nI could not understand at all what was being argued here.\n\nIt should be noted that nowhere in the manuscript (aside from introduction and conclusions) do \"uncorrelated representation\" appears aside from the paragraph:\n\n> The previous paper Yu et al. (2020) claims that the rate-distortion loss should have enough dimensions to make the learned features of the subspace uncorrelated. We have shown that some condition might make the learning features is isotropic to the perturbation.\n\nWhere I could not understand what the authors meant.\n\n> There are two cases for the training process. For case 1 we will update r via golden search for every new sampling noise \u03be both in maximum and minimum process, and for case 2 only update r for the minimum process.\n\nAs above.\n\n**Moreover:**\n\nThe work appears to have been rushed in the best scenario: leftover highlighting in the abstract, leftover Contributions and Acknowledgments sections, a truncated Appendix at the end."
            },
            "questions": {
                "value": "Would it please be possible to address all the concerns raised in the Weaknesses section?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The study applies a minimax approach to BNNs, aiming to bolster robustness in neural networks. Using Brownian motion-based noise within a deterministic-stochastic network pairing, it analyzes how factors like embedding dimension, batch normalization, and bias affect robustness. Key results highlight that batch normalization reduces stability, whereas models with sufficient embedding dimensions are robust to perturbations. The approach\u2019s applications in out of  detection suggest a promising direction for practical deployment."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* $\\textbf{Innovative Use of Minimax in BNNs}$: Applying the minimax framework to Bayesian Neural Networks is an innovative approach that extends beyond the traditional deterministic setups seen in adversarial training or GANs.\n* $\\textbf{ Comprehensive Robustness Evaluation}$: The paper covers a broad range of robustness aspects, from embedding dimensions to noise impacts across various datasets, including some well-known dataset.\n* $\\textbf{Clear Problem Motivation}$\n* $\\textbf{Experimental Validation}$: Experimental results, particularly the effect of batch normalization and bias on robustness, provide almost satisfiable empirical support for the theoretical framework."
            },
            "weaknesses": {
                "value": "* $ \\textbf{Clarity and Readability}$: Some areas, such as the detailed mathematical formulations, could be streamlined or better explained.\n\n* $\\textbf{Limited Experiment Scope}$: While the paper uses popular datasets (MNIST, CIFAR-10, and FMNIST), testing on additional complex datasets could further validate the generalizability of the proposed methods.\n\n* $\\textbf{Lack of Comparisons with Baselines}$: Although robustness and stability are discussed, the paper does not thoroughly compare the proposed Minimax BNN with other advanced models or methods, such as traditional BNNs or adversarial training frameworks.\n\n* $\\textbf{Lack of Explanation of the Problem Setting}$\n\n* $\\textbf{Depth of Discussion on out of distribution Detection}$: The out-of-distribution detection section feels limited, as it mainly lists results without exploring potential reasons or implications for  out of distribution performance in depth. \n\n* $\\textbf{Not well-plished}$: The paper does not feel well-polished, and several key sections lack sufficient justification."
            },
            "questions": {
                "value": "* How does the proposed minimax BNN approach compare to adversarial training in robustness performance?\n\n* What are the computational implications of using minimax optimization for BNNs?\n\n* Why do certain batch normalization and bias configurations disrupt robustness, and how can this insight be utilized in network design?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The idea behind this work is quite interesting as there are still 3-4 potential remaining pages, I highly recommend rewriting the paper from beginning to end and elaborating further on certain sections, such as Section 2, to reduce ambiguity."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper reads more like a draft, and is poorly written, especially since many terms are undefined, and appear out of nowhere during the paper reading. It is difficult to even understand what contributions the authors aim for, let alone whether the experiments that they conduct actually show this."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Unfortunately, it is difficult to find any particular strength. The topic might be important, but it is not even clear what is the main motivation of the paper: Analyzing the trade-off between robustness and performance ?!"
            },
            "weaknesses": {
                "value": "Unfortunately, again, I will make a generic comment: The paper is poorly written - the description of the problem, the formulation, the experiments, and the conclusions from them. Below are many comments, some are indeed minor, but they represent the general quality of the paper:\n\n\u2022 The citation format is wrong, write, e.g. (Bi et al., 2022)\n\n\u2022 Abstract \u2013 yellow marked text.,\n\n\u2022 Intro, first paragraph \u2013 unclear sentence: (1) \u201cA simple baseline for image classification for deep deterministic uncertainty with MCMC Mukhoti et al. (2023).\u201d (2)\n\n\u2022 Intro, line 49, it is not explained anywhere before what is meant by the \u201cminimax method\u201d. This makes it difficult to go through the rest of the introduction, because it is unclear what is the operation of each of the two players in the game, and what is the reward for each of them. \n\n\u2022 First contribution \u2013 lines 69-72: It is difficult to understand, but it reads something like \u2013 \u201cOur experiments verify that enough embedding dimension (?) has large impact on the robustness of simple CNN\u201d. This is a vague statement. What does this concretely mean ? \n\n\u2022 Second contribution \u2013 lines 73-76: What does it mean for a trained NN to use stochastic sampling neural networks? The claims \u201ceasier implementation\u201d and \u201cmore intuitive\u201d are again vague.\n\n\u2022 Equation (1): Even though this is said to be equivalent to a minimax problem, it does not look like one. As the paper is about minimax formulation, this should be explicit. \n\n\u2022 Equation (1): The term \u201cpre\u201d in the constraint is undefined, and so is *\\rho* and so is *h* (this is explained only after Equation (2)).\n\n\u2022 Line 90: What is \u201cthe restriction condition\u201d ? \n\n\u2022 Line 107: \u201c*k* denote the number of classes\u201d \u2013 Before this point, no classification task has been described. \n\n\u2022 Lines 107-109: The term MCR and *\\Delta R* are not properly explained. The role of *Z* is unclear. \n\n\u2022 Line 113: \u201cthe figure of the minimum process of radius\u201d is unclear. \n\n\u2022 Line 154-157, results: It is first mentioned that \u201cthe results of MinMax BNN are slightly worse than LDR\u201d, but then the opposite \u201cand another reason why LDR Dai et al. (2022) performs slightly worse..\u201d. Is NetD the result of the method proposed in the paper ? This performs worse than LDR. \n\n\u2022 Lines 159-161: I do not see how these conclusions stem so obviously from Figure 2. \n\n\u2022 Table I: What are each of the cases ? This is unexplained.\n\n\u2022 Line 168: What is \u201cBrownian motion\u201d in this context ? \n\n\u2022 Line 170: The radius seems to be stable already in 64 dimensions.\n\n\u2022 Line 179: \u201cis given in Fig. IV\u201d \u2013 inconsistent with previous writing, should be \u201cFigure 4\u201d.\n\n\u2022 Figure 4B: Why is the graph on [b] panel has this weird shape ? \n\n\u2022 Line 232: \u201cHistogram of trained models\u201d \u2013 Histogram of what ?\n\n\u2022 Tables 2 and 3: Different values of *r* are compared for different datasets, but for which method ? There is no comparison to a different method. \n\n\u2022 Line 261: Should be \u201cWe design...\u201d\n\n\u2022 Line 268: \u201care shown in Table VII\u201d \u2013 inconsistent with previous writing, and probably should be \u201cTable 4\u201d."
            },
            "questions": {
                "value": "Given the above, it is difficult to come up with intelligent or constructive questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposes a loss function inspired by minimax games and proposes that training Bayesian networks with this loss can improve robustness. The work then lists numerous numerical experiments to support its claim about the improved robustness. The experiments cover several popular datasets and test several different architectures of the networks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- Leveraging the minimax view to improve robustness, as mentioned in this paper, is interesting. Similar idea is also seen in recent works such as [1].\n- A number of numerical experiments have been listed in this work.\n\n[1] Buening, Thomas Kleine, et al. \"Minimax-bayes reinforcement learning.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2023."
            },
            "weaknesses": {
                "value": "- First, this work is clearly neither well-written nor prepared. This includes unexplained abbreviations (e.g. LDR), numbering misalignments in multiple figures, underexplained captions (e.g. Fig 1, 4), unlabelled axes (e.g. Fig 3), and unchanged templates (page 7). Understanding the point of each of the numerical evidences is thereby difficult.\n- Second, many notations are not defined. For example, I do not see the function pre() in the constraint of Eq (1) defined anywhere. And \\mu, \\rho, and r in Eq (1) are even defined almost 1 page later after Eq (2). Additionally, the definitions, such as \"\\rho denotes the randomness or variance shape of \\xi\", are too vague to be rigorous. Also, the summand in (2) contains nothing indexed by i.\n- Also, MCR seems to be a central concept. For completeness it should be defined explicitly.\n- In addition to the difficulty in following the figure explanations, it also seems to me that the authors only list metrics of the networks trained with their proposed loss. Their contribution is not demonstrated due to a lack of baseline, such as showing that networks trained with other losses or sampled deterministically are relatively not robust. The only comparison seems to be on the accuracy to LDR in Table 1, which shows a worse performance and is remarked by the authors as \"not the main focus\".\n- The authors claim that the presence of bias and batch norm largely undermines the robustness of the trained networks, without providing further insights either intuitively or numerically."
            },
            "questions": {
                "value": "- Please see weaknesses above\n- What is \"golden search\" for case 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}