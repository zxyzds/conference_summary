{
    "id": "3fl1SENSYO",
    "title": "Unleashing the Potential of Diffusion Models for Incomplete Data Imputation",
    "abstract": "Generative models play an important role in missing data imputation in that they aim to learn the joint distribution of full data. However, applying advanced deep generative models (such as Diffusion models) to missing data imputation is challenging due to 1) the inherent incompleteness of the training data and 2) the difficulty in performing conditional inference from unconditional generative models. To deal with these challenges, this paper introduces DiffPuter, a tailored diffusion model combined with the Expectation-Maximization (EM) algorithm for missing data imputation. DiffPuter iteratively trains a diffusion model to learn the joint distribution of missing and observed data and performs an accurate conditional sampling to update the missing values using a tailored reversed sampling strategy. Our theoretical analysis shows that DiffPuter's training step corresponds to the maximum likelihood estimation of data density (M-step), and its sampling step represents the Expected A Posteriori estimation of missing values (E-step). Extensive experiments across ten diverse datasets and comparisons with 17 different imputation methods demonstrate DiffPuter's superior performance. Notably, DiffPuter achieves an average improvement of 8.10\\% in MAE and 5.64\\% in RMSE compared to the most competitive existing method.",
    "keywords": [
        "Diffusion models",
        "missing data imputation"
    ],
    "primary_area": "generative models",
    "TLDR": "This paper combines EM algorithm and a Diffusion model for missing data imputation",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=3fl1SENSYO",
    "pdf_link": "https://openreview.net/pdf?id=3fl1SENSYO",
    "comments": [
        {
            "summary": {
                "value": "The paper addresses the imputation of data missing completely at random (MCAR) in tabular data, handling both continuous and categorical variables. The authors propose an EM procedure with a conditional diffusion model for imputation, featuring a novel adaptation of the annealing process for better conditioning on observed values. The paper demonstrates strong results across multiple datasets in comparison with leading methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The paper is well-written with a clear, thorough, and concise introduction that effectively summarizes key points from previous works\n* The authors specifically address the challenges of the problem and provide clever solution to mitigate them\n* The paper's main novelty is supported by theoretical proof\n* The evaluations are comprehensive, with thorough and convincing ablation studies"
            },
            "weaknesses": {
                "value": "* A major concern regarding evaluations - while the paper claims to use a single hyperparameter setting throughout, it's unclear how hyperparameters for other methods were selected and their sensitivity to these HP. For me, this concern significantly impacts the overall assessment of the paper.\n\n* While the results are impressive, their importance is not clear. A more convincing evaluation would include the effect on downstream tasks, given imputation is only a first step in most pipelines. \n\n* Another point regarding evaluations, is the sole focus on data missing completely at random. While the MER assumption is important, it is the MNER which is a primary focus in many imputation methods.\n\n* The 0/1 continuous encoding of categorical data is unusual, given that binary data is a known challenge for diffusion models (for example in fields like graph generation). Also, the use of mean is inherently problematic due to common multi-modality in the data\n\n* The novelty of the method compared to other approaches is not clearly articulated in the related works section\n\n### Smaller Issues\n* Given the method's novelty isn't specific to tabular data, the related work should include other imputation methods (e.g., image inpainting)\n* A simulation study with multiple modes would be valuable, particularly as diffusion-based models should excel in such scenarios\n* Despite highlighting the importance of initialization in the EM procedure, the paper doesn't address this point. (Particularly relevant given the naive initial imputation approach)\n* It would be interesting to analyze the relationship between delta_t size and ML solution approximation.\n* Figure 4 lacks clarity"
            },
            "questions": {
                "value": "In biology, missing values are often represented as 0 (or another \"limit of detection\" (LOD) value), making it difficult to distinguish between actual LOD values and data missing at random (which can comprise 30% of data in cases like proteomics and single-cell analysis). Do you have any ideas about how this problem could be addressed? Note that the fraction of missing values might be known and could potentially be conditioned on."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The missing value imputation is a very important problem in both machine learning and statistics. Although deep generative imputation methods have shown promise, there is still substantial room for improvement, even for matching the performance of some traditional machine learning approaches. This paper introduces DIFFPUTER, a tailored diffusion model combined with the Expectation-Maximization (EM) algorithm for missing data imputation, and shows its promising performance on a variety of datasets,"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Theoretical analysis: DIFFPUTER\u2019s training step corresponds to the maximum likelihood estimation of data density (M-step), and its sampling step represents the Expected A Posteriori estimation of missing values (E-step). \n2. Extensive experiments that demonstrate the good performance, as compared with existing baselines, of the proposed method across various datasets."
            },
            "weaknesses": {
                "value": "the computational complexity is not explicitely discussed or compared on the numerical experiments, see details below."
            },
            "questions": {
                "value": "This paper is well-written and easy to understand. This work combines EM with the diffusion model to improve the potential inconsistency caused by missing values in the training process of diffusion models. Since EM is used with K iterations and N number of samples in the E-step, it would be beneficial to also compare the computational complexity (time complexity) of the proposed method with other diffusion-type methods, either in the discussion of the number of operations or comparing the running time in some of the numerical experiments. This would offer more insights into the proposed methods' performance from different perspectives."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces an adaptation of the EM algorithm for missing data imputation, leveraging advanced diffusion-based models to perform precise density estimation in the M-step and provide robust imputations in the E-step, inspired by the RePaint algorithm. The authors reference theoretical analyses from prior work to support the use of diffusion models for density estimation and prove a theorem demonstrating that E-step samples can be drawn from the true conditional distribution. Extensive empirical evaluations highlight the proposed method\u2019s robustness and superiority over various baseline approaches, many of which do not incorporate the EM algorithm."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Robust imputation method based on EM. \n- Well written and structured. \n- The method is theoretically grounded. \n- The empirical analysis is extensive."
            },
            "weaknesses": {
                "value": "- Motivation appears to overlook recent work.\n- Experimental section lacks fair comparison and clarity.\n- Discussion of limitations is lacking.\n- Given these weaknesses, the contribution is not strongly justified."
            },
            "questions": {
                "value": "### Motivation appears to overlook recent work\n\n- The two main issues presented as motivation for this work are unclear. The paper claims that generative imputation methods (i) require joint estimation of observed and missing data distributions and (ii) struggle with conditional inference. I find both statements questionable. Numerous studies adapt deep generative models to estimate only the observed data distribution [1-5], which could serve in the M-step of an EM algorithm. Some of these are even referenced in this paper. Moreover, all of these methods allow for straightforward Monte Carlo estimation of $\\mathbb{E}[p(\\mathbf{x}_m | \\mathbf{x}_o)]$ for the E-step, similar to the proposed diffusion-based model. For instance, a more robust importance-weighted estimator is proposed in [4] (see Eq. (12)).\n\n- This brings me to a second point: if multiple DGMs could, indeed, replace diffusion models within the EM framework, how is diffusion specifically justified for tabular data? This approach might be advantageous for high-dimensional data, where diffusion models effectively approximate $p(\\mathbf{x})$ and avoid lossy compression (as in VAEs). However, given the lower-dimensional datasets studied here, it remains unclear why a VAE-based approach, for example, wouldn\u2019t perform as well as diffusion.\n\n### Experimental section lacks fair comparison and clarity\n\n- Based on my earlier points, I would expect an ablation study comparing different DGMs within the EM algorithm. The baselines in the current experiments appear to rely on simple placeholder values for missing data (e.g., zero or mean imputation), effectively completing only one M-step. This is likely to produce suboptimal results, so a performance gap seems unsurprising.\n\n- The assertion \"Traditional machine learning methods are still powerful imputers\" would benefit from supporting references. I am skeptical, as optimal validation could be harder to achieve in probabilistic settings.\n\n- The claim that generative methods excel on continuous data requires clarification. Here, the diffusion model seems to assume Gaussianity across all dimensions, using $argmax$ as a proxy to obtain discrete outputs, which is not the optimal to model heterogeneous data [2, 3, 5]. \n\n- The statement \"imputation methods are specifically designed for in-sample imputation and cannot be applied to the out-of-sample setting\" also needs elaboration. As mentioned, many DGMs designed for missing data can perform out-of-sample imputation.\n\n- In Figure 2, MissDiff appears to fail or encounter out-of-memory issues. This is surprising, as MissDiff\u2019s architecture is similar to the diffusion network used here.\n\n### Discussion of limitations is lacking\n\n- The main text does not discuss limitations, particularly the high computational cost. A brief note is found in the Appendix, but this isn\u2019t referenced within the primary text. DiffPuter\u2019s approach requires retraining the diffusion model $k$ times, so application to high-dimensional data (e.g., images) would be computationally intense relative to alternatives. I am also curious if the M-step converges faster with higher values of $k$, as this could enhance efficiency.\n\n### Other minor questions\n\n- Figure 6: Why does error decrease as observed data ratio drops? I found the final paragraph of Section 5 somewhat unclear; further clarification here would be helpful.\n\n### Typos\n- Line 515: Change *\", Reducing\"* to *\", reducing\"*.\n\n\n### References\n\n[1] Ma, Chao, et al. \"EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE.\" International Conference on Machine Learning. PMLR, 2019.\n\n[2] Ma, Chao, et al. \"VAEM: a deep generative model for heterogeneous mixed type data.\" Advances in Neural Information Processing Systems 33 (2020): 11237-11247.\n\n[3] Peis, Ignacio, Chao Ma, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. \"Missing data imputation and acquisition with deep hierarchical models and hamiltonian monte carlo.\" Advances in Neural Information Processing Systems 35 (2022): 35839-35851.\n\n[4] Mattei, Pierre-Alexandre, and Jes Frellsen. \"MIWAE: Deep generative modelling and imputation of incomplete data sets.\" International conference on machine learning. PMLR, 2019.\n\n[5] Nazabal, Alfredo, et al. \"Handling incomplete heterogeneous data using VAEs.\" Pattern Recognition 107 (2020): 107501."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors combine diffusion processes and Expectation-Maximization (EM) algorithms to propose a novel way to impute missing data when both training and tests sets contain missing data. The proposed solution is shown to target the correct conditional distribution (distribution of missing data conditional on observed ones). Imputation values are computed by taken the expectation with respect to this distribution, which is approximated by the sample mean. Experiments on ten real-world data sets show the benefit of the proposed method, compared to various state-of-the-art imputation algorithms (machine and deep learning algorithms)."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The authors propose a new method to impute missing data for continuous and discrete inputs. The proposed method appears to be new, with excellent performances. An extensive literature review has been done to present and explain the previous approaches to deal with missing values via imputation. The method is clearly explained, the paper well-written, and the experiments show the benefit of the proposed method."
            },
            "weaknesses": {
                "value": "I only have three remarks: \n- RMSE and MAE are measures that encourage the imputation to target the (conditional) mean or median. In both cases, the target is not a distribution but a single quantity. Recent works (https://arxiv.org/abs/2002.03860) have shown that such measures do not properly evaluate the correctness of an imputation method. Imputation score (https://arxiv.org/pdf/2106.03742) can be used instead to assess the quality of imputations. As the proposed method generates a distribution and not a single point estimate, it is likely that its performance will be higher with respect to this metric, showing that it is able to recover the underlying distribution of the data. Presenting imputation scores in the tables would definitely improve the strength of the paper, in my opinion.\n- The computational performances of DiffPuter should be discussed in the main text. Table 4 is interesting, as it shows that the training time is larger, but not too important. However, the two considered data sets have few features. It would be appealing to consider larger data sets with (i) more observations and/or (ii) more variables to see how the predictive performances and the training time behave. \n- I have trouble understanding the proof of Theorem 1. Notations are confused to me. Adding a table of notations, with exact definitions at the beginning of the Appendix would help. Besides, many approximations are done in the proof : l.730, 731, 750, 753. This results in the theorem being imprecise. For example, nothing is assumed about the quality of the neural network $\\varepsilon_{\\theta}$. What type of convergence is required for Theorem 1 to be valid? Similarly, in Theorem 1, $\\sigma(T)$ is not assumed to be large, whereas it is required in the proof. Please clarify the different assumptions and the proof."
            },
            "questions": {
                "value": "- l.197: could you specify the choice of $\\sigma(t)$? \n- l.225-227: the paragraph does not correspond to the equation: the negative log likelihood is upper bounded by the loss plus a constant, which does not imply that optimizing the first leads to optimizing the second.\n- Section 5.1, how does the method behave when different masks are present in the training and test set? Does it degrade the performances? \n- Section 5.1, how were the hyperparameter chosen for the different baselines? Are these baselines comparable (in terms of number of parameters for example) with the proposed method? Could you add such a discussion in the Appendix? Could you also describe in details the missing data mechanisms used for the different settings (MAR and MNAR encapsulate a lot of data generating processes)?\n- l.366-367, Can you explain the good performances of the proposed method compared to MissDiff and TabCSDI?\n\n\nl.399 : \"Imputaing\"\nl. 468 : \"Gestrue\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}