{
    "id": "xQit6JBDR5",
    "title": "Look Around and Find Out: OOD Detection with Relative Angles",
    "abstract": "Deep learning systems deployed in real-world applications often encounter data that is different from their in-distribution (ID). A reliable system should ideally abstain from making decisions in this out-of-distribution (OOD) setting. Existing state-of-the-art methods primarily focus on feature distances, such as k-th nearest neighbors and distances to decision boundaries, either overlooking or ineffectively using in-distribution statistics. In this work, we propose a novel angle-based metric for OOD detection that is computed relative to the in-distribution structure. We demonstrate that the angles between feature representations and decision boundaries, viewed from the mean of in-distribution features, serve as an effective discriminative factor between ID and OOD data. Our method achieves state-of-the-art performance on CIFAR-10 and ImageNet benchmarks, reducing FPR95 by 0.88% and 7.74% respectively. Our scoring function is compatible with existing feature space regularization techniques, enhancing performance. Additionally, its scale-invariance property enables creating an ensemble of models for OOD detection via simple score summation.",
    "keywords": [
        "out-of-distribution",
        "out-of-distribution detection",
        "decision boundaries"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=xQit6JBDR5",
    "pdf_link": "https://openreview.net/pdf?id=xQit6JBDR5",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes to calculate the angle between the feature representation and the decision boundary, viewing from the mean of ID representations, to compute a score for identifying OOD examples. The method is evaluated on two popular benchmarks: CIFAR100 and Imagenet for OOD detection."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow.\n\n2. Relying on the angle between feature representations and the decision boundary seems to be novel.\n\n3. The geometric interpretation of the presented method is convincing.\n\n4. The presented method can easily be integrated into existing frameworks."
            },
            "weaknesses": {
                "value": "1. I am somewhat skeptical about the performance gain. Although the paper claim performance gains across both benchmarks, the improvement is marginal for CIFAR100 (0.8% FPR95) and only evident on average. Looking at Table 1 and Table 2, the method lags behind other methods on an individual basis. It\u2019s important to discuss why the method does not generalize well on an individual basis.\n\n2. The method is only compared on ResNet architectures. How does it perform on other recent architectures, such as Vision Transformers? Given that the method relies heavily on feature and decision boundaries, validating it on diverse architectures is essential to confirm its architecture-agnostic and plug-in characteristics.\n\nMinor Fixes: Please review the references. Some include only the publication year without the publication venue."
            },
            "questions": {
                "value": "Mostly, my concerns are on performance gain and the experiments on different architectures. If authors can convincingly address my concerns, I am willing to change my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel method for out-of-distribution (OOD) detection based on feature representations in neural networks. The proposed approach, LAFO (Look Around and Find Out), introduces an angle-based metric that measures the angle between feature representations and decision boundaries relative to the mean in-distribution (ID) feature. This approach leverages the relationship between feature vectors and decision boundaries to differentiate between ID and OOD samples effectively."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The idea sounds novel. The paper introduces a novel angle-based metric for OOD detection, which measures the angle between feature representations and decision boundaries relative to the mean of in-distribution (ID) data.\n\n2. This paper conducts extensive experiments to validate the proposed approach, including the standard benchmarks, and demonstrates its flexibility by incorporating it into ensemble methods and combining it with activation shaping algorithms.\n\n3. This paper also explained the connection between LAFO and the similar approach fDBD."
            },
            "weaknesses": {
                "value": "1. The exploration of ID statistics beyond the mean is limited. As OOD detection can benefit from a richer representation of ID statistics, does the \"ID mean\" refer to the mean across all classes? How about class-specific means or other statistical summaries? If the author includes these experiments or analyses, the paper will be strengthened. \n\n2. The experiments do not sufficiently address why and how LAFO enhances ensemble performance compared to other methods. It would be beneficial to see a more detailed analysis of how the angle-based scores behave in various ensemble settings, such as different architectures or training losses, to better understand when and why LAFO performs optimally."
            },
            "questions": {
                "value": "1. Why is the CSI baseline used for CIFAR10 OOD benchmark, but not used for imageNet benchmark?\n\n2. Did you consider the application of LAFO on multi-modal foundation models, such as CLIP?\n\n3. The feature is evaluated through the composed function $f_1\\circ...\\circ f_{L-1} \\circ g $, can you explain the reason why using this way or show some references for this? Did you consider other ways to represent features?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents Look Around and Find Out (LAFO), a novel approach for out-of-distribution (OOD) detection using angle-based metrics. By calculating angles between feature representations and decision boundaries in relation to the mean of in-distribution (ID) features, LAFO improves OOD detection performance by leveraging the geometric relationships within feature space. The proposed method demonstrates robust performance across multiple benchmarks (CIFAR-10, ImageNet), significantly reducing false positive rates (FPR95) compared to state-of-the-art methods. Additionally, LAFO is hyperparameter-free, scale-invariant, and compatible with ensemble models, which enhances its practical utility."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The angle-based approach relative to ID mean is novel in differentiating ID and OOD samples.\n- LAFO\u2019s lack of hyperparameters simplifies its use in practical scenarios and avoids overfitting issues associated with tuning.\n- The model achieves impressive results on CIFAR-10 and ImageNet, showcasing its scalability from smaller to larger datasets.\n- LAFO can be combined with other activation shaping methods, demonstrating flexibility in enhancing model confidence scores."
            },
            "weaknesses": {
                "value": "- While effective, using only the ID mean for centering may limit adaptability across highly variable datasets. Incorporating other statistics could improve robustness.\n- The experiments focus on ResNet architectures. Additional comparisons with transformer-based or CLIP-based architectures could provide more insights.\n- The paper does not fully explore scenarios where LAFO may struggle, such as in cases with minimal separability between ID and OOD distributions.\n- Although LAFO is efficient, the paper could address its performance in real-time or resource-constrained settings to provide a more comprehensive view."
            },
            "questions": {
                "value": "The effectiveness of LAFO in scenarios with severe ID class overlapping?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposed a novel angle-based metric for OOD detection that is computed relative to the in-distribution structure. They demonstrate that the angles between feature representations and decision boundaries, viewed from the mean of in-distribution features, serve as an effective discriminative factor between ID and OOD data. Experiments on CIFAR10 and ImageNet shows SOTA performance compared to other detection methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The performance is good and the analysis is easy to understand.\nThe metric is scale-invariant, allowing ensemble for better performance.\nThe experiment is comprehensive."
            },
            "weaknesses": {
                "value": "1. From Figure 1, the angle \\alpha is helpful for better distinguishing ID and OOD data. And there lacks a comparison between the sine of \\alpha, the sine of \\theta, and the division of them. I think only the sine of \\alpha in Figure 2 is not convincing to demonstrate that the angle \\alpha is not very informative for ID and OOD separation.\n\n2. For experiments, I think the author should report detection results on a vanilla trained model, which is a more common and practical setting for post-hoc detection methods. The current results are all based on supervised contrastive training models.\n\n3. For experiments, it should compare with ReAct method on ImageNet OOD benchmark (in Table 2), since my empirical experience tells that ReAct always shows remarkable performance on ImageNet dataset."
            },
            "questions": {
                "value": "no more question"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}