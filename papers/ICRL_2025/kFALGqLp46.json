{
    "id": "kFALGqLp46",
    "title": "Sanitizing LLMs: Retrospective Learning for Self-Correction of Inconsistent Samples via User Preferences",
    "abstract": "With the advent of large language models (LLMs), using LLMs in conjunction with prompt-based tasks has demonstrated the ability to reduce the high cost and inefficiency of human annotations. Nonetheless, in unsupervised new downstream tasks that require user preferences to align data annotations with expectations, existing evaluation methods for prompt-based tasks become ineffective, especially when ground truth annotations are insufficient or missing. To fill this gap, we propose the novel Consistent and Inconsistent (CAI) Ratio, inspired by our experimental observation that LLMs underperform when the number of inconsistent samples\u2014those with inconsistent predictions across LLMs and the student model\u2014exceeds the number of consistent samples. By estimating the CAI ratio and identifying consistent and inconsistent samples with our proposed CAI identification approach, we aim to minimize inconsistency and enhance the accuracy of LLM-generated annotations for unsupervised data. To achieve this, we introduce Retrospective Learning (RL) with user preference, a data-centric approach that collaborates with the student model and LLMs, using a small number of human annotations as user preferences to resolve inconsistencies in the identified samples. Applied to five domain-specific NLP datasets, our Retrospective Learning approach, leveraging CAI identification, significantly improved the accuracy of LLM-generated responses, with the CAI ratio increasing as the accuracy improved.",
    "keywords": [
        "Large language Model",
        "Prompt Based Task",
        "New Downstream Task with Unsupervised Data",
        "Unsupervised Data annotation with User Preference"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=kFALGqLp46",
    "pdf_link": "https://openreview.net/pdf?id=kFALGqLp46",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces the Consistent and Inconsistent (CAI) Ratio which serves as an effective evaluation metric for unsupervised data with user preferences and Retrospective Learning(RL) to self-correct the identified inconsistent samples using consistent samples."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The results are diverse and demonstrate the effectiveness of the proposed approach.\n- The idea behind the proposed ratio and data-centric approach is intuitive."
            },
            "weaknesses": {
                "value": "- Figure 1 lacks clarity and should present each circle in sequential order. Additionally, the notation in the text does not correspond with the notation in the figure.\n- In fact, my primary question throughout the entire paper is why a student model is necessary at all; this aspect does not seem to be addressed in the introduction. The motivation seems to lack clarity and justification. \n- There is a lack of detail regarding the clustering operations."
            },
            "questions": {
                "value": "- At line 116, referencing a work from 1999 cannot be considered \"recently.\" \n- Additionally, careful attention should be given to the appropriate use of \\citet and \\citep for citations, as well as ensuring consistent and correct application of \\ref and \\eqref."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "For ensure the model generated labels/responses are aligned with end-user needs, this paper first proposes a consistent and inconsistent ratio for evaluating the performance of LLMs or student generated annotations. The main motivation is the consistent samples have significantly higher accuracy than inconsistent ones. This ratio is used to identify consistent and inconsistent samples. For resolving the self-correction with limited user preference data, this paper also introduces a new method retrospective learning to identify and correct inconsistent samples for minimizing inconsistency and enhancing the accuracy of LLM annotations. The proposed method achieves a better classification accuracy consistently cross datasets with a higher consistent and inconsistent ratio."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Strengths: \n\n1.\tFor assessing the annotations generated by LLMs or student model, this paper proposes a consistent and inconsistent sample identification and ratio. It can identify the consistent and inconsistent samples. It utilized the predictions from teacher model and student model. If the predictions from these two models are same, then it is a consistent sample. Vise versa.\n\n2.\tThe retrospective learning method is proposed for self-correction. It includes two modules: divide-and-conquer self-correction and majority voting. With this method, the prediction accuracy is improved because inconsistent samples impact the model performance."
            },
            "weaknesses": {
                "value": "Weaknesses:\n\n1.\tAlthough this paper has shown some results on various datasets, it still lacks the comparison with other methods that can handle the similar problem. \n\n2.\tMore experiments and explanations about the reliability of the CAI score is needed. And this score is highly depended on the selected teacher model and student model. More explorations and comparisons are needed here."
            },
            "questions": {
                "value": "Please check the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Authors propose a metric called Consistent and Inconsistent (CAI) Ratio where they identify the ratio of consistant and inconsistent data points. Then they use this metric and propose a method called Retrospective Learning (RL) to make more inconsistent data points consistant which can help boost the accuracy of the generated data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The approach proposed in the paper is straightforward, easy to understand and easy to implement which can make people to easily use it."
            },
            "weaknesses": {
                "value": "While the approach proposed in the paper is easy to understand, the paper is not written clearly! Specially the beginning few sections of the paper including the introduction. The reason is that there were many undefined terms in the beginning of the paper that would make it hard to understand the paper in the beginning. The reader might understand the paper only after going through the paper multiple times and decoding the terms. The paper might need significant revision to make it clear. In addition, there are confusing terminology used in the paper like using RL for Retrospective Learning. I would advise changing these acronyms to something that is not widely used to avoid confusion. In addition, the motivation of the work is not super clear to me either. All these points resulted in the paper to not be fully clear and made it hard for me to assess the paper completely. \n\nAnother concern is that authors use the same metric as an evaluation metric (CAI) based on which the mitigation approach is proposed which might not be fair. Although authors use accuracy as a metric as well, it would be good to use other metrics to make the results more robust. Can authors do some human experiments or perhaps use other metrics as well?"
            },
            "questions": {
                "value": "Mentioned the question in the weaknesses section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}