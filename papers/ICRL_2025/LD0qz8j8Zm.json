{
    "id": "LD0qz8j8Zm",
    "title": "Evaluating topological fitness of human brain-inspired sub-circuits in Echo State Networks",
    "abstract": "Recent years have witnessed an emerging trend in neuromorphic computing that centers around the use of brain connectomics as a blueprint for artificial neural networks. Connectomics-based neuromorphic computing has primarily focused on embedding human brain large-scale structural connectomes (SCs), as estimated from diffusion Magnetic Resonance Imaging (dMRI) modality, to echo-state networks (ESNs). A critical step in ESN embedding requires pre-determined read-in and read-out layers constructed by the induced subgraphs (e.g., a priori set of functional sub-circuits/networks) of the embedded reservoir (e.g., SCs). As a priori set of functional sub-circuits are derived from functional MRI (fMRI) modality, it is unknown, till this point, whether the embedding of fMRI-induced sub-circuits/networks onto SCs is well justified from i) the neuro-physiological perspective and ii) ESN performance across a variety of tasks. In this paper, we proposed a pipeline to implement and evaluate ESNs with various embedded topology and processing/memorization tasks. To this end, we showed that different performance optimums are highly dependent on the neuro-physiological characteristics of these pre-determined fMRI-induced sub-circuits. In general, fMRI-induced sub-circuit-embedded ESN outperforms simple bipartite and various null models with feed-forward properties commonly seen in MLP for different tasks and reservoir criticality conditions. Noticeably, we found that the reservoir model performance is heavily dependent on the functional sub-circuits neuro-physiological properties with respect to different cognitive tasks and their corresponding computation-memorization balances. Specifically, we showed that default mode network's superior performance across the majority of tasks is related to its functional dichotomy property. Finally, we provided a thorough analysis of the topological properties of pre-determined fMRI-induced sub-circuits and highlighted their graph-theoretical properties that play significant roles in determining the ESN performance.",
    "keywords": [
        "Computational Neuroscience",
        "Neural Data Analysis",
        "Neuromorphic Computing",
        "Recurrent Neural Networks",
        "Echo-state Networks",
        "Reservoir Computing",
        "Network Topology",
        "Bio-inspired Neural Networks"
    ],
    "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=LD0qz8j8Zm",
    "pdf_link": "https://openreview.net/pdf?id=LD0qz8j8Zm",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a method to evaluate the topological fitness of human brain-inspired echo state networks (ESNs) by embedding structural connectomes (SC) and functional connectomes (FC). It aims to assess the impact of various functional sub-circuits (derived from fMRI) on ESN performance in processing and memory tasks. Experimental results suggest that ESN performance is significantly influenced by the neurophysiological characteristics of specific functional sub-circuits across different tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper provides empirical evidence that the topology of different sub-circuits can influence network performance, contributing a valuable experimental perspective to the study of biologically inspired network structures in computational neuroscience."
            },
            "weaknesses": {
                "value": "The contribution of this paper feels limited, as it neither introduces novel methodological advancements nor offers in-depth insights into the experimental results. The study primarily involves modifying network structure, observing performance variations, and drawing conclusions. Given the study's focus on computational neuroscience, providing theoretical explanations or a mathematical basis for the observed phenomena would be essential to strengthen the findings and their broader applicability."
            },
            "questions": {
                "value": "I recommend that the authors include theoretical and mathematical analysis to substantiate the results derived from their computational model. This would help clarify the mechanisms driving the observed impacts of different sub-circuit topologies."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this work, the authors evaluate the computational efficiency of brain connectome with the echo state networks. Interesting, they found that that the brain topology induced some benefit in different tasks. Overall, the exploration on such interdisciplinary field is very interesting and would be inspiring for future work."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The approach of understanding brain topology with ESN is very interesting although I cannot exactly judge whether there are similar approaches before. \n\n2. The paper is clearly written and easy to understand. \n\n3. They provide comparisons on different setups."
            },
            "weaknesses": {
                "value": "1. There are some missing related works. For example, Ref[1] performs a similar analysis with RNN, Ref[2] talks about modularity with HebbFF, and Ref[3] summarizes the potential paradigms of integrating connectome to ANNs. Relating the current work with existing ones will help position the value of the current work. \n\n2. Why do you evaluate according to the 7 readout Yeo network? Although this one is popular, it needs verification about the robustness of the results here with other potential partitions. In addition, considering the number of neurons in different networks are distinct, it is necessary to control the covariants here. \n\n3. Many of the results, including but not limited to those in Figure 3,4,5 and Table 1 are reported with the statistical significance. Thus it is hard to tell whether the differences are statistically meaningful. Some perturbation and bootstrap based statistics should be reported here to improve the quality of the results. \n\n4. The results in Table 1 is quite isolated with the others. The authors should focus on the cognitive tasks and provide some mechanistic insight on what kind of specific topology or property in the connectome leads to the improvement of model performance. \n\n5. The relationship between network measurement and model performance could be investigated across subjects as well where you can adopt the FC/SC for each subject separately and evaluate their performances on tasks. HCP or other dataset with task data would be helpful here. \n\n\nRef:\n[1] https://www.nature.com/articles/s41467-022-28323-7\n[2] https://www.science.org/doi/full/10.1126/sciadv.adm8430\n[3] https://www.nature.com/articles/s41586-023-06670-9"
            },
            "questions": {
                "value": "Please check the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the impact of embedding human brain-inspired topologies, particularly the Default Mode Network (DMN), into Echo State Networks (ESNs) to enhance performance in cognitive tasks. By incorporating the structural properties of the DMN, such as modularity and high centrality, into ESNs, the study investigates whether these biologically inspired architectures can improve network performance in tasks requiring memory and decision-making. The key contribution lies in demonstrating that DMN-based ESNs outperform random networks on several tasks, suggesting that brain-inspired functional topologies can enhance artificial network performance. This work bridges neuroscience and machine learning, providing insights into how brain-like structures can be beneficial in artificial cognitive processing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The study innovatively embeds human brain functional topologies, like the DMN, into ESNs, bridging neuroscience and machine learning to enhance network performance.\n\n2  The paper is well-written, with clear descriptions of the ESN model and results, making it accessible for readers in both neuroscience and AI.\n\n3  This work is valuable for AI and neuroscience, suggesting that brain-inspired network structures could lead to more efficient artificial networks for cognitive tasks."
            },
            "weaknesses": {
                "value": "1 The Default Mode Network (DMN) is a resting-state network and may not optimally support task-specific performance enhancements. To address this, the authors could include a rationale for using DMN in active task contexts or, preferably, conduct comparisons with task-relevant networks like the Executive or Attention Networks. Testing these would clarify if the observed performance gains are unique to DMN topology or simply due to network modularity.\n\n2 The paper lacks comparisons with empirical neurobiological data, which would strengthen the biological plausibility of embedding functional networks in ESNs. Incorporating neural data, such as functional MRI or EEG data for verification, or comparing modeled task performance with observed human data would improve the paper's rigor and relevance to neuroscience.\n\n3 The effects of key parameters (e.g., connection density, node centrality) on ESN performance are not fully explored. Conducting sensitivity analyses or providing ablation studies on these parameters could help understand which aspects of DMN topology are crucial for performance improvements.\n\n4 The study only compares DMN-based ESNs with random networks, without considering other biologically plausible alternatives like small-world or scale-free networks. Including these structures would provide a broader understanding of which network topologies, beyond DMN, contribute to the observed performance gains.\n\n5 While the study highlights improvements on experimental tasks, its implications for real-world or long-term applications remain unclear. Testing the ESN on more complex, real-world-inspired tasks or applications would offer insights into the practical relevance and robustness of the proposed approach."
            },
            "questions": {
                "value": "1 Since the Default Mode Network (DMN) is primarily a resting-state network, why was it chosen to enhance task performance, given that other task-relevant networks might be better suited? \n2 Did the study explore other biologically plausible network topologies (e.g., small-world or scale-free networks) in the ESN structure?\n3 Was empirical neurobiological data, such as functional MRI or EEG, considered for validating the model\u2019s assumptions or findings?\n4 Are there plans to evaluate the ESN with DMN topology on more complex or real-world-inspired tasks to assess its practical utility?\n5 How sensitive is the model's performance to variations in parameters like connection density or node centrality within the DMN structure?\n6 Could the authors expand on how specific DMN properties, such as modularity or centrality, might contribute to ESN performance, even beyond cognitive tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "no concerns"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a already seen approach that integrates human brain-inspired topologies into ESNs. The findings suggest that neuro-physiological features of brain sub-circuits can, in some cases, improve performance in tasks related to processing and memory.\n\nOverall the paper lack real output from ESN and reads more like a biology paper in structure, vocabulary and the nature of many big theory mistakes.\n* the wrong citation for memory capacity and confusion on echo state property.\n* The overall structure and vocabulary is a bit confusing.\n\nThe results presented are too weak to be considered significant. The conclusion that \u201cdifferent topological properties are conducive to the processing of different tasks\u201d highlights the lack of substantial findings.\n\nIn my view, the focus of this paper should have been on the various \u201cvariants\u201d used to generate the network rather than on ESN performance and evaluate the performance on well motivated task that resemble the ones the investigated circuit might perform. Unfortunately, the performance of the investigated connectivity models is not particularly compelling compared to traditional ESN models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The subject is interesting but not well motivated. See questions.\n\nA clear strength of the paper is thorough in the citation of similar works, they are well cited and the difference with present work is clear. The paper studies many variants of connectivity generations which is always good."
            },
            "weaknesses": {
                "value": "One of the claims in the paper is that it \u201cfound that the performance of the reservoir model is not strictly defined by the reservoir\u2019s echo-state property,\u201d but it incorrectly associates this with \u201cthe spectral radius of the connectivity matrix.\u201d This is a misunderstanding, as it is commonly stated that if the spectral radius of the connectivity matrix is below 1, the network respects the echo-state property. However, a network can still respect the echo-state property even if its spectral radius exceeds 1. This confusion undermines one of the paper\u2019s key claims.\n\nAdditionally, the concept of memory capacity is incorrectly attributed to Suarez et al. (2020), when it should be credited to Jaeger (2002). The paper also misuses this concept. To clarify, Suarez (2020) does cite Jaeger (2002), so this mistake is not theirs.\n\nThe structure and wording of the paper is also confusing. For instance, the section titled \u201cStructural and functional connectomes\u201d should not be part of the dataset description, but rather included in the section explaining how the models are formed. Referring to a model as \"control\" is not common in Machine learning. \n\nThe results are too weak to be really interesting as many previous paper (rightfully cited in the present one) have already explored this path."
            },
            "questions": {
                "value": "How does the temporal scale of the biological networks studied compare to the temporal scale of the tasks performed? Is there any motivation for why the temporal scale of these biological networks and the computations they perform would be relevant for the tasks being investigated?\n\nWhy does the memory capacity task use Pearson correlation as the evaluation metric?\n\nWhat motivates the use of the F1-score instead of accuracy in this study?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}