{
    "id": "wxPnuFp8fZ",
    "title": "Self-Supervised Diffusion MRI Denoising via Iterative and Stable Refinement",
    "abstract": "The MRI, including diffusion MRI (dMRI), serves as a ``microscope'' for anatomical structures and routinely mitigates the influence of low signal-to-noise ratio scans by compromising temporal or spatial resolution. However, these compromises fail to meet clinical demands for both efficiency and precision. Consequently, the denoising technique plays a crucial role, especially for dMRI, which lacks clean data. In this paper, we introduce Di-Fusion, a fully self-supervised denoising method that leverages the latter diffusion steps and an adaptive sampling process. Unlike previous approaches, our single-stage framework achieves efficient and stable training without an explicit noise model and offers adaptive and controllable results in the sampling process. Our thorough experiments on real and simulated data demonstrate that Di-Fusion outperforms the state-of-the-art dMRI denoising methods in microstructure modeling, tractography tracking, and other downstream tasks. Codes are available in the supplementary material.",
    "keywords": [
        "Diffusion based models",
        "Self-supervised MRI denoising"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=wxPnuFp8fZ",
    "pdf_link": "https://openreview.net/pdf?id=wxPnuFp8fZ",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes a novel self-supervised denoising method Di-Fusion that leverages the latter diffusion steps and an adaptive sampling process.  Di-Fusion outperforms two slightly older methods and a state-of-the-art approach on   and on downstream processes like tractography."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Paper is easy to follow.\nResults across multiple real and simulated datasets, suggesting generalizability of approach.\nBaseline is a recent state-of-the-art.\nThe authors released their code to the reviewers, which is well-written, informative and aides reproducibility."
            },
            "weaknesses": {
                "value": "Did the authors consider using: https://arxiv.org/pdf/2305.00042  and    https://arxiv.org/pdf/2309.05794  as baselines?\nBetter signpost the extensive results in the supplementary materials.\nSome parts of the paper read a bit odd and should be checked for oddities e.g. from the introduction 'The MRI, including ...', 'Consequently, the denoising technique plays a crucial role..'"
            },
            "questions": {
                "value": "Please see weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Di-Fusion, a fully self-supervised diffusion MRI (dMRI) denoising method designed to enhance the signal-to-noise ratio (SNR) of MRI data without requiring clean reference data. The authors leverage novel late diffusion steps and an adaptive sampling process to create a single-stage framework that operates without an explicit noise model. Di-Fusion demonstrates superior performance over state-of-the-art denoising methods in tasks such as microstructure modeling and tractography. The method\u2019s efficacy is validated through extensive quantitative and qualitative evaluations on real and simulated data."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- **Flexibility with data and noise models**: Instead of relying on explicit noise models or clean training data, the method relies on an N2N training strategy and pixel shuffling to reorganize the noise, providing strong generalization potential across different noise distributions. This suggests that the method has the potential to be applied to a wider range of denoising scenarios, such as cryo-EM.\n- Compared to the current state-of-the-art method, DDM^2, this approach demonstrates comprehensive improvements. Not only does it outperform in terms of performance, but it is also simpler to implement. Notably, this method does not require additional denoiser training, significantly enhancing its practical usability.\n- As a study on dMRI denoising, this paper conducts thorough and comprehensive experiments, including extensive comparisons and analyses on downstream task performance. This renders the work methodologically and experimentally well-rounded."
            },
            "weaknesses": {
                "value": "Please refer to the **Questions** section for details."
            },
            "questions": {
                "value": "- To my understanding, the primary goal of dMRI denoising is to reduce the number of gradients required during acquisition, thus accelerating DWI scanning. In downstream tasks based on DTI, the authors compare DTI metrics computed from noisy images with those from denoised images. Why did the authors not use more DWI data to compute a clean DTI metric as a reference for comparison?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new self-supervised learning-based denoising method for diffusion MRI (dMRI). The proposed method leveraged the diffusion modeling concept, but instead of training a diffusion model with \u201cclean images\u201d as x_0 and noise as x_T, it utilized two diffusion weighted images (DWIs) with different diffusion encodings at both ends of a \u201cdiffusion-like\u201d process. A denoising network was trained by predicting one DWI using a linear combination of two DWIs and an added noise term. The linear combination coefficients are time-dependent and determined via a scheduling strategy similar to training a diffusion model. The network was then used for a conditional sampling step for generating the final denoised images. The idea to utilize images acquired with different diffusion encodings to denoise one of them is interesting and the training strategy is an interesting approach to leverage the diffusion modeling concept, especially with training only latter diffusion steps to reduce hallucinations. However, several key assumptions made are questionable and the overall methodology and presentation lacks clarity. Evaluation using only dMRI signal model goodness of fit is limited and can be biased. There are a few overstatements that can mislead the readers. Detailed comments can be found below."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "A diffusion-like modeling that learns the relationship between two DWI volumes with different diffusion encodings to denoise one or each other.\n\nTraining only later step diffusion to avoid hallucination\n\nA fusion strategy that exploits linear combination of two DWIs with different contrasts with time-dependent coefficients and iterative refinement.\n\nExtensive evaluations using both simulations that exactly followed the assumptions for the proposed methodology and practical magnitude DWI data."
            },
            "weaknesses": {
                "value": "There are statements that can be misleading in the context of MR physics (aka domain knowledge). For example, \"the noise predominantly originates from physical interferences (Fadnavis et al., 2020a)\". This statement about physical interferences is  both vague and inaccurate. This work is dealing with thermal noise or noise resulting from thermal noise in the measurements, which is not really physical interferences depending on how ones interpret them. Another example, \"Different clinical applications require varying numbers of diffusion vectors and acquisition strategies, which makes modeling the noise distribution and further implementing denoising techniques challenging\". Acquiring DWIs with varying numbers of diffusion vectors had nothing to do with the difficulty of  modeling noise distribution.\n\nMany key assumptions for the proposed method was built on do not hold which made the theoretical/mathematical foundations questionable, e.g.,\na) It seems that the authors assumed DWIs acquired with different diffusion encodings had the same underlying \u201cclean\u201d image and were corrupted by independent noise. This is inaccurate. In fact, two DWIs can have rather different contrasts due to the diffusion encoding effects, e.g., different diffusion encoding directions. More specifically, x and x\u2019 cannot be simply modeled as the same y plus different noise. What are the implications of this assumption not met?\n\nb) Line 111: The authors claimed that that the proposed method does not require an explicit noise model. This is an overstatement. The J-invariance assumption, which formed the basis of the training objective in Eq. (9) implicitly requires that the noise distribution be zero-means and conditionally independent. Furthermore, additive noise model was assumed, x = y + n1 (Line 200). In dMRI, the magnitude images with higher b-values (stronger diffusion weightings) can have lower SNR for which additive noise may not hold. These need to be clarified.\n\n-  Overall, the presentation lacks clarity and there seem to be some concerning inaccuracies.\na) The linear combination relationship claimed in Section 3.1 does not seem accurate. I checked the derivation. Eq. 31 is correct which is known (so this is not a contribution of the authors), but I'm not sure about going from Eq. 31 to 32 as F_theta predicts x_0, but they are not equal, and there is also an additional term of sigma_t^2*z. Therefore, I don't think it's a correct statement to say x_(t-1) is a linear interpolation between x_out and x_t. But is this really needed for the proposed method? I really don\u2019t see a connection between what\u2019s argued theoretically and what\u2019s actually being implemented.\n\nb) There are a few other inaccurate mathematical statements and notations which are confusing. For example, Eq. 7, the left side has q(x1:T |xt*) which is a joint distribution for x1 to xT, and the right side is a Gaussian distribution for xt. \nOn Line 160: {xt}1:T was described as\u201dobtained from the reverse process.\u201d However, in\nFigure 1 and on the right side of Equation (7) on Line 186, it appears that xt is a corrupted version of xt*.  This interpretation, along with the notation in the Fig. 1, implies that {xt}1:T would represent a forward process. It appears to this reviewer the authors had not been using a consistent definition of forward and reverse diffusion which made the overall description rather confusing. These are just examples of inconsistencies found.\n\nc) According to the J-invariance property, the noise should ideally have zero mean\nand be conditionally independent of the target output. This requirement is necessary to ensure that the expected loss for self-supervised training asymptotical approaching the supervised loss. However, the input to F(.) in Eq. (9) includes xt*, which is a linear combination of x and x\u2019 (Eq. (6)). Given that x serves as the supervision signal for the loss, this implies a correlation between the input x\u2217t and the target x, which would violate the conditional independence requirement for J-invariance."
            },
            "questions": {
                "value": "In Eq. (5) on Line 155, the authors highlighted a specific term as the \u201dmajor difference\u201d between xt\u22121 and x^bar_t\u22121. Could the authors clarify why this particular term is considered the primary source of difference? Furthermore, can the authors elaborate on the underlying reason(s) for the \u201cdrift\u201d in the model and how it emerges during the reverse diffusion process?\n\nAccording to the definition of the Fusion process in Eq. (6)  and the \u201cforward process\u201d in Eq. (7), it appears that the starting point for the forward process changes based on t, as x_t* is dependent on t. This dependence implies that the Fusion process dynamically adjusts the starting point of the forward process at each step, which is unconventional compared to typical diffusion models. Could the authors clarify the rationale behind this design?\n\nOther more recent self-supervised denoising methods should be compared, if not for all, e.g., Noise2Score and Recorrupted2Recorrupted etc."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This is a new denoising method for dMRI data. Combines DL-based diffusion models with a bit of fusion. The fusion process stabilizes issues that DDM2 has.\n\nI suggest that the authors refrain from large claims. For example, it says that it outperforms the other methods. But I do not see any speed or memory comparisons. \n\nIn the comparisons I would also add MPPCA. I would also cite Patch2Self2 (CVPR 24). Patch2Self has clearly outperformed MPPCA however still many people use MPPCA.\n\nThe paper does a great job on the methodological sections. \nIn providing code and using open source standards.\n\nHowever, at least a thorough review of language is required.\n\nQualitatively it is hard to see large advantages over Patch2Self but nonetheless the method is useful. \n\nIn the revision please report time and memory usage. I would also compare against Patch2Self2 if possible.\n\nAlso it would be important to explain the setup. What GPUs were used for training?"
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "Great way to stabilize the diffusion process."
            },
            "weaknesses": {
                "value": "Refrain from large claims. \n\nReport time and memory usage.\n\nReport setup (GPU types, numbers and VRAM).\n\nCheck statements."
            },
            "questions": {
                "value": "What is the actual minimum number of B0 and DWI volumes required ?\n\nCan this work with data that have a single B0? Would that be denoised?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 10
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a method for denoising diffusion MRI data sets.\n\nThis is a well-studied problem with many solutions in the literature. It is an important problem, as diffusion MRI is widely used for neuroscience and for clinical medicine. Recent years have seen a trend towards using self-supervised approaches to characterise the noise distribution and separate noise from the underlying signal.  This submission falls very much in this category, but proposes a different algorithm to those that are popular in the literature.\n\nExperiments compare against five baselines and results appear competitive with other methods, sometimes surpassing them."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The algorithm appears novel, although I found it hard to tell from the literature review how novel it is - whether it takes ideas from other areas and repurposes them for this problem, or if this is an algorithm specifically designed for diffusion MRI.\n\nThe problem is an important one with widespread application.\n\nResults appear competitive on a few example images shown in the figures."
            },
            "weaknesses": {
                "value": "The baselines chosen do not include the most widely used denoising methods.  A clear omission is the random-matrix theory approaches proposed by Veraart et al in a series of very highly cited papers starting with Neuroimage 2016.\n\nThe only quantitative results use simulations, which seem likely to be skewed towards to capabilities of the proposed algorithm.\n\nThe qualitative results on actual human data are questionable as to whether they show improvement over baselines.  Even if they do, these are single cherry-picked examples and it is not clear whether these are advantages that manifest over large collections of images/scenarios."
            },
            "questions": {
                "value": "Corresponding to weaknesses listed above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}