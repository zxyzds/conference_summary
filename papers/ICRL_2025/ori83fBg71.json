{
    "id": "ori83fBg71",
    "title": "SPECTRUM: Empowering Online Handwriting Verification via Temporal-Frequency Multimodal Representation Learning",
    "abstract": "Tapping into the uncharted multimodal representation learning in online handwriting verification (OHV), we propose SPECTRUM, a temporal-frequency synergistic model tailored to enhance handwriting representations. SPECTRUM comprises three core components: (1) a multi-scale interactor that interweaves fine-grained temporal and frequency features across multiple scales through complementary domain interaction; (2) a self-gated fusion module, dynamically integrating global temporal and frequency features via self-driven balancing. Collectively, these two components achieve micro-to-macro multimodal integration; (3) a multimodal distance-based verifier that fully harnesses temporal and frequency representations, sharpening genuine-forged discrimination beyond conventional temporal-only approaches. Extensive experiments demonstrate SPECTRUM's pronounced outperformance over existing OHV methods. Furthermore, we reveal that incorporating multiple handwritten biometrics fundamentally improves the discriminatory power of individual writing features. These findings not only validate the efficacy of multimodal learning in OHV but also encourage broader multimodal research across both feature and biometric domains, potentially opening new avenues for future explorations. Code will be publicly available.",
    "keywords": [
        "Online handwriting verification; Multimodal representation learning; Temporal and frequency learning; Handwritten biometrics"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We propose a multimodal temporal-frequency synergistic model to empower online handwriting verification.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ori83fBg71",
    "pdf_link": "https://openreview.net/pdf?id=ori83fBg71",
    "comments": [
        {
            "summary": {
                "value": "This is primarily a paper on online handwriting verification. The main contribution of this paper can be summarized as,\n\n- a multi-scale interactor that integrates fine-grained temporal and frequency features across multiple scales through complementary domain interactions\n- a self-gated fusion module, dynamically integrating global temporal and frequency features through self-driven balancing.\n- a multimodal distance-based verifier that fully leverages temporal and frequency representations, enhancing genuine-versus-forged discrimination beyond traditional temporal-only methods.\n\nThe authors designed several experiments to demonstrate the effectiveness of their approach."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors have clearly articulated the main focus and innovations of their research, and the experiments have, to some extent, validated the effectiveness of their approach."
            },
            "weaknesses": {
                "value": "The main concerns, questions, limitations and weaknesses of this paper are as follows:\n\n- In this paper, images and their frequency domain information obtained via DFT are used as input for network training, and this approach is referred to as multimodal features learning by the authors. However, I believe this terminology is inappropriate (although the even and odd time steps are treated separately as temporal and frequency features, respectively). Multimodal typically refers to different types of data sources, such as visual, text, audio, or sensor data. Therefore, the combination of temporal and spatial domains is more accurately described as multi-dimensional or multi-scale features rather than multimodal.\n\n- Could the authors provide a comprehensive analysis of the inference speed during the model testing phase and compare it with previous algorithms?\n\n- More ablation studies should be conducted to validate the effectiveness of the design \"$x_{even}$ for temporal and $x_{odd}$ for frequency\". Specifically, the experiments that should be supplemented include \"$x_{even}$ for frequency and $x_{odd}$ for temporal\" and \"both $x_{even}$ and $x_{odd}$ for frequency and both $x_{even}$ and $x_{odd}$ for temporal\".\n\n- In Tables 1, 2, 3 and 5, the existing algorithms compared by the authors were all proposed at least two years ago. Are there any more recent algorithms available for comparison?\n\n- What is the parameter count for each module in the proposed algorithm? Could the authors provide a comprehensive analysis and compare it with previous algorithms?\n\n- Any ablation studies about the number of multi-scale interactors? Any differences between every interactor (e.g., inputs,  structure) except for the \"1D learnable complex weights\"? If not, why not directly increase the learnable parameters of single-scale interactor and shared other learnable parameters? \n\n- Any visualization results that can validate the effectiveness of the introduced \"1D learnable complex weights\"?\n\n- How much performance improvement does the introduction of multi-head self-attention bring to the model?\n\n- Any visualization results that can validate the effectiveness of the introduced \"self-gated fusion module\"?\n\n- One peculiar point is that the authors claim frequency and temporal domains as two modalities (a claim I find unreasonable), yet they perform no alignment during feature fusion (like LMM). Instead, they simply learn a weight to fuse them, which supposedly yields good results.\n\n- Why not Linear + softmax for \"self-gated fusion module\"?\n\n- The formula representations for sequence images are inconsistent in Section 3.1 and 3.2.\n\n- How to set c in Eq. (7) for practical application?\n\n- Any ablations studies on the loss weight in Eq. (8)?\n\nOverall, this is not a sufficiently strong work that could be accepted by ICLR, as its main contribution\u2014combining temporal and frequency features for online handwriting verification\u2014is already commonplace in the field of deep learning. Additionally, modules like the self-gated fusion module, designed to support the proposed temporal and frequency integration strategy, lack novelty (these modules add a significant number of extra parameters and computational load to achieve the performance improvement, which is meaningless).  Finally, many expressions in the paper are also inadequately phrased."
            },
            "questions": {
                "value": "Please refer to the content in the 'weaknesses' box; it will not be reiterated here."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This submission proposes an online handwriting verification method, SPECTRUM, using temporal- frequency information. Multi-scale interactors are proposed to facilitate finegrained interaction between temporal and frequency features. To balance the weight of temporal and frequency features, a self-gated fusion module is applied. Experiments are conducted on three online datasets -- MSDS-ChS, MSDS-TDS, and DeepSignDB Tolosana, and the results are superior to its peers."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "+ Combing temporal and frequency information.\n+ Performance superior to its peers.\n+ Idea is easy to follow."
            },
            "weaknesses": {
                "value": "- Limited novelty. Fourier transform has been widely used in OHV before. The submission works on some details on using FT.\n- Experiments only conducted on the three datasets and lacking comparison on multi-linguistic cases."
            },
            "questions": {
                "value": "I don't have any question on this kind submission, correct but very limited incremental contribution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes SPECTRUM, which is a temporal-frequency synergistic model tailored to enhance handwriting representations to deal with online handwriting verification (OHV) problems. This module comprises three components: a multi-scale interactor that interweaves fine-grained temporal and frequency features; a self-gated fusion module to dynamically integrate global temporal and frequency features; a multimodal distance-based verifier that fully harnesses temporal and frequency representations. The main contributions are as follows: (1) first propose a multimodal representation model for OHV; (2) a multi-scale interactor and self-gated fusion module, designing a multi-modal distance-based verifier; (3) detailed experiments to verify the effectiveness of the proposed SEPCTRUM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe research paper is well-written. The paper is clear and detailed in discussing the main points of the concept with a carefully-designed experiment process which includes results for main datasets and ablation studies. The author also describes the limitations and future research directions in the end of the paper.\n2.\tThe multi-modal learning paradigm for OHV demonstrates a degree of originality. While previous methods typically employed a single modality, focusing on either temporal or frequency aspects, the author proposed a module that effectively fuses these two dynamic modalities."
            },
            "weaknesses": {
                "value": "1.\tSome experiments indicated that the performance of SPECTRUM is suboptimal. For instance, in the evaluation on DeepSignDB (Table 3), SPECTRUM did not outperform previous methods, such as Sig2Vec and DsDTW, in certain aspects. The author did not discuss the reasons for SPECTRUM\u2019s weaker performance on this dataset.\n2.\tIn the experimental process, the methods used for comparison are primarily from 2021 and 2022, which are somewhat outdated. The paper should discuss recent advancements in OHV methods and include comparisons with more recent approaches.\n3.\tSome parameter choices are unclear, and additional ablation studies are needed. For example, why is $\\lambda$ set to 0.1? Are there any ablation studies to support this choice? Similarly, how is the threshold $c$ determined, and are there any justifications or ablation studies provided? Moreover, the loss terms include $L_{intra}$, $L_{tri}$, and $L_{BCE}$; however, the paper does not explain why these particular losses were chosen or if any ablation studies were conducted to validate their selection."
            },
            "questions": {
                "value": "1.\tThe author proposed SPECTRUM with a multi-modal learning paradigm; however, the comparison methods used throughout the paper are mostly from before 2022. How has the OHV method evolved in 2023 and 2024? Are there any recent advancements from the past two years?\n2.\tThe paper introduces SPECTRUM, which performs open-set verification, but it is only evaluated in three settings: Chinese signature, token digit string, and Latin signature. Can SPECTRUM generalize effectively to other settings?\n3.\tCan the SPECTRUM perform better than Transformer-based models?\n4.\tThis paper is well-executed, but some experiments and details are somewhat outdated and lack recent developments. If the author could address these issues thoroughly, I would reconsider the final rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces SPECTRUM, a multi-modal representation model designed to enhance online handwriting verification (OHV) by integrating temporal and frequency features. The model employs a multi-scale interactor for fine-grained temporal and frequency feature interaction, a self-gated fusion module for macro-level integration, and a multimodal distance-based verifier (MDV) that leverages temporal and frequency representations to distinguish genuine handwriting from forgeries. Experimental results across three major datasets (MSDS-ChS, MSDS-TDS, and DeepSignDB) demonstrate SPECTRUM\u2019s superior performance in skilled and random forgery scenarios, setting new benchmarks for OHV accuracy. Furthermore, combining multiple handwritten biometrics, such as Chinese signatures and token digit strings, boosts verification performance, underscoring the model\u2019s versatility and potential for broader biometric applications."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "- **Innovative Multi-Modal Architecture**: SPECTRUM\u2019s integration of temporal and frequency modalities sets it apart from traditional temporal-only OHV methods, making it highly effective in distinguishing genuine handwriting from forgeries.\n- **Effective Verification Across Datasets**: The model\u2019s demonstrated success across different datasets (MSDS-ChS, MSDS-TDS, and DeepSignDB) indicates its robustness and adaptability, with performance gains across Chinese and Latin signature verifications.\n- **Advanced Metric for Verification**: The multimodal distance-based verifier (MDV) introduces a more nuanced approach to evaluating handwriting authenticity by leveraging dual modalities, significantly enhancing verification task accuracy.\n- **Comprehensive Experimental Analysis**: The authors conduct thorough ablation studies, baseline comparisons, and multimodal tests, offering a holistic evaluation of SPECTRUM\u2019s performance across multiple scenarios."
            },
            "weaknesses": {
                "value": "- **Scalability and Real-World Feasibility**: Although SPECTRUM demonstrates high performance, the paper could further discuss computational efficiency, especially for large-scale OHV tasks or real-time applications. Time would be beneficial if an analysis of computational cost or inference were included.\n- **Limited Exploration of Dataset Biases**: The paper briefly mentions the use of Chinese and Latin signatures but does not explore potential biases that could arise from dataset limitations. A discussion on demographic diversity in handwriting samples would help assess the generalizability of SPECTRUM.\n- **Impact of Multi-Scale Integration**: While the multi-scale interactor is effective, the paper could delve deeper into the effects of different scale configurations, particularly for datasets with variable stroke dynamics, such as cursive signatures or complex character-based languages."
            },
            "questions": {
                "value": "1. Computational Efficiency: Could you provide insights on SPECTRUM's computational efficiency, particularly in real-time scenarios? What optimizations could be applied to enhance its performance?\n\t2. Diversity in Handwriting Samples: Have you considered or evaluated SPECTRUM\u2019s performance across diverse demographic groups? How might this impact its robustness in real-world applications?\n\t3. Future Directions for Multi-Modal OHV: Beyond temporal and frequency features, do you envision incorporating additional modalities, such as pressure or spatial data, to enhance verification performance further?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}