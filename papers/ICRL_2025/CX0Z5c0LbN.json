{
    "id": "CX0Z5c0LbN",
    "title": "Challenging the Counterintuitive: Revisiting Simple Likelihood Tests with Normalizing Flows for Tabular Data Anomaly Detection",
    "abstract": "In this study, we propose a novel approach to anomaly detection in the tabular domain using normalizing flows, leveraging a simple likelihood test to achieve state-of-the-art performance in unsupervised learning. Although simple likelihood tests have been shown to fail in anomaly detection for image data, we redefine the counterintuitive phenomenon and demonstrate, both theoretically and empirically, why this method succeeds in the tabular domain. Our approach outperforms traditional anomaly detection methods by offering more consistent results. Furthermore, we question the practice of fine-tuning parameters for each dataset individually, ensuring fair and unbiased comparisons by adopting uniform hyperparameters across all datasets. Through extensive experimentation, we validate the robustness and scalability of our method, highlighting its practical effectiveness in real-world settings.",
    "keywords": [
        "anomaly detection",
        "tabular data",
        "self-supervised learning",
        "generative model"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CX0Z5c0LbN",
    "pdf_link": "https://openreview.net/pdf?id=CX0Z5c0LbN",
    "comments": [
        {
            "summary": {
                "value": "Deep generative models like normalizing flows have shown counterintuitive behavior when detecting anomalies in image data (Nalisnick et al., 2018). The paper considers using normalizing flows to detect anomalies but in the tabular data domain. The paper doesn\u2019t find the counterintuitive observation re-occurs. The authors claim normalizing flows are effective methods for real-world tabular data anomaly detection and demonstrate the phenomenon empirically through one specific model. The authors borrow the properties of Euclidean norms in high dimensional space to explain why normalizing flows fail in high dimensional spaces."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The paper has done large-scale experiments on ADBench datasets. A lot of methods have been evaluated in the same setting.\n- The limitation section covers some of the concerning aspects."
            },
            "weaknesses": {
                "value": "My main concern comes from the reasoning of the claim\n- There are ambiguities in definition 1. According to it, does OCSVM have counterintuitive performance as it is rated to be the worst among compared methods?\n- The empirical evidence is weak. The paper should discuss other normalizing flows rather than NF-SLT in Table 1.\n- The theoretical analysis only focuses on high-dimension curse and is not specific to flow methods. Moreover, it doesn\u2019t clearly state why flow methods succeed in tabular data anomaly detection."
            },
            "questions": {
                "value": "Here are some questions / minor concerns:\n- How about the original definition \u2013 OOD has higher likelihood than ID? Why don\u2019t you use that definition?\n- Does fef 1 consider model complexity?\n- Overclaimed? L226: \u201cTo the best of our knowledge, this is the first time we have run an experiment with all the tabular data proposed in ADBench\u2026\u201d A lot of papers have grounded their experiments on the whole ADBench.\n- What makes the difference between subplots 3, 4 and subplots 1, 2 in Fig 1?\n- L159: \u201c...higher likelihoods to OOD data\u2026\u201d should be \u201clower\u201d"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper solves tabular anomaly detection with normalizing flow model and formalizes the counterintuitive phenomenon."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Introduces the normalizing flow model for tabular anomaly detection."
            },
            "weaknesses": {
                "value": "Please refer to questions below"
            },
            "questions": {
                "value": "\u2022 The method in the paper does not elaborate on the implementation details, which is not reader-friendly.\n\u2022 In Section 5, only show the results on synthetic datasets, such as cardio and cardiotocography, cover and donors, ionosphere and letter, and so on, these datasets \nin the same dimension, why not use real datasets for analysis like [1]?\n[1] Why Normalizing Flows Fail to Detect Out-of-Distribution Data. NeurIPS 2020.\n\u2022 Compared with the results reported by MCM[2], the effect of using Fair hyperparameter is quite different. If fine-tuning is used, why not use the best results?\n[2] MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data. ICLR 2024.\n\u2022 I'd also like to see NPT-AD [3] performance results, as these are not presented in the paper.\n[3] Beyond Individual Input for Deep Anomaly Detection on Tabular Data. ICML 2024.\n\u2022 What is the time cost and computational cost of different models\uff1f"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores the use of normalizing flow for tabular anomaly detection, and the experiments appear to demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1\u3001The paper offers a theoretical analysis of the proposed NF-SLT.\n\n2\u3001Extensive experiments are conducted to demonstrate the effectiveness of NF-SLT."
            },
            "weaknesses": {
                "value": "1\u3001The authors claim that normalizing flow fails to perform anomaly detection for images. However, many studies in unsupervised anomaly detection achieve state-of-the-art results in detecting visual anomalies, such as Fastflow [1] and Cflow-ad [2].\n\n2\u3001The performance comparisons are limited. NF-SLT uses a relatively strong normalizing flow as the backbone. However, these baselines are lighter and are not SOTAs in this field. The comparisons are not convincing. More importantly, there are SOTA normalizing flow-based anomaly detection methods, such as GANF [3] and MTGFlow [4], which should be included to make a meaningful comparison.\n\n3\u3001Could you provide visualizations to demonstrate that the log-likelihood can be regarded as an anomaly indicator? Relying solely on these quantitative results fails to present an intuitive advantage over NF-SLT.\n\n[1] Yu1, J., Zheng, Y., Wang, X., Li, W., Wu, Y., Zhao, R., & Wu, L. (2021). FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows. ArXiv, abs/2111.07677.\n\n[2] Gudovskiy, D.A., Ishizaka, S., & Kozuka, K. (2021). CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows. 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 1819-1828.\n\n[3] Dai, E., & Chen, J. (2022). Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series. ArXiv, abs/2202.07857.\n\n[4] Zhou, Q., Chen, J., Liu, H., He, S., & Meng, W. (2022). Detecting Multivariate Time Series Anomalies with Zero Known Label. AAAI Conference on Artificial Intelligence."
            },
            "questions": {
                "value": "See weaknesses. I will consider improving my rating if the authors could address my concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to explain why AD using generative models works tabular data but fails on images. It first performs an extensive and careful comparison between methods showing that differently from some previous reports, kNN performs the best on tabular AD and inverse flows second. It then explain the apparent divergence from the image AD results using euclidean norm concentration arguments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The reviewer believes the main contribution in this paper is the careful and fair comparison of tabular AD approaches, The field has been plagued by unfair evaluation making the true SoTA unclear. Showing that simple kNN remains the best method is important. Note that past papers also showed this e.g. [1] but as many methods appeared since that claimed to be better than kNN, it is useful to have an up-to-date evaluation. The reviewer would have preferred this to be the focus of the paper.  \n\n[1] Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection , Gu et al,, NeuIPS'19"
            },
            "weaknesses": {
                "value": "The reviewer believes the premise of this paper is unsound. The claim is that images suffer from the \"counterintuitive phenomenon\" due to high dimension, while tabular data do not due to lower dimension. However, the story is more nuanced. The generative models here were estimated on image pixels. The story however would be completely different if the images were first pre-processed by a pretrained deep feature extractor (as is standard in image AD). In that case, kNN based methods achieve SoTA performance (e.g., PANDA or PatchCore) and inverse flow methods on the deep features perform comparably. This is despite the fact that the feature dimension is very large. \n\nThe reviewer believes that current empirical evidence points to a different direction from the one proposed here. The main issue with kNN / likelihood methods is not the dimensionality of the data, but rather the quality of the representation. Tabular datasets typically have human engineered features which are excellent representations. Even simple L2 distance between raw tabular features is often related to semantic difference. Pixels are not semantic image representations. L2 distance between image pixels is not well correlated with semantic distance. Deep pretrained image features are again excellent semantic representations. This explains why kNN (and therefore also likelihood methods which compute the PDF is the representation space) behave the way they do . The result is therefore not particularly surprising, and the provided explanation is probably not the most salient one."
            },
            "questions": {
                "value": "The reviewer provided an alternative explanation for the phenomenon. The rebuttal should challenge this explanation or convince in some other way why the story is dimension and not the quality of representation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper combines existing normalizing flows based methods with a simple likelihood test for anomaly detection in tabular domain. The authors also redefine the counterintuitive phenomenon, which deteriorates the performance of normalizing flows based methods in image domain,  and demonstrate, both theoretically and empirically, why this method succeeds in the tabular domain. To avoid biased and impractical hyper-parameter selection, this paper leverages grid search and adopts the hyperparameter combination with the highest performance for each comparison methods. The experimental results are encouraging compared to baselines on all 47 tabular datasets presented in ADBench. This paper also discusses the impact of the Euclidean norm on the method as the data dimension increases."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper can provide insights into the advancement of normalizing flows methods for anomaly detection, the discussion on the impact of data dimensionality to the simple likelihood tests in tabular data is meaningful, the experimental results are unbiased and promising."
            },
            "weaknesses": {
                "value": "1. The article only discusses the impact of the data dimension on the success of the simple likelihood testing using normalizing flows in the tabular domain. However, the difference between tabular data and image data is not just that the dimensionality is lower. For example, the features of image data are homogeneous, highly correlated, while the features of tabular data are heterogeneous, some features are totally irrelevant. This paper lacks the analysis of the impact of these other differences on the counterintuitive phenomenon. When the feature dimensions are the same, what is the difference between tabular data and image data in terms of counterintuitive phenomenon?\n\n2. The method in this paper is just an application of existing normalizing flow models rather other presenting a new method, which limits the novelty of the paper. Besides, as mentioned in the paper, the experiments are conducted only using relatively simple models, NICE and RealNVP, rather than advanced normalizing flow models, will employing an advanced model further improve the performance? \n\n3. One contribution in this paper is that it conducts fair hyperparameter selection, however, the paper just leverage a simple grid search for each comparison method, exploring the performance and difference of other hyperparameter selection methods could enrich the analysis."
            },
            "questions": {
                "value": "See Above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}