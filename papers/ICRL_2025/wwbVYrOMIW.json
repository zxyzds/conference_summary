{
    "id": "wwbVYrOMIW",
    "title": "POC: Preventing the Over-Collapse of Classes for Class-Incremental Learning",
    "abstract": "Deep neural network-based classification models often suffer from catastrophic forgetting during class-incremental learning (CIL). Previous studies reveal that it results from the overlap between seen and future classes after being mapped by model to its feature space through extracting the features. In this paper, we analyze that this overlap mainly results from the $\\textit{over-collapse}$ of seen classes, where the model tends to map originally separated one seen class and its adjacent regions in input space to be mixed in the feature space, making them indistinguishable. To this end, we propose a two-step framework to $\\textbf{P}$revent the $\\textbf{O}$ver-$\\textbf{C}$ollapse (POC). During training, POC first learns and applies a set of transformations to the training samples of seen classes. Based on our theoretical analysis, the transformation results will locate in the adjacent regions of the seen classes in the input space so that we can let them represent the adjacent regions. Then, the model's optimization objective is modified to additionally classify between the seen classes and the adjacent regions, separating them in model's feature space so that preventing the over-collapse. To retain the model's generalization on the seen classes, a deterministic contrastive loss that makes the separate features of seen classes and adjacent regions close is further introduced. Since POC uses the adjacent regions exclusively for classification, it can be easily adopted by existing CIL methods. Experiments on CIFAR-100 and ImageNet demonstrate that POC effectively increases the last/average incremental accuracy of six SOTA CIL methods by 3.5\\%/3.0\\% on average respectively.",
    "keywords": [
        "Class-Incremental Learning",
        "Over-Collapse",
        "Catastrophic Forgetting"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=wwbVYrOMIW",
    "pdf_link": "https://openreview.net/pdf?id=wwbVYrOMIW",
    "comments": [
        {
            "summary": {
                "value": "the authors propose a two-step framework called Prevent the Over-Collapse (POC) for class incremental learning. During training, POC applies transformations to training samples of seen classes, maintaining their distinction in the feature space. It also introduces an expanded classifier to separate seen classes from adjacent regions. In the testing phase, the expanded classifier is masked, allowing classification of seen classes without extra computational costs. POC incorporates a deterministic contrastive loss to keep adjacent regions close to their original classes, enhancing generalization. Experimental results on CIFAR-100 and ImageNet show that POC improves the last and average incremental accuracy of several state-of-the-art CIL methods by 3.5% and 3.0%, respectively."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-\tThe proposed POC framework effectively prevents the overlap between seen and future classes in the feature space as shown in fig.3. This innovative approach might enhance the model's ability to generalize across tasks.\n-\tThe experimental results show that POC can robustly enhance the performance of various CIL approaches across several approaches.\n-\tThe article provides sufficient evidence for some of its claims in the appendix."
            },
            "weaknesses": {
                "value": "-\tAn important assumption of the POC is that it addresses the issue of over-collapse, which can lead to catastrophic forgetting. However, there is insufficient literature to prove that over-collapse is the cause of catastrophic forgetting. The citations provided in the article, such as Masana et al., 2022 on line 184, do not offer relevant explanations, and the article also does not sufficiently analyze the over-collapse phenomenon as claimed in its contributions. This results in the article appearing to lack a reasonable motivation for its claims.\n-\tThe POC requires inference on multiple augmented images, which may lead to a significant increase in training costs. However, the article does not discuss this issue.\n-\tI\u2019m not certain that the primary reason POC is effective is due to its backbone having seen multiple augmented images. I believe it is necessary to conduct an experiment where all images augmented by learnable augmentations are used as positive samples corresponding to their categories for direct training. I think this approach could also yield some performance improvement, and it might not perform worse than the results shown by POC."
            },
            "questions": {
                "value": "All my concerns are mentioned in the weakness. And I think the experiments in the third line of weakness should be conducted."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the over-collapse phenomenon in class incremental learning (CIL) that makes it difficult to distinguish the seen and unseen classes.\nTo address this issue, the authors suggest distinguishing the seen classes and their transformed versions.\nTo generate samples close yet adequately distant from the original ones, the authors suggest rotation and a learnable affine transformation and theoretically demonstrate the effectiveness of these transformations.\nThe authors argue that the proposed method can prevent over-collapse phenomenon, thereby enhancing generalization ability to unseen classes."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The most intriguing aspect is generating samples that are close yet distinct from the original ones.\nTo prevent the rotated samples from being overly similar to the original ones, the authors propose learning a set of affine transformations, ensuring the generated samples are adequately adjacent but maintain a sufficient distance from the originals.\nThe theoretical analysis further supports the effectiveness of the proposed transformation for generating adjacent samples."
            },
            "weaknesses": {
                "value": "It seems that there are no significant issues on the paper.\nOne minor concern may be the generalization ability of the proposed method.\nCan the proposed method be applied to other tasks over the image classification task?\nThe reviewer thinks it is somewhat difficult to directly generalize the proposed method to other tasks, which may limit its value."
            },
            "questions": {
                "value": "Please refer to the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to improve the generalization on seen classes in CIL by preventing the over-collapse (POC) of seen classes. To this end, the authors generate samples in adjacent regions by some learnable transformations and making the classification model predict them with a modified loss, which is much similar to IL2A where it predicts auxiliary classes generated by mixup. The authors use theories in OOD detection to prove such transformations generate samples in adjacent regions. Furthermore, the author claims the generated samples in adjacent regions are prone to be far away from the seen class, thus introduces the deterministic contrastive loss (DCL) to make them closer to the seen class. Finally, the authors perform performance comparisons with SOTAs and similar works, verify the effectiveness of DCL and POC with ablation study on them and plotting ICD and ICG metrics during the incremental training."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The reported performance of the method out-performs similar works like IL2A.\n- The proposed method is compatible with various methods in CIL."
            },
            "weaknesses": {
                "value": "- The reason why over-collapse leads to forgetting is not clear enough. It seems to assume the samples in the future class are in the adjacent area of the previous samples.\n- The DCL is somewhat not well-motivated, there is no empirical or theoretical evidence provided about the _far away_ projection. Instead, the authors state that the distance of the transformed sample is upper-bounded in Proposition 3.2."
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}