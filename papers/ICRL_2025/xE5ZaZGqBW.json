{
    "id": "xE5ZaZGqBW",
    "title": "Hypercone Assisted Contour Generation for Out-of-Distribution Detection",
    "abstract": "Recent advances in the field of out-of-distribution (OOD) detection have placed great emphasis on learning better representations suited to this task. While there have been distance-based approaches, distributional awareness has seldom been exploited for better performance. We present HACk-OOD, a novel OOD detection method that makes no distributional assumption about the data, but automatically adapts to its distribution. Specifically, HACk-OOD constructs a set of hypercones by maximizing the angular distance to neighbors in a given data-point's vicinity, to approximate the contour within which in-distribution (ID) data-points lie. Experimental results show state-of-the-art FPR@95 and AUROC performance on Near-OOD detection and on Far-OOD detection on the challenging CIFAR-100 benchmark without explicitly training for OOD performance.",
    "keywords": [
        "OOD detection",
        "Out-of-distribution detection",
        "Computer Vision",
        "Deep Learning",
        "Representation Learning"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "HACk-OOD is a novel, training-agnostic OOD detection method that constructs hypercones in the feature space to approximate in-distribution contours of classes, without making distributional assumptions or explicitly training for OOD detection.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=xE5ZaZGqBW",
    "pdf_link": "https://openreview.net/pdf?id=xE5ZaZGqBW",
    "comments": [
        {
            "summary": {
                "value": "HACk-OOD is a post-training OOD detection method using hypercone projections to construct class-specific contours in embedding space. The approach achieves SOTA performance on CIFAR-100 and improves with larger networks. Including Imagenet experiments could further demonstrate scalability on large datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "HACk-OOD introduces a unique method using hypercone projections to delineate class contours, avoiding traditional Gaussian distribution assumptions and offering greater flexibility in complex feature spaces. The method achieves competitive, often superior, results on challenging datasets like CIFAR-100, demonstrating strong performance in both near and far OOD detection scenarios."
            },
            "weaknesses": {
                "value": "1. Experiments are limited to CIFAR-based datasets, testing on a large-scale dataset like Imagenet would better validate the method\u2019s scalability. Also evaluating HACk-OOD on the OpenOOD benchmark would provide a clearer comparison to recent methods. I would consider rating this paper higher if Imagenet results were provided.\n\n2. Missing comparisons with some of the latest post-hoc OOD methods, such as ASH and SCALE. Including these would offer a more comprehensive assessment of its relative performance.\n\nDjurisic, Andrija, et al. \"Extremely simple activation shaping for out-of-distribution detection.\" ICLR 2022\nXu, Kai, et al. \"Scaling for training time and post-hoc out-of-distribution detection enhancement.\" ICLR 2023"
            },
            "questions": {
                "value": "See Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a post-training out-of-distribution (OOD) detection method, HAC_k-OOD, which models the training data distribution through a set of hypercones and assesses OOD status based on whether a test sample falls within any hypercone. Specifically, for each class, the method first computes the class centroid and defines an angular boundary using the k-th nearest neighbors for each training point. Additionally, a radial boundary is set based on the mean and variance of the sample norms within the angular boundaries. During inference, a sample is classified as OOD if it lies outside either the angular or radial boundaries. Experiments were conducted using ResNet-18, ResNet-34, and ResNet-50, with both supervised contrastive learning and cross-entropy loss. The method was evaluated on CIFAR-10/100 as the in-distribution dataset and tested on various OOD datasets, covering both near and far OOD scenarios."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The method takes an interesting approach to distance-based OOD detection by relaxing the distributional assumptions and, unlike naive KNN, still leveraging nearby training data statistics to construct class contours. To the best of my knowledge, the use of hypercones for this purpose is novel and appears well-motivated.\n\n2. The authors present their method clearly, making the paper easy to follow and understand.\n\n3. Although the method involves hyperparameter k, the authors provide a practical approach to estimating it without requiring additional OOD data.\n\n4. The experiments investigate various model sizes and training losses, demonstrating their impact on distance-based methods. Overall, the method benefits more from larger models trained with contrastive loss, as these models produce more distinguishable features."
            },
            "weaknesses": {
                "value": "1. The computational complexity is a concern for this method. Since the computation appears to increase with the size of the training dataset, it\u2019s unclear if this approach would be feasible for large-scale, real-world applications. Although the authors state that the method is computationally efficient and support this with inference time per sample, I encourage them to provide a more detailed discussion on this aspect. For instance, what is the time required to construct the hypercones? A comparison of inference times with other methods would also be valuable.\n\n2. How would the method perform on a large-scale, real-world dataset like ImageNet? Many recent OOD detection methods use ImageNet-1k as the in-distribution (ID) dataset. I encourage the authors to consider experiments on this dataset to evaluate the general applicability of the method in more realistic scenarios.\n\n3. Recent work has explored OOD detection using CLIP as a backbone model (eg. [a1]), as CLIP may offer a more robust feature space. It would be interesting to see how this method performs when applied to a CLIP-based model.\n\n4. Could the authors elaborate on why this method outperforms a naive KNN approach? One advantage seems to be that the method leverages the nearest neighbors within the training set (as opposed to KNN\u2019s i.i.d. approach) to construct hypercones, which may capture more robust information about class boundaries. Additionally, an ablation study using either angular or radial boundaries separately for OOD detection could provide valuable insights into the method\u2019s effectiveness and support future research.\n\n5. While the paper is generally well-written, a few sections could be clearer. For example, in lines 80-81, P_in is referenced without being introduced in a previous formula. Additionally, in Section 5.2, only ResNet-34 is mentioned as the backbone model, though ResNet-18 and ResNet-50 are also used.\n\n[a1] Ming, Yifei, et al. \"Delving into out-of-distribution detection with vision-language representations.\" Advances in neural information processing systems 35 (2022)."
            },
            "questions": {
                "value": "Please see the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a post-training method for out-of-distribution (OOD) detection. The method approximates the contour of each class with a set of hypercones and defines per-hypercone decision boundaries. \nMore specifically, the hypercones are drawn as follows: \n1. compute per-class centroids, which will be the apex of the class hypercones \n2. take a class sample and set the hypercone axis to be the vector that points its (penultimate) representation \n3. set the opening angle to be the angle between the hypercone axis and the k-th nearest neighbor from the sample representation\n4. set the decision boundary using the distribution of representations within the hypercone's angular boundary\n\nThe method is an extension of another technique, SSD+, which assumes the decision boundary could be modeled with a unique hypersphere (or multidimensional ellipsoid) per class. It's training does not require OOD data. \n\nExperimentally, the authors follow common practice and evaluate the OOD performance with the CIFAR-100 dataset as an in-distribution dataset and many different datasets as out-of-distribution datasets. Two types of pre-trained classification models are tested: models trained with a softmax cross-entropy loss and with a supervised contrastive loss. \nThe method achieves SOTA results in the supervised contrastive learning setup and is competitive in the cross-entropy setting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow. The authors provide a good summary of the different approaches to OOD, a background section on hypercones, and a clear and precise method description. \n2. Relevance and novelty of the method: the algorithm doesn't require assumptions about the data distribution and can model complex embedding spaces since it draws multiple hypercones per class and since it defines per-hypercone decision boundaries. \n3. The authors discuss some limitations of the method (e.g., it works less well with smaller models )."
            },
            "weaknesses": {
                "value": "1. Limited evaluation: the method is only evaluated on models pre-trained on the *quite simple* CIFAR datasets and not on more complex datasets such as the ImageNet-200 or ImageNet-1k OOD benchmarks."
            },
            "questions": {
                "value": "- (see Weakness 1): how does the method perform on the ImageNet (200 or 1k) OOD benchmarks? Its evaluation on benchmarks beyond *quite simple* datasets (i.e., CIFAR-10/CIFAR-100) would strengthen the claims. \n- What is the intuition behind the use of hypercones? Isn't the embedding space of a class more \"dense\" close to its centroid?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a post-training strategy for Out-Of-Distribution (OOD) detection for image classification. The proposed method assumes no access to the OOD samples and employs a set of hypercones with varying cutoff distances in feature space to define the class boundaries of in-distribution data. The work evaluates this method and a combination with a previous OOD technique on the Far-OOD and near-OOD detection benchmarks, with comparisons to a set of baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper addresses an important problem and proposes a new distance-based model based on hypercones. \n2. The evaluation of the method seems comprehensive and it achieves strong results in some cases."
            },
            "weaknesses": {
                "value": "1. The paper is not clearly motivated. The discussion on training-based and distance-based post-training methods are insufficient. While the introduction section listed many previous methods, it is unclear what OOD modeling challenges this method aims to address, in particular for the distance-based approach.\n2. The assumption of this method is very restrictive. As stated in Line 064, it requires \"that ID and OOD data are separable in the space\", which is unrealistic for real-world data. \n3. The novelty of this method is limited. The proposed hypercone representation is similar to a mixture of Gaussian kernels for the ID data distribution.     \n4. The presentation of this work lacks clarity and the technical details are difficult to follow. Several parts of Sec 4.3 are confusing: 1) Line 260: Why do the hypercone representations rely on the test data feature Z_{test}, which should not be used during model construction? 2) Line 299: How is the score function defined and what threshold is used during the inference (in Sec 4.4)?    \n5. The experimental evaluation is lacking in three aspects: 1) The experimental setup is limited, which only considers three ResNet-based backbones. More modern architectures, such as ViT, should be included to validate its generalization. 2) The ablative study is lacking. What contributions are from the hypercones? What if it is replaced by Gaussians? 3) The performance of the original version HAC_k-OOD is mixed in both Table 1 and 2, and in most of cases, it is worse than the SOTA methods. It is unclear whether the proposed representation is truly effective."
            },
            "questions": {
                "value": "Please address the questions in the weaknesses part as above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}