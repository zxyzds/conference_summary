{
    "id": "zSHoaTNlmA",
    "title": "Segmentation using efficient residual networks with attention-fusion modules",
    "abstract": "Fusing the global and local semantic information in segmentation networks is a challenging task with the problems of computational cost and long-range dependencies to improve state-of-the-art methods. Based on the recent success of transformers and attention mechanisms, this research utilizes an encoder-decoder architecture named SERNet-Former, integrating convolutional neural networks with attention-based algorithms for efficient segmentation. Accordingly, attention-boosting modules are employed together with the conventional residual networks to deal with the computational cost in deriving the feature maps of the global context in the encoder, generating the unique baseline architecture, Efficient-ResNet. The decoder network is developed with additional attention-fusion networks leveraging the semantic information from the global and local contexts. Attention-fusion networks also deploy additional convolution layers in the decoder part and improve the efficiency of the network in the one-to-one conversion of the semantic information. The challenging CamVid and Cityscapes datasets are used to develop and test the network and observe the improvements by the proposed methods applied to the residual networks. Accordingly, SERNet-Former sets state-of-the-art results (84.6 \\% mean IoU) on the CamVid and (87.3 \\% mean IoU) the Cityscapes validation datasets, and challenging results (84.8 \\% mean IoU) on the Cityscapes test dataset. The project repository will be shared with the reader.",
    "keywords": [
        "Segmentation",
        "Attention mechanisms",
        "Efficient residual networks"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "Unique efficient residual network with attention mechanisms and fusion networks are developed to overcome the increasing computational cost of fusing semantic information from global and local contexts of segmentation networks.",
    "creation_date": "2024-09-20",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=zSHoaTNlmA",
    "pdf_link": "https://openreview.net/pdf?id=zSHoaTNlmA",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a transformer with an encoder-decoder structure to fuse the global and local information from the image for semantic segmentation. The proposed method improves the semantic segmentation on multiple datasets, demonstrating its effectiveness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The proposed method improves the segmentation results based on the transformer architecture, which is lightweight."
            },
            "weaknesses": {
                "value": "1. It should be noted that IEEE CVMI has accepted the manuscript \"SERNet-Former: Segmentation by Efficient-ResNet with Attention-Boosting Gates and Attention-Fusion Networks.\" Although CVMI has not yet provided the official version of the accepted paper, the author has provided a GitHub repository, which indicates that CVMI has accepted the paper. Furthermore, the figures and experimental results in the GitHub repository with arXiv and CVPRW versions are the same as those in the paper submitted to ICLR. The author should clarify this.\n\n2. Apart from the above point, I find that this paper's presentation is of low quality. It lacks the motivation to propose a new method of fusing local and global semantics, which has been well-known for improving semantic segmentation performance. I suppose this motivation is presented in the introduction, which is missed in every part of the paper. Though the performances have been compared in the experimental section, I still cannot figure out why the proposed method yields better results. Furthermore, the presentation of the method lacks the necessary information. The critical Figure 2 fails to provide a clear illustration of the method. The relationship between Figure 2 and the equations is also unclear. This fact further disallows the reader to understand the insight behind the method.\n\n3. Though the proposed method improves the segmentation results, it still lags behind other methods on important datasets (see test set on Cityscapes in Tab 4).\n\nBased on the above points, I believe this submission fails to meet the ICLR standard and recommend its rejection."
            },
            "questions": {
                "value": "See the \"Weaknesses\" above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper \"SERNet-Former: Segmentation by Efficient-ResNet with Attention-Boosting Gates and Attention-Fusion Networks\" introduces an innovative segmentation framework that leverages advanced attention mechanisms within a robust network architecture. The authors provide comprehensive experimental results that validate their approach against existing methods, demonstrating its effectiveness across multiple datasets. However, the manuscript could be improved by addressing the limitations of the method, expanding the discussion of the ablation studies, and including a broader range of comparative benchmarks. Overall, this work represents a significant contribution to the field of image segmentation. \n\n**However**, I noticed that this paper has already been accepted by IEEE CVMI 2024, titled \"SERNet-Former: Segmentation by Efficient-ResNet with Attention-Boosting Gates and Attention-Fusion Networks.\" You can view the acceptance list for the conference at https://cvmi2024.iiita.ac.in/AcceptedPapers.php. After comparing the version in the GitHub repository (https://github.com/serdarch/SERNet-Former) with the version submitted by the authors to ICLR, it appears that there are only minimal differences between the two."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- **Innovative Approach**: The paper presents a novel method, SERNet-Former, which combines Efficient-ResNet with attention mechanisms, demonstrating a promising advancement in segmentation tasks.\n- **Comprehensive Experiments**: The authors conduct extensive experiments across various datasets, showcasing the effectiveness of their approach and providing a thorough comparison with existing methods.\n- **Clear Presentation**: The manuscript is well-organized, with a logical flow that makes the methodology and results easy to follow, enhancing the overall readability."
            },
            "weaknesses": {
                "value": "- **Limited Discussion on Limitations**: The paper could benefit from a more in-depth discussion of the limitations of the proposed method, particularly in relation to different types of data or specific segmentation challenges.\n- **Insufficient Detail in Ablation Studies**: While the authors present some ablation studies, additional detail on the impact of each component in the network would strengthen the understanding of their contributions.\n- **Comparative Analysis**: The comparison with state-of-the-art methods could be more robust, particularly by including more recent benchmarks to provide a clearer context for the performance claims."
            },
            "questions": {
                "value": "I noticed that this paper has already been accepted by IEEE CVMI 2024, titled \"SERNet-Former: Segmentation by Efficient-ResNet with Attention-Boosting Gates and Attention-Fusion Networks.\"\n\nAdditionally, I have a question regarding:\n\n1. **What specific metrics were used to evaluate the performance of SERNet-Former compared to existing segmentation methods, and how do these metrics support the claims made by the authors regarding its effectiveness?**\n\n2. **Can the authors provide more details on the design choices behind the attention mechanisms used in SERNet-Former and how they contribute to the model's overall performance in segmentation tasks?**"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "-"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "-"
            },
            "weaknesses": {
                "value": "Considering that this paper has already been accepted by IEEE CVMI, I think it should be rejected."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes AbGs,AfNs to fuse global and local semantic information in segmentation. Attention-fusion networks are desined in the decoder part to improve the efficiency."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.This paper has made useful explorations in the fusion of global and local information, bringing some inspiration to this field.\n2.Experimental results show that this method has some advantages"
            },
            "weaknesses": {
                "value": "1.The writing of this article is poor. Many sentences are not clear and not easy to understand. Some sentences are too long and difficult to understand. e.g. line 125: The multi-scale problem in computer vision can be described as the discrepancy in integrating the different sizes of spatial and channel-based semantic information of an object acquired from the global and local contexts of segmentation networks.\nline 203\uff1aIt is aimed at developing an encoder-decoder architecture with additional attention mechanisms to get efficient segmentation networks fusing semantic information from different contexts by regarding the multi-scale problem.\n\n2.The method in this article lacks insight, and many designs are tricky.  e.g. Why are there two consecutive layers (AbM4, AbM5) in H/8 and W/8 resolutions? For another question, please refer to Question 2.\n\n3.The experimental analysis is not enough, and the ablation experiment is not very sufficient. More details can refer to Question 4.\n\n4.This paper seems to have multiple submissions\uff0cwhich was accepted by IEEE CVMI previously."
            },
            "questions": {
                "value": "1. Why is the sigmoid function used as the activation function in the AbG module? Will it aggravate the gradient vanishing problem during training? Have you tried other activation functions?\n2. Dilation-based convolution is used in DbN module, why not use dilation convolution in encoder and decoder part?\n3. During upsampling, the image size changes from H/4, W/4 to H, W. Why not use progressive upsampling?\n4. From Table 3 and Table 4, your performances are not as good as InternImage and VitAdapter-L(test mIoU). What are the parameters and inference speed(e.g millisecond) of these two methods? How do they compare to yours?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}