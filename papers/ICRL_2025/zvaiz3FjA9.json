{
    "id": "zvaiz3FjA9",
    "title": "Designing Concise ConvNets with Columnar Stages",
    "abstract": "In the era of vision Transformers, the recent success of VanillaNet shows the huge\npotential of simple and concise convolutional neural networks (ConvNets). Where\nsuch models mainly focus on runtime, it is also crucial to simultaneously focus\non other aspects, e.g., FLOPs, parameters, etc, to strengthen their utility further.\nTo this end, we introduce a refreshing ConvNet macro design called Columnar\nStage Network (CoSNet). CoSNet has a systematically developed simple and\nconcise structure, smaller depth, low parameter count, low FLOPs, and attention-\nless operations, well suited for resource-constrained deployment. The key novelty\nof CoSNet is deploying parallel convolutions with fewer kernels fed by input\nreplication, using columnar stacking of these convolutions, and minimizing the use\nof 1\u00d71 convolution layers. Our comprehensive evaluations show that CoSNet rivals\nmany renowned ConvNets and Transformer designs under resource-constrained\nscenarios. Pretrained models shall be open-sourced.",
    "keywords": [
        "Convolutional Neural Networks",
        "Columnar Stages",
        "Input Replication",
        "Image Classification",
        "Detection"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "A simple and accurate ConvNet backbone for resource constraints scenarios",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=zvaiz3FjA9",
    "pdf_link": "https://openreview.net/pdf?id=zvaiz3FjA9",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces Columnar Stage Network (CoSNet) to deploy parallel conv units with fewer kernels, and reduce the 1x1 conv layers. To optimize the model efficiency, this paper follows the design objectives to reduce depth and branching, as well as to control the parameter growth, maintain computation intensity and uniform primitive operations."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper revisits some of the fundamental design ideas in conv net and proposed some interesting ideas. \n1. Shallow-deep projection is quite interesting. This inherits ideas from ResNet and expands to deep connection. \n2. It achieves competitive performances (accuracy and latency) with reduced network depth and parameters counts. \n3. It also introduces a pairwise frequent fusion (PFF) to fuse information across different columns."
            },
            "weaknesses": {
                "value": "Please refer to the questions section, where some clarity or more experiments would be great."
            },
            "questions": {
                "value": "1. what's the difference between group conv and parallel columnar conv?\n2. How much of efficiency and accuracy gain can be translated downstream to segmentation and detection work?\n3. What's the memory overhead with the input replication?\n4. How much depth is required for deep projection to have significant impact?\n5. I see some similarity between PFF and self-attention modules in transformer. What's the performance like if using some fusing all columns simultaneously?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a simple and concise structure called CoSNet, which has smaller depth, low parameter count, low FLOPs, and attention less operations, well suited for resource-constrained deploy. The work presents a range of experiments that sufficiently support its claims. It is very  interesting for readers.\n\nOverall, it is a good read. The manuscript might get better if a few suggestions (given below) are incorporated."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The writing is easy to read and clearly explains everything in the paper.\n2. The experimental result is good compared to the previous works. Empirically, the method seems to offer strong accuracy, compared to existing methods with similar architectures."
            },
            "weaknesses": {
                "value": "1. Some details are missing.  For example, how is the value of parallel convolution M determined? I think that different values of M will affect the performance. Please explain this details in the text. Other minor issues, such as Section 3.4 is missing in Figure 2 (c), and you should add it.\n2. How is the design like \"input replication\" to improving performance for example? Authors need to give some details in the manuscript.\n3. The related work is comprehensive. However, the authors only highlight the salient features of the previous works that they apply in their network. The manuscript can benefit from discussing shortcomings of the existing methods as research gaps in the section \"Related Work\"."
            },
            "questions": {
                "value": "1. Some details are missing.  For example, how is the value of parallel convolution M determined? I think that different values of M will affect the performance. Please explain this details in the text. Other minor issues, such as Section 3.4 is missing in Figure 2 (c), and you should add it.\n2. How is the design like \"input replication\" to improving performance for example? Authors need to give some details in the manuscript.\n3. The related work is comprehensive. However, the authors only highlight the salient features of the previous works that they apply in their network. The manuscript can benefit from discussing shortcomings of the existing methods as research gaps in the section \"Related Work\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a refreshing ConvNet macro design called Columnar Stage Network (CoSNet) with smaller depth, low parameter count, low FLOPs, and attention-less operations. \nIts comprehensive evaluations show that CoSNet rivals many renowned ConvNets and Transformer designs under resource-constrained scenarios."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The motivation is reasonable. \n2. The result is comparable with the state-of-the-art.\n3. The paper is easy to understand."
            },
            "weaknesses": {
                "value": "1. Typo: VanillaNet is published in NeurIPS 2023, instead of 2024.\n2. Lack of some new comparison methods, all models were published in 2023 and even earlier. \n   The author should provide more comparisons like InceptionNeXt[1] and UniRepLKNet [2]. \n3. The Top-1 accuracy of EfficientNet-B0 is 76.3 [3] or 77.1 [4], but the author gives a much poorer result of 75.1. \n   Similar problems also happen on ConvNeXt-T (82.1 in [5] but 81.8 in this paper) and EfficientViT-M5 (77.1 in [6] but 76.8 in this paper, and 522M FLOPs in [6] and 600M in this paper). \n\n\n[1] InceptionNeXt: When Inception Meets ConvNeXt. CVPR 2024\n[2] UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video, Point Cloud, Time-Series and Image Recognition. CVPR 2024\n[3] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019\n[4] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv 2019\n[5] A ConvNet for the 2020s. CVPR 2022\n[6] EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention. CVPR 2023"
            },
            "questions": {
                "value": "As listed in Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}