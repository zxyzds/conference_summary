{
    "id": "V9UsZBbTvZ",
    "title": "Masked Mamba: An Efficient Self-Supervised Framework for Pathological Image Classification",
    "abstract": "Pathological image classification is one of the challenging tasks in the field of pathological imaging. The scarcity of high-quality annotated images, the high degree of similarity among pathological samples, the heavy reliance on specific regional areas, and the variability in stained sections all serve as tests of the performance of classifiers. Recently, the Mamba-based model has garnered unprecedented attention and has achieved exceptional performance across various tasks. However, employing visual Mamba in pathological classification does not address the aforementioned challenges. Therefore, in this work, we propose a novel architecture named Masked Mamba, which exhibits significant advantages in terms of low-cost inference and robust classification performance. It is based on two core designs. First, we developed a convolution-based Patch Ghosting aimed at enhancing the classification network's acquisition of specific local area features and its capability to capture multi-scale features by introducing residual connections of similar feature maps. Furthermore, we investigated the integration of Masked Autoencoders (MAE) and State Space Modules (SSM) to further emphasize local features in images and extract robust feature representations from varying staining and slicing conditions, compensating for the lack of high-quality annotated images. We validated our algorithm's performance using four publicly available pathological image datasets. The experimental results indicate that we achieved State-of-the-Art outcomes across these datasets.",
    "keywords": [
        "Pathological image classification",
        "Mamba model",
        "Self-supervised learning"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=V9UsZBbTvZ",
    "pdf_link": "https://openreview.net/pdf?id=V9UsZBbTvZ",
    "comments": [
        {
            "summary": {
                "value": "The authors have built an image encoder self-supervised learning training tech for histopathological patches from whole slide images.  The technique uses principles of masked image encodinf (i.e. masked autoencoder) and principle for training recurrent neural networks (i.e. mamba) to build masked mamba.  The authors also built a novel model for subpatch merging called patch ghosting that is incorporated in the the masked mamba training archetecture.  The authors benchmark their technique on several patch level classfication tasks against standard architectures including MAE with favorable performance.  The authors also show that within their architecture patched ghosting outperforms ViT and Swin transformer."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The concept is novel.  We are interested in any and all SSL techniques that improve upon others for feature extraction of downstream tasks. \n\nThe model does show modest improvement on chosen benchmarks relative to MAE. \n\nThe masked mamba approach, relative to ViT and Swin Transformer is also a novel approach that could be explored in more detail."
            },
            "weaknesses": {
                "value": "I believe that a some portions  of the text (not the entire paper) was written with an LLM.  It makes the paper read a little hyperbolic with unneeded adjectives and superlatives.  A sentence like \"... manifested the most exemplary classification proficiency.\" is not likely something someone would write.  Although I cannot certain. \n\nOur experience is that masking strategies have yielded poor results for feature extraction for downstream tasks.  Not benchmarking with more successful techniques like DINO doesn't make sense to me. If authors can show performance relative to DINO that would greatly strengthen paper. \n\nGenerally speaking feature extraction encoders are most useful for allowing whole slide image classification tasks.  Any experiments showing performance on a useful whole slide image task would enhance this work."
            },
            "questions": {
                "value": "Given that the model is not segmenting cells, how can you claim \"Therefore, our Patch Ghosting generates feature maps that encourage the model to capture diverse feature representations of similar cells.\" I don't see experiments that support such a claim."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors proposed a new, self-supervised framework designed to improve the classification of pathological images. The framework includes a unique Patch Ghosting module that captures local image features effectively, and a MixedMamba Block to enhance the model's understanding of global and long-range dependencies. This proposed design helps overcome issues related to limited high-quality annotated data and variability in sample staining."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors proposed a newer feature representation learning method using Mamba."
            },
            "weaknesses": {
                "value": "1.\tThe quality of the paper is poor. The equations do not aid the audience in understanding the work and lack significant details.\n2.\tThe title claims that the method is unsupervised. However, training the classification head still requires labels, making the claim of unsupervised classification inaccurate. The Mamba-based unsupervised autoencoder only extracts feature embeddings. Therefore, the work should be described as unsupervised feature representation learning with a supervised classification method."
            },
            "questions": {
                "value": "1. In line 161, \u201cThe 1 is transformed\u2026,\u201d what does '1' refer to?\n2. In equation 1, what do A, B, and C represent? The authors only provided the dimensions of these matrices but did not explain their significance.\n3. The proposed model's accuracy and F1 scores are exceptionally high for the LaC dataset compared to other models. The LaC dataset features are known to be extremely difficult to distinguish. Please address how the proposed method effectively learned the embedding space and extracted features that can be utilized efficiently."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a self supervised model for pathology image tasks that is based on the Mamba model and Masked auto encoder. The propsoed method modifies the convolution operation in Mamba and the patch merging procedure. Additionally it is trained with 75% masked input and learns to reconstruct the input images. The model is evaluated on 4 pathology datasets on image classification tasks and shows improved performance compared to various baselines."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper proposes modifications to the Mamba model to make it more suitable for pathology image analysis. \n- The experimental results show improved performance compared to various baselines.\n- The proposed method tries to take advantage of the feature robustness provided by Masked auto encoders to enhance the training of Mamba model."
            },
            "weaknesses": {
                "value": "- Using SSM is listed as a contribution even though it is already an integral part of the Mamba model adapted in the paper.\n\n- Also from the contributions: \"By leveraging a blend of deep separable and regular convolutions as alternatives to traditional causal convolutions, our\napproach reinvents the extraction and sequentialization of spatial features,\". This is an over statement. A combination of separable and regular convolutions have been used in previous models, Inception to name one.\n\n- The intuition behind the patch ghosting operation is not clear. I'm not sure where the name comes from and why it is better than other patch merging operations. Even the ablation studies don't show significant improvement in 3 out of 4 tasks.\n\n- The model proposed even though sounds general is only evaluated and targeted towards pathology image classification tasks. No segmentation of WSI classification, and no other types of medical or natural image datasets.\n\n- Datasets description is lacking:\n\t- The reference for the dataset TCGA COAD: Couture (2022) is a review paper and not a dataset paper.\n\t- There is no mention of the datasets tasks, their labels, and class-wise statistics.\n\t- It is not clear whether there is a data split that is published with the datasets or the authors split the data.\n\t- If the split was done by the authors, there is no mention of how the splitting performed other than the ratio and there no cross validation evaluation.\n\t- It is mentioned that the patches are resized to 224 by 224 but the original magnification of the datasets is not mentioned.\n\n- The following statement needs clarification: \"the resolution in pathological images is often influenced by staining and sectioning\"\n\n- The evaluation does not include more current models that have shown good performance on pathology images, such as pathology foundational models, CTransPath, PLIP,\n\n- The improvement in performance is mostly fractional. It is not clear how signficant are the results.\n\n- In Equation 6, the second line, it is not clear what double arrows mean.\n\n- In line 288, SSD was not mentioned before.\n\n- Typo: line 161: The 1 is transformed into a discrete function\n- Typo: eq 11: incorrect sign (1+yn)"
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes Masked Mamba, an efficient model for pathological image classification. To adapt Mamba for pathological images, it introduce a patch ghosting module to capture multi-scale features and employ masked autoencoders to extract robust feature representations. Experimental results demonstrate that Masked Mamba achieves state-of-the-art performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe proposed patch ghosting module effectively enhances locality with multi-scale information, making it highly practical.\n2.\tExtending Mamba from 1D sequence modeling to 2D image modeling is a valuable and well-motivated approach."
            },
            "weaknesses": {
                "value": "1.\tThe combination of Vision-Mamba and masked autoencoders shows limited novelty, as neither component is original to the authors.\n2.\tThe patch ghosting module should be compared to the commonly used Local Perception Unit described in [1].\n3.\tAlthough the paper claims that Masked Mamba is efficient, it lacks a table comparing parameters or FLOPs to substantiate this claim.\n4.\tThis paper resizes all pathological images to 224\u00d7224, which fails to convincingly demonstrate that Mamba is applicable to high-resolution pathological images.\n5.\tThe writing and expression could be improved, as the contributions in the abstract and introduction are inconsistent. \n[1] Guo J, Han K, Wu H, et al. Cmt: Convolutional neural networks meet vision transformers[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 12175-12185."
            },
            "questions": {
                "value": "No question"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}