{
    "id": "LRSspInlN5",
    "title": "Towards Black-Box Membership Inference Attack for Diffusion Models",
    "abstract": "Given the rising popularity of AI-generated art and the associated copyright con-\ncerns, identifying whether an artwork was used to train a diffusion model is an\nimportant research topic. The work approaches this problem from the membership\ninference attack (MIA) perspective. We first identify the limitation of applying\nexisting MIA methods for proprietary diffusion models: the required access of\ninternal U-nets. To address the above problem, we introduce a novel member-\nship inference attack method that uses only the image-to-image variation API and\noperates without access to the model\u2019s internal U-net. We validate our method\nusing DDIM and Stable Diffusion setups and further extend both our approach and\nexisting algorithms to the Diffusion Transformer architecture. Our experimental\nresults consistently outperform previous methods.",
    "keywords": [
        "diffusion model",
        "membership inference attack"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "A Black-Box Membership Inference Attack Algorithm for Diffusion Models",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=LRSspInlN5",
    "pdf_link": "https://openreview.net/pdf?id=LRSspInlN5",
    "comments": [
        {
            "summary": {
                "value": "To provide protection for the artworks and detect misuse of data, this paper proposes a black-box membership inference attack for diffusion models used in image generation. It first gives a brief introduction to popular diffusion models. Then it introduces the black-box MIA method based on the variation API. The core idea of the method is based on the hypothesis that images used in the training set typically result in smaller reconstruction errors compared to images not in the training set. Experiments are conducted on several datasets, followed by further ablation studies and an application in a real-world setting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper introduces a novel black-box MIA method that merely requires access to variation API, which makes it more practical and easy to perform.\n\n2. The core idea of the proposed method is intuitive and effective, as demonstrated through both theoretical and experimental results.\n\n3. The experiments are comprehensive. The proposed method is applied to three diffusion models and experiments are conducted on multiple datasets. Also, further ablation study for several key hyper-parameters and real application to DALL-E\u2019s API are conducted."
            },
            "weaknesses": {
                "value": "1. The written of this paper can be further improved. The motivation discussed in Introduction is not solid enough in my opinion.\n\n2. Although many experiments are conducted, the analysis to the results is insufficient. For example, in Table 1, the TP value of REDOFFUSE on CIFAR-10 is much lower than others, while no analysis is provided. Also, there is a lack of analysis on why longer diffusion steps, an important factor affecting performance, seriously degrade the results. Potential solutions for this issue should also be discussed.\n\n3. More cases should be provided to analyze the differences between member and non-member samples. But there is only one case in Sec.6."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel membership inference attack method that uses only the image-to-image variation API and\noperates without access to the underlying model. The experimental results suggest that the model offers a significant boost over prior works."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Clear and intuitive method. As someone who does not directly work on membership inference problems, the proposed methodology makes a lot of sense. I am not able to judge if prior works have proposed a similar idea before.\n- The paper provides a good theoretical analysis of the effectiveness of the proposed method.\n- The performance boost over prior works seems to be quite significant."
            },
            "weaknesses": {
                "value": "- The paper should better discuss the connections between the proposed idea and prior works. For example, have relevant ideas been proposed in other types of membership inference attack methods?\n- The abstract is too brief. The paper could benefit from elaborating the abstract with more insights of the proposed method and the key experimental results."
            },
            "questions": {
                "value": "- Since the proposed idea is quite intuitive, have relevant ideas been proposed in other types of membership inference attack methods?\n- Table 4 is vague, how to interpret the L1 and L2 distance as membership inference accuracy? \n- In general, is there a way to provide any confidence to the membership inference results? After all, any mistake could lead to wrong accuse for the diffusion API."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The research will lead to claims regarding commercial image generation APIs (such as DALL-E 2 in this paper) has used copyrighted data. Since such membership inference results are uncertain, that may lead to controversies in the general public."
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a new membership inference attack method for diffusion models. Unlike previous approaches that require direct access to the U-Net component within the diffusion model, this method only needs access to the model\u2019s variation API. Extensive experiments demonstrate the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Strength:\n1. The paper is well written and easy to follow.\n\n2. The paper considers a broad range of model types, including DDIM, Stable Diffusion, and Diffusion Transformers and the proposed method performs well across different models.\n\n3. The paper provides theoretical justification for the proposed method."
            },
            "weaknesses": {
                "value": "1. **Practicality of the Scenario**: The paper assumes that the variation API allows users to conduct denoising by querying the model with noisy images and receiving denoised outputs. However, in most real-world APIs for diffusion models (e.g., Stable Diffusion 3 API [1]), users typically only have access to final generated images and cannot query intermediate denoising stages. Therefore, while the proposed attack method does not require model parameter access, it may not be feasible for API-only models. If there are any API-only models with accessible variation APIs, it would be helpful if the authors could provide references to these in the rebuttal.\n\n2. **Lack of a Comparison of Computational Requirements**: As mentioned in Weakness 1, although the paper suggests that the method can operate in a black-box setting, its reliance on denoising queries rather than direct image generation could limit its applicability similarly to \u201cwhite-box\u201d approaches. Therefore, it is reasonable and necessary to have more comparison, particularly of computational resource requirements, because it seems that the proposed method may require more computational resources compared with the baselines.\n\n3. **Clarity of Algorithm Explanation**: The intuition behind the proposed algorithm in Section 4.2 is not clear enough. The statement, \u201cIf the noise prediction from the neural network exhibited high bias, the network could adjust to fit the bias term, further reducing the training loss,\u201d is ambiguous. What specifically is meant by \u201cbias\u201d here, and why does this lead to the condition $ \\nabla_\\theta L(\\theta) = 0$ for a well-trained model? While the method itself is intuitive, a more thorough explanation in this section would improve clarity.\n\n[1] Stability AI. (2024). Stable Diffusion 3 API. Stability AI. Available from https://stability.ai/news/stable-diffusion-3-api"
            },
            "questions": {
                "value": "1. Can the proposed method further generalize to fine-tuning of diffusion models?\n\n2. Although the DDIM model is widely used and much more effective than DDPM, can you still provide some results regarding the performance in DDPM?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This article explores the limitations of SOTA methods in addressing the significant problem of identifying whether an artwork has been used to train a diffusion model, i.e., the required access of internal U-nets. To this end, this paper proposes a new membership inference attack method that is based on an image-to-image transformation API without accessing to the model's internal U-net. The experimental results reflect the effectiveness of this method to some extent."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "-This article aims to identify whether an artwork was used to train a diffusion model without accessing to the model's internal U-net, which is an Interesting and relevant topic that fits within the scope of the conference.\n- Novelty. The article proposes a novel membership inference attack method based on an image-to-image transformation API.\n- The author(s) performed several experiments, and try to validate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "- A certain part of experimental results reveal that the proposed method can only achieve very limited improvements over the existing SOTA methods. For example, as shown in Table 1, the proposed method only improves by about 1-3% on most metrics, and even performs worse than the SOTA method PIAN on the TP metric for CIFAR10. Unfortunately, the authors did not discuss or explain this in the paper. Therefore, the effectiveness of the proposed method is questionable.\n-The organization of this paper lacks clarity. The author does not clarify why it is difficult to implement MIA without access to the internal U-net, what challenges will be encountered, and how the author effectively addresses these challenges. Without this crucial information, it is difficult to evaluate the significance of the authors\u2019 work.\n- The organization of this paper is poor. In the ablation experiments, the author attempts to test the impact of experimental parameters on the robustness of the algorithm; however, the evaluation metric is one-sided (i.e., only AUC). Hence, the experiment results are therefore difficult to be convincing. While we note that the author seems to provide more contents in the appendix, but these contents exceed the page limits of the paper and should not be considered.\n- The application experiments may have biases, as the author only conducts the evaluations on a single model (DALL-E) and relies on a small dataset (i.e., only 30 famous paintings and 30 generated paintings). Hence, the experiment results are therefore difficult to be convincing. Without comprehensive experiments, the effectiveness of the proposed methods cannot be validly verified.\n\nThe paper requires an in-depth editorial review. The authors are recommended to examine structure, argumentation, and language clarity to ensure the paper meets high-quality standards. For example, the equation numbering in the paper is chaotic, and the format of Algorithm 1 lacks indentation"
            },
            "questions": {
                "value": "-Could authors provide more detailed discussion or explanation on the experiemnt results precented in Table 1?\n-Could authors clarify the challenges that will be encountered while implementing MIA without accessing to the internal U-net, as well as how the author effectively addresses these challenges?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}