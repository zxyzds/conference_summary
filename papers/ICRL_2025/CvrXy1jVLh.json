{
    "id": "CvrXy1jVLh",
    "title": "Neural Architecture Search by Learning a Hierarchical Search Space",
    "abstract": "Monte Carlo Tree Search (MCTS) is a powerful tool for many non-differentiable search related problems such as adversarial games. However, the performance of such approach highly depends on the order of the nodes that are considered at each branching of the tree. If the first branches are not discriminative enough, i.e. they cannot distinguish between promising and deceiving configurations for the final task, the efficiency of the search is exponentially reduced. While in some cases the order of the branching is given as part of the problem (e.g. in chess the sequential order of the moves is defined by the game), in others, such as Neural Architecture Search (NAS), the visiting order of the tree is not important, and only the final architecture matters. In this paper, we study and analyze several sampling methods and branching alternatives for MCTS and propose to learn the branching by hierarchical clustering of architectures based on their similarity. The similarity is measured by the pairwise distance of output vectors of architectures. Experimental results on two challenging benchmarks on CIFAR10 and ImageNet show that MCTS, if provided with a good branching hierarchy, can yield promising solutions more efficiently than other approaches for NAS problems.",
    "keywords": [
        "Neural Architecture Search",
        "Monte-Carlo Tree Search",
        "Hierarchical Search Space",
        "Hierarchical Clustering"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "We propose a new method to learn hierarchical structure of NAS space for more efficient Monte-Carlo Tree Search method.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CvrXy1jVLh",
    "pdf_link": "https://openreview.net/pdf?id=CvrXy1jVLh",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a method for supernet sampling for neural architecture search using Monte-Carlo Tree Search (MCTS). After an initial phase of supernet training, the method uses similarity distances between architecture outputs and hierarchical clustering to build a search tree, then continue the supernet training by sampling from this tree using MCTS."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-The paper is overall well written.\n-The methodology is well-explained and the contributions are clearly defined, the paper is well-placed in the literature.\n-While not theoretically justified, the idea of learning the Monte-Carlo tree is promising.\n-The experimental results are convincing on the ImageNet dataset."
            },
            "weaknesses": {
                "value": "-The method still requires initial supernet training using uniform sampling before being able to build the tree, which is known to be computationally heavy.\n-The overall contribution seems incremental, as it is mainly a new way to construct a Monte-Carlo tree for supernet sampling.\n-For the experiment on the pooling dataset, the authors explain that this extremely small search space of 36 architectures is challenging because the initial supernet training shares weights between architectures with different pooling configurations. Given that the proposed method discriminates architectures by comparing the outputs after supernet pre-training, I wonder how the method is able to find a more efficient representation of the tree if the weights themselves are not optimal. Furthermore, the classical sampling methods (uniform, Boltzmann\u2026) are unable to find the best architecture out of 36? How many samples are performed? The results, while in line with the results of [1], seem surprising and the paper could benefit from a more thorough explanation.\n-There are several typos and the writing is overall unclear in Section 5.1.\n-Is the Boltzmann sampling over UCT in Section 4.2 necessary? The UCT formula already offers a trade-off between exploration and exploitation. If it is necessary, then an ablation study could be useful.\n-The following claim : \u201cDifferent from other works such as Wang et al. (2021a) and Zhao et al. (2021b) that use the model accuracy directly for the tree design, the output vector provides more information for clustering architectures\u201d seems unsupported.\n-Building the search tree requires building a hierarchical clustering. As the authors use the pairwise distance matrix of all architectures in the search space over a mini-batch, the complexity of building this hierarchical clustering is O(n^2) complexity. For large search spaces, this could be very inefficient. A comparative complexity analysis of the proposed method would be welcome.\n\n[1] : Javan et al., Balanced Mixture of SuperNets for Learning the CNN Pooling Architecture, 2023"
            },
            "questions": {
                "value": "The paper proposes an interesting idea, is mainly well-written and shows some good results on benchmark datasets. As written in the weaknesses section, there are several avenues for clarification and improvements on the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper challenges the commonly assumed node independence in Neural Architecture Search (NAS), which may limit both efficiency and performance. To address this, the authors propose a Monte Carlo Tree Search (MCTS) method incorporating a learned hierarchical tree structure, built with agglomerative clustering based on model output distances, to improve NAS effectiveness. Experiments are conducted on NAS benchmarks for CIFAR-10 and ImageNet image classification tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The paper introduces an approach by addressing node dependencies to improve NAS efficiency.\n* Leveraging the UCT (Upper Confidence bounds applied to Trees) approach, the authors further utilize a learned tree structure to reduce the reliance on manually crafted search space designs.\n* The paper provides ablation studies to analyze the effects of the proposed method in more depth."
            },
            "weaknesses": {
                "value": "* The abstract may benefit from significant revision. Currently, it primarily highlights MCTS fundamentals and suggests general applicability, but the paper is focused on a NAS-specific task that utilizes MCTS and related techniques to enhance NAS performance. The abstract and introduction appear inconsistent in conveying the core contribution and scope.\n* The rationale behind using model output distances to construct the tree structure and improve NAS is not clearly discussed, and the method itself lacks detail. This part should be the core of the paper, yet there is minimal explanation in the main text.\n* While resource constraints may be a factor, it remains unclear whether the method scales well for large networks, which are particularly relevant in NAS applications. The experiments mainly validate that the learned tree provides slight improvements but do not assess scalability in larger search spaces.\n\nMinor Comments\n* Line 306: check around \"Fig.3.4(a)\""
            },
            "questions": {
                "value": "* How does this method compare with other state-of-the-art NAS techniques, such as those in the Neural Architecture Transfer (NAT) series?\n* What insights or theoretical basis underlie the decision to use model output distances for improving NAS performance? (I already assume this will be addressed in a revision in my score.)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a Neural Architecture Search (NAS) approach that leverages Monte Carlo Tree Search (MCTS) with a learned hierarchical search space. Instead of using a non-optimal, pre-defined hierarchical search order, this paper proposes to learn the branching by hierarchical clustering of architectures based on their similarity measured by the pairwise distance of output of architectures. The experiments on CIFAR10 and ImageNet demonstrate that the proposed approach yields better solutions than previous approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper highlights the shortcomings of the previously used node independence assumption and demonstrates that too restrictive assumptions converge to worse solutions."
            },
            "weaknesses": {
                "value": "The weaknesses of this paper are the limited novelty, results not significant, and the unclear approach.\n\nFirst, for the limited novelty and results not significant, this work improves previous works (Wang et al., 2021a; Zhao et al., 2021b) by replacing the model accuracy with the output vector. While the output vector provides more information for clustering architectures, the novelty is limited. Furthermore, the results only slightly outperform previous works (Su et al., 2021a; You et al. 2020; \u2026), which is insignificant. In addition, making early tree nodes more discriminative is highly relevant to the partitioning or splitting problems in decision tree learning, which has been studied by many in the past (Costa and Pedreira, 2023).\nCosta, V.G., Pedreira, C.E. Recent advances in decision trees: an updated survey. Artif Intell Rev 56, 4765\u20134800 (2023).\n\nSecond, the presentation has a lot of improvements, especially the approach. The proposed method is ambiguous and does not seem like MCTS. MCTS uses UCT to select child modes; however, the proposed method uses Boltzmann sampling with a UCB-like score as the parameter. The authors should justify whether this design follows the UCT foundations of balancing exploration and exploitation. \nMost importantly, using $Acc(a_i)/n_i$ in Eq. 4 is weird. From the definition, the first term in the formula is the average reward (Eq. 1 in Kocsis & Szepesv\u00e1ri, 2006). However, Eq. 4 further divides the accuracy by the visit count. Since the accuracy $Acc(a_i)$ is already considered the average reward, it makes no sense. If this is not a typo, the authors should justify the correctness of such a design.\n\nPlease refer below for more questions."
            },
            "questions": {
                "value": "Questions related to the proposed MCTS procedure:\n- As the tree is already constructed, does the algorithm still run selection from a single root node and then expand the known tree structure? Or does it just start sampling from the entirely constructed tree?\n- The typical MCTS involves several phases (e.g., selection, expansion, simulation, backpropagation) per simulation, while it is unclear how the proposed procedures in Algorithm 1 are linked to these phases.\n- It is mentioned that $C(a_i) = Acc(a_i)$ for architecture search in line 340. Does it mean that for supernet training, $C(a_i)$ is set to Eq. 4? It is unclear which parts use $Acc(a_i)$ or Eq. 4 in Algorithm 1.\n- In Algorithm, $P_{train}$, $P_{search}$, and Eq. 5 are not defined.\n- In line 358, it is mentioned that there is a warm-up period for uniform sampling, which is also not included in the typical MCTS routines (Kocsis & Szepesv\u00e1ri, 2006). As MCTS should already be able to balance exploration and exploitation, what is the purpose of adding such a warm-up period?\n- In line 360, why is $C(a_i) < 1$ when nodes are visited?\n\nOther comments related to typos and presentation issues:\n- For Figure 1, it is difficult to understand why the subfigures \"independent\" and \"joint\" are drawn like this.\n- For Figure 2, (b) and (c) use different styles to represent the tree structure, which should be normalized to the same.\n- The section title \"3.4 Sampling with conditional probabilities: Monte Carlo Tree Search\" is confusing as this section does not seem to have any links to (the typical) MCTS.\n- For Table 3, \"the categorical vector representation\" is not included in the discussion.\n- Some terms are not consistently used, e.g., \"Monte Carlo Tree Search\" or \"Monte-Carlo Tree Search\"; \"equation\" or \"eq.\" or \"Eq.\".\n- Several typos, e.g., \"Fig.3.4(a)\", \"and T the temperature term\", \"UTC\".\n- Placing Algorithm 1 in Appendix B lowers the readability. It would be more appropriate to include it in the main text, especially since the authors often refer to it with \"see algorithm 1 in Appendix B\".\n- In Algorithm 1, the equations should be explicitly stated instead of mentioning \"as in Eq. 1.\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}