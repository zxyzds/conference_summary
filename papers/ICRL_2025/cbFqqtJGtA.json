{
    "id": "cbFqqtJGtA",
    "title": "Predicting perturbation targets with causal differential networks",
    "abstract": "Rationally identifying variables responsible for changes to a biological system can enable myriad applications in disease understanding and cell engineering. From a causality perspective, we are given two datasets generated by the same causal model, one observational (control) and one interventional (perturbed). The goal is to isolate the subset of measured variables (e.g. genes) that were the targets of the intervention, i.e. those whose conditional independencies have changed. Knowing the causal graph would limit the search space, allowing us to efficiently pinpoint these variables. However, current algorithms that infer causal graphs in the presence of unknown intervention targets scale poorly to the hundreds or thousands of variables in biological data, as they must jointly search the combinatorial spaces of graphs and consistent intervention targets. In this work, we propose a causality-inspired approach for predicting perturbation targets that decouples the two search steps. First, we use an amortized causal discovery model to separately infer causal graphs from the observational and interventional datasets. Then, we learn to map these paired graphs to the sets of variables that were intervened upon, in a supervised learning framework. This approach consistently outperforms baselines for perturbation modeling on seven single-cell transcriptomics datasets, each with thousands of measured variables. We also demonstrate significant improvements over six causal discovery algorithms in predicting intervention targets across a variety of tractable, synthetic datasets.",
    "keywords": [
        "perturbation experiments",
        "Perturb-seq",
        "transcriptomics",
        "causality"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "We propose a causality-inspired approach for predicting perturbation targets from paired single-cell datasets.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=cbFqqtJGtA",
    "pdf_link": "https://openreview.net/pdf?id=cbFqqtJGtA",
    "comments": [
        {
            "summary": {
                "value": "The authors focus on the problem of Identifying the direct targets of interventions in single cell perturbation data (perturb-seq). The challenge consists in filtering solely the direct targets out of a large number of downstream affected genes. The proposed approach, namely causal differential networks (CDN), first extract the causal networks underlying unperturbed and perturbed data. The networks are then compared with an axial-attention based classifier, so that to identify nodes (genes) that are the direct targets of the intervention. Finally, the authors assess CDN's performances on five perturb-seq datasets, as well as on data from two chemical perturbation studies."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This work addresses an interesting problem, i.e., the identification of direct targets in perturbation experiments.  The manuscript is well structured and written, and an extensive evaluation is presented both on real-world and simulated data."
            },
            "weaknesses": {
                "value": "The novelty of the CDN method is debatable, being the direct combination of two other already published algorithms, i.e., an amortized causal discovery model (Wu et al.,2024) and the axial attention-based classifier (Ho et al., 2020).\n\nInterventions may directly affect genes other than their intended targets (off target effects). However, it is not clear if this issue was taken into consideration during the analysis of real-world data.\n\nExperiments would benefit from a comparison against a trivial classifier, so that to establish a truly minimal baseline."
            },
            "questions": {
                "value": "I would like to ask the authors to address the weaknesses highlighted above:\n- please elaborate further on the novelty of your proposed approach. Did you devise any algorithmic improvement? Or is CDN solely the combination of previously published algorithms?\n- Can you explain whether the current analysis setting would be robust against biases introduced by off-target effects?\n- As reported in Table 6, the direct target of many interventions can be trivially identified as the gene with the largest fold-change in expression. It would be useful to include a trivial classifier in all computational comparisons that simply considers the first n genes with the largest log fold change as direct targets (n is a user-set parameter). Such a classifier would help gauging what additional contribution complex causal approaches provide with respect to a very simplistic solution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors tackle the problem of identifying the intervention target from two (namely, observational and interventional) datasets on e.g., single cells. Supervised causal learning approaches are used to estimate two structures separately for each dataset, and then target is identified by comparing the two estimated structures."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The use of supervised causal discovery in biology field is interesting -- though without solid asymptotic guarantee, supervised method usually impose priors about the domain to the model (which is exactly the case for biology data; while the priors can usually be hard to formalize) to improve the empirical performance.\n\n- The experiments are relatively comprehensive."
            },
            "weaknesses": {
                "value": "1. The motivation is quite unclear, making the contribution also questionable:\n   - To me the problem of identifying intervention target (at least in the presence of latent variables) is too easy and standard: theoretically one variable is intervened iff given any other set of variables, its conditional distribution changes between the two distributions, i.e., there is an direct edge between the domain index variable and it.\n   - The authors claim that existing methods \"scale poorly\", \"must search combinatorial spaces\": I don't quite get that. According to above, one only need to locally learn the Markov boundary of the domain index variable (which is a binary variable 0/1 indicating for each sample which dataset it is from in the pooled dataset). Since we usually assume that the domain index is a root variable (interventions are applied exogenously), such MB consists of the children and spouses, and then some trivial CI tests within the MB can reveal the true children. The MB can be learned very efficiently, using e.g., graph LASSO or its nonlinear variants.\n   - Speaking of efficiency, instead, what the authors proposed (to learn two graphs separately, and then compare the two only for learning the intervention target) seems too overkill.\n   - So could the authors give more explanations for where and how the proposed method is better than existing ones?\n\n2. For a identifiability guarantee, a formal list of assumptions (e.g., which kind of faithfulness is needed) are expected.\n\n3. More details and insights about the usage of supervised model is needed:\n   - The choice of supervised learning isn't merely due to its availability. We choose it because it can leverage abundant data from either real world or synthetics, and hopefully gain some prior knowledge (which can be hard to formalized) about the domain to the model. So, more elaboration on these are expected: how authors simulate the data or collect real-world data for this specific case, for the model's reliability and generalizability?\n   - Also, how are the two graphs learn separately? Are there any constraints to ensure they don't vary too much? How to solve the conflicts between the two learned graph, e.g., some difference that cannot be explained by any intervention?\n   - Please explain why it is necessary to learn two graphs separately. It appears way too overkill.\n\n4. More literature review are expected (especially on the early developments):\n   - For (generally) identifying changes:\n     - Kevin D Hoover. The logic of causal inference: Econometrics and the conditional analysis of causation.\nEconomics & Philosophy, 6(2):207\u2013234, 1990.\n     - Jin Tian and Judea Pearl. Causal discovery from changes. arXiv preprint arXiv:1301.2312, 2001.\n     - Whitney K Newey and James L Powell. Instrumental variable estimation of nonparametric models. Econometrica, 71(5):1565\u20131578, 2003.\n     - Kevin B Korb, Lucas R Hope, Ann E Nicholson, and Karl Axnick. Varieties of causal intervention. In PRICAI 2004: Trends in Artificial Intelligence: 8th Pacific Rim International Conference on Artificial Intelligence, Auckland, New Zealand, August 9-13, 2004. Proceedings 8, pp. 322\u2013331. Springer, 2004.\n      - Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour, and Bernhard Sch\u00f6lkopf. Causal discovery from heterogeneous/nonstationary data. Journal of Machine Learning Research, 21(89):1\u201353, 2020.\n      - Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Causal discovery from soft inter- ventions with unknown targets: Characterization and learning. Advances in Neural Information Processing Systems, 33:9551\u20139561, 2020.\n   - For supervised causal discovery:\n      - Isabelle Guyon. Cause-effect pairs kaggle competition, 2013. URL https://www. kaggle. com/c/cause- effect-pairs, pp. 165, 2013.\n      - Li, Hebi, Qi Xiao, and Jin Tian. \"Supervised whole dag causal discovery.\" arXiv preprint arXiv:2006.04697, 2020.\n      - Dai, Haoyue, et al. \"Ml4c: Seeing causality through latent vicinity.\" Proceedings of the 2023 SIAM International Conference on Data Mining (SDM). Society for Industrial and Applied Mathematics, 2023."
            },
            "questions": {
                "value": "See in \"weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposes a method for predicting the (set of) variables targeted by a perturbation from observations of the variables under control and perturbation conditions. The method, called CDN, first maps both datasets to embeddings that represent the interactions of the NxN variables using a pretrained (frozen) causal discovery transformer model of prior work. Given this input representation, it then trains a shallow transformer-style prediction model in classification of the perturbation targets. The approach is evaluated on several single-cell sequencing screens involving gene and drug perturbations, as well as synthetic datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The problem studied in this work is a relevant problem in the application of machine learning to biology. Contrary to several related works in the causal discovery literature, a strength of this work is its evaluation on several real-world datasets. The empirical results appear good. However, the paper does not compare to any prior specialist methods that are specifically used to predict intervention targets in biology applications, so it is hard to assess how useful the method is to the biology community."
            },
            "weaknesses": {
                "value": "-\tFrom the perspective of the machine learning community, the method contribution is very marginal. The idea consists of extracting edge embeddings from an existing, pre-trained transformer model, and then training a 1-layer prediction layer in (multi-hot) binary classification from these features. This is a straightforward supervised learning task, and nothing about the conception or design of the method is specifically motivated by the (biological) problem at hand. The main text of the paper does not adequately motivate that the specific architecture by Ho et al. (2020) used here, apart from arguing that the function class is sufficiently descriptive (Section 3.4).\n-\tIn particular, framing the algorithm as based on \u201ccausality\u201d is misleading. There is no algorithmic component underlying the approach that is rooted in a mechanistic model, intervention modeling, or a causal graph. The CDN is a simple classifier that maps Xs to Ys (interaction embeddings to whether or not variables were targeted). \n-\tThe formalization of what a \u201ctarget\u201d may not make much sense in the context of biology. In biological (dynamical) systems, changing conditional independencies may not be restricted to the variables targeted by a perturbation. This is because, if the true data-generating process is not a structural causal model, then interventions may not leave other conditional independencies invariant (see e.g. example by [A]). I also don\u2019t agree with the statement that \u201cit is common to assume\u201d that the data was generated by a structural causal model (l. 50). This assumption is rarely made in computational biology and, for example, due to acyclicity assumptions of the causal graph, not commonly regarded a good assumption.\n-\tMotivation: The discussion around forward vs backward prediction in the introduction is confusing as a motivation of the task of perturbation target prediction. These are not the same task, and neither of them are more nor less suited for experimental design. In the \u201cforward\u201d task, we assume we know the targets. Why does that make these classes of \u201cforward\u201d methods worse at larger combinatorial search spaces than when predicting targets in a \u201cbackward\u201d approach? In both cases, we must design new experiments in a combinatorial search space.\n-\tThe \u201cclaims\u201d in Section 3.4. on \u201cTheoretical Context\u201d are misleading/vacuous and do not provide any theoretical insight. It is not informative to say that the function class used to train the classifier (here, axial attention) is \u201cwell-specified\u201d (i.e. complex enough) to map the covariate X to the target Y. A lot of function classes can do this (e.g. an MLP). The question is whether they will do so, for example, in the large sample limit, but no such questions are addressed or studied here.\n\n[A] Alejandro Tejada-Lapuerta, Paul Bertin, Stefan Bauer, Hananeh Aliee, Yoshua Bengio, Fabian J Theis: Causal machine learning for single-cell genomics"
            },
            "questions": {
                "value": "-\tHow confident can we be in the ground-truth \u201ctargets\u201d used for the drug perturbation datasets for the evaluation? \n-\t\u201cTo ensure high quality labels, we filtered perturbations to those that induced over 10 differentially-expressed genes\u201d (l. 294). This does not make the **labels** more high quality. If anything, it ensures that the considered perturbations are strong. But whether or not the target labels are accurate does not depend on the variable selection. Please provide some more information on the quality of the labels.\n-\tIn the description of the correlation metric, what does this sentence mean?: \u201c[\u2026] similarity between the (ground truth) mean log- fold change of the top prediction that was observed as a perturbation, and that of the actual perturbation (given as input)\u201d (l. 335). Specifically, what is the \u201ctop prediction that was observed as a perturbation\u201d?\n-\t\u201cLINEAR and MLP take as input the mean expression of all perturbation targets, plus the top 2000 highly-variable genes\u201d Since the perturbation targets are what need to be predicted, what does it mean here to take as input the mean expression of all targets, which are supposedly unknown? Moreover, what does it mean to \u201ctake as input a gene\u201d? Do you mean the mean expression of that gene again? I don\u2019t think this baseline makes sense, because it is impossible for a method to predict the **interactions/targets** based on the mean of the variables, without any covariance/correlation information. It would make much more sense to perform classification based on either correlation/covariance information of all NxN variables or the pre-trained edge embeddings used by CDN."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a method to predict perturbation targets in biological data using the proposed causal differential networks (CDN). The idea is to infer the causal graph from observational and interventional datasets through a pre-trained model, and then learn the mapping from features to the variables targeted by interventions. The proposed method is validated on both synthetic and real-world datasets with STOA performance. However, the reliance on accurate causal graphs and labeled data presents challenges that may need to be addressed for broader applicability."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "In my view, the major contribution of this paper is to propose a potential way to scalably identify the perturbed variables, which is especially meaningful in biology tasks. \n\nThe proposed method is abundantly validated on both synthetic and real-world datasets, demonstrating the performance of CDN is non-trivial. \n\nThe presentation is generally good, despite a few expressions that might be confusing for readers without a biology background, e.g. DE."
            },
            "weaknesses": {
                "value": "Supervised learning for causal discovery is an intriguing concept. While I personally believe these two ideas are somewhat contradictory, the performance of supervised causal discovery in this paper is notable. The biggest limitation so far is the lack of discussion around the pretrained causal featurizer, which will clearly influence the identified targets. The paper mentions using a fixed pretrained model. I am not sure if there is any modification of the model across different datasets. Using the same model for every dataset is not entirely reasonable. \n\nAnother limitation is the lack of discussion of out-of-distribution. In the real-world scenario where there are no labels at all, the supervised learning-based method doesn't have any guarantee. Investigation of the performance of this scenario is appreciated and valued. (For the experiment on unseen cell lines, I am not sure I understand it correctly. Currently, I understand it as in distribution generalization rather than out-of-distribution)."
            },
            "questions": {
                "value": "- What is DE in Figure~3? \n- Can the authors elaborate more on \"unseen cell lines\"? Does that mean we have the same variables as \"seen cell lines\" but only different data samples, or even different distributions? \n- For all datasets, exactly the same pretrained model is used or there is a modification for different datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}