{
    "id": "vFanHFE4Qv",
    "title": "Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive learning",
    "abstract": "The Platonic Representation Hypothesis posits that behind different modalities of data (what we sense or detect), there exists a universal, modality-independent representation of reality. Inspired by this, we treat each neuron as a system, where we can detect the neuron\u2019s multi-segment activity data under different peripheral conditions. We believe that, similar to the Platonic idea, there exists a time-invariant representation behind the different segments of the same neuron, which reflects the intrinsic properties of the neuron\u2019s system. Intrinsic properties include the molecular profiles, brain regions and morphological structure, etc. The optimization objective for obtaining the intrinsic representation of neurons should satisfy two criteria: (I) segments from the same neuron should have a higher similarity than segments from different neurons; (II) the representations should generalize well to out-of-domain data. To achieve this, we employ contrastive learning, treating different segments from the same neuron as positive pairs and segments from different neurons as negative pairs. During the implementation, we chose the VICReg, which uses only positive pairs for optimization but indirectly separates dissimilar samples via regularization terms. To validate the efficacy of our method, we first applied it to simulated neuron population dynamics data generated using the Izhikevich model. We successfully confirmed that our approach captures the type of each neuron as defined by preset hyperparameters. We then applied our method to two real-world neuron dynamics datasets, including spatial transcriptomics-derived neuron type annotations and the brain regions where each neuron is located. The learned representations from our model not only predict neuron type and location but also show robustness when tested on out-of-domain data (unseen animals). This demonstrates the potential of our approach in advancing the understanding of neuronal systems and offers valuable insights for future neuroscience research.",
    "keywords": [
        "representation learning",
        "biology",
        "neuroscience",
        "contrastive learning"
    ],
    "primary_area": "applications to neuroscience & cognitive science",
    "TLDR": "",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-11-15",
    "forum_link": "https://openreview.net/forum?id=vFanHFE4Qv",
    "pdf_link": "https://openreview.net/pdf?id=vFanHFE4Qv",
    "comments": [
        {
            "comment": {
                "value": "- I revised the explanation of the the validity of the Steinmetz dataset experiments again, and I referred to the point of view of developmental neurobiology: \"During neurodevelopment, where the position of a neuron is crucial for its differentiation, maturation, and connectivity[1]. The location can influence the neuron's gene expression, synaptic connections, and ultimately its function. In this sense, the location is an intrinsic property because it defines role within the nervous system.\"\n\n[1]Patel N, Poo M M. Orientation of neurite growth by extracellular electric fields[J]. Journal of Neuroscience, 1982, 2(4): 483-496.\n\nMy previous explanation misunderstood your meaning. Please check whether the above new explanation is reasonable.\nI have revised it in Line 292."
            }
        },
        {
            "title": {
                "value": "response weeknesses"
            },
            "comment": {
                "value": "- Our model is a two-stage design: the first step: the process of obtaining neuronal representations is a self-supervised process, sharing a single model, and any new mouse data can be added to the old data for training. Step 2: The training set and test set are presented in the second step, and K-Fold is used for downstream tasks on the neuronal representations obtained in the first step, and folds along the mice identity.\n- We enriched the content of Figure1 and wrote a detailed caption. The revised pdf has been uploaded.\n- The role of CEBRA is to integrate the surrounding information of a single neuron, and if the surrounding information is not integrated, the model cannot converge if it is directly input, which is what we did at the beginning, and then we found CEBRA to solve it.\nOther contrastive learning methods require the design of negative sample pairs, which is relatively complex for neuroscience data, and the design of negative sample pairs has a greater impact, while VICReg does not need to design negative sample pairs\n- We performed a k-fold experiment with three different random numbers for each fold, and the final results were reported as mean and standard deviations, and the results table has been updated.\n\nThanks for your advice. I hope you can consider it again!"
            }
        },
        {
            "comment": {
                "value": "- I add \"It is worth noting that the location of the brain region where the neuron is located is an external property, which itself cannot be regarded as a intrinsic property, but we assume that this external property is constant in the short experimental time range, indirectly as an intrinsic property of the neuron.\" to explain the validity of the Steinmetz dataset experiments.\nRegarding the intrinsic properties of the outside of neurons, this is a topic worth continuing to explore. There may also be external properties that remain unchanged until death.\n\n- The details in the abstract have been modified as you suggested. (line 16 and 18)\n- We use NeurPIR uniformly and introduce it in the introduction.\n- We fix the table overflow issue.\n- We add a description of firing types / neuron types / brain regions to the appendix.\n- We add the note above picture 1.\nThank you for your advice. I hope you can consider it again!"
            }
        },
        {
            "title": {
                "value": "I will adjust my scores accordingly, minor things remain."
            },
            "comment": {
                "value": "Thank you once again for the clarifications and addressing the weaknesses. I will adjust my soundness score and overall score accordingly.\n\nThe distinction between \u201cintrinsic\u201d vs \u201cinternal\u201d is a valid point. However, then an explanation is required as to how an \u201cexternal property\u201d such as location of an object can be an \u201cintrinsic property\u201d of said object, which is not obvious and therefore **must** be included e.g. with the introduction of the dataset. I suppose that indeed for neurons the location of a specific neuron is not independent of its other properties and inherently linked (see developmental neurobiology). This would then explain the validity of the Steinmetz dataset experiments. \n\nThank you for the revised abstract and included limitations. I will adjust my presentation score and overall score accordingly.\n\n1) Regarding the abstract: it is **much** more understandable and straightforward to me. I especially appreciate addressing each previous point carefully. Some remaining ambiguities, and related potential suggestion e.g.:\n- \u201cdifferent segments of the same neuron\u201d -> \u201cdifferent recording segment from the same neuron\u201d? (line 16)\n- \u201cbrain regions\u201d -> \u201clocation within brain regions\u201d? (line 18)\n- now the method name NeuPIR or Neu**r**PIR is not mentioned until page 4 or 7 -> probably it should be included already in the abstract and it should definitely be used in a consistent manner; one **xor** the other.\n\n2) Regarding Figures and Tables: I still believe Figure 1 could benefit from more labels such as X, H, Z, P, F or at least CEBRA, VICReg. Tables should not go over the margins (e.g. Table 3), and Titles of subplots should be appropriately sized (e.g. Figure 2). Consider also using PDF figures for quality improvement instead. Finally, aggregate metrics across firing types / neuron types / brain regions would still help to compare the methods at a glance (at least in appendix). \n\nI will assume in good faith that a Steinmetz dataset explanation will be included and the minor complaints (in so far the authors agree) will be addressed in the final versions of the manuscript. The new soundness and presentation score is 3 each, and the overall score an 8."
            }
        },
        {
            "comment": {
                "value": "Thanks for the reminder, I've fixed the method\u2018name and reuploaded the pdf\n\nIn addition, I also reorganized the introduction according to the ideas you suggested, and told it in the following order:\n(1) Try to obtain the intrinsic representation of neurons inspired by Platonic representation.\n\n(2) Contrastive learning is the idea of \u200b\u200b\u200b\u200bobtaining the inherent representation of neurons.\n\n(3)VICReg is the specific implementation method.\n\n(4) The data preprocessing problems faced when contrastive learning is directly applied are solved by the CEBRA method.\n\n(5) Brief summary and discussion of various experiments.\n\nThe methods section reexplains how we use CEBRA to avoid misunderstandings.\n\nYour suggestions have greatly improved the readability and clarity of our papers. Thank you sincerely!"
            }
        },
        {
            "comment": {
                "value": "Thanks for the thoughtful response. In light of the updated experiments and the new abstract I'm happy to increase my overall score to a 5 and soundness to 3. Could you address the other weaknesses I mentioned? In particular, if major changes have been made to the text in the method or introduction section, it would helpful to delineate them. (Also, note that the method's name does not currently appear throughout the paper -- perhaps a LaTeX issue?)\n\nI stand by my assessment of the novelty of the proposed work -- this is an applications paper. That said, the specific approach of contrastive learning for the broader research direction of forming data-based representations of individual neurons is new to my knowledge as well as a natural pairing of problem and technique, and the scientific findings have merit."
            }
        },
        {
            "title": {
                "value": "About the novelty"
            },
            "comment": {
                "value": "CEBRA is just our data preprocessing step, and CEBRA itself is used to study neuronal populations.\nWe consider the problem from the perspective of a single neuron and cleverly use CEBRA to process the surrounding information relative to a single neuron. CEBRA is equivalent to a step in data preprocessing.\nIt is unfair to regard our work as A+B work. We are the first to consider representation learning of the intrinsic properties of single neurons from a contrastive learning perspective, which is is a whole new field of computational neuroscience.\nWe sincerely hope you will consider our work again, thank you!"
            }
        },
        {
            "comment": {
                "value": "why the Steinmetz Dataset is suitable to learn \u201cneuron internal representations\u201d as opposed to \u201cneuron external representations\u201d?\n\n- You're right, the brain regions where neurons are located can indeed be expressed as external properties of neurons, but notice that the words we use are \u2019intrinsic\u2018, whether external or internal, as long as they are time-invariant, we can regard them as intrinsic for a neuron.\n\n2)-4) of the listed weaknesses:\n\n- Limitations: (1) The representation learned by our method can only distinguish neurons with large differences in essential attributes. For example, if neurons consider more refined brain area labels, it is difficult to distinguish them, which requires more data to support training. (2) The learned neurons represent that only data collected from the same technology are supported, and the generalization of cross-platform data, such as two-photon data and neurpixel data, remains to be explored. (3) Considering very long timescales, it is possible that some of the short-term invariant properties of neurons may change, which can be used to study changes in neuronal properties during the development of diseases such as Alzheimer's disease.\n- Abstract (revised version): The Platonic Representation Hypothesis posits that behind different modalities of data (what we sense or detect), there exists a universal, modality-independent representation of reality. Inspired by this, we treat each neuron as a system, where we can detect the neuron\u2019s multi-segment activity data under different peripheral conditions. We believe that, similar to the Platonic idea, there exists a time-invariant representation behind the different segments of the same neuron, which reflects the intrinsic properties of the neuron\u2019s system. Intrinsic properties include the molecular profiles, brain regions and morphological structure, etc. The optimization objective for obtaining the intrinsic representation of neurons should satisfy two criteria: (I) segments from the same neuron should have a higher similarity than segments from different neurons; (II) the representations should generalize well to out-of-domain data. To achieve this, we employ contrastive learning, treating different segments from the same neuron as positive pairs and segments from different neurons as negative pairs. During the implementation, we chose the VICReg, which uses only positive pairs for optimization but indirectly separates dissimilar samples via regularization terms. To validate the efficacy of our method, we first applied it to simulated neuron population dynamics data generated using the Izhikevich model. We successfully confirmed that our approach captures the type of each neuron as defined by preset hyperparameters. We then applied our method to two real-world neuron dynamics datasets, including spatial transcriptomics-derived neuron type annotations and the brain regions where each neuron is located. The learned representations from our model not only predict neuron type and location but also show robustness when tested on out-of-domain data (unseen animals). This demonstrates the potential of our approach in advancing the understanding of neuronal systems and offers valuable insights for future neuroscience research.\n- I have redrawn the picture to make legend and caption clearer and increased it to a resolution of 600dpi.\n- I have resubmitted the revised manuscript.\n\nThank you for your advice. I hope you can consider it again!"
            }
        },
        {
            "title": {
                "value": "Further clarifications needed, comment on novelty:"
            },
            "comment": {
                "value": "Thank you for the clarifications and improvements regarding questions 2)-7). \n\nRegarding question 1) the explanation is too general; could you please more concretely explain why the Steinmetz Dataset is suitable to learn \u201cneuron internal representations\u201d as opposed to \u201cneuron external representations\u201d?\n\nFurtheremore, could you please specify whether for the final manuscript you would address points 2)-4) of the listed weaknesses?\n\nUnlike reviewer **bVqe**, I do not see a problem with the novelty of the method or research question, even if it consists of the straightforward combination of well known computation blocks, and as mentioned, I am not aware of any papers investigating the same research question. Therefore I believe this is a very interesting contribution to the field, and a distinctive strength of the paper. I\u2019m open to evidence to the contrary in terms of related literature."
            }
        },
        {
            "comment": {
                "value": "Time complexity of NeuPIR compared to other baselines?\n\n- If we disregard the time spent on data preprocessing, the time consumed by all methods would indeed increase proportionally with the multiple of the sample size. You might have doubts about this statement, especially when we employ contrastive learning, as it should not exhibit proportional growth. However, it is important to note that we are using VICReg, which only requires the training of positive sample pairs. About time cost, Neuprint takes the representation of neurons as an input embedding of a transformer and updates it using a backpropagation algorithm, which is difficult to train, takes 25 hours, takes up 60 gigabytes of memory on top of the A100(80G). LOLCAT is a supervised training, it is the easiest to converge, the same A100(80G) above, takes 1 hour, uses 10G memory. Our method is a self-supervised contrast learning process, which is the same as A100(80G), takes 15G memory and takes 4h to converge. \n\nWould it be possible to evaluate on more fine-grained information such as spatial location of individual units?\n\n- We can conduct more fine-grained brain area classification experiments, but if the brain areas are divided more finely, the number of samples in each brain area may not be sufficient, and the neurons in some brain areas are very similar, making it difficult to distinguish. These are all worth exploring in the future, thank you for the new inspiration\n\nHow many data samples are required to learn effective embedding?\n\n- each session we use is 5000*400 (timepoints*neurons), each neuron we will sample 8 positive pairs, effective embedding needs at least two session like this.\n\nWe have revised the paper to do K-fold cross-validation, and each fold is experimented with with a different random number and reports the mean and variance. We tried to delete any part of VICReg for experiments, but no convergence could be achieved if any part was deleted."
            }
        },
        {
            "comment": {
                "value": "How exactly are the experiments on the Steinmetz dataset supporting the claims of neuron intrinsic representation learning?\n\n-The intrinsic representation of a neuron is, in fact, a time-invariant representation. We obtain a time-invariant representation for each neuron through a self-supervised approach. The question then arises: how can we validate the effectiveness of this time-invariant property? To address this, we take into account the time-invariant attributes of neurons that are already known from prior knowledge, such as neuron type and the brain region in which the neuron is located.\n\nFor the Bugeon Dataset: why was only data of mice A used?\n\n-Thanks for the suggestion, the cross animal results are more meaningful for neuroscience, so we changed the evaluations from one animal to multiple animals. Specifically, we have four mice, so 4-fold was used, with the folds based on the identity of the mice. We also divided a validation set and used a random search strategy to tune the hyperparameters of methods being compared, employing the best models on the test set. We have revised the result in the paper.\n\nFor the Steinmetz Dataset; why wan\u2019t also e.g. a 10-fold crossvalidation used (folds along the mice identity)?\n\n-Following your suggestion, we have reconducted the experiments and used 10-fold cross-validation (with folds based on the identity of the mice). We also replaced the original bar charts with a table to present more detailed information, including the precision, recall, and F1 scores details.\n\nWould you expect you method to also perform well if the number of Izhikevich neuron \u201ctypes\u201d was greatly increased (e.g. 10,20,30 categories)?\n\n-Strictly speaking, the performance of the model depends on the similarity between different neuron types, rather than the number of types. If the added categories are very similar to each other, the model's performance is likely to decrease. However, if the added categories still exhibit distinguishable differences, the performance should remain unchanged.\n\nWill/are the exact labels used for three experiments, and in particular for Bugeon be available for others to be able to reproduce the experiments exactly?\n\n-Of course, I am willing to provide a jupyternotebook[1] to show how to preprocess Bugeon dataset[3], download dataset from [2].\n\nWould you expect different results if max-pooling was used instead of mean-pooling?\n\n-I believe that max pooling will not perform better than average pooling, because before the neuronal data is input, it has already undergone binning of the firing rate, which is already similar to a max pooling operation. If we were to use max pooling again, it would lead to a significant loss of information.\n\nIs there any more literature / papers exactly doing single neuron characterization based on neuron population activity (possibly on other datasets)? It seems to be challenging to find more related literature.\n\n-I came up with this idea when I saw that there's work now using deep learning to learn the inherent properties of different singers voices, and you can refer to the papers that inspired my idea[4].\n\n[1]https://drive.google.com/file/d/1Gf9RS49K2W0npLE3kY77GD--s0oHgXRA/view?usp=drive_link\n[2]https://figshare.com/articles/dataset/A_transcriptomic_axis_predicts_state_modulation_of_cortical_interneurons/19448531\n[3]https://www.nature.com/articles/s41586-022-04915-7\n[4]https://dl.acm.org/doi/10.1109/TASLP.2022.3169627"
            }
        },
        {
            "comment": {
                "value": "The abstract says \"PRH posits that representations of different activity segments of the same neuron converge, while segments from inherently dissimilar neurons diverge\" (lines 19-21). What representations this is referring to is not clear in context.\n - PRH inspired us to treat each neuron as a system and learn the time-invariant intrinsic properties of each neuron's system representation. Our representation indeed differs from the Platonic representation, as you pointed out. Using \"Neuron Platonic Intrinsic Representation\" is not appropriate, and we have revised the title accordingly. Additionally, we have clarified the relationship between PRH and Neuron Intrinsic Representation in both the abstract and the introduction.\n\nThe introduction should be more specific about what the method actually is, what the contrastive objective is, etc.\n- In this paper, we set the optimization objective for obtaining the intrinsic representation of neurons as follows: clips from the same neuron should have a higher average similarity than clips from different neurons. We employ a contrastive learning approach to achieve this optimization goal, treating different segments from the same neuron as positive pairs and segments from different neurons as negative pairs. During the implementation of the contrastive learning method, we realized that directly optimizing for the separation of samples from different neurons might be too rigid (since different neurons do not necessarily mean dissimilarity). Therefore, we chose the VICReg approach, which only uses positive pairs for optimization but indirectly separates dissimilar samples through regularization terms.\nThank you for your suggestion. We have revised the introduction to make the reasoning clearer and to provide more detailed key points.\n\nIdentifying cell type seems like a paradigmatic task where compressing neural activity into binned firing rate loses important information which may be contained in the spike train.\n- Identifying cell types is indeed a paradigmatic task, but our work is not focused on cell type identification. Rather, we use this as a downstream task to demonstrate that the learned time-invariant intrinsic representations contain meaningful information, of which cell type is one component. Although binning the firing rate may lose some detailed information, it still retains key features of neuronal activity. For example, binning the firing rate allows us to observe the overall response pattern of neurons under specific stimuli. What we are learning is the time-invariant intrinsic representation of individual neurons, which is also a overall representation. Binned firing rate is a standard preprocessing step in neuroscience data analysis when processing large-scale neural data. This approach is primarily aimed at reducing computational complexity and data storage requirements, making some level of information compression necessary. On the other hand, it aligns with the fact that neurons encode information according to frequency patterns.\n\nThe method section should provide more information about what CEBRA is.\n- CEBRA serves as an encoder for the dynamic activity information of neuronal populations. Its advantage lies in its ability to encode both neuronal activity data (N*T) and corresponding auxiliary variables, such as behavior and external stimuli (M*T), into a low-dim (D*T). In CEBRA, D does not correspond to individual neurons, aiming to uncover the relationships between neuronal activity and these variables.\nOur work focuses on obtaining intrinsic representations for individual neurons. We cleverly utilize CEBRA from a different perspective as a preprocessing step for our input data. From each neuron, we use CEBRA to integrate the single neuronal peripheral information (such as activity of neighboring neuronal populations and behavioral data) for each segment of a single neuron. This process encodes the peripheral information associated with each segment of an individual neuron. Our work primarily involves contrastive learning to different segments of the same neuron.\nThank you for your suggestion. I have added a detailed description of CEBRA in the Methods section, along with an explanation of how we use it.\n\nThe cross-animal generalization experiment (5.3) is interesting but as predicting cell type is the more relevant problem I would be interested to see a similar generalization experiment with a cell type dataset as in 5.2.\n- Thanks for the suggestion, the cross animal results are more meaningful for neuroscience, so we changed the evaluations from one animal to multiple animals. Specifically, we have four mice, so 4-fold was used, with the folds based on the identity of the mice. We also divided a validation set and used a random search strategy to tune the hyperparameters of methods being compared, employing the best models on the test set. We have revised the result in the paper."
            }
        },
        {
            "comment": {
                "value": "Line 54 and 55: \n- Although VICReg does not explicitly use negative pairs like other contrastive methods, it still indirectly promotes the separation of different samples through the variance and covariance regularization terms. The variance regularization ensures that the representations have sufficient spread, meaning that for dissimilar samples, their feature representations are less likely to collapse into a small region of the embedding space. The covariance regularization helps ensure that features are not highly correlated, promoting more distinct and diverse representations. VICReg relies on a more subtle approach, achieving the desired separation through variance and covariance regularization.[1] \n\nFigure 1: \n- In this paper, we set the optimization objective for obtaining time-invariant intrinsic representations of neurons as follows: clips(segments) from the same neuron should have a higher average similarity than clips from different neurons. Figure 1 illustrates how this objective can be achieved using a contrastive learning approach, where different clips from the same neuron are treated as positive pairs and clips from different neurons are treated as negative pairs. This is the main idea conveyed by Figure 1.\nHowever, when selecting a specific contrastive learning method, we realized that directly optimizing for the separation of clips from different neurons may be too rigid (as different neurons do not necessarily represent dissimilarity). Therefore, we chose to implement VICReg, which optimizes using only positive pairs, but indirectly separates dissimilar samples through regularization terms. We have revised the caption of the figure to explain more detail.\n\nLine 134: \n- In this paper, we are not learning representations of neuron populations, nor are we performing dimensionality reduction on neuronal population activity. Instead, we aim to learn a time-invariant intrinsic representation for each individual neuron. Each neuron is considered separately, and the activity information from the remaining neurons in the population is treated as peripheral information (equation 1: X_st) for that specific neuron, which acts as auxiliary variables. The peripheral information for each neuron is processed and encoded using CEBRA.\n\nLine 149: \n- If a neuron has data from multiple sessions, we will select segments of 512 time points from different sessions as positive pairs for that neuron. If a neuron only has data from a single session, we will randomly select non-overlapping segments, with lengths randomly ranging from 200 to 512 time points, as positive pairs for that neuron. During implementation, we have ensured the use of an algorithm that prevents overlap between these segments.\n\nLine 155:\n- A session refers to a single stage or individual experiment in a neuroscience study where data is collected. If you want to know more about session, please read this link[2]. The input dimension of the model is the same as the length of the segment. For example, if there are 300 time points, the first session's Xse would be represented as [1, for i in range(300)].\n\nLine 161: \n- Based on the previous question, if a neuron only has data from a single session, we will randomly select non-overlapping segments of lengths ranging from 200 to 512 time points as positive pairs for that neuron. For these segments of varying lengths, we ultimately need to map them to the same dimensionality. Adaptive average pooling is a suitable tool for this task, as it does not require explicitly specifying a fixed pooling window size. Instead, we can set a consistent output size, and the pooling operation will automatically adjust to accommodate the varying segment lengths. Adaptive average pooling is capable of handling inputs of different lengths and extracting important feature information, mapping them to a consistent dimensionality.\n\nLine 202: \n- It is set to a fixed value of 1, as we referenced in the original VICReg paper and other works that utilize VICReg, which all adopt this setting. The choice of the target value is an interesting topic worth further exploration, especially in terms of its impact on negative pairs. However, this would become the focus of another paper dedicated to contrastive learning.\n\nFigure 4: \n- We replaced the original bar charts with a table to present more detailed information, including the precision, recall, and F1 scores details. \n\n[1] Bardes, Adrien, Jean Ponce, and Yann LeCun. \"Vicreg: Variance-invariance-covariance regularization for self-supervised learning.\" arXiv preprint arXiv:2105.04906 (2021).\n[2]https://allensdk.readthedocs.io/en/latest/visual_behavior_optical_physiology.html#session-structure"
            }
        },
        {
            "summary": {
                "value": "The paper introduced NeurPIR, a self-supervised contrastive learning approach to learn intrinsic representation for each neuron from population dynamics. The method leveraged CEBRA and VICReg for representation learning, and was evaluated using synthetic and two mouse datasets, showing ability to learn representations indicative of neuronal intrinsic properties that are decodable by downstream classifiers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The method combines CEBRA and VICReg to incorporate surrounding information and learn enhanced representation with contrastive learning, which is a novel approach.\n* The paper is well motivated and tackles an important problem in neuroscience.\n* The writing is clear and logical."
            },
            "weaknesses": {
                "value": "* The usefulness of the out-of-domain evaluation on Steinmetz dataset is questionable. It seems as described on line 266, the self-supervised contrastive learning is performed on all neurons of all mice, including the test mice, i.e. the self-supervised model and classifier have to be retrained everytime new mice come in. Can any part of the model at least be reused during test time?\n* Model architecture is not clearly explained by figures or texts. Some details of the methods are missing (elaborated in Questions).\n* Some ablation studies are missing that would otherwise be helpful to understand the method in greater detail. For example, an ablation on which surrounding information included in the CEBRA framework has the most impact, or an ablation on different choices of contrastive learning methods besides VICReg might be helpful. \n* Results in tables and figures do not have errorbars. Adding sensitivity analyses would be helpful to quantify how significant the improvements of NeurPIR over the baselines are."
            },
            "questions": {
                "value": "* Line 54 and 55: the paper is motivated to make segments of activity from the same neuron or similar neurons to converge, while dissimilar neurons diverge. However, VICReg only uses positive pairs, and adds regularization to prevent representation collapse. How does using VICReg help push dissimilar neurons apart according to the motivation? \n* Figure 1: description in the texts and accompanying caption to understand this figure are missing. The figure does illustrate negative pairs, however, VICReg does not use negative pairs as mentioned above. How are negative pairs processed by the NeurPIR model?\n* Line 134: the goal was to learn intrinsic neuronal representations on neuron population data, but it does not seem that activity of other neurons are used in the model (equations 1 to 4). How does the model use population dynamics to learn neuronal representations?\n* Line 149: what is the length of one segment? Is there a chance that two randomly selected segments overlap with each other?\n* Line 155: what is session information $X_{se}$? What are dimensions of $X_{st}$, $X_{be}$, $X_{se}$, $X_{si}$?\n* Line 161: can the author provide more details on what is adaptive average pooling?\n* Line 202: how the target value $\\mu$ was set?\n* Figure 4: how about precision, recall, and F1 scores (to be consistent with Tables 1 and 2)?\n* It would also be helpful to provide additional details on the architecture design and training process, e.g. hyper-parameters, training time, etc."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposed NeurPIR, which focus on learning a platonic representation from neural activities data to reflect the inherent properties and neuronal identity, relating to molecular information. The goal of this work is to learned representations robust to variations due to external stimuli and experiment conditions. It utilized the self-supervised multi-segment contrastive learning strategy from CEBRA, and learning representations for neurons with compare data from different segments, different behavior information, session information, and for neurons share similar functional roles to align closely in their representations. And they further aggregate the representation with adaptive average pooling to extract time-invariant representations. They further incorporate VICReg loss to enhance the prediction. The work is evaluated on three benchmarks: Izhikevich simulation model, spatial transcriptomics data with neural activities, neuron location with out-of-domain data, and compared with two existing baselines NeuPRINT and LOLCAT."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The work is evaluated on three representative benchmarks, including one synthetic dataset, and two neural datasets. And it is compared against with two baselines and demonstrating SOTA performance in most of the tasks.\n2. The work utilized a novel, distinct and effective method to utilize contrastive learning strategy to learn the platonic representation, compared to NeuPRINT with learning time-invariant representations with a neuron-wise look-up table for dynamics forecasting during self-supervised learning, or LOLCAT with label-guided representation with end-to-end supervised learning. \n3. The out-of-domain evaluation on unseen mice is an important question, which increases the soundness of the evaluations."
            },
            "weaknesses": {
                "value": "1. The core of the proposed approaches similar strategy as CEBRA to utilize the contrastive self-supervised approach for representation learning. The major difference from CEBRA is that it utilizes the adaptive average pooling to aggregated into time-invariant embedding, which might not necessarily guarantee the converge of the representation based on the data sampling. Further investigation could be done on how to guarantee converge based on different sampling strategy, or the requirement of amount of data to affect the predictive performance of the downstream tasks.\n2. The evaluation on Steinmetz dataset is evaluated on decoding brain region with the learned intrinsic representations is related to analyze the invariant properties of the neurons, while brain region is only coarsely reflecting information from neuronal level, would it be possible to evaluate on more fine-grained information such as spatial location of individual units?\n3. Ablation studies of VICReg loss should be performed.\n3. Sensitivity analysis (i.e. error bar) are not included in Fig 4, the effect of data shuffling, random initialization, etc. could be reported.\n4. Figure quality (i.e. font size, resolution) in the paper as limited, presentation and writing could be improved."
            },
            "questions": {
                "value": "1. Time complexity of NeuPIR compared to other baselines?\n2. How many data samples are required to learn effective embedding?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a contrastive learning method (NeuPIR) for analyzing single-neuron activity data, with the goal of obtaining a representation which preserves property-level similarity of neurons (e.g. cell type). The method combines a variational autoencoder (CEBRA) with a contrastive loss (VICreg). NeuPIR is applied to a synthetic dataset and real neural datasets with cell type and brain area information, and compared against a few other methods of feature extraction (PCA, UMAP, NeuPRINT, & LOLCAT)."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* Understanding the role of cell type diversity is a major challenge for neuroscience. A contrastive approach like this one, which can in principle be trained without labels, is likely to be the way forward given the difficulty of obtaining cell type information and activity simultaneously.\n* Furthermore, learning representations which preserve cell property information is a application of obvious interest to the ICLR community.\n* This paper performs the right experimental evaluations for its method, starting with a synthetic dataset, then moving to a real dataset where ground truth cell type information is available, and finally a real dataset with only brain region information, and compares against appropriate competitor methods."
            },
            "weaknesses": {
                "value": "* The framing in terms of the \"Platonic Representation Hypothesis\" [1] feels like hype chasing. What is being presented here is just a contrastive learning method which is meant to identify similarity and differences in properties of neurons. This is not actually related to the PRH in a meaningful sense, which is about how representations _of the world_ converge across models in completely different domains. I am willing to raise my score if the framing of the paper (primarily title, abstract, introduction) is substantially revised to take this into account.\n* The details of the method are not clear to me. CEBRA [2], at least as proposed, takes in a window of activity across a population of neurons (among other covariates) and maps it to a single latent point. I believe that here CEBRA is being applied to the activity of single neurons and their covariates but this is an important distinction which is not made explicit in the text.\n* I am not convinced that other methods are being fairly compared to NeuPIR. There is a lack of detail about how hyperparameter selection occurred in the experiments which makes this difficult to evaluate. For instance, LOLCAT fails to label any neurons at all as Sst in Table 2 which suggests it wasn't tuned correctly for the task.\n* The method is not significantly original as it is combining the pre-existing CEBRA architecture [2] with the VIC contrastive loss [3], making this nearly a pure applications paper. This is not necessarily a flaw but does put the burden of innovation on the value of its scientific findings.\n\n[1] Huh, Minyoung, et al. \"The platonic representation hypothesis.\" arXiv preprint arXiv:2405.07987 (2024).\n[2] Schneider, Steffen, Jin Hwa Lee, and Mackenzie Weygandt Mathis. \"Learnable latent embeddings for joint behavioural and neural analysis.\" Nature 617.7960 (2023): 360-368.\n[3] Bardes, Adrien, Jean Ponce, and Yann LeCun. \"Vicreg: Variance-invariance-covariance regularization for self-supervised learning.\" arXiv preprint arXiv:2105.04906 (2021)."
            },
            "questions": {
                "value": "* The abstract says \"PRH posits that representations of different activity segments of the same neuron converge, while segments from inherently dissimilar neurons diverge\" (lines 19-21). What representations this is referring to is not clear in context.\n* The introduction should be more specific about what the method actually is, what the contrastive objective is, etc.\n* Identifying cell type seems like a paradigmatic task where compressing neural activity into binned firing rate loses important information which may be contained in the spike train.\n* The method section should provide more information about what CEBRA is.\n* The cross-animal generalization experiment (5.3) is interesting but as predicting cell type is the more relevant problem I would be interested to see a similar generalization experiment with a cell type dataset as in 5.2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proses a novel method called NeurPIR for extracting individual neuron representation based of neuron population recordings in a self-supervised fashion. For this purpose NeurPIR essentially combines a neural data specific sampling method, average pooled CEPRA embeddings, and a VICReg contrastive loss in a cohesive manner. The method is evaluated on a suite of synthetic and real neuron population activity recordings, where it superior performance to alternative methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper tackles a relevant, yet extremely challanging task: extracting individual neuron characteristics from neuron population data.\n- The paper convincingly demonstrates the proposed methods ability to do so to some extent, in particular compared to other available methods.\n- The related literature, methods and experiments section is very detailed and well written, aiding interpretability of the results and reproducibility."
            },
            "weaknesses": {
                "value": "* 1\\) The Steinmetz dataset experiment: likely doeant support the claim of being able to extract neuron internal represenations, as the method was trained to predict the location of the neurons, arguably an external neuron property?\n   - Even if two exactly same neurons were integrated into two different brain regions they are likely identifiable through their activity as the differences in input to the two regions typically significantly deviates.\n   - To claim exactraction of neuron intrinsic properties, the above effect would have to be significantly smaller than neuron intrinsic properly related differences, which is not validated.\n* 2\\) The Conclusion: is crucially missing a paragraph on the limitations of the proposed method and the experimental findings. The paper would significantly benefit from it.\n* 3\\) The Abstract: the first half is very confusing to read and doesn\u2019t make it clear what the paper is actually about (for someone from a general computational neuroscience background). The paper would therefore greatly benefit from simpler and more concrete wording there.\n   - Examples of terms that were not really helpful to me : \u201cdecoupling of intrinsic properties, \u201ctime-varying dynamics\u201d, \u201cdynamic activities\u201d, \u201cvarying signals\u201d, etc. What property, whos dynamics, what activity, which signal?\n   - In particular \u201cintrinsic properties\u201d should be immediately followed by examples (later given), and the first mention of PRH feels out of place and its unclear how it relates to the sentences surrounding it. \n   - Furthermore, in the context of computational neuroscience \u201cwhat information is conveyed by neural activities\u201d most often implies figuring out what neurons try to communicate to process information, which the paper is not about. \n   - Finally, a statement like \u201cNeurPIR captures the preset hyperparameters of each neuron\u201d implies precise recovery e.g. $b = 0.2$. The proposed method was rather shown to capture rough categorical differences instead. More appropriate would could be e.g. \u201cNeurPIR captures the class/category/type of each neuron\u201d.\n* 4\\) The Figures: have barely readable label sizes and legends, or missing annotation.\n   - Figures 2 and 3 feature barely readable label sizes and legend\n  - Figure 1 could use more labels that help relate the model description to the images in the figure. (e.g. X, H, Z, P, F, CEBRA, VICReg)\n* 5\\) The Tables (or their descriptions): would benefit from some aggregate metrics across all categories.\n* 6\\) For Reproducibility: manual labeling like in the Bugeon is hard to reproduce, and its unclear to me from the text whether these will be / are provided."
            },
            "questions": {
                "value": "1) How exactly are the experiments on the Steinmetz dataset supporting the claims of neuron intrinsic representation learning?\n2) For the Bugeon Dataset: why was only data of mice A used?\n3) For the Steinmetz Dataset; why wan\u2019t also e.g. a 10-fold crossvalidation used (folds along the mice identity)?\n4) Would you expect you method to also perform well if the number of Izhikevich neuron \u201ctypes\u201d was greatly increased (e.g. 10,20,30 categories)?\n5) Will/are the exact labels used for three experiments, and in particular for Bugeon be available for others to be able to reproduce the experiments exactly?\n6) Would you expect different results if max-pooling was used instead of mean-pooling?\n7) Is there any more literature / papers exactly doing single neuron characterization based on neuron population activity (possibly on other datasets)? It seems to be challenging to find more related literature."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}