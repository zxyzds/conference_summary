{
    "id": "dIaykjbiiL",
    "title": "Are Synthetic Time-series Data Really not as Good as Real Data?",
    "abstract": "To alleviate the commonly encountered inadequate time-series data problem in DL (DL), we develop a non-DL generic data synthesis method. When current methods require real data or data statistics to train generators or synthesize data, our method InfoBoost enables zero-shot training of models without the need for real data or data statistics. Additionally, as an application of our synthetic data, we train an unconditional feature (rhythm, noise, trend) decomposer based on our synthetic data, which is applicable to real time-series data.  Through experiments, our non-DL synthetic data enables models to achieve superior performance on unsupervised tasks and self-supervised prediction \\& imputation compared models using real data. Visualized case studies further demonstrate the effectiveness of our novel unconditional feature decomposer trained with our synthetic data.",
    "keywords": [
        "Time-Series Data",
        "Data Synthesis",
        "Non-Deep-Learning Data Synthesis",
        "InfoBoost",
        "Prediction",
        "Imputation",
        "Feature Decomposition"
    ],
    "primary_area": "generative models",
    "TLDR": "InfoBoost, a non-deep-learning method for synthesizing time-series data, which enables superior performance for tasks like prediction and imputation, and facilitates feature decomposition without requiring real data & info.",
    "creation_date": "2024-09-20",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=dIaykjbiiL",
    "pdf_link": "https://openreview.net/pdf?id=dIaykjbiiL",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes InfoBoost, an algorithmic method for generating synthetic time series. The algorithm is based on simulating trend, periodic, and noise components and then combining them. The authors demonstrate the method's utility by adding the generated data to real data in various experimental scenarios."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- **Variety of the datasets in the experiments**. The authors evaluate their method on a wide variety of datasets."
            },
            "weaknesses": {
                "value": "- **Writing.** The paper is hard to read and needs to be better structured. For instance, it would be helpful to provide a pseudocode and a dedicated section that describes the proposed method step-by-step. Additionally, the design choices are not discussed. The paper contains many typos and requires significant polishing.\n- **Methodological contribution.** The authors propose an algorithm for generating random time series signals while not discussing at all any guarantees of such an algorithm. Also, the training algorithm is not clearly presented.\n- **Empirical results**. It would be great to compare the method with STS and other methods for synthetic time series generation. The empirical results, in my opinion, are not currently reproducible because the paper lacks details about it, and the source code is not available."
            },
            "questions": {
                "value": ">  data problem in DL (DL),\n\nTypo\n\n>  on training DL\n\nDL model?\n\nMany other typos in the text.\n\nReferences and citations do not seem to follow ICLR guidelines.\n\n\n>  non-DL approach (no need for real data to train)\n\n\u201cno need for real data to train\u201d != non-DL. \u201cno need for real data to train\u201d means it does not require data, whereas non-DL means \u201cdoes not use deep learning methods\u201d\n\n\nIs it possible to learn parameters of your simulator with simulation-based inference?\n\nIt is easy to come up with many different designs of a simulator that uses periodic-trend-noise decomposition? Why is your design better?\n\nThe empirical results seem to be very surprising in my opinion. I encourage authors to add their code and provide clear guidelines to reproduce it."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper attempts to suggest that one can use exclusively. synthetic data to augment the learning of a machine learning based model. It suggests techniques to construct the time series data in a way which encompasses a wide array of signals."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "It is good that they have suggested to use a wide array of signals for the synthetic data generation."
            },
            "weaknesses": {
                "value": "This is unfortunately not enough to have sufficient novelty for publication, although it can be built upon further. And it is not carefully thought out in my opinion. For example we may consider Figure 1 there is a diagrammatic separation of \"Ryth\", \"Noise\", and \"Trend\", in a way that these feel orthogonal constructors to an overarching to an extent, but these are not in practice. \"Ryth\" has elements of noise and trend added into it, \"Noise\" has elements of Ryth and trend added into it implicitly (if the authors don't believe so, one can simply look at a simple noise process such as random walk used to model stock prices and why that implicitly tends to drift from a non zero trend over time), and \"trend\" is the only the true seperator. But then why didn't you work in the frequency domain for \"Rhyth\" and explicitly change the low freq. domain peaks of said signal. This would be far more amenable for methods in low freq. structural engineering where you could justifiy a stronger use of this approach?\n\nIn this sense to summarise, there needs to be a proper and full mathematical justification of why \"Ryth\" and \"Noise\" are separately allowed to be modeled in addition to the infinitude of ways in which one can decompose signal construction. In addition to trend in a way of F = f + noise type of way where it is clear here \"f\" is a kind of low frequency trend component and \"noise\" is a type high frequency additional, yet pseudo-orthogonal component.\n\nIn addition to this there is not ample comparison to other time series synthesis approaches in my opinion. Since there has already been a lot of \"frequency mixing\" and \"amplitude mixing\" based time series synthesis based approaches already done in classical literature (not even considering modern literature on the topic at this point) on the topic and the authors have not demonstrated why \"their\" over arching approach is clearly superior. It is fine if it is also the same in my opinion, but provides a uniquely distinct window we haven't explored before but have not also seen that. If the authors could comment on why they feel their approach provides a strong and unique angle to their problem, above such traditional approaches that could be nice for a future contribution."
            },
            "questions": {
                "value": "I have no questions at the moment, but in the follow up discussion I am open to discussing responses and questions to the paper from the authors in this format."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper describes a synthetic time series data generator for\nzero-shot learning of models. It is claimed not to need DL, real data\nor statistics."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The goal is important: of generating simulated data to aid in learning\nwhen data are limited. And to do that in as task-agnostic way as\npossible.\n\nThe proposed method is tested in three different kinds of case\nstudies."
            },
            "weaknesses": {
                "value": "The writing is unclear. Concepts are not introduced before being used,\nand the main learning setup and goal is not stated clearly\nanywhere. Some examples in the Questions below. A couple of others: In\nFig 7 it is not clear what the fig shows and what can be concluded\nfrom it. In Eqn 8 the notation has not been introduced.\n\nOverstated claims: While some aspects of the proposed method may be\n\"non-DL\" and \"without the need for real data or data statistics\", it\nis hard to see how generalizable learning would be possible without\nany data or task-relevant inductive biases whatsoever. No free lunch\napplies.\n\nSome unclarities are resolved in the supplementary material but the\nmain points should become clear already in the main text."
            },
            "questions": {
                "value": "1. Why is the method called non-DL?\n\n2. How does the method guarantee generalization for new data, if it does\nnot use any real data or data statistics? Where do the inductive\nbiases come from?\n\n3. In section 3.2: says \"only needs input data\". What data, and does that\nnot imply you need data?\n\n4. In section 4.1 you talk about random real-world subsets. What were\nthey used for, precisely?\n\n5. What is the learning task the data is generated for?\n\n6. Example of unclearities: what does eqn 2 mean?\n\n7. Generating trends (section 3.1.3): Seems the genrated waveforms differ\nfrom the earlier ones only in the length of the period. How different\nis the length?\n\n8. What are the labels mentioned in Section 3.2? What broadcasting and\ninterpolation do you refer to?\n\n9. Section 4.1: What is \"the 'sync' group\"?\n\n10. Fig 5: too small and thin font. The table is not really understandable\nbased on the current explanation.\n\n11. p. 8: What autoencoding performance do you refer to, precisely?\n\n12. Fig 6: Is this prediction a sensible task in each domain? WHy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel method for generating synthetic data that requires no information from real data yet remains highly effective for downstream tasks. By combining elements of rhythm, noise, and trend, the synthetic data is created and then applied to downstream tasks such as unsupervised learning, forecasting, and data imputation, ultimately enhancing performance in these areas."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The experimental results are intriguing, showing that synthetic data unrelated to the original dataset can effectively boost performance."
            },
            "weaknesses": {
                "value": "1.\tThe writing quality is quite low, with too many incomplete sentences and typos.\n2.\tIn the fourth paragraph of the Introduction, the link between proposing a frequency-based method and addressing significant variations is weak.\n3.\tThe author compares their method to data generation models; however, the primary purpose of data generation models is to simulate real data distribution. Since it\u2019s impossible to replicate real data distribution without any information from actual data, this approach cannot be considered a true data generation method.\n4.\tWhy aren\u2019t the structures of the decomposer networks included in the main manuscript?"
            },
            "questions": {
                "value": "See Weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}