{
    "id": "k8KsI84Ds7",
    "title": "Process-Driven Autoformalization in Lean 4",
    "abstract": "Autoformalization, the conversion of natural language mathematics into formal languages, offers significant potential for advancing mathematical reasoning. However, existing efforts are limited to formal languages with substantial online corpora and struggle to keep pace with rapidly evolving languages like Lean 4. To bridge this gap, we propose a large-scale dataset \\textbf{Form}alization for \\textbf{L}ean~\\textbf{4} (\\textbf{\\dataset}) designed to comprehensively evaluate the autoformalization capabilities of large language models (LLMs), encompassing both statements and proofs in natural and formal languages. Additionally, we introduce the\n\\textbf{P}rocess-\\textbf{D}riven \\textbf{A}utoformalization (\\textbf{\\method}) framework\nthat leverages the precise feedback from Lean 4 compilers to enhance autoformalization. \nExtensive experiments demonstrate that \\method improves autoformalization, enabling higher compiler accuracy and human-evaluation scores using less filtered training data. \nMoreover, when fine-tuned with data containing detailed process information, \\method exhibits enhanced data utilization, resulting in more substantial improvements in autoformalization for Lean 4.",
    "keywords": [
        "Large Language Models",
        "Autoformalization",
        "Lean 4",
        "Formal Math",
        "Process Supervision",
        "Formal Reasoning",
        "Mathematical Reasoning",
        "AI for Math",
        "Automated Theorem Proving"
    ],
    "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)",
    "TLDR": "We introduces the FormL4 benchmark to evaluate autoformalization in Lean 4, along with a process-supervised verifier that enhances the accuracy of LLMs in converting informal statements and proofs into formal ones.",
    "creation_date": "2024-09-20",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=k8KsI84Ds7",
    "pdf_link": "https://openreview.net/pdf?id=k8KsI84Ds7",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a new dataset FormL4 for evaluating autoformalization in Lean4. The paper also proposes a framework called PDA to improve autoformalization capabilities of LLMs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The introduced dataset would be useful for LLM-based auto formalization research\n- The evaluation is comprehensive and uses human evaluation for autoformalizer performance"
            },
            "weaknesses": {
                "value": "- Line 103: One of the contributions states that - \u201cWe propose a process-driven framework PDA that leverages formal languages to provide process feedback on reasoning, enhancing the autoformalization capabilities of LLMs.\u201d \n\nThis statement is unclear. The PDA framework is specific to Lean4 and the technique or evaluation doesn\u2019t really convince me that the technique would enhance LLMs ability to autoformalize for any formal language. \n\n\n- Line 176: \u201cThe real test set is constructed by collecting natural language math questions and answers from LI et al. (2024).\u201d Can you give more information about the real test than this? What is the reason for generating this subset? Can you also give more information on the cited source.\n\n\n- Line 194: \u201cduring informalization, the provided proof steps could potentially add informative context to the preceded formal theorem statement in the prompt, hence improving informalization quality, observed both in our human evaluation results (Table 6)\u201d - How does results from Table 6 infer the observation made here? \n\n\n- Line 197: \u201c in autoformalization, the existence of proof steps also enables us to examine autoformalization performance by assessing the validity of the formalized combination of theorem statements and proof using a compiler, increasing the difficulty and granularity of autoformalization evaluation.\u201d\nIs it not possible to use the Lean4 compiler with statement + empty proof to get the compiler feedback on the theorem statement?\n\n\n- Line 201-208: It is still unclear to me what this part is inferring. One of the main contributions of the paper in comparison to prior works mentioned in Table 2, is that FormL4 consists of proofs and the primary usage is for process-driven feedback. Does this mean FormL4 dataset consists of incorrect proofs of theorems? Yet, these incorrect proofs are useful for the autoformalization task to provide better context?\n\n\n- Line 259: \u201cThe average success rate was 0.72, indicating relatively high-quality informalization performance.\u201d How do I assess that this is high-quality? Relative to what?\n\n\n\n## Minor\n\n- Line 190: typo \u201cstatemen\u201d\n- Line 229: what is \u201cscalable oversight research\u201d?\n- Line 285: replace \u201cformal language compiler feedback\u201d with just \u201ccompiler feedback\u201d or \u201cLean4 compiler feedback\u201d\n- Line 360: \u201c It provides an objective measure of progress, mitigating the potential for bias arising from isolated interactions between the autoformalizer and verifier.\u201d What is bias in this context?\n- Line 406: \u201cTo improve its performance in real-world scenarios, we further fine-tune it on successfully compiled outputs from GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021).\u201d  Compiled outputs from what? I know these as math problem datasets, in what form is this dataset used in fine-tuning?\n\n- Line 419: In section 5.1.2 how is the evaluated VEA obtained? Which verifier was used to train VEA? I can\u2019t seem to find many details regarding this evaluation\n \n- Line 427: \u201c. In contrast, VEA offers a more time-efficient approach by using predictive labels from our trained verifier, though it may not match RFT\u2019s data quality.\u201d Is this time reported in the appendix?\n- Table 6: can you describe the columns of Table 6 in the description?"
            },
            "questions": {
                "value": "Please see questions in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new benchmark and evaluation framework for autoformalization in Lean 4 called FormL4. In order to improve autoformalization ability, the authors also introduce PDA, Process-Driven Autoformalization, which uses feedback from Lean 4's interpreter."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Autoformalization is an important problem, and there is not yet a good benchmark in the literature measuring its success, so the problem this paper tackles is important and relevant\n- Incorporating execution feedback during autoformalization is a new idea\n- The method presented in the paper shows strong performance compared to off-the-shelf models.\n- The benchmark is curated with a combination of automation and manual checking."
            },
            "weaknesses": {
                "value": "- Because the dataset was constructed from LLM-based informalization, I am not convinced of the quality of the benchmark. I read Appendix F, and while the authors do run a human manual check, only a small number of samples seem to be checked. In addition, the human success rate found was only 72%, which does not seem sufficient when the samples are being used for a benchmark.\n- The PDA framework uses compiler feedback as a signal for correctness, while the final evaluation is whether the generated code compiles. Code that compiles is not necessary correct, so the final metric could potentially be misleading and not be a good measure of true autoformalization ability.\n- Mathlib theorems may require a lot of dependencies and external knowledge in order to understand. In addition, there are niche primitives in Mathlib that the model has little chance of understanding. Unless these are filtered out, this benchmark feels like it is testing knowledge of obscure Mathlib premises."
            },
            "questions": {
                "value": "- How do you ensure that all the samples in the benchmark are correct and reliable?\n- There could be many potential autoformalizations of an informal statement. How do you ensure that correct autoformalizations are marked as correct, and incorrect ones are not? Do you just use compilation? Is your method reliable, and do you have any estimations of the precision/recall of the resulting evaluation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces two main contributions to improve autoformalization (converting natural language mathematics into formal languages) for Lean 4, a modern theorem prover:\n\n1. FormL4: A comprehensive dataset containing 17k examples designed to evaluate autoformalization capabilities in Lean 4. Unlike existing datasets that only contain theorem statements, FormL4 includes both statements and their corresponding proofs in both natural and formal languages. The dataset features three test sets: random, basic (focusing on fundamental concepts), and real (derived from real-world math problems).\n2. Process-Driven Autoformalization (PDA): A novel framework that leverages detailed feedback from the Lean 4 compiler to enhance autoformalization. The framework consists of:\n    - A Process-Supervised Verifier (PSV) trained using step-level compiler feedback\n    - An iterative refinement strategy combining Rejective Sampling Fine-tuning (RFT) with a Verifier-Enhanced Autoformalizer (VEA)\n\nThrough extensive experiments, the authors aim to demonstrate that their PDA framework significantly outperforms existing approaches, with the combined RFT+VEA model showing the best performance across all test sets. The process-supervised training approach consistently outperforms outcome-supervised methods, and the authors do a human evaluation to validate the effectiveness of their approach."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Originality\n    - The core idea of using compiler feedback in a systematic way to improve autoformalization is valuable and is implemented in a novel way\n    - The attempt to create a comprehensive dataset for Lean 4 that includes both formal and informal pairs of both statements and proofs addresses an important gap in the field\n    - The process-driven approach to verification represents a new direction in autoformalization\n2. Quality\n    - The methodology for preventing formal terms from appearing in autoinformalized descriptions is well done and well documented (Appendix C)\n    - The experimental setup includes multiple meaningful test sets (random, basic, and real-world)\n    - The approach to compiler feedback integration is technically sound in concept\n    - The code and data will be made public, supporting reproducibility\n3. Clarity\n    - The overall paper structure follows a logical progression\n    - The technical writing at the sentence level is generally clear\n    - The motivation and potential impact are well articulated\n4. Significance:\n    - The paper addresses important challenges in automating formal verification:\n        - The problem of autoformalization for Lean 4 is significant and timely\n        - Using compiler feedback for training could be valuable even beyond this specific application\n        - The attempt to bridge informal and formal mathematics remains an important goal\n        - This kind of approach could reduce the burden of formal verification"
            },
            "weaknesses": {
                "value": "The strengths above are significantly undermined by:\n\n- Systematic and apparently hyperbolic misrepresentation of dataset quality\n- The lack of proper baselines and controls\n- Missing adequate qualitative analysis of failure modes\n- Serious methodological flaws in evaluation\n- Potentially misleading reporting practices\n\nSignificant concerns in detail:\n\n- L166\u2014167: Is any effort made to ensure that we don\u2019t have pairs of lemmas that are essentially the same (for example, one proving `x=y` and another proving `y=x`) which end up on different sides of the train/test split?\n- The paper seems to systematically obfuscate the quality of the FormL4 dataset.  The examples I found are:\n    - L201\u2014203 \u201cIt is important to note that translating proof steps is much more challenging than translating statements and that FormL4 does not aim at ensuring strict semantic alignment between formal and natural-language proof in our informalized output.\u201d If the dataset does not guarantee a match between the formal and natural-language proofs, this caveat should be made much earlier in the paper.  This is especially the case given how much emphasis is placed on how FormL4 is \u201crigorously quality-checked manually\u201d (L47\u201448)\n    - L205\u2014208: \u201cthe quality of FormL4 and our evaluation framework does not pertain to whether the natural-language proof perfectly corresponds to the formal proof.\u201d  This sentence does not make sense.  While the evaluation framework is based on *usefulness* of the natural-language proof to generating the formal proof, and the soundness of the evaluation is not compromised in cases where the natural-language proof does not correspond to the formal proof (and would not be compromised even if the natural-language proof were nonsense), the semantic correspondence is certainly relevant to the *quality* of the dataset.\n    - L213\u2014215: \u201c${}^5$ In practice, we observe that it is usually infeasible to perfectly translate a set of formal proofs to a natural language. This is because formal proofs are often expressed in pre-defined lemmas or environments that are exclusively constructed in the Lean 4 language, and there are no existing corresponding concepts in natural language that a non-expert in Lean 4 could easily understand.\u201d  The first sentence here is misleading, and the second sentence seems bogus.  On line 202 you say that \u201cstrict semantic alignment\u201d is not ensured, while here you say that \u201cperfect[] transl[ation]\u201d is infeasible.  Almost all tactics have a relatively-easy-to-understand description in natural language that, while perhaps imperfect, is strictly semantically aligned.  For example, you might transcribe an `auto`-like tactic by saying \u201cThis follows by combining facts x, y, and z in some order\u201d, where `x` , `y`, and `z` are the lemmas found by `auto`.  Some steps might not be worth translating (for example, `clear h` , translated as \u201cfrom this point forward, we will not make use of the fact that \u2026\u201d, might be worthless to include).  Moreover, even if tactics may be hard to describe, the proof objects generated by the tactics could certainly be translated with near perfection.\n        \n        Ultimately, the informalization should be permitted to elide details, but not to make incorrect steps; otherwise, you should drop the language that the entire dataset is of impeccable quality and restrict such claims to the alignment of statements in the dataset, while merely saying that the dataset includes potentially incorrect formal-informal proof pairs.\n        \n    - L256\u2014257: \u201cextensive manual verification\u201d is used to mean \u201c\u224870% accuracy looking at \u2248 3% of the data\u201d.  For a work involving formal verification to use \u201cverification\u201d to mean \u201cat least \u2248 2% correct\u201d is at least skirting the boundary of the code of ethics (specifically the \u201cUphold High Standards of Scientific Excellence\u201d and \"Be Honest, Trustworthy and Transparent\u201d sections), if not outright violating it.\n    - Table 14 is damning, and is buried in Appendix N\n    - L1566\u2014L1569: Where is the line for the final **baseline** model in Table 14?  What are its performance results?\n- L245\u2014247: What about the 20% of samples where Gemini failed?\n- The evaluation (cf Table 4) does not measure the right baselines and fails to establish an absence of data contamination.  A proper baseline would involve comparison with an autoformalizer trained on randomized mislabeled data from FormL4 (pairs of informal-formal that are unrelated), as well as, ideally, a comparison with the closed source models that provide fine-tuning APIs when fine-tuned to do next token prediction on the FormL4 pairs (both randomized and correctly labeled).  (Another possibility for large models is putting a couple dozen randomly chosen examples in context.). Correspondingly, L423, \u201ceffectiveness of our dataset\u201d might just be homogeneity between the train and test split.\n- Qualitative evaluation of failure modes is inadequate:\n    - L1284\u2014L1289: \u201cThe incompatibility of certain theorem statements for informalization due to their topics or settings.\u201d  What does this mean?  What are examples?  Please elaborate on this more in the text.\n    - L1284\u2014L1289: \u201cIndividual subjectivity in determining the condition constraints that need to be specified in natural language\u201d Does this mean that most human-checked informalizations were merely incomplete rather than incorrect?  Can you include numbers for completeness of informalization separately for correctness / lack of error?\n    - No examples of challenging cases or failure modes for formalization"
            },
            "questions": {
                "value": "Questions:\n\n- Figure 1 suggests that the PSV only includes information on which statement failed, not utilizing the error message from the proof assistant.  Is this right?\n- L245\u2014246: What does \u201csuccess\u201d mean in \u201cinformalization success\u201d?\n- L418-419: What are RFT and VEA?  How do they work?  This should be explained, not just referenced\n- L512-515 \u201cThose whose proof validity is true achieve significantly better autoformalization performance.\u201d. I am very confused by this paragraph.  What is the difference between \u201cproof validity\u201d (whether the sample passes the Lean 4 compiler\u201d) and \u201cautoformalization performance\u201d (whether or not the sample generated by the autoformalizer was a valid proof?)?  Is the difference that the latter also includes human evaluation of whether the formalized proof is faithful to the informal proof sketch?  Or is it only about faithfulness to the informal proof sketch and does not include proof validity?\n\nComments: \n\n- It might be better to use \u201cverifier model\u201d instead of \u201cverifier\u201d to better disambiguate between the Lean compiler and the PSV model.  I was confused, for example, at L361\u2014362 \u201cmitigating the potential for bias arising from isolated interactions between the autoformalizer and the verifier\u201d before realizing that \u201cthe verifier\u201d meant the PSV model.\n- Table 4 and especially the discussion of synergistic benefits is lacking a test of statistical significance.\n- L504: \u201cin 12\u201d what is 12?\n- The end of section 5 could do with some rewording.  \u201cFactorial Design\u201d has nothing to do with the factorial function, \u201cinvestigate whether the following variable changes will impact model [\u2026] performances\u201d (L495\u2014496) makes it sound like you're doing interventions rather than factor analysis, it's not clear how \u201cTest Set Categories\u201d is varied when doing factor analysis, and it should have a consistent name rather than changing to \u201cDataset Split\u201d on L523.\n- Section 6 needs significant rewording; I include minor comments below, but most egregiously, the second sentence (describing FormL4\u2019s focus) seems to be confusing the dataset with the PDA method.\n- L418\u2014419: RFT and VEA should be explained, not just referenced\n\nMinor comments:\n\n- L141: Tense mismatch in \u201cExisting datasets [\u2026] aims to create\u201d\n- L176\u2014177: \u201cLI et al.\u201d seems miscapitalized?\n- L190\u2014191: \u201cStatemen\u201d is missing a \u201ct\u201d at the end\n- L194\u2014195: \u201cpreceded\u201d \u21d2 \u201cpreceding\u201d\n- L195\u2014196: \u201c[\u2026] informalization quality, observed both [\u2026]\u201d this sentence is run-on, consider splitting it at the \u201c,\u201d\n- L326: the equation should not have a `[ht]` figure specifier.\n- L491: \u201cfalls short of even empowered\u201d incorrect grammar\n- L493: \u201csyntactically true\u201d \u21d2 \u201csemantically valid\u201d or \u201csemantically meaningful\u201d.  Unlike Python or C, a theorem statement in Lean that compiles is more than just syntactically valid.\n- L519\u2014520: \u201cthan due to their\u201d is missing a word\n- L533 \u201cdrive\u201d \u21d2 \u201cdriven\u201d\n- L534\u2014536: incorrect use of comma to join two clauses with different subjects in \u201cUnlike the existing dataset focuses, FormL4 focuses on tapping\u201d; \u201cfocuses\u201d is used as a noun in the first clause but a verb in the second clause, and hence the sentence is comparing the focuses of existing datasets to the dataset FormL4.\n- L536 \u201cstatement\u201d \u21d2 \u201cstatements\u201d\n- L537 \u201cLean 4 compilers\u201d \u21d2 \u201cthe Lean 4 compiler\u201d\n- L539: you could include Agda as well.  Unlike the other proof assistants, proof terms are generally given directly and in full rather than using tactics.\n- L1005\u20141008: You\u2019re underselling FormL4 by describing it just as a way to keep up with changes in Lean.  Either that, or you\u2019re drastically overselling it in the main body.\n- L1011 \u201cLean 4\u2019s syntax\u201d should maybe be \u201cLean 4\u2019s tactics\u201d?  Not sure.\n- L1073\u2014L1074: you used `'` instead of ``` to start a quotation (twice)\n- L1101\u20141102, L1110-1111: Does the prompt actually inconsistently capitalize \u201cLean\u201d?\n- L1203\u20141204: \u201ctheir proof\u201d \u21d2 \u201ctheir proofs\u201d\n- Section E.1: It is not clear what text is verbatim from your prompting and what text is descriptive for readers of the paper.  Presumably \u201cyou\u201d in E.1.2 does not refer to the reader.\n- L1310\u20141311, L1470\u20141471 you use `'` instead of ``` to start a quotation\n- L1427\u20141428: Perhaps you should say \u201cLean 4\u2019s compilation times are a bottleneck\u201d instead of claiming that \u201cthere is significant room for improvement\u201d, unless you know enough about proof assistant performance engineering to know that the performance improvement times you\u2019re claiming are, in fact, possible.\n- L1439\u20141440: Probably you want `\\textsc{FormL}4` instead of `FORML 4`\n- L1507: check capitalization of \u201cMinif2f\u201d\n- L1690: you should get rid of the negative vspace, the text is overlapping the table\n- You should make sure you're consistent (and correct) about using \u201cLean 4\u201d vs \u201cLean4\u201d (L1651, L217, L219, L492, L498, etc)\n- If you want to, you can get small caps in the pdf bookmarks ToC by replacing the section heading (L1512) of `Analysis for Training and Test Data in FormL4` with `Analysis for Training and Test Data in \\texorpdfstring{\\textsc{FormL}4}{F\u1d0f\u0280\u1d0dL4}`  (and similarly with Appendix P.3)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a novel approach to autoformalization\u2014the automatic translation of mathematical text into formal language\u2014by creating a new dataset and framework specifically for Lean 4. The dataset, FORML4, includes both formal and natural language versions of mathematical statements and proofs, enabling a comprehensive evaluation of large language models (LLMs) in autoformalization tasks for Lean 4. The authors also propose the Process-Driven Autoformalization (PDA) framework, which iteratively improves model performance through Lean 4 compiler feedback. By incorporating a Process-Supervised Verifier (PSV) that identifies specific errors in the formalization process, the PDA framework enhances the semantic accuracy of formal translations. Experiments demonstrate that this approach boosts performance and data utilization efficiency. FORML4 and PDA together aim to push forward formal language generation quality and adaptability in mathematical reasoning tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. It creates a unique Lean 4 dataset (FORML4) with statements and proofs for comprehensive model evaluation.\n2. The proposed approach PDA shows some improvements and also helped with the dataset."
            },
            "weaknesses": {
                "value": "I do not see significant weaknesses."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}