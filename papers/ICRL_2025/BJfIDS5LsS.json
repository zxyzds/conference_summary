{
    "id": "BJfIDS5LsS",
    "title": "MASIMU: Multi-Agent Speedy and Interpretable Machine Unlearning",
    "abstract": "The regulatory landscape around the use of personal data to train AI/ML models is rapidly evolving to protect privacy of sensitive information like user locations or medical data and improve AI trustworthiness. Practitioners must now provide the capability to unlearn or forget data---the forget set---that was used to train an AI model, without triggering a full model re-train on the remaining data---the retain set to be computationally efficient.  Existing unlearning approaches train via some combination of fine-tuning pre-trained AI models solely on the retain set, pruning model weights then unlearning, and model-sparsification-assisted unlearning. In our research paper, we use deep learning (DL), multi-agent reinforcement learning (MARL) and explainable AI (XAI) methods to formulate a faster, more robust and interpretable unlearning method than past works. Our method, multi-agent speedy and interpretable machine unlearning (MASIMU), fine-tunes a pre-trained model on the retain set, interpretably re-weighting the gradients of the fine-tuned loss function by computing the similarity influences of the forget set on the batched retain set based on weights generated by an XAI method.  We add a MARL framework on top to address the challenge of high dimensional training spaces by having multiple agents learning to communicate positional beliefs and navigate in image environments. The per-agent observation spaces have lower dimensions, leading to the agents focusing on unlearning interpretable gradients of important superpixels that influence the target labels in the learning criteria.  We provide extensive experiments on four datasets---CIFAR-10, MNIST, high resolution satellite images in RESISC-45, skin cancer images in HAM-10000 to unlearn for preserving medical privacy---computing robustness, interpretability, and speed relative to the dimensionality of the training features, and find that MASIMU outcompetes other unlearning methods.",
    "keywords": [
        "multi-agent",
        "unlearning",
        "interpretable",
        "faster",
        "robust",
        "MASIMU",
        "LIME",
        "reinforcement learning",
        "explainable AI",
        "XAI"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "Multi-Agent Speedy and Interpretable Machine Unlearning is a novel AI privacy framework for sensitive information, which is faster with multiple agents reducing the observation space per agent and interpretable with LIME XAI method.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=BJfIDS5LsS",
    "pdf_link": "https://openreview.net/pdf?id=BJfIDS5LsS",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces Multi-Agent Machine Unlearning (MAMU), a multi-agent framework for machine unlearning, which aims to remove specific data points from trained models without complete retraining. The framework uses multiple agents that work collaboratively using recurrent neural networks (RNNs) to traverse and process images. The authors present four variants of their framework: MALMU (LSTM-based), MASMU (GRU-based), and their interpretable counterparts MALIMU and MASIMU. The approach is evaluated on high-dimensional data like images, examining both unlearning speed and model accuracy on retained data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Unlearning is an important field, which will be necessitated as privacy regulations and \"right to be forgotten\" requirements become more prevalent in real-world ML applications\n- The approach of using MARL for unlearning is (to my knowledge at least) novel\n- Evaluations cover a wide variety of datasets, including medical"
            },
            "weaknesses": {
                "value": "- There is no dedicated related work section, and the introduction itself is quite bare. I recommend adding an explicit related work section\n- There is no comparison to existing state-of-the-art unlearning methods making it impossible to evaluate the claimed advantages of MASIMU in the context of current unlearning literature\n- Results do not include statistical significance tests, and performance metrics are quite close in many cases, leading to uncertainty about whether the proposed method offers meaningful improvements over baselines"
            },
            "questions": {
                "value": "- **Line 254**: Apart from the unlearning reweighing, how is your method different from Mousavi et al., 2019a? The multi agent algorithm you are using seems to be theirs, so I would not claim novelty\n- **Line 379**: Which results in this table are statistically significant? Also the presentation of this table could be improved e.g. is lower or higher better for MIA / COMP\n- **Line 401**: It's not obvious the value of plotting the accuracy / loss curves in the main paper. This would be better left for the appendix and would provide room for a proper related works section\n- **Line 433**: Similarly to table 1, presentation in this table is poor. On its merits, it lacks statistical significance, and the results look very close to each other. Which results are statistically significant?\n- **Line 461**: Similarly here the unlearning accuracy and loss plots do not provide much value. What are you trying to show by providing these plots in the main paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces MASIMU, a framework aiming to enhance the efficiency, robustness, and interpretability of machine unlearning processes in deep learning models. The authors propose a method that purportedly outperforms existing unlearning approaches by integrating deep learning, multi-agent reinforcement learning (MARL), and explainable AI (XAI) techniques. The framework is evaluated on four datasets: CIFAR-10, MNIST, RESISC-45, and HAM-10000 to demonstrate its effectiveness in handling high-dimensional data and sensitive information."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper addresses the timely and significant issue of machine unlearning in the context of evolving privacy regulations and AI trustworthiness, which is crucial for applications involving sensitive data.\n2. The attempt to combine deep learning, MARL, and XAI reflects an interdisciplinary approach, showcasing an effort to tackle the unlearning problem from multiple angles.\n3. The use of various datasets, including high-resolution and medical images, indicates an effort to validate the method across different domains and data types."
            },
            "weaknesses": {
                "value": "1. It is unclear whether the authors conducted a comprehensive literature review of current state-of-the-art machine unlearning techniques [1-3]. Specifically, how does MASIMU differentiate itself from or improve upon existing methods? Additionally, the manuscript fails to provide comparisons between the MASIMU framework and other state-of-the-art machine unlearning techniques. Without such comparative analyses, it remains ambiguous whether MASIMU offers any substantive improvements. Why have the authors not conducted quantitative comparisons with other advanced machine unlearning methods? How does MASIMU perform in terms of efficiency, effectiveness, and scalability relative to these existing methods?\n\n2. It is a recognized standard in machine unlearning research to use retraining as the benchmark for unlearning performance [1-5]. However, the paper does not provide such baseline results for reference.\n\n3. The inherent trade-off between the ability to retain knowledge and the level of residual information pertaining to the forgotten data is not addressed. An in-depth discussion on this relationship would enhance the understanding of the proposed method\u2019s effectiveness.\n\n4. While the paper highlights the incorporation of LIME to achieve interpretability within the MASIMU framework, it lacks specific statistical explanations detailing this interpretability within the unlearning context. How does LIME's integration specifically enhance the interpretability of the unlearning process in MASIMU? The inclusion of visualizations or case studies demonstrating this interpretability and its benefits to the unlearning process would be valuable.\n\n5. The paper does not provide a theoretical basis or analysis to underpin the proposed method. Critical components, such as the integration of MARL and XAI in the context of machine unlearning, are not theoretically justified. What is the theoretical foundation of the MASIMU framework? Can the authors provide theoretical proofs or analyses to substantiate claims regarding the improved efficiency, robustness, and interpretability of their approach?\n\n6. The manuscript suffers from writing issues, including grammatical errors and unclear explanations, which hinder the reader's comprehension of the proposed method and its contributions. The figures are difficult to read (Fig. 3 and 4), and there are duplicate citations (e.g. 570-572). Have the authors conducted a thorough revision to improve the clarity and coherence of the paper? Additionally, could the authors consider reorganizing the structure to present the methods and results in a more logical and clear manner?\n\n7. The analysis of experimental results is insufficient, as it lacks comparisons with relevant baselines and detailed discussions on the evaluation metrics used. Important details such as hyperparameter settings and statistical significance are omitted. Furthermore, the authors have not provided the source code, which would facilitate implementation and further validation of their work.\n\n> [1] Fan, Chongyu, et al. \"SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation.\" The Twelfth International Conference on Learning Representations.\n> \n> [2] Liu, Jiancheng, et al. \"Model sparsity can simplify machine unlearning.\" Advances in Neural Information Processing Systems 36 (2024). \n> \n> [3] Kurmanji, Meghdad, et al. \"Towards unbounded machine unlearning.\" Advances in neural information processing systems 36 (2024).\n> \n> [4] Golatkar, Aditya, Alessandro Achille, and Stefano Soatto. \"Eternal sunshine of the spotless net: Selective forgetting in deep networks.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n> \n> [5] Thudi, Anvith, et al. \"Unrolling sgd: Understanding factors influencing machine unlearning.\" 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P). IEEE, 2022."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces MASIMU, a framework that combines machine unlearning (MU) with a multi-agent reinforcement learning (MARL) setup for improved efficiency and interpretability. The method relies on two components. First, it leverages an interpretable AI (XAI) method to weight gradients based on the influence of data marked for removal (forget set) and their similarities to the retain set. Second, the authors introduce a multi-agent reinforcement learning (MARL) framework, in order to effectively manage high-dimensional data by having multiple agents communicate positional information and navigate image environments; this setup reduces each agent's observation space, allowing them to focus on unlearning critical gradients associated with key super-pixels that impact target labels. The authors performs experiments on MNIST, CIFAR-10, RESISC-45 (satellite images), and HAM-10000 (skin cancer images) and evaluate MASIMU\u2019s performance in terms of robustness, interpretability, and speed."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The core ideas introduced by the authors are original and interesting:\n- Utilizing a XAI method (LIME) to compare the similarities of the retain and forget samples and weight gradients accordingly is compelling, and might be able to improve unlearning benchmarks, as well as our understanding of it.\n- The MARL framework proposed to reduce the input dimension and focus agents on unlearning interpretable gradients of important superpixels is also an interesting approach.\n- The authors use various metrics in their evaluations (time, completeness, MIA) that go beyond the standard ones used."
            },
            "weaknesses": {
                "value": "My main concerns about the paper are the following:\n- Presentation: it's very challenging to fully understand the methods used and all its components. \n- Experiments: it seems that the comparisons are only between a baseline and variations of the framework introduced. I'd like to see how MASIMU performs against other state-of-the-art unlearning techniques. \n- Complexity of the framework: the MARL approach introduced has a lot of complexity and computational overheads, raising questions about the generalizability of the approach on other settings. \n- Vision-only: could the framework be extended to handle non-vision (for example language) tasks? If so, how?"
            },
            "questions": {
                "value": "My questions are based on the weaknesses mentioned and how they could be improved: \n- Is it possible to improve the presentation? E.g. give the high level ideas about the framework choices (why LIME?, why MARL?, what are the motivations?), figures and high-level descriptions about the approach, and clarifying various parts of the text and the algorithms. Ideally, the reader should be able to follow along the paper easily, and the techniques introduced should \"make sense\" to them.\n- Can we add experiments of MASIMU against other state-of-the-art (SOTA) unlearning techniques?\n- Can the authors address the question about the generalizability of their approach? How hard is it to make it work on a different setup, against the SOTA? How carefully should the hyper-parameters be chosen, and how big is the effort to do so?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a new method Multi-Agent Speedy Interpretable Machine Unlearning\n(MASIMU) for efficiently \u201cunlearning\u201d data from AI models, essential for privacy compliance\nwithout requiring complete model retraining. This approach combines deep learning,\nreinforcement learning, and explainable AI(LIME) to remove specific data influences. It\nfine-tunes a model on the retain set while re-weighting gradients to diminish the impact of data\nneeding removal (the forget set). By using multiple agents with reinforcement learning, MASIMU\nbreaks down complex image data into smaller, manageable parts, allowing faster and more\ninterpretable unlearning. This method has shown good performance in speed, robustness, and\ninterpretability across various datasets, including CIFAR-10, MNIST, and sensitive medical\nimages."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The authors have formulated a critical, state-of-the-art problem in AI by proposing a\nmethod focused on enhancing trustworthiness and safeguarding the privacy of data.\n2. The proposed method described in this paper is clear and easy to follow for\nreproduction.\n3. The MASIMU framework incorporate a multi-agent system to divide the unlearning tasks\namong agents, which allows for faster processing and more manageable handling of\nhigh-dimensional data"
            },
            "weaknesses": {
                "value": "1. Since machine unlearning is not entirely a new concept, the author should compare the\nresults with at least one or more existing works that are similar, such as \"SALUN:\nEmpowering Machine Unlearning via Gradient-Based Weight Saliency in Both Image\nClassification and Generation,\" published in ICLR 2024.\n2. The results presented in the paper do not sufficiently support the authors' claims. To\nstrengthen their findings, they should consider using well-known datasets like ImageNet\nto demonstrate the effectiveness of their method. Additionally, including qualitative\nexamples of the model's behavior regarding the forgotten image set would enhance\nclarity and impact.\n3. A well-structured and state-of-the-art literature review on existing works in machine\nunlearning is missing from the paper.\n4. What is the motivation for performing machine unlearning on the selected datasets? i) You can easily train a new model within a few minutes or hours. ii) None of the datasets have an intuitive application to machine unlearning. Why not report results on the same dataset as the 2023 contest that the authors cite?"
            },
            "questions": {
                "value": "There was a contest on this topic in 2023 at NeurIPS. Why have you not compared against those solutions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}