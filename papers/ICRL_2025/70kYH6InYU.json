{
    "id": "70kYH6InYU",
    "title": "Intelligent Control in Embodied Robotics: Enhancing Human-Robot Interaction through Adaptive Control Techniques",
    "abstract": "Current embodied intelligence models often lack the ability to adjust control methods dynamically in response to human intentions, limiting their effectiveness in real-world interactions. This paper proposes a novel framework that enables robots to dynamically adapt their control parameters by integrating large language models (LLMs) with intelligent controllers. \nOur approach simulates human-robot interactions and generates synthetic training data, allowing robots to better understand and respond to diverse human needs. We validate the framework using two commonly used control techniques and demonstrate that it can effectively adjust control methods, such as Proportional-Integral-Derivative (PID) and Nonlinear Model Predictive Control (NMPC), based on real-time human feedback. Experimental results show that our model enhances adaptability and responsiveness in human-robot interaction.\n This work advances embodied intelligence by introducing an adaptive control framework and providing a scalable method for data generation, which together enable more intuitive and effective robot behaviors.",
    "keywords": [
        "Embodied Intelligence",
        "Large Language Models (LLMs)",
        "Human-Robot Interaction",
        "Adaptive Control",
        "Data Amplification"
    ],
    "primary_area": "applications to robotics, autonomy, planning",
    "TLDR": "This paper enables robots to adaptively adjust control methods for smarter human interactions.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=70kYH6InYU",
    "pdf_link": "https://openreview.net/pdf?id=70kYH6InYU",
    "comments": [
        {
            "summary": {
                "value": "The problem and motivation is well framed and well known and the idea of parameterize the control parameters with human feedback is relevant. However, from the motivation of using LLMs to produce parametrized control to the results obtained do not \"Conclusion.The experimental results demonstrate that the proposed framework is capable of training intelligent models that can fine-tune various robotic control methods across diverse environments to meet human requirements.\" This works looks interesting as a method for tuning controllers with natural language, but it is way far from embodied intelligence and empathy keywords that are described in the paper."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* Clear and sound motivation\n* Continuous control parametrized by language"
            },
            "weaknesses": {
                "value": "* LLM analysis is missing\n* Parametrization is not well described. Provide the parameters used in each controller and their definition.\n* Empathy is not provided to the robot. In such a case, perceived empathy, but I doubt it.\n* Promising direction. While the authors talk about using the method for more complex controllers, the challenging direction is to produce more complex behaviours."
            },
            "questions": {
                "value": "How the human knows the reference control parameters?\n\nPlease provide a clear description of this: \"Prompt model M to understand the relationship between control parameters and feedback\"\n\nCould you provide a better analysis of the method and not only two exemplary cases. (the appendix gives more information on how it works than the methods section.\n\nWhat is the LLM architecture backbone?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "However, Safety in using human input in natural language for a critical control plant should be addressed."
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes using a prompting mechanism with a large language model (LLM) to fine-tune parameters of two control algorithms to align with human preferences. It attempts to introduce \"empathy\" as a guiding concept in algorithmic adjustments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Uses LLMs, a current trend, which may attract interest.\n2. Provides a rudimentary exploration of aligning algorithm outputs with user preferences."
            },
            "weaknesses": {
                "value": "I think works lack novelty. Using a large language model (LLM) to adjust control parameters based on human preferences is a repurposing of existing techniques rather than a novel concept. Human-in-the-loop control systems and preference-based tuning have been well-explored, making this approach more about applying known methods than advancing new knowledge. It doesn't break new ground conceptually, which is crucial for meaningful research contributions.\n\nThe paper then introduces empathy as a goal without a clear definition or a rigorous way to measure it in a control context. Empathy is not inherently quantifiable in control algorithms, and this lack of clarity makes the problem ill-suited for rigorous scientific investigation. While this might offer an interesting discussion for a student project, research demands concrete metrics and definitions, which this project does not provide. The use of this term seems more like a buzzword than a meaningful contribution.\n\nWithout a specific, compelling application or demonstrable impact, this type of control tuning has limited relevance. The problem is more theoretical than practical, with no strong justification for why fine-tuning to human preferences adds substantial value or solves a pressing issue. This scope is acceptable for student exploration but lacks the depth and relevance expected in publishable research.\n\nI also find some vagueness in methodology: How human preferences are generated and quantified is unclear. The authors do not provide a rigorous methodology for capturing, validating, or generalizing these preferences. This makes the approach seem arbitrary and undermines reproducibility."
            },
            "questions": {
                "value": "How were human preferences quantified, and what criteria were used to validate these preferences?\nWhat concrete advantages does this approach offer over traditional or established methods in adaptive control?\nCan the authors clarify the role of \"empathy\" in this study? How does it translate to actionable parameters in control algorithms?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel framework to realize  human-in-the-loop improvement of robot behavior by allowing robots to dynamically adjust their control strategies based on real-time human feedback. \nThe framework utilize large language models (LLMs) and adaptive control methods.\n By using LLMs for simulated data generation, it achieves a new type of personalized human-robot interactions.\nThe method is combined with PID and NMPC control.\nThe performance was tested using a simple robot system,"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper innovatively uses LLMs to adapt control parameters for low-level robot control, whereas most LLM applications in robotics focus on high-level planning. This novel approach to using LLMs for low-level controller adjustment represents a significant contribution.\n- The proposed framework enables real-time personalization, offering a fresh and promising approach to human-robot interaction."
            },
            "weaknesses": {
                "value": "- he framework has been tested primarily in simulated and simplified environments, demonstrating only preliminary validation of the proposed concept. The paper lacks testing in realistic robotic scenarios, which limits the strength of evidence supporting its practical applicability."
            },
            "questions": {
                "value": "<Major Comments>\n1. How can this framework be extended and validated for more complex and realistic robotic scenarios?\n2. The advantages of using LLMs for parameter tuning over active exploration methods (like Bayesian optimization) need to be better demonstrated.\n\n\n\n<Minor Comments>\n1. Several parentheses are missing throughout the text, for example:\n   - \"worldPfeifer & Iida, 2004 (Line 32)\n   - \"layersFigure 1 (Line 53)\n\n2. Figure 1 depicts low-level control based on position control. For real-world applications, dynamic aspects such as force-based and velocity-based control are crucial. Given the citations of Pfeifer et al.'s work, the paper should address dynamics and morphological computation.\n\n3. Figure 5 appears distorted.\n\n4. The definition of I (information) lacks clarity.\n\n5. Figures 6 and 7 have illegible legends."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the challenge of enabling robots to dynamically adapt their low-level control parameters in response to human intentions\u2014a limitation in current embodied intelligence models. The authors propose a framework that uses large language models (LLMs) to directly optimize controller parameters while keeping human feedback in the loop as text prompts to the LLM.\n\nThe authors demonstrate the framework on two classic controllers\u2014PID and Non-Linear MPC\u2014on a robot car, showing that the proposed framework is capable of outputting and optimizing low-level controls that match human commands/preferences."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "**Originality:**\n\n- The paper focuses on translating high-level commands to low-level control using LLMs in the domain of human-robot interaction, which is a novel topic in recent years.\n\n**Quality:**\n\n- The paper conducts full experiments on two types of controllers on a physical robot, with quantitative data analysis demonstrating that the proposed framework is capable of optimizing robot controllers given human feedback.\n\n**Clarity:**\n\n- The use of diagrams and figures helps explain the proposed framework and the overall challenge of translating high-level commands to low-level control, highlighting why the problem is important.\n\n**Significance:**\n\n- The paper tackles the significant issue of adaptability in low-level robot control, which is crucial for enhancing human-robot interaction."
            },
            "weaknesses": {
                "value": "**Originality:**\n\n- Although the topic is novel, there are several established approaches that bridge the gap between high-level commands and low-level control through the use of large language models (LLMs) on low-level controllers, making the authors' work not entirely new.\n    - **Yu, Wenhao, et al. \"Language to rewards for robotic skill synthesis.\" *arXiv preprint* arXiv:2306.08647 (2023):**\n        - This paper introduces a framework in which LLMs translate natural language instructions into reward functions. These functions are then optimized by a motion controller (e.g., RL or MPC) to generate low-level control actions, demonstrating complex skills like making a robotic dog perform a handstand or a moonwalk.\n    - **Ma, Yecheng Jason, et al. \"Eureka: Human-level reward design via coding large language models.\" *arXiv preprint* arXiv:2310.12931 (2023):**\n        - This paper introduces a framework that translates natural language commands into reward functions, with a focus on robot skill acquisition via reinforcement learning (RL) rather than on optimizing PID or MPC for human-robot interaction.\n    - While the current paper\u2019s approach is unique in that it directly prompts LLMs to output control parameters in textual form (as opposed to using an intermediate reward function), it still overlaps with previous work in that both approaches translate high/mid-level commands to low-level control through LLMs.\n        - The authors could mention this existing work and clarify their approach\u2019s uniqueness by emphasizing the absence of an intermediate reward representation.\n        - They might also find inspiration in similar works that employ LLMs as optimizers, such as:\n            - **Yang, Chengrun, et al. \u201cLarge Language Models as Optimizers.\u201d *arXiv preprint* arXiv:2309.03409 (2024):**\n                - This work uses LLMs iteratively to generate solutions for optimization tasks, like linear regression and the traveling salesman problem, by updating prompts to improve solutions, which could offer useful insights for the authors.\n\n**Quality:**\n\n- The integration of LLMs with control algorithms is insufficiently detailed. It is unclear how the LLM processes human feedback and translates it into control parameter adjustments. Specifically:\n    - From the conversation example in the appendix, it can be inferred that the LLM outputs control parameters directly in text form, with human preferences/instructions added to the prompt. However, this is not clearly explained in the main article.\n    - To improve clarity, the authors could create or update diagrams that illustrate the human-interaction schema, clarify data modalities at each step, and provide examples of human commands.\n- The human commands used in experimental validation are limited to simple dynamics (e.g., \u201cspeed up,\u201d \u201creduce fluctuation\u201d).\n    - This is inferred from the example in the appendix, as the authors did not describe the types of human commands/preferences used in the experiment.\n        - They could provide more examples of human-robot interaction or include more detailed system architecture diagrams.\n    - The focus on simple dynamics like \u201cspeed up\u201d is problematic, as these are common optimization objectives. It remains unclear whether the optimization is genuinely guided by human preferences or if it is merely performing basic optimization tasks.\n        - This argument would be strengthened if the authors demonstrated uncommon objectives like \u201cspin around\u201d or \u201cmove in a zigzag motion.\u201d\n- The paper does not quantitatively compare the proposed method against existing approaches, making it difficult to evaluate the contributions' significance.\n- The paper mentions robot empathy but does not define what empathy means in this context or provide quantitative measurements and evaluation.\n    - Based on the work described, it appears the authors interpret empathy as the robot's ability to adjust control output based on human feedback. However, empathy as a concept is broader (encompassing emotion, theory of mind, etc.).\n    - A clear, limited definition of empathy would strengthen the paper.\n\n**Clarity:**\n\n- The paper discusses broad topics such as embodied intelligence and human-robot interactions, which may be too general and not directly relevant to the work presented.\n    - Based on the actual experiment, the authors could consider limiting the scope to focus on translating mid-level commands to controller output and optimizing with LLMs based on human preferences. They could also discuss background and related work specifically in this area in the introduction section, rather than broadly covering topics like embodied intelligence, human-robot interaction, and empathy.\n- The authors should clarify which LLM model they are using, and what techniques (e.g., prompt engineering, fine-tuning) are applied. Adding these details, with citations, would improve clarity.\n- The paper lacks sufficient details and examples of the types of human commands/preferences being incorporated.\n- Several parts of the paper are unclear, with grammatical errors and missing space characters. Examples include:\n    - \"thus Enhancing Robots\u2019 Empathy(ERE).\"\n    - \"layersFigure 1\"\n    - \"physical worldPfeifer & Iida (2004)\"\n- Section titles like \u201cDifficulties\u201d and \u201cProblem\u201d could be more specific.\n- Including a \"Conclusion\" section within the \"Related Work\" section is unusual and could be reconsidered.\n\n**Significance:**\n\n- Although using LLMs to adapt low-level control parameters is promising, the experiments in the paper are relatively simplistic and may not convincingly demonstrate the practical significance of the proposed method. The tasks used for validation\u2014such as adjusting simple dynamics in a robotic car\u2014are basic and do not fully showcase the potential benefits of the approach in more complex or real-world scenarios. This limits the ability to assess how the method would perform in more complex and uncertain settings, which are common in practical human-robot interactions.\n- Without quantitative comparisons with existing methods, it is challenging to evaluate the significance of the proposed approach.\n- The paper does not sufficiently discuss how the proposed framework could generalize to other types of robots, control methods, or tasks beyond the one tested. Without demonstrating broader applicability, the significance of the work may be limited to niche applications.\n- Since the paper emphasizes improving human-robot interaction and robot empathy, the absence of user studies or evaluations involving human participants is a significant gap."
            },
            "questions": {
                "value": "- Could the authors provide more detailed explanations or examples of how the LLM processes human feedback and adjusts control parameters? Specifically, how does the LLM interface with the control algorithms? What types of human feedback and commands are being used besides the one provided in the appendix? Can the authors provide an overall description?\n- Have the authors considered conducting experiments with more complex robots and on more challenging tasks?\n- Can the authors perform human evaluation studies to see how well the proposed framework addresses human feedback/intention and how well it improves robot empathy?\n- How does the proposed method compare quantitatively with existing approaches that address adaptability in robot control and translate high-level commands to low-level control? Including such comparisons would strengthen the evaluation.\n- What are the computational requirements of integrating LLMs into low-level control tasks? How does the method ensure real-time performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}