{
    "id": "mNVR9jJYqK",
    "title": "DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing",
    "abstract": "We introduce DRESS, a novel approach for generating stylized large language model (LLM) responses through representation editing. Existing methods like prompting and fine-tuning are either insufficient for complex style adaptation or computationally expensive, particularly in tasks like NPC creation or character role-playing. Our approach leverages the over-parameterized nature of LLMs to disentangle a style-relevant subspace within the model's representation space to conduct representation editing, ensuring a minimal impact on the original semantics. By applying adaptive editing strengths, we dynamically adjust the steering vectors in the style subspace to maintain both stylistic fidelity and semantic integrity. We develop two stylized QA benchmark datasets to validate the effectiveness of DRESS, and the results demonstrate significant improvements compared to baseline methods such as prompting and ITI. In short, DRESS is a lightweight, train-free solution for enhancing LLMs with flexible and effective style control, making it particularly useful for developing stylized conversational agents. Codes and benchmark datasets are available at https://anonymous.4open.science/r/DRESS-LLM.",
    "keywords": [
        "Large Language Models",
        "Stylized Question-Answering",
        "Representation Editing"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=mNVR9jJYqK",
    "pdf_link": "https://openreview.net/pdf?id=mNVR9jJYqK",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces DRESS, i.e., Disentangling Representation Editing in Style Subspace, a new approach for generating stylized responses from Large Language Models (LLMs) via representation editing. The core idea is to disentangle and edit within style-relevant subspaces of the LLM's representation space, enabling training-free style adaptation while preserving semantic meaning. Empirical results on the curated benchmark show that DRESS outperforms baselines including prompting, SFT, and other representation editing approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed approach is well-motivated and intuitive. The approach has clear advantages over previous methods such as prompting and SFT.\n- The training-free approach achieves superior performance compared to supervised fine-tuning, which shows the effectiveness of DRESS.\n- The paper\u2019s writing and presentation are clear and easy to follow."
            },
            "weaknesses": {
                "value": "- The dataset construction process heavily relies on GPT-4 to collect the stylized responses, which could be limited and biased with GPT-4\u2019s capability.\n- The evaluation benchmark only considers two language styles, one for each language. This can be quite limited as it is not clear whether the approach can be well generalized to other styles.\n- The evaluation task and the use case discussed in this work are also limited. The paper solely focuses on the stylized QA task. However, the effectiveness of style transfer or editing techniques should be proven under more realistic settings, such as conversation and more general user-AI interactions.\n- The paper only applied Qwen-1.5-14B-Chat as the base LLM. It\u2019s not clear whether the improvement and the conclusions can be generalized to other LLMs, such as LLaMA."
            },
            "questions": {
                "value": "- For the SFT baselines, have the authors also considered applying full finetuning? What would be the performance?\n- Have the authors tried to apply the approaches to other sizes of LLMs? For example, what would be the results when you apply DRESS to a 7B/8B LLM?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduce DRESS, a new method for making LLMs generate answers in specific style without need training. Main contributions:\n* Propose style subspace editing technique that find and modify specific parts of LLM representations to control output style\n* Use 3 key techniques: attention head filtering, style subspace filtering, adaptive editing strength\n* Create 2 benchmark datasets (Shakespeare-style English, Dream of Red Chamber-style Chinese) for testing stylized QA\n* Show better results than previous methods like prompting, fine-tuning, etc."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The proposed approach is novel, interesting and intuitive, instead of traditional prompting/fine-tuning, they find and edit \"style subspace\" in LLM representations. This is more efficient because no training needed\n* The paper has good theoretical foundation, they use concepts like orthogonality of representations and attention head functions to justify their method\n* Implementation details are clearly presented in the paper, they explain exact math formulas and algorithms, make it easy to reproduce\n* This paper conducted comprehensive experiments, which test on 2 very different language styles (English + Chinese), compare with strong baselines, use multiple evaluation metrics. The results look convincing, both automatic metrics and GPT-4 ratings show clear improvements over baselines"
            },
            "weaknesses": {
                "value": "* Need more analysis why method work better, authors show good results but don't explain deeply why style subspace editing is better than other approaches\n* Some technical terms not explained well - like \"style-relevant subspace\", \"adaptive editing strength\" - need more intuitive explanation\n* There are limited style types tested, only try 2 literary styles, should test more modern styles like formal/casual, different emotions, etc.\n* Lacking of through discussion of limitations\n* This paper's ablation studies are not enough - should test each component (attention filtering, subspace filtering, adaptive editing) separately to show importance"
            },
            "questions": {
                "value": "Have you tried methods similar to knowledge editing?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Stylized generation to reference style is an important problem in language generation. This paper introduces a new approach for stylized generation with LLM that differs from prompting and fine-tuning based approaches. To ensure that the generation quality is not compromised in the pursuit of stylized generation, the paper introduces the notion of steering vectors that is learnt by filtering the appropriate attention head that controls the style aspects of the generation and filtering the irrelevant style subspaces to minimize the impact on semantics while maximizing the impact on style. To evaluate the approach, the paper further introduces 2 benchmarks: Shakespeare style English QA and Dream of Red Chamber styled Chinese QA."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The approach is interesting and builds on top of existing works. There is a lot of value to the solution and the extensive evaluation is impressive."
            },
            "weaknesses": {
                "value": "Given the problem is being tackled by several researchers over the past few years, I would have loved to see more details on the \"data hunger\" of the proposed approach. For e.g., a prompting based approach requires only a few samples and if the current approach is only marginally better than that in qualitative comparisons, the value might be ambiguous. To this end, I would like to see a bit more detailed comparison along the lines of the data needs - which is critical to extend to low-resource style adaptation cases."
            },
            "questions": {
                "value": "Seen the weakness section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces an approach for style transfer. The main motivation is to learn a style-relevant subspace, and then project the common language model space to this space to enable stylized response. This work is similar in spirit to different model editing papers for knowledge editing. The only difference is that here the style is more or less an implicit form of knowledge. The paper suggests that the model is lightweight, training-free in terms of the inference."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well written and clearly motivated.\n2. The paper's approach is technically sound.\n3. The evaluation seems to show improvement."
            },
            "weaknesses": {
                "value": "1. The approach seems quite ad-hoc. Though it's not a prompt-based method, but it's trying to distill the prompt-based method into a low-rank representation space. From this perspective, it's still a prompt-based approach. \n2. The prompt-based approach has many mentioned limitations. Also, it's really hard to make sure the content is exactly the same while only the style gets shifted. This error in the data synthesis pipeline will influence the performance of the method.\n3. The experiments of this paper is highly limited to two styles. These two styles can be easily achievable by prompting. The paper was motivated to go beyond this, however, the experiments do not support that."
            },
            "questions": {
                "value": "The notation in section 4 is quite confusing. \n\n1. I don't see the definition of N in equation (4). The lowercased n seems to indicate the dataset size. But the capital N seems to indicate a different thing?\n2. the q_i in SVD shares the same notation as equation (3). But I think they are totally different things.\n3. why is q missing in equation (5)? There isn't enough justification for that."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}