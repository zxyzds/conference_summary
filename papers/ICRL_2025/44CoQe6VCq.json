{
    "id": "44CoQe6VCq",
    "title": "Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning",
    "abstract": "Large language models (LLMs) have showcased remarkable reasoning capabilities, yet they remain susceptible to errors, particularly in temporal reasoning tasks involving complex temporal logic. Existing research has explored LLM performance on temporal reasoning using diverse datasets and benchmarks. However, these studies often rely on real-world data that LLMs may have encountered during pre-training or employ anonymization techniques that can inadvertently introduce factual inconsistencies. In this work, we address these limitations by introducing novel synthetic datasets specifically designed to assess LLM temporal reasoning abilities in various scenarios. The diversity of question types across these datasets enables systematic investigation into the impact of the problem structure, size, question type, fact order, and other factors on LLM performance. Our findings provide valuable insights into the strengths and weaknesses of current LLMs in temporal reasoning tasks. To foster further research in this area, we will open-source the datasets and evaluation framework used in our experiments.",
    "keywords": [
        "Temporal Reasoning",
        "Temporal Graphs",
        "LLMs"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=44CoQe6VCq",
    "pdf_link": "https://openreview.net/pdf?id=44CoQe6VCq",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces two datasets specifically crafted to evaluate large language models (LLMs) on temporal reasoning across diverse scenarios. The authors argue that existing benchmarks for temporal reasoning primarily use question-answering tasks based on Knowledge Graph -style temporal facts about well-known entities. Such benchmarks may reflect a model\u2019s capacity to leverage prior knowledge rather than assess true temporal reasoning skills. To this end. the proposed datasets aim to measure two core temporal reasoning abilities of LLMs: (1) understanding the semantics and logic of time, and (2) performing temporal arithmetic."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- For the ToT-Semantic dataset, designed to evaluate LLMs on temporal semantics and logic, the authors employ seven graph generation algorithms and develop eight manually crafted question types. This diversity allows the generation of a large volume of synthetic questions, adding rigor to the dataset and covering various temporal reasoning facets.\n\n- The study provides detailed insights into the temporal reasoning capabilities of frontier LLMs, including how factors such as graph size, question type, and temporal fact ordering influence performance. These observations offer valuable understanding into both the strengths and limitations of current LLMs in temporal reasoning."
            },
            "weaknesses": {
                "value": "- While ToT-Semantic focuses on temporal semantics and logical reasoning, the paper does not clearly explain how the graph generation process ensures the correctness of graph evolution. Specifically, the distinction between generating static graphs and those with temporal dynamics is not addressed, leaving questions about the dataset's fidelity to real-world temporal processes. \n\n- In introduction, the paper emphasizes the importance of evaluating LLMs on temporal reasoning but does not clearly explain why a graph structure is essential for this assessment. Could the authors elaborate on the necessity of graphs in this context?"
            },
            "questions": {
                "value": "As mentioned in weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper focuses on evaluating the temporal reasoning abilities of large language models (LLMs). The authors introduce a new synthetic dataset, Test of Time (ToT), which consists of two tasks: ToT-Semantic for temporal semantics and logic, and ToT-Arithmetic for temporal calculations. The study evaluates five LLMs and analyzes the impact of factors like graph structure, question type, and fact order on performance. The findings provide insights into LLMs' strengths and weaknesses in temporal reasoning."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-\tThe proposed ToT benchmark is designed to address the limitations of existing benchmarks by encompassing a wider variety of graph structures and question types, enabling a more nuanced evaluation of LLMs' temporal reasoning abilities\n-\tThe authors offer an evaluation of temporal reasoning by decoupling it into semantic and arithmetic aspects. This two-pronged approach provides a more detailed analysis of LLM capabilities."
            },
            "weaknesses": {
                "value": "-\tAs mentioned in the limitation section, the benchmark focuses on scenarios where both the start and end times of a fact are mentioned within a single sentence. But real-world temporal information can be spread across multiple sentences or documents.\n-\tThe authors generate questions using templates, which might not fully capture the complexity and variability of natural language found in real-world temporal reasoning tasks."
            },
            "questions": {
                "value": "1.\tHow would the performance of LLMs change if the benchmark included static facts in addition to explicit temporal facts?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Dealing with the dataset quality and potential leakage problems, this paper introduces a novel method to synthesize a benchmark for comprehensive temporal reasoning benchmarks. The benchmark contains semantic and arithmetic questions with fine-grained topology control. Extensive experiments are conducted and show insightful conclusions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The data synthesis process benefits from the graph-guided control, and could be generalized to many other tasks.\n- The constructed data are comprehensive and include many perspectives with quality control.\n- Experiments are extensively conducted on multiple aspects, and provide some insights on future directions."
            },
            "weaknesses": {
                "value": "- Some claims lack of quantitative evidence:\n    - \u201creal-world data that LLMs may have encountered during pre-training or employ anonymization techniques that can inadvertently introduce factual inconsistencies\u201d Could you add some quantitative evidence showing the GPT-4 or Gemini-1.5 Pro baselines have pre-training data contaminations?\n    - \u201cLLMs could even potentially guess the original entities due to their adjacent relations\u201d This also lacks of quantitative evidence. If this is a commonsense, there should be relevant references cited.\n- The literature review is not sufficient, and there are many researches on math-related temporal reasoning tasks. There lacks of relevant references in the introduction and the related work.\n    - Wang, Y., & Zhao, Y. (2023). Tram: Benchmarking temporal reasoning for large language models.\u00a0*arXiv preprint arXiv:2310.00835*.\n    - Chu, Z., Chen, J., Chen, Q., Yu, W., Wang, H., Liu, M., & Qin, B. (2023). Timebench: A comprehensive evaluation of temporal reasoning abilities in large language models.\u00a0*arXiv preprint arXiv:2311.17667*.\n    - Su, Z., Zhang, J., Zhu, T., Qu, X., Li, J., Zhang, M., & Cheng, Y. (2024). Timo: Towards Better Temporal Reasoning for Language Models.\u00a0*arXiv preprint arXiv:2406.14192*."
            },
            "questions": {
                "value": "- Some details are missing.\n    - Line 212: \u201cwe generated questions per graph generation and per question type\u201d: Please explain how to generate such questions. Are they generated from templates, manual annotations, or LLMs?\n    - Line 369: Is it because the superior performance on longer contexts? Is there a correlation between long-context performance (or overall task performance e.g., MMLU, GSM8K, MATH500) and the final temporal reasoning performance? Are there sufficient test cases with more edges for providing robust evaluation?\n- Typos:\n    - Line 275: Funcionalizing \u2192 Functionalizing"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this work, the authors introduce two novel synthetic datasets, TOT-Semantic and TOT-Arithmetic, specifically designed to evaluate LLMs\u2019 temporal reasoning abilities with graph-like facts from two perspectives: (1) understanding the semantics and logic of time, and (2) performing accurate temporal arithmetic. The authors also conduct extensive experiments to examine how LLM performance is influenced by the graph structure, graph size, question type, and fact ordering of the problem."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The method works on temporal reasoning with LLM, an important area of research that contributes to understanding the model's overall complex reasoning capabilities.\n\nThe authors conduct several experiments. Their analysis and the data offer valuable insights for future research."
            },
            "weaknesses": {
                "value": "The paper lacks detail on dataset construction. For instance, how are the final questions generated in both TOT datasets? Are templates being used? (see also question 1)\n\nThe number of baselines is limited. Additional approaches could include directly generating code for TOT-Arithmetic or applying few-shot or self-consistency."
            },
            "questions": {
                "value": "1. Have the authors considered how the format of the date/time, such as words versus numerical format, might influence the model\u2019s performance?\n\n2. For 4.1, 4.1.1, what task does the author evaluate?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}