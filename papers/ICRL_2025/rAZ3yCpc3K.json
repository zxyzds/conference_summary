{
    "id": "rAZ3yCpc3K",
    "title": "The Deficit of New Information in Diffusion Models: A Focus on Diverse Samples",
    "abstract": "Diffusion models are renowned for their state-of-the-art performance in generating high-quality images. Identifying samples with new information beyond the training data is essential for data augmentation, especially for enhancing model performance in diverse and unforeseen real-world scenarios. However, the investigation of new information in the generated samples has not been well explored. Our investigation through the lens of information theory reveals that diffusion models do not produce new information beyond what exists in the training data. Next, we introduce the concept of diverse samples (DS) to prove that generated images could contain information not present in the training data for diffusion models. Furthermore, we propose a method for identifying diverse samples among generated images by extracting deep features and detecting images that fall outside the boundary of real images. We demonstrate that diverse samples exist in the generated data of diffusion models, attributed to the estimation of forward and backward processes, but it can only produce a limited number of diverse samples, underscoring a notable gap in their capabilities in generating diverse samples. In addition, our experiment on the Chest X-ray dataset demonstrates that the diverse samples are more useful in improving classification accuracy than vanilla-generated samples. The source code is available at \\url{https://github.com/lypz12024/diffusion-diverse-samples}.",
    "keywords": [
        "DIffusion Models",
        "Diverse Samples",
        "Information Theory"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=rAZ3yCpc3K",
    "pdf_link": "https://openreview.net/pdf?id=rAZ3yCpc3K",
    "comments": [
        {
            "summary": {
                "value": "The paper explores diffusion models\u2019 ability on generating out-of-distribution samples, which is an essential aspect for data augmentation. By calculating t-SNE on the extracted features from both real and generated images, it is stated that diffusion models rarely generate out-of-distribution data."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is motivated by an essential question of whether a diffusion model can generate diverse samples, and therefore, can serve as a reliable data augmentation technique.\n\n2. The paper reveals the limitation of diffusion models on generating out-of-distribution data through both information theory and experiments."
            },
            "weaknesses": {
                "value": "1. Evaluating the diffusion models\u2019 ability on generating out-of-distribution data seems not to be an unexplored area, taking these works as examples [1][2]. Thus, there is concern about the paper\u2019s novelty. It would be better if the author can include these previous work and discuss the difference.\n\n2. The dimension of t-SNE seems not explicitly mentioned in the paper. As a dimensional reduction technique, I hardly agree only considering the top significant features can tell if the generated samples are out-of-distribution or not. Difference in less significant features can also lead to out-of-distribution data. I would suggest evaluating the correlation between the number of diverse samples and the number of dimensions used in t-SNE.\n\n[1] Ramachandran, Sai Niranjan, et al. \"Understanding the Generalization of Pretrained Diffusion Models on Out-of-Distribution Data.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 13. 2024.\n\n[2] Graham, Mark S., et al. \"Denoising diffusion models for out-of-distribution detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023."
            },
            "questions": {
                "value": "My main concern is that if the diffusion model cannot generate out-of-distribution data, I am curious why the generated images from the diffusion model can lead to performance boost in classification tasks on Chest X-ray. I would suggest the examination on whether the performance boost comes from increased data volume or if there are subtle variations in the generated images that contribute to improved classification."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents an information-theoretic analysis of diffusion models, demonstrating that they usually fail to generate truly novel information beyond their training data. In fact, theoretically perfect diffusion models are shown to produce no new information at all. To address this limitation, the authors introduce the concept of a *Diverse Sample* (DS). A DS is a sample generated by the diffusion model that contains information not present in the training data. By filtering generated samples to identify DSs, the authors propose a method to augment datasets and improve the performance of downstream tasks like classification."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. This paper raises a critical concern about the effectiveness of generative model-based data augmentation for downstream tasks. It argues that generated samples may not contain information distinct from the original dataset, potentially limiting their ability to improve performance.\n2. The proposed DS-based augmentation technique demonstrates significant performance improvements on imbalanced chest X-ray (CXR) classification tasks compared to traditional generative model-based approaches.\n3. The paper's concepts and algorithms are clear and easy to follow."
            },
            "weaknesses": {
                "value": "1. The paper's first claim regarding the limitations of diffusion models in generating new information during training and inference is a well-established fact in the field of generative modeling. This is not a novel contribution. All generative models, by design, aim to learn and reproduce the underlying data distribution.\n2. The proposed *Diverse Sample* (DS) method bears significant similarity to the technique employed in the *improved Precision-Recall* [1] method to identify out-of-distribution samples. While the DS method relies on a less robust approach, potentially making it more susceptible to noise and outliers compared to the KNN-based method in [1].\n3. The assertion that DS samples contain novel, augmentation-worthy information is questionable. Given the nature of generative models, it is more likely that these samples represent low-probability, low-quality outputs that the model has incorrectly generated. The decreasing trend of DS samples with improved samplers, as evident in Table 1, further supports this argument.\n4. The paper's analysis of generative model-based data augmentation diverges from the prevailing understanding. Data augmentation is typically employed when training data is a limited subset of the true data distribution. The effectiveness of this technique stems from the inherent generalization capabilities of machine learning algorithms [2]. Generative models are expected to approximate the true distribution, enabling the generation of synthetic data that can enhance model performance. The paper's perspective does not align with this widely accepted view.\n\n[1] Kynk\u00e4\u00e4nniemi, Tuomas, et al. \"Improved precision and recall metric for assessing generative models.\" *NeurIPS* (2019).\n\n[2] Chen, Yunhao, Zihui Yan, and Yunjie Zhu. \"A comprehensive survey for generative data augmentation.\"\u00a0*Neurocomputing*\u00a0(2024): 128167."
            },
            "questions": {
                "value": "1. Is data augmentation using DS effective in balanced datasets? Is it also effective in general image classification tasks beyond chest X-ray analysis?\n2. How does the performance of data augmentation using DS compare to methods employing diffusion models for minority sample generation, such as the approach in [3]?\n3. Please provide a proof for equations (9) and (10). Does this property still hold true when using a scheduler, such as the one proposed in [3], that ensures zero signal-to-noise ratio (SNR) at the final timestep $T$?\n4. The identified weakness of the proposed method is its susceptibility to incorrect sampling, which can result in the generation of erroneous data samples. Are there techniques to address this limitation?\n\n[3] Um, Soobin, et al. \"Don't Play Favorites: Minority Guidance for Diffusion Models.\"\u00a0*ICLR*\u00a0(2024).\n\n[4] Lin, Shanchuan, et al. \"Common diffusion noise schedules and sample steps are flawed.\"\u00a0*WACV* (2024)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper examines whether diffusion models generate new information beyond training data, finding that they typically replicate existing information. To address this, the authors introduce Diverse Samples (DS)\u2014generated images that differ from the training data due to model approximations. By identifying these samples through feature analysis, the study shows that diverse samples enhance classification accuracy in underrepresented classes, such as in a Chest X-ray dataset, underscoring the value of improved diversity in diffusion models for effective data augmentation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The question of whether and to what extent diffusion models can generate samples with new information is both interesting and important.\n2. The experiments seem easy to reproduce, as the authors have provided the source code."
            },
            "weaknesses": {
                "value": "1. **The mathematical analysis is not very sound**: Equation (13) states that \u201cthe ideal mutual information at the start and end should be the same,\u201d which doesn\u2019t make sense to me. Since $x_T$ is pure Gaussian noise, it shouldn\u2019t carry any information relevant to the image $x_0$.\n2. **The arguments are not very convincing**: The authors argue that ideal diffusion models perfectly align with the training distribution and, therefore, cannot introduce new information, whereas imperfections allow the model to generate diverse samples that deviate from the training data manifold. However, the paper uses a pre-trained latent diffusion model, which could be trained on data that includes the four datasets used. The generation of diverse samples does not imply they contain \u201cinformation not present in the training data.\u201d\n3. **Experimental results**: The results on the Chest X-ray dataset using diverse samples (DS) are not very compelling (e.g., the DS accuracy for the PNEUMONIA class is lower than that of the original images). To substantiate the claim that diverse samples selected by the proposed algorithm can enhance accuracy, additional experiments on different datasets are needed, rather than focusing on just one dataset."
            },
            "questions": {
                "value": "See the questions in the above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}