{
    "id": "RaR3ETzyKp",
    "title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance",
    "abstract": "Recent research pinpoints that different diffusion methods and architectures \ntrained on the same dataset produce similar results for the same input noise. \nThis property suggests that they have some preferable noises for a given sample. \nBy visualizing the noise-sample pairs of rectified flow models and stable diffusion models in two-dimensional spaces, \nwe observe that the preferable paths, connecting preferable noises to the corresponding samples, \nare much well organized with significant fewer crossings comparing with \nthe random paths, connecting random noises to training samples. \nIn high-dimensional space, paths rarely intersect. \nThe path crossings in two-dimensional spaces indicate the shorter inter-path distance \nin the corresponding high-dimensional spaces. \nInspired by this observation, we propose the Distance-Aware Noise-Sample Matching (DANSM) method \nto lengthen the inter-path distance for speeding up the model training. \nDANSM is derived from rectified flow models, which allow using a closed-form formula to calculate the inter-path distance. \nTo further simplify the optimization, we derive the relationship between inter-path distance and path length, \nand use the latter in the optimization surrogate. \nDANSM is evaluated on both image and latent spaces by rectified flow models and diffusion models. \nThe experimental results show that DANSM can significantly improve the training speed by 30\\% $\\sim$ 40\\%\nwithout sacrificing the generation quality.",
    "keywords": [
        "Rectified Flow Models",
        "Training",
        "Easing",
        "Distance-Aware Noise-Sample Matching",
        "DANSM"
    ],
    "primary_area": "generative models",
    "TLDR": "easing the training process of rectified flow models by better noise-sample pairs in each training epoch",
    "creation_date": "2024-09-21",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=RaR3ETzyKp",
    "pdf_link": "https://openreview.net/pdf?id=RaR3ETzyKp",
    "comments": [
        {
            "summary": {
                "value": "This work proposes Distance-AwareNoise-Sample Matching (DANSM) to increase training speed in generative models without any loss (in fact gain) in performance. The proposed method is inspired by \"the difference between random paths used in training and preferable paths from well-trained models\".\nThe work is theoretically motivated and sound.\nThe work offers limited evaluations, however, they seem to be sufficient to make the case."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The work is well written except for a few typos (for example, in line 198/199 \"To **analysis**\" is written instead of \"To **analyse**\", and in line 309/310 \"have not been **evaluation** on RFM\" is written instead of **evaluated**).\n\nThe idea is sound and is theoretically motivated, the results are in line with the hypothesis.\nThe implementation seems simple and straightforward. \n\nThe claims made in the paper seem to be backed by empirical evaluations."
            },
            "weaknesses": {
                "value": "I have 2 major points in this regard:\n1. The plots are not well made, some of the lines in the plots, for example, Figure 6(b), Figure 7(b), and Figure (b) seem to be starting from arbitrary locations. It would help to invest more time and make better-looking plots without these artifacts, or if they are not artifacts then an explanation for the same would be very helpful.\n\n2. The work lacks comparisons to \"Immiscible Diffusion\", while the paper does point out the key differences in lines 307-315, it would be interesting to see empirical evaluations in comparison to \"Immiscible Diffusion\" since the methods are closely related."
            },
            "questions": {
                "value": "Q1- I would appreciate a better explanation for Figure 6 (b), the plot looks a bit unclear to me. Additionally, there are lines behind the legend curbing my ability to understand the plot completely. My essential question is that unlike Figure 7, in Figure 6 (b) I do not see any gains in training times when using the proposed method. Is this understanding of mine correct?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores how different diffusion methods yield similar results with the same dataset, identifying \"preferable noises\" for samples. It introduces the Distance-Aware Noise-Sample Matching (DANSM) method to optimize training by increasing inter-path distances. DANSM significantly speeds up training by 30%\u201340% without losing quality, offering insights into enhancing diffusion model efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The diagram is very clear, making it easy to understand how different diffusion methods yield similar results with the same dataset, identifying \"preferable noises\" for samples.\n\n2. The proposed method significantly speeds up training by 30%\u201340% without losing quality, offering new insights into enhancing diffusion model efficiency."
            },
            "weaknesses": {
                "value": "1. The FID calculations are measured with very few sampling steps, making it difficult to ensure the quality of the generated results. It would be beneficial to provide a comparison of different methods while maintaining image quality, ideally with visualizations, such as images decoded using stable diffusion.\n\n2. The experiments were only validated on CIFAR and LSUN-BEDROOM datasets. Validation on a broader range of datasets, such as ImageNet and FFHQ, would provide more comprehensive insights. Additionally, including some actual generated images for visual comparison would be advantageous."
            },
            "questions": {
                "value": "1. Include a comparison using longer sampling steps.\n\n2. Conduct more extensive experiments on complex datasets."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper reveals that different diffusion models trained on the same dataset tend to produce similar outputs when given the same input noise. This suggests the existence of \"preferable noise-sample pairs\" in the training process. The authors propose the Distance-Aware Noise-Sample Matching method to lengthen the inter-path distance for speeding up the training of diffusion-based models. The experiments show that the proposed method improves the training speed by about 30%~40%."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper presents a framework that simplifies the optimization of inter-path distances to path length optimization, based on the observations of noise-sample pair relationships in diffusion models.\n\nThe approach leverages closed-form formulas derived from rectified flow models to enable efficient optimization without requiring architectural modifications, making it easy to integrate with existing methods."
            },
            "weaknesses": {
                "value": "The authors heavily emphasize \"consistent model reproducibility,\" which seems interesting but abruptly transitions to proposing a method for improving training speed. This makes the main idea of the paper quite unclear.\n\nThe presentation of the proposed method is vague, and Algorithm 1 cannot be effectively reproduced with the provided steps. I suggest adding mathematical formulations in Sections 3.3 and 4.2 to rigorously explain how the proposed model is optimized.\n\nRegarding experiments, the paper lacks visual comparison results, which are crucial for method evaluation, especially when the FID quantitative metrics show minimal differences at the tiny scale discussed. I also recommend comparing with more methods and incorporating the proposed training speed improvement approach across more SD models. I believe the paper should present higher-resolution and larger-scale generation results. Given the computational benefits brought by this work's methodology, these tasks should be more computationally feasible."
            },
            "questions": {
                "value": "Why is it necessary to learn latent-noise pairs that are well-aligned in the t-SNE space? This might suggest that straight flow matching is preferable, but the underlying reasoning is not clearly explained in the paper. Furthermore, I am confused about whether \"consistent model reproducibility\" is beneficial or detrimental for diffusion-based models. The fact that different model architectures can generate similar images from the same noise might indicate limited generation patterns due to the isotropic nature of the Gaussian noise."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}