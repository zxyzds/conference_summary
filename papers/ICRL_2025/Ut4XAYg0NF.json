{
    "id": "Ut4XAYg0NF",
    "title": "Explainable Sequential Optimization",
    "abstract": "We propose formulating stochastic model predictive control into a coalition game to use Shapley values for feature attribution. Such analysis is crucial for transparency and achieving optimal outcomes in high-stake applications such as portfolio optimization and autonomous driving. We categorize Shapley values estimation methods into three families: those based on weighted linear regression, sampling permutations, and multilinear extension.  We survey, benchmark, and provide valuable insight into these methods, previously not attempted in this context. Our experiments show that halved Owen sampling from multilinear extension and KernelShap-Paired from weighted linear regression, both utilizing antithetic sampling, perform best.",
    "keywords": [
        "Explainability",
        "Sequential Optimization"
    ],
    "primary_area": "optimization",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Ut4XAYg0NF",
    "pdf_link": "https://openreview.net/pdf?id=Ut4XAYg0NF",
    "comments": [
        {
            "summary": {
                "value": "This paper formulates stochastic model predictive control into a coalition game, and uses Shapley values for feature attribution. Specifically, it has performed a systematic study of explaining stochastic model predictive control systems. It has also surveyed existing methods for estimating Shapley values. Detailed experiment results have been provided in Section 5."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The considered problem seems to be interesting and important.\n\n- This paper has done a good job of literature review.\n\n- The experiment results in Section 5 seem to be rigorous and extensive."
            },
            "weaknesses": {
                "value": "- The main body of this paper is not self-contained. In particular, some key concepts such as Shapley values are defined in the appendices. Please move them to the main body to make the paper self-contained and more readable."
            },
            "questions": {
                "value": "Please address the weaknesses listed above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper considers solving a control problem using explainable methods. Specifically, the author(s) proposes reformulating the control problem as a coalition game, enabling the use of Shapley values to specify the contribution of each individual feature. The author(s) also reviews relevant literature on Shapley value estimation and applies these methods in numerical studies."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "I summarize the paper's contributions as follows:\n\n* **Originality**: The application of Shapley values to sequential control appears to be novel, to the best of my knowledge. Additionally, the concept of \"explainable\" sequential optimization has received relatively little attention in the literature.\n* **Quality**: The paper is soundly written. I did not identify any technical errors.\n* **Clarity**: Overall, the paper is well-organized and easy to understand.\n* **Significance**: The methods are relevant to the field of \"explainable\" AI and could potentially be very useful and applicable in practical scenarios."
            },
            "weaknesses": {
                "value": "1. The paper predominantly focuses on the example of portfolio optimization, where the meaning of Shapley value is clear. However, its interpretation becomes less unclear when applied to other control problems in robotics and operations research. The paper could be potentially improved by adding more use cases to strengthen the motivation of the proposal.  \n\n2. Including numerical experiments is excellent, and I anticipated to see how the proposed methods demonstrate 'explainability' through Shapley values. However, it seems the authors focused solely on comparing different methods for computing Shapley ratios and reporting these estimates, without discussing their explanatory power. However, such explanations are necessary to illustrate how the proposed method is 'explainable'.\n\n3. In terms of presentation, the paper reads like a survey paper as in several places, it mentions it surveys methods for Shapley value estimation and compare these methods numerically. It may be beneficial to revise the presentation to ensure the paper is not primarily a survey. \n\n4. Additionally, the main text frequently refers to the appendix for more detailed explanations, which disrupts the flow of reading. I suggest to reduce the number of such references where possible to enhance readability."
            },
            "questions": {
                "value": "Please refer to the weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "It would be useful to clarify the contributions of this paper in the rebuttal. It seems to me that this paper is a combination of an introduction to Shapley values, a literature review of this subject and an experimental study of related methods. If this is the aim, I believe that the paper would be better placed in a journal and it should be expanded. In particular, in the main paper, the introduction to the subject is quite short and assumes some knowledge of collaborative games. If the aim of this paper is to introduce this subject to a wider audience then a more thorough introduction is appropriate.  On the other hand, if the assumption is that the reader is already quite familiar with collaborative games then I wonder how much is gained by some light touch overview and an experimental study of a topic (Shapley values) which has been introduced in the 50s and for which a Nobel prize has been awarded -- surely a reader familiar with collaborative games will have a good understanding of Shapley values."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper provides an overview of classical subject in game theory and an extensive experimental study."
            },
            "weaknesses": {
                "value": "I believe that the paper is misplaced in a conference and it would be better to write a review article for a journal, if the aim is to introduce a wider audience to the subject."
            },
            "questions": {
                "value": "It would be useful to clarify the contributions of this paper in the rebuttal and to explain what the authors are aiming for."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes using Shapley values to perform feature attribution in Model Predictive Control (MPC) problems, where different features include constraints and losses. A portfolio optimization use case is considered where multiple Shapley value estimation methods are benchmarked."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper discusses and proposes an explainability approach to Model Predicting Control based on Shapley values which, to the best of my knowledge, is novel.\nThe experimental study is extensive and sound."
            },
            "weaknesses": {
                "value": "The main weaknesses of the paper are: \n- The presentation can be improved significantly. It would be good to define Shapley value somewhere in the main text? Moreover, all the plots are clearly not presentable (legends are too small, lines too thin). There are probably too many repetitive plots in the main text and too little details on estimation methods benchmarked. \n- The paper, starting from its motivations, is heavily focused on MPC for portfolio optimization setups. Thus, although I could imagine similar considerations hold in other MPC problems, it is not clear that experimental results transfer.\n- Based on the above, the title is too general. Sequential optimization covers many sub-fields (e.g. bandits, online convex optimization, etc.) in which there is no notion of features (i.e. constraint or losses) similar to the ones considered in the paper."
            },
            "questions": {
                "value": "- The MPC is based on receding-horizons, where computed actions (and thus selected constraints/losses) are only useful for planning. How are these 2 time-scale separations (i.e. planning vs. acting) taken into account for computing Shapley values? \n\n- Was supplementary material correctly submitted as separate pdf? From what I see the submission contains a single *pdf with 36 pages."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper stuides the problem of explaining the influences of constraints and loss terms in stochastic model predictve control problems. In particular, an additive component atribution model is considered."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The problem setting is interesting. In multi-stage problems, credit assignment / attributing results to decisions is a very important topic to study.\n\n----"
            },
            "weaknesses": {
                "value": "*1.* The paper is not well-written and is very hard to follow. I have a hard time figuring out the connections between some sentences. \n\n*2.* The main contribution of this paper is missing in the main paper, i.e., the connection/formulation of the explainable stochastic MPC and coalition game is not well presented in Section 4. Table 1 does not provide enough information for readers to understand.\n\n\n*3.* Simulation results are hard to follow. The baselines are not introduced or explained. The figures are too small. \n\n---"
            },
            "questions": {
                "value": "N.A."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}