{
    "id": "8ljEGpXuqB",
    "title": "Generating GFlowNets as You Wish with Diffusion Process",
    "abstract": "Generative Flow Networks (GFlowNets) are probabilistic samplers that learn stochastic policies to generate diverse sets of high-reward objects, which is essential in scientific discovery tasks. However, most existing GFlowNets necessitate training, becoming costly as the diversity of GFlowNets expands and trajectory lengths increase. To alleviate this problem,  we propose a method to Generate high-performing GFlowNet parameters based on a given model structure, called GenFlowNet. Specifically, we first prepare an autoencoder to extract latent representations of GeFlowNet parameters and reconstruct them. Then, a structure encoder is trained alongside a conditional latent diffusion model to generate the target GFlowNet parameters based on the given structure information. To the best of our knowledge, it is the first exploration to generate parameters of a probabilistic sampler using the diffusion process. It enables us to obtain a new GFlowNet without training, effectively reducing the trial-and-error cost during GFlowNet development. Extensive experiments on diverse structures and tasks validate the superiority and generalizability of our method.",
    "keywords": [
        "GFlowNet",
        "Parameter generation"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=8ljEGpXuqB",
    "pdf_link": "https://openreview.net/pdf?id=8ljEGpXuqB",
    "comments": [
        {
            "summary": {
                "value": "The authors propose a method to generate GFlowNets based on previously trained policy. Their method (GenFlowNet) condenses policy parameters using an autoencoder. Then, it employs a latent conditional diffusion process in the latent space to create new policy parameters conditioned on an encoding of the target architecture."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* To the best of my knowledge, the best work on developing generalizable initializations of parameters for GFlowNets."
            },
            "weaknesses": {
                "value": "* Experiments lack proper description. For instance, are different Rewards used to train the auto-encoder in the hypergrid task? Or do you fix the same $R\\_0$, $R\\_1$, $R\\_2$, and $H$ for all GFlowNets comprising the training set? Is the aim solely to create new architectures for the same reward --- that has been learned before? I have several questions regarding the experimental setup below. If the method cannot generalize to unseen rewards, I don't see how it can be useful.\n\n* While the hyper grid task and molecule generation are challenging ones, the experimental suit is rather slim compared to other recent works in the GFlowNet literature\n\n* There are limitations that the authors do not properly address. For instance, how does GenFlowNet behave when for varying rewards? How does it fare when the forward policies are not MLPs?\n\n* No error bars or standard deviation."
            },
            "questions": {
                "value": "* What is the unit for \"Time usage\" in Table 1? Seconds, hours?\n\n* In line 307, the authors highlight the \"superior performance in sampling distribution accuracy\". This seems like an overstatement, given the very small gaps in Table 1 and the lack of uncertainty measurements.\n\n* Authors state GenFlowNets enable the generation of accurate GFlowNets without training. However, Figure 4 makes it look like the parameters generated by GenFlowNets are used as initialization. Is this correct? Please elaborate.\n\n* It seems odd that a training-free GFlowNet would perform better than a trained one (assuming the latter is properly trained). Could you share a rationale for this?\n\n* For section 3.3, are the GFlowNets drawn from the GenFlowNet trained for the hypergrid task? Please provide more details"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel idea to generate GFlowNets, which are deep learning models that hierarchically generate sequential actions in parameter space. They use an autoencoder to create a latent mapping of parameters and use a conditional diffusion model in the latent space to generate a proper latent representation of parameters. This method enables generalization over the parameter space, allowing us to obtain new GFlowNets without training."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Very novel idea (more like crazy idea)."
            },
            "weaknesses": {
                "value": "There are several concerns:\n\n1. Scalability may be limited.\n\n\n2. The motivation is unclear\u2014why is this approach necessary?\n\n\n3. The empirical results do not reflect real-world performance."
            },
            "questions": {
                "value": "1. Can this method be used to measure uncertainty from a Bayesian perspective? I'm asking because this work seems to be connected with AutoML and hypernetworks.\n\n\n2. Can you provide a clearer motivation for why we need this?\n\n\n3. Is this method scalable to large-scale tasks that require very complex parameterizations (e.g., LLMs, text-to-image models) within GFlowNets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors proposed using a VAE to learn the latent space of GFlowNet parameters, followed by using DMs to generate the GFlowNet parameters. They used different synthetic data for the evaluation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "If the method proves effective in real scenarios, it could help improve training in situations where GFlowNet struggles; however, the current experiments do not support this outcome."
            },
            "weaknesses": {
                "value": "- The experiments are based solely on synthetic data, which does not strongly support most of the claims, such as those in Figure 1.\n\n- While the authors mention where GFlowNet training struggles\u2014such as with increasing trajectory length in the abstract\u2014they do not clarify whether they successfully addressed these issues.\n\n- The novelty is somewhat limited, as it relies on an existing latent diffusion model without any modifications."
            },
            "questions": {
                "value": "- What are the specific distinctions that make adapting existing parameter generation methods challenging for GFlowNet parameters?\n\n- The dataset preparation for the AE component lacks clarity. Could you please elaborate on this? How many models did you generate? How many samples were created? Which datasets were used for this purpose?\n\n- Including additional real-world datasets would be greatly appreciated."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores parameter generation for GFlowNets, as GFlowNets require high costs to train, e.g., sampling an exponential number of trajectories. To generate parameters, this paper proposes a two-fold method: (1) generating a latent representation of parameters via reverse diffusion given the structural information of an environment and (2) decoding this representation into parameters. The overall method is similar to a prior study [1], but extends it to consider the condition specifying the environment. The experiments show that the proposed generative method can adapt to unseen environmental structures.\n\n---\n\n[1] Wang et al., Neural Network Parameter Diffusion"
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This work is the first to investigate the parameter generation for GFlowNets, which can also be naturally extended to reinforcement applications.\n- The proposed method demonstrates that generated parameters can achieve similar or superior performance compared to parameters obtained from conventional training of GFlowNets."
            },
            "weaknesses": {
                "value": "My primary concerns arise from doubts regarding the practical utility of the proposed methods.\n\n- **About motivation.** This paper argues that generating the parameters given environmental information, e.g., state dimensions, makes it easy to obtain parameters for new environments. However, one might consider defining a forward policy conditioned on such information, e.g., $ P_F(s|s'; \\text{Structure}) $, and training it. Given this alternative, what benefits does the parameter generation provides?\n\n- **About extensibility.** Although the method considers environment-specific structural information, e.g., state dimension in a hyper-grid, it seems challenging to incorporate most components of GFlowNets in practice. For example, in specifying information of environments, how should one consider different reward functions, e.g., addressing different properties, or different action spaces, e.g., fragment-based and reaction-based transitions?\n\n- **About experiments**. The considered tasks are limited to show usefulness of the proposed method (only considers eight different structures for a hyper-grid). Furthermore, the most experiments only consider the relatively simple task, i.e., a hyper-grid, and simple structural variations, i.e, changes in dimensions, without exploring more advanced tasks, e.g., RNA sequence generation, or complex environmental variations. Although the experiments consider a molecular generation task, it does not specify what $I$ is.  \n\n- **About results.** In Table 4 and 5, the performance improvements seem too minor. Especially, in Table 4, it is hard to understand why $N=2$ and $N=5$ yield the similar generalization performance. Can you clarify more details on this?"
            },
            "questions": {
                "value": "- What is $I$ in Table 3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}