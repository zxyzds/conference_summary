{
    "id": "XXzOzJRyOZ",
    "title": "Incorporating Visual Correspondence into Diffusion Model for Visual Try-On",
    "abstract": "Diffusion models have shown preliminary success in virtual try-on (VTON) task. The typical dual-branch architecture comprises two UNets for implicit garment deformation and synthesized image generation respectively, and has emerged as the recipe for VTON task. Nevertheless, the problem remains challenging to preserve the shape and every detail of the given garment due to the intrinsic stochasticity of diffusion model. To alleviate this issue, we novelly propose to explicitly capitalize on visual correspondence as the prior to tame diffusion process instead of simply feeding the whole garment into UNet as the appearance reference. Specifically, we interpret the fine-grained appearance and texture details as a set of structured semantic points, and match the semantic points rooted in garment to the ones over target person through local flow warping. Such 2D points are then augmented into 3D-aware cues with depth/normal map of target person. The correspondence mimics the way of putting clothing on human body and the 3D-aware cues act as semantic point matching to supervise diffusion model training. A point-focused diffusion loss is further devised to fully take the advantage of semantic point matching. Extensive experiments demonstrate strong garment detail preservation of our approach, evidenced by state-of-the-art VTON performances on both VITON-HD and DressCode datasets.",
    "keywords": [
        "Virtual Try-On",
        "Image Generation"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=XXzOzJRyOZ",
    "pdf_link": "https://openreview.net/pdf?id=XXzOzJRyOZ",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a novel approach for virtual try-on tasks, addressing the challenge of preserving garment shape and fine-grained details. Specifically, the authors propose Semantic Point Matching Diffusion (SPM-Diff), a model that leverages structured semantic points as visual correspondence cues between garments and target human models. By mapping 2D semantic points to 3D-aware cues through depth and normal maps, SPM-Diff aligns garment details closely with the target human body. Experimental results on VITON-HD and DressCode datasets demonstrate the effectiveness of SPM-Diff."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper leverages semantic point matching as a prior to enhance garment shape and texture preservation.\n\n- Extensive testing on the VITON-HD and DressCode datasets demonstrates the model's robustness and superior performance.\n\n- The authors have provided the code to ensure reproducibility of their results."
            },
            "weaknesses": {
                "value": "- In line 254, local flow warping is used as a method to associate semantic points with their counterparts on the target person. It would be better to provide more detail on the local flow warping process for better understanding.\n\n- For Figure 5, it\u2019s difficult to assess the accuracy of the matched points. Using different colors (e.g. red and green) to illustrate correct and incorrect mappings would improve clarity.\n\n- Adding a figure to illustrate feature injection would help clarify how point features are incorporated into the Main-UNet."
            },
            "questions": {
                "value": "- Could you provide more details on the local flow warping process?\n\n- In Figure 5, are all the points shown the correct correspondences? If not, would it be possible to use different colors to distinguish correct from incorrect point mappings? Additionally, how do you assess the accuracy or correctness of these point mappings?\n\n- It would be better to include a figure to illustrate the feature injection process, specifically showing how point features are integrated into the Main-UNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents SPM-Diff, a virtual try-on framework utilizing diffusion models that maintain garment details and shape leveraging visual correspondence. Due to warping variability, traditional VTON methods using diffusion models have difficulty preserving garment features. SPM-Diff addresses this issue by focusing on \"semantic points\" in garment images that capture detailed textures and shapes. Experiments on the VITON-HD and DressCode benchmarks show that SPM-Diff achieves state-of-the-art results in virtual try-on."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. By identifying and aligning stable \"semantic points\" between garment and human images, SPM-Diff effectively reduces randomness in diffusion models, enabling precise and accurate garment reproduction.\n\n2. The incorporation of 3D depth and normal maps enhances realism by accurately controlling garment fit over the body, reflecting considerable thought in modeling garment behavior in 3D space."
            },
            "weaknesses": {
                "value": "1. SPM-Diff's dependence on semantic points may lead to instability when many points are used due to interpolation and projection errors, as discussed regarding point count sensitivity.\n\n2. SPM-Diff relies heavily on accurate depth and normal maps, which may limit its generalization to datasets or images without dependable 3D cues.\n\n3. Although the model effectively preserves garment details, evaluations primarily concentrate on image quality metrics, neglecting user-centered metrics such as perceived realism in end-user studies.\n\n4. Introducing \"visual correspondence\" into diffusion for virtual try-on is not new. Please clarify the \"Semantic Point Matching\" with \"Warping parameters learning\""
            },
            "questions": {
                "value": "The core idea of this paper is to integrate visual correspondence into the diffusion model. However, visual correspondence is not a new thing that is widely used in traditional try-ons. In addition, some people used warping + diffusion, such as : WarpDiffusion: Efficient Diffusion Model for High-Fidelity Virtual Try-on.\n\nPlease clarify their differences and provide more details about the novelty, not just replace \"warping\" with \"visual correspondence\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new method for virtual try-on by enforcing explicit correspondence through structured semantic points, which are first extracted from the garment image and then warped into the target body pose through local flow warping. The pair of points then serve as priors to guide the overall generation process of the try-on diffusion model, composed of a garment reference net and a main generation net. Experiments demonstrate this method generates high-quality try-on results."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe proposed method is able to generate high-quality virtual try-on results. Experiments show that the proposed method outperforms existing pipelines.\n2.\tThe idea of the paper that adopts pair of semantic points to facilitate the generation process and serve as an extra supervision signal is interesting and reasonable. If robust corresponding points could be found between the garment and the target body, they could be very good priors to boost the diffusion process. \n3.\tThe paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "The main weakness of the paper is on semantic point matching.\na)\tHow to acquire robust and accurate point matching should be the focus of the paper. However, this paper did not address this problem but rely on the local warping method proposed in GP-VTON[1], which is another virtual try-on method. This raises the concern about the contribution.\nb)\tThe evaluation of the accuracy of the point-matching method is very limited. The point matching should achieve much more accurate results than the base diffusion model thus it could be used as a prior to guide the generation process. However, this is not demonstrated in the paper.\n\n[1] GP-VTON: Towards General Purpose Virtual Try-on via Collaborative Local-Flow Global-Parsing Learning https://arxiv.org/abs/2303.13756"
            },
            "questions": {
                "value": "There are a few questions apart from the weakness:\n1.\tAs the local flow warping adopted in the paper relies on the coarse human body estimated with SMPL, I doubt if the warping method is capable of dealing with loose clothes like dresses or skirts. If not, will the proposed point prior still work to facilitate the generation process and get a good result?\n2.\tIn lines 262-264, the author claims that pre-trained garment/geometry feature encoders are adopted to extract features for the following generation process, but I could not find any clarification on how these encoders were obtained. The author should clarify this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}