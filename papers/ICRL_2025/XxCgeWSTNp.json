{
    "id": "XxCgeWSTNp",
    "title": "Improved Sampling Algorithms for L\u00e9vy-It\u00f4 Diffusion Models",
    "abstract": "L\u00e9vy-It\u00f4 denoising diffusion models relying on isotropic \u03b1-stable noise instead of Gaussian distribution have recently been shown to improve performance of conventional diffusion models in image generation on imbalanced datasets while performing comparably in the standard settings. However, the stochastic algorithm of sampling from such models consists in solving the stochastic differential equation describing only an approximate inverse of the process of adding \u03b1-stable noise to data which may lead to suboptimal performance. In this paper, we derive a parametric family of stochastic differential equations whose solutions have the same marginal densities as those of the forward diffusion and show that the appropriate choice of the parameter values can improve quality of the generated images when the number of reverse diffusion steps is small. Also, we demonstrate that L\u00e9vy-It\u00f4 diffusion models are applicable to diverse domains and show that a well-trained text-to-speech L\u00e9vy-It\u00f4 model may have advantages over standard diffusion models on highly imbalanced datasets.",
    "keywords": [
        "generative modeling",
        "diffusion models",
        "L\u00e9vy-It\u00f4 models",
        "\u03b1-stable L\u00e9vy processes",
        "stochastic differential equations"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=XxCgeWSTNp",
    "pdf_link": "https://openreview.net/pdf?id=XxCgeWSTNp",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a paremetric family of SDEs allowing different sampling scheme from a single pretrained Levy Ito diffusion model. It brings the toolbox for Levy Ito diffusion models (LIM) closer to that of standard \"Gaussian\" diffusion models (DM). Empirically, the authors find that the new paremetric family of SDEs has benefit in term of generated samples quality and diversity at low number of functional evaluations, which lowers the computational cost of sampling from Levy Ito diffusion models. Finally, they train a text-to-speech diffusion model on an imbalanced dataset and evalutate the benefits of LIMs compared to DM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "* The parametric family of SDEs derived by the author is new and offer more flexibility for LIM sampling.\n* The authors give a rigorous derivation of the proposed SDEs\n* The paper clearly tries to show how their theoretical results compare with existing litterature on LIMs. It explains clearly what is the limitation of Yoon et al (approximation of the reverse process).\n* Promising results for text to speech models\n* The paper is well written overall"
            },
            "weaknesses": {
                "value": "* The experiments about text to speech models are interesting and promising but they are not tied to the main results of the paper (theoretical and empirical contributions to LIM sampling). The baseline DM against which authors compare is also new and has the modifications outlined in lines 809 to 825 in the Appendix.\n* The simple toy example explains well why processes with zero mean and finite variations cannot be omitted completely in low NFE schemes. However, in my opinion, the paper does not explain clearly what steps/changes in the parametric family of SDEs prevents any such (intractable) process to come into play. I understand from line 286 that the reverse time SDE is no longer a model of the forward time SDE and that trajectories are different. Is that what allows you to have \"better\" SDEs?\n* (Not a real weakness per se) The new paremetric family of SDEs does not improve the capabilities of LIM in term of imbalance \"correction\". As examplified by table 4."
            },
            "questions": {
                "value": "* Please explain weakness 2.\n* For the text to speech model, even on the main mode (female speakers), LIMs outerperform Gaussian DMs. Why is that? Wouldn't we expect Gaussians DM to perform better on the main mode of the distribution? Does fixing the \"bias\" in the text encoder (line 809 to 825) unfairly disadvantage Gaussians DM even on the main mode? What would the results have been with a standard encoder (or alternatively do you have other baselines for text to speech imbalanced modeling that would shed light on the benefits of LIM on both the main mode and the tail mode)? You are also using an ODE sampler, which, in your image generation experiment, favors the less frequent class. \n* It seems that the common accepted reason for which LIMs are better for imbalanced datasets is that L\u00e9vy Ito processes, with their heavy tails and jump possibilities, better cover less probable isolated modes of the data distribution. In your opinion, why does this phenomenon subsist when using ODE sampling? In your imbalanced CIFAR experiment, classes 8 and 9 seem favored by the ODE."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Levy diffusion models perform better (especially on rare classes) when it\u2019s trained on imbalanced datasets. However, the previous reverse Levy process doesn\u2019t have same marginal probabilities at each noise level due to the omitted intractable term, resulting in non-exact sampling. \nThe authors propose a novel parametric family of SDE whose solutions have the same marginal densities as the forward levy diffusion process, leading to exact solutions. \nEmpirical experiments demonstrate that the proposed reverse process has superior sample quality with small number of sampling steps, and also performs good in terms of sample diversity."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is well-organized, and the technique derivations are solid. Also most of the arguments are well supported by experiments. \n- Instead of developing a reverse-time process of the forward Levy-Ito SDE, the authors propose parametric reverse-time SDEs that have the same marginal probability densities as the forward process, which gives exact sampling. \n- It seems like compare to the baseline SDE, the proposed one is good with multiple numerical solvers. For example, in Table 1 and 2, SDE(11) performs good with both solvers, while baseline SDE approximate(9) has a different performance with different solvers."
            },
            "weaknesses": {
                "value": "- Though the improvement of FID scores given small number of sampling steps (e.g. N=20) is huge, the improvement on imbalanced CIFAR10 is marginal. Also, it could be nice to provide some FID scores of samples from Gaussian diffusion models, which shows a clear improvement in imbalanced dataset. \n- In the speech synthesis experiment, the authors compare the proposed model only with the Gaussian-based diffusion model. However, it remains unclear whether this model is still SOTA when compared to the baseline L\u00e9vy-It\u00f4 diffusion model."
            },
            "questions": {
                "value": "- In table 3, I wonder how many times the authors run the experiments? It seems that for both FID and coverage metrics, the proposed SDE has very close performance to the baseline SDE. \n- In the speech synthesis experiment, could you provide a comparison to the baseline L\u00e9vy-It\u00f4 diffusion model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper offers a novel method for sampling using a L\u00e9vy-It\u00f4 diffusion model based on a new formulation of its corresponding SDE. The authors identify an issue in existing methods for the reverse SDE caused by neglecting one of the terms, and offer a solution. The paper includes experiments which compare the generation results of the proposed solutions to alternatives, as well as a demonstration of its use in addressing skewed training datasets in the text-to-speech field."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper analyzes L\u00e9vy processed and their use for diffusion models, a field which is under-explored.\n- The proposition in the paper is straightforward and mathematically justified.\n- The experiments in the paper provide evidence of the benefits of the new method."
            },
            "weaknesses": {
                "value": "- The presentation of the paper could be improved, both at the sentence and at the paragraph level.\n- The figures and naming scheme makes it hard to follow the result and illustrations in the paper. (specifically in Fig. (4), Fig (1), Tab. (5))\n- The takeaway from the experiment shown in Tab. (4) is unclear. While Tab. (3) shows a small advantage for the proposed method, the results in Tab. (4) do not reflect that.\n- The evidence for an advantage in underrepresented data could be made stronger (using more examples, specifically in the image domain).\n\nIf some of my weaknesses are properly addressed I am inclined to raise my score."
            },
            "questions": {
                "value": "- I believe it would be easier to follow the comparisons by using a consistent naming scheme, instead of the current SDE(<number>)\n- How do extremely small NFEs (5-15) effect the sampling quality of the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "A family of inverse dynamics is derived for diffusion models that use isotropic (\\alpha)-stable noise instead of Gaussian noise. Such models have been proposed recently with a deterministic inverse dynamics and a stochastic one. The deterministic dynamics is guaranteed to retrieve the exact marginal distributions. Unfortunately, the stochastic dynamics yields only approximate solutions.  This paper addresses this limitation. The algorithm is expected to be effective for data generation on imbalanced datasets. Its practical usefulness is experimentally examined in applications to image generation and text-to-speech tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "A parametric family of inverse dynamics is derived for diffusion models that use isotropic (\\alpha)-stable noise instead of Gaussian noise. Unlike the previously proposed one, this family is guaranteed to exactly retrieve the target marginal distributions for any parameter setting in ideal cases."
            },
            "weaknesses": {
                "value": "Writing in section 3.3 is sloppy. Since \"some intractable data-dependent process Z_t\" is not explained sufficiently, it is difficult to grasp the relation between the previously proposed algorithm and the current one."
            },
            "questions": {
                "value": "The relation between the algorithm by Yoon et al (2023) and the current one is unclear. Please explain more details on how equations (4) and (11) are related."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}