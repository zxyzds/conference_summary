{
    "id": "kQCHCkNk7s",
    "title": "AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data",
    "abstract": "The site conditions that make astronomical observatories in space and on the ground so desirable---cold and dark---demand a physical remoteness that leads to limited data transmission capabilities. Such transmission limitations directly bottleneck the amount of data acquired and in an era of costly modern observatories, any improvements in lossless data compression has the potential scale to billions of dollars worth of additional science that can be accomplished on the same instrument. Traditional lossless methods for compressing astrophysical data are manually designed. Neural data compression, on the other hand, holds the promise of learning compression algorithms end-to-end from data and outperforming classical techniques by leveraging the unique spatial, temporal, and wavelength structures of astronomical images. This paper introduces [AstroCompress](https://huggingface.co/AnonAstroData): a neural compression challenge for astrophysics data, featuring four new datasets (and one legacy dataset) with 16-bit unsigned integer imaging data in various modes: space-based, ground-based, multi-wavelength, and time-series imaging. We provide code to easily access the data and benchmark seven lossless compression methods  (three neural and four non-neural, including all practical state-of-the-art algorithms).\nOur results on lossless compression indicate that lossless neural compression techniques can enhance data collection at observatories, and provide guidance on the adoption of neural compression in scientific applications. Though the scope of this paper is restricted to lossless compression, we also comment on the potential exploration of lossy compression methods in future studies.",
    "keywords": [
        "astronomy",
        "physics",
        "astrophysics",
        "compression",
        "neural compression",
        "computer vision",
        "remote sensing"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "A large astrophysical raw imaging dataset curated for compression benchmarks, with an initial evaluation of neural and classical lossless compression methods.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=kQCHCkNk7s",
    "pdf_link": "https://openreview.net/pdf?id=kQCHCkNk7s",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces AstroCompress, a benchmark dataset designed for multi-purpose compression of astronomical images, providing a foundation for advancing astronomy-specific and science-oriented lossless neural compression. Through comprehensive experiments, various image compression codecs are tested and evaluated."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The released dataset is made open-accessible and well-organized for researchers to follow.\n2. Several lossless compression codecs have been tested including both learned/traditional methods. Evaluations of the impact on datasets and methods are presented."
            },
            "weaknesses": {
                "value": "1. Since many of the datasets are from publicly accessible resources, therefore i suggest that the authors should contribute more over the analysis and deeper evaluation of the re-organized AstroCompress dataset.\n2. The cross-dataset evaluation can be improved. In this paper, only brief conclusions about the generalization of different codecs are provided. A deeper evaluation of the similarity between different datasets and the reason for performing differently for different codecs is suggested."
            },
            "questions": {
                "value": "If there also exists some codecs specially designed for astro data, the authors should also provide some evaluation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper provide a dataset and benchmark for astronomical data compression. The dataset is relatively large (320 GB). Besides, the dataset composes 5 distinct subsets, which covers images of different dimension, resoluton and content types. The authors evaluate the datasets on different lossless compression methods, including IDF, L3C, PixelCNN++, JPEG series and RICE."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The dataset composes of diverse images, from 2D to 4D, which is impressive. The selective of neural lossless codec baseline is smart. In fact. IDF, L3C and PixelCNN++ represent three major paradigms of lossless compression: normalizing flow, latent variable model and auto-regressive model. In fact, I can not think of a better choice if I need to choose three most representative lossless image codec."
            },
            "weaknesses": {
                "value": "One most evident weakness is that the authors evaluate 7 general lossless codec and only 1 astronomical codec (published in 2009). I have two explainations for this evaluation:\n* The authors's evaluation is not thorough, many astronomical codecs are omitted.\n* The astronomical data compression is not an active research area, and the only reasonable baseline is published 15 years ago.\nEither of the explaination makes me hesitate about accepting this paper.\n\nBesides, I am not really sure about how important astronomical data compression is to ICLR community. From the BACKGROUND AND RELATED WORK section in this paper, I find that most papers of astronomical data compression are published in remote sensing and compression related venues, not machine learning related venues (NIPS, ICLR, ICML, CVPR, ICCV, ECCV, etc.). I am not really sure about:\n* How many people in ICLR community is interested in astronomical data compression?\n* How many people in astronomical data compression community will read ICLR?"
            },
            "questions": {
                "value": "It is the first time that I ever review a benchmark paper. I am not definitely sure about my evaluation. And I am glad to change my mind if other reviewers are positive toward this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper describes a new dataset for benchmarking neural compression on astronomical data. The paper lays out how the efficacy of astronomical experiments is highly dependent storage and transmission, and that the fidelity of the data must be preserved, motivating the use of neural lossless compression. The dataset itself is apparently unprecedented in scope for astronomical data with five sub-datasets including a mix of 2D still images as well as spatio-temporal and multispectral hypercubes of high resolution. The paper concludes by testing a series of well know neural and non-neural lossless compression algorithms on the dataset."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper makes a strong contribution to astrological and neural compression research. The paper lays out clearly how astrological experiments depend on good compression and why a dataset specific to astrological data is necessary. The scope of the dataset is also impressive. It is likely that a researcher working on neural compression, lossless or otherwise, would be interested in findings from testing their method on this dataset. Likewise I can imagine astrological researchers using results on this dataset to decide what methods to deploy. Finally the assembly procedure and details in Appendix A shows that great care was put into the curation of the data."
            },
            "weaknesses": {
                "value": "The only thing which I would have liked to see more discussion on was the point about runtime/compression ratio. Is there any actionable recommendation here? Also given that JPEG-XL is mostly a reference implementation right now and hasn't been optimized while the neural methods require a GPU, is it  fair comparison to say that it is slower?"
            },
            "questions": {
                "value": "* Any actionable recommendation around neural/classical compression based on results?\n* Are resource requirements (GPU, memory) factored into speed results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a benchmark dataset designed for multi-purpose compression of astronomical imagery. A range of image compression codecs is tested and evaluated through comprehensive experiments. The benchmark dataset can serve for researches in astronomy-specific and science-specific lossless neural compression by providing a carefully curated, accessible dataset, along with easily referenceable benchmarks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The released dataset is well organized and large in scale and diversity to cover a wide range of astrophysics data.\n2. The tested anchors are representative, including both popular learned and conventional codecs."
            },
            "weaknesses": {
                "value": "1.\tTwo different methods for handling 16-bit images are discussed and tested. It is recommended that the performance differences between these methods be highlighted.\n2.\tThe proposed dataset\u2019s effectiveness, especially in comparison to existing datasets such as Maireles-Gonz\u00e1lez et al. (2023), could be explored more thoroughly.\n3.\tThe performance of RGB-pretrained models on the AstroCompress dataset are suggested to be examined and reported.\n4.\tThe implementation details regarding correlated-frame compression could be clarified further. Specifically, it should be explained whether different frames are compressed independently for each tested anchor, or if a different approach is used."
            },
            "questions": {
                "value": "As an important aspect in image compression, some preliminary experiments and evaluation on lossy compression are expected."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}