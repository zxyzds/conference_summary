{
    "id": "VRTCXYvPxc",
    "title": "VIDEOGUARD: PROTECTING VIDEO CONTENT FROM UNAUTHORIZED EDITING",
    "abstract": "With the rapid development of generative technology, current generative models can generate high-fidelity digital content and edit it in a controlled manner. However, there is a risk that malicious individuals might misuse these capabilities for misleading or unlawful activities. Although existing research has attempted to shield photographic images from being manipulated by generative models, there remains a significant disparity in the protection offered to video content editing. To bridge the gap, we propose a protection method named VideoGuard, which can effectively protect videos from unauthorized malicious editing. This protection is achieved through the subtle introduction of nearly unnoticeable perturbation that interferes with the functioning of the intended generative diffusion models. Different from images, videos consist of sequential frames, containing not only visual content but also motion dynamics. Due to the redundancy between video frames, and inter-frame attention mechanism in video diffusion models, simply applying image-based protection methods separately to every video frame can not shield video from unauthorized editing. To tackle the above challenge, rather than optimize perturbation in a frame-wise manner like image-based methods, we adopt joint frame optimization, treating all the video frames as an optimization entity. Furthermore, we extract video motion information and fuse it into optimization objectives. Thereby, these alterations can effectively compel the models to produce outputs that are implausible and inconsistent. We provide a pipeline to optimize such a perturbation. Finally, we use both objective metrics and subjective metrics to demonstrate the efficacy of our method, and the results show that the protection performance of VideoGuard is superior to all the baseline methods.",
    "keywords": [
        "Diffusion Models",
        "Video Editing Protection"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "Propose a method for protecting videos from malicious editing",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=VRTCXYvPxc",
    "pdf_link": "https://openreview.net/pdf?id=VRTCXYvPxc",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes VideoGuard to protect video content from unauthorized editing by diffusion-based video editing models.  VideoGuard introduces a two-stage optimization pipeline, including Optimizing DDIM Inversion Latent and Optimizing Video Perturbation."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This work regards the video and its inversion as a whole, instead of using an image-based approach and processing it frame by frame. It's reasonable.\n2. Experimental results demonstrate the effectiveness of the two-stage approach."
            },
            "weaknesses": {
                "value": "1. The experiments are insufficient and do not introduce enough baseline methods to prove the superiority of the proposed method.\n2. Lack of test results on more video editing methods."
            },
            "questions": {
                "value": "Please demonstrate the superiority of the proposed method through more sufficient experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes VideoGuard to protect videos from unauthorized editing. VideoGuard consists of two-stage pipelines. In the first stage, the authors use DDIM inversion process to get an initial noise latent from the original video. Then, the method optimizes the latent so that the denoising from the latent will result in a disrupted video, and therefore the video editing will be unsuccessful.  In the second stage, the method tries to find a perturbation that after adding it on top of the source video it can make the inversion of the video close to the optimized latent from stage 1. In addition, the added perturbation is required to be imperceptible. Therefore, VideoGuard can produce a similar source video that is free of unauthorized editing."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed approach is interesting and reasonable to achieve the goal of protecting videos from unauthorized editing.\n2. VideoGuard is to protect the video in the video pixel space, and the enhanced video is similar to the source video with extra shield.\n3. The method treats the video as a whole without needing to process each frame individually."
            },
            "weaknesses": {
                "value": "My major concern is the results of VideoGuard. Although VideoGuard is a reasonable approach, seems the performance is not very effective. \n\nFirst of all, the video editing used seems not good. The edited videos are not very realistic from the examples shown in the paper. If the video editing method is not strong enough, it might be easy to protect the source video from effective editing.\n\nSecond, the protection result of VideoGuard is not good. As shown in the second row of Fig.3, VideoGuard fails to protect the source video. The immunized video is successfully changed by the prompt. Also, as shown in Fig. 5, the edited video protected by VideoGuard changed a lot, deviating a lot from the source video.\n\nFor the quantitative result, compared to the baseline without protection, the number did not make a large difference. I suppose the metric number will be very difference when comparing with and without protection."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces VideoGuard, a method designed to protect videos from unauthorized editing by generative diffusion models. Unlike prior efforts that primarily focus on images, VideoGuard specifically addresses the unique challenges posed by video content, including the sequential structure of frames and the presence of motion dynamics. The approach involves adding imperceptible perturbations across frames, which disrupt the generative model's operations without compromising the visual quality of the video. The paper presents a pipeline for implementing these perturbations and validates VideoGuard's effectiveness using various metrics."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This work represents the first attempt to prevent unauthorized manipulation of videos, paving the way for future research in this area."
            },
            "weaknesses": {
                "value": "**Novelty:** While this work is a pioneering attempt to counter unauthorized manipulation in video editing models, the proposed method demonstrates limited innovation. The two-stage learning approach lacks specific insights tailored to this task. Specifically, in both stage 1 and 2, the authors apply PGD to learn the perturbated latent code and protedcted videos. However, PGD is published in 2018, which is outdated. I suggest the authors to customize a new temporal attack method for the task. \n\n**Motivation:** The authors propose that their method prevents unauthorized video editing, yet it essentially functions as a targeted attack, meaning the input video can still be manipulated. Namely, the goal of preventing unauthorized video editing is not fully achieved in this work. Additionally, the resulting videos align more closely with a target latent rather than the input prompt. Furthermore, the method requires full access to the model's architecture, presenting a significant limitation. Although cross-model results are reported in experiments, the method shows poor transferability to unseen models. In real-world scenarios, the transferability to unseen models and datasets is crucial. More transferability evaluations are expected to enhance the quality of this work.\n\n**Methodology:** Stage 1 uses first-order difference to capture motion information, while Stage 2 aims to align the latent code of protected videos with an anchor code. However, these techniques are too simple and lack insights to the task of video protection. The authors do not fully use the temporal information in sequential signals. \n\n**Experiments:** The method exhibits limited quantitative and qualitative improvements. In Table 1, its performance is only slightly better than the random noise baseline. This work fails to compare with SOTA attack methods, such as BSR [a] and ILPD [b]. The effectiveness of the qualitative results is not clearly demonstrated. \n\n[a] K. Wang, X. He, W. Wang, and X. Wang. Boosting adversarial transferability by block shuffle and rotation. In Proc. IEEE Int\u2019l Conf. Computer Vision and Pattern Recognition, 2024.\n[b] Q. Li, Y. Guo, W. Zuo, and H. Chen. Improving adversarial transferability via intermediate-level perturbation decay. Proc. Annual Conf. Neural Information Processing Systems, 2023."
            },
            "questions": {
                "value": "What datasets are used in training and testing? It seems the testing data only comprises 80 text-video pairs. I concern that the data size is too limited to demonstrate the effectivenss of the proposed approach."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces a protection method called VideoGuard, designed to safeguard videos against unauthorized malicious editing. The optimization process involves analyzing all frames collectively, with the differences between frames extracted as motion information for optimization purposes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. This work adopts adversarial attack techniques from the field of image attacks into the video field to safeguard video editing methods that require the DDIM inversion step."
            },
            "weaknesses": {
                "value": "1. The video editing methods tested are quite outdated. Many contemporary video editing models, such as [1, 2, 3], do not require the DDIM inversion steps. In this case, does the method still remain effective?\n\n2. The method appears to merely adopt techniques from the field of image attacks, but applied in a higher-dimensional space that includes the timestamp.\n\n3. From Figure 3, it appears that the protection is ineffective, as the identities of Biden and Trump remain quite evident, with only minor color distortions present. To prevent the generation of these identities, methods for concept erasure, such as those described in [4, 5, 6, 7], could be considered. A brief discussion on concept removal in the related work section would be expected.\n\n5. The layout of the main pipeline figure (Figure 2) is poorly arranged. The text and formulas should be enlarged for improved readability.\n\n6. The citation format is incorrect, further diminishing readability. The authors have mistakenly used integral citations instead of non-integral citations. Please correct this.\n\n---\n[1] Consistent Video-to-Video Transfer Using Synthetic Dataset\n\n[2] Video Editing via Factorized Diffusion Distillation\n\n[3] Fairy: Fast parallelized instruction-guided video-to-video synthesis.\n\n[4] Erasing Concepts from Diffusion Models\n\n[5] Ablating Concepts in Text-to-Image Diffusion Models\n\n[6] MACE: Mass Concept Erasure in Diffusion Models\n\n[7] Separable Multi-Concept Erasure from Diffusion Models"
            },
            "questions": {
                "value": "Please refer to the weaknesses.\n\nIf the authors adequately address my concerns during the rebuttal, I am open to adjusting my score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}