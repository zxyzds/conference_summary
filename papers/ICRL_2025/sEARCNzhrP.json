{
    "id": "sEARCNzhrP",
    "title": "Interaction Makes Better Segmentation: An Interaction-based Framework for Temporal Action Segmentation",
    "abstract": "Temporal action segmentation aims to classify the action category of each frame in untrimmed videos, primarily using RGB video and skeleton data. Most existing methods adopt a two-stage process: feature extraction and temporal modeling. However, we observe significant limitations in their spatio-temporal modeling: (i) Existing temporal modeling modules conduct frame-level and action-level interactions at a fixed temporal resolution, which over-smooths temporal features and leads to blurred action boundaries; (ii) Skeleton-based methods generally adopt temporal modeling modules originally designed for RGB video data, causing a misalignment between extracted features and temporal modeling modules. In this paper, we propose a novel Interaction-based framework for Action segmentation (InterAct) to address these issues. Firstly, we propose multi-scale frame-action interaction (MFAI) to facilitate frame-action interactions across varying temporal scales. This enhances the model's ability to capture complex temporal dynamics, producing more expressive temporal representations and alleviating the over-smoothing issue. Meanwhile, recognizing the complementary nature of different spatial modalities, we propose decoupled spatial modality interaction (DSMI). It decouples the modeling of spatial modalities and applies a deep fusion strategy to interactively integrate multi-scale spatial features. This results in more discriminative spatial features that are better aligned with the temporal modeling modules. Extensive experiments on six large-scale benchmarks demonstrate that InterAct significantly outperforms state-of-the-art methods on both RGB-based and skeleton-based datasets across diverse scenarios.",
    "keywords": [
        "Video Understanding; Video Analysis;"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=sEARCNzhrP",
    "pdf_link": "https://openreview.net/pdf?id=sEARCNzhrP",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a novel Interaction-based framework for Action segmentation,  which integrates multiple temporal resolutions\nfor frame-action modeling, thereby enhancing temporal interactions. Extensive experimental results demonstrate its effectiveness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper is well-written and it achieves good performance on the benchmarks."
            },
            "weaknesses": {
                "value": "- The contribution of multi-scale temporal modeling have been studied well by many previous works. So this paper has limited novelty.\n- Missing recent SOTA methods, like Semantic2Graph and ASPnet.\n- Whether the two modal data (RGB and skeleton data) fusion can be used as the input of the model, the experimental results can provide help to the author."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To enhance skeleton-based action segmentation by extracting more discriminative features, the authors propose multi-scale spatial modeling to fuse different modalities. To improve action segmentation by capturing complex temporal dynamics, the authors propose a MFAI that facilitates frame-action interactions across multiple temporal scales."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper clearly outlines its motivations, proposing a MFAI for frame-action interactions and a DSMI for fusing spatial features, with a certain degree of originality."
            },
            "weaknesses": {
                "value": "1.\tThe motivations outlined in the Introduction assume that iterative frame-action interactions at a constant temporal resolution would result in over-smoothing. To substantiate this, a visualization experiment is conducted, which shows that boundaries become more visually discernible. However, the effect may be due to the boundary prediction module and the existing label smoothing method. When aiming to elucidate the precise role of a structure, it is advisable to conduct a single-variable analysis. Regrettably, the paper lacks ablation experiments about both the boundary prediction module and the operations at a fixed temporal resolution. Therefore, the experimental support is insufficient for the conclusion, and the analysis is not rigorous, which makes the motivation speculative and lacks persuasiveness. Suggestions: \n(1) Conduct a comparative analysis of t-SNE visualization results, where one is derived from InterAct and another is from a modified version of InterAct devoid of the BPM.\n(2) To ascertain whether a fixed temporal resolution poses a limitation, compare t-SNE visualization outcomes between InterAct and a variant where the encoder-decoder is substituted with MS-TCN.\n(3) To evaluate the impact of label smoothing, eliminate the BPM and replace label smoothing with the Average employed by FACT.\n\n2.\tSome SOTA methods are not compared in this paper, such as ASPnet, Semantic2Graph, and BIT. I suggest not to ignore these methods that perform better than the proposed one, because some methods also adopt frame-action interaction, such as BIT, and multiply modalities fusion, such as ASPnet. Comparing your method with the above SOTA methods can effectively underscore the merits of your solution, particularly because: (1) Your DSMI serves as a fusion strategy, echoing similar strategies proposed by ASPNet and Semantic2Graph in feature fusion. (2) Your MFAI constitutes a frame-action interaction module, paralleling the frame-action interaction module introduced by BIT.\n\n3.\tMany grammar errors need to be corrected, for example,\n    (1) The last line of page 4, \u201csuffers from\u201d should be \u201csuffer from\u201d.\n    (2) In Section 2.1, \u201cframe and action level\u201d should be revised to \u201cframe and action levels\u201d. \n    (3) In the line before equation (8), \u201cas follow\u201d should be revised to \u201cas follows\u201d.\n    (4) Line -5 of page 5, \u201cD is the feature dimensions\u201d should be revised. \nWe suggest that the authors have the paper professionally proofread or reviewed by a native English speaker to address language issues comprehensively.\n\n4.\tBoth MFAI and MAFI are used in this paper, which makes me confused about the paper. We suggest consistently use one acronym throughout the paper and include it in a list of abbreviations for clarity."
            },
            "questions": {
                "value": "Did you experiment with replacing the encoder-decoder with models like MS-TCN or ASFormer that operate on fixed full temporal resolution? If yes, please add the descriptions. If not, your motivation for multi-scale analysis in the introduction lacks support."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces **InterAct**, a framework that advances temporal action segmentation by enhancing frame-action interactions and aligning spatial modalities in RGB and skeleton data. It targets limitations in existing temporal modeling techniques that over-smooth temporal features and blur action boundaries. The framework's two key components are Multi-scale Frame-Action Interaction (MFAI) and Decoupled Spatial Modality Interaction (DSMI). MFAI enables frame-action interaction at various temporal scales, and DSMI decouples spatial modeling for RGB and skeleton data to create better-aligned spatial representations. Extensive experimentation demonstrates InterAct\u2019s effectiveness in improving state-of-the-art results across multiple datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea of using a shared backbone for both skeleton-based and RGB-feature action segmentation is promising. The method is evaluated on six diverse datasets, showing substantial improvements over competitive benchmarks."
            },
            "weaknesses": {
                "value": "### 1. Unsupported Claims on Over-Smoothing and Blurred Boundaries\n The authors assert that RGB-based TAS methods suffer from over-smoothing, which they argue leads to blurred action boundaries. However, this claim lacks convincing evidence:\n- More thorough proof is necessary to validate that over-smoothing indeed causes boundary detection issues.\n- It is unclear how the results presented in Figure 4 support the claim of over-smoothing. Further clarification is needed to explain the causal link between the observed effects in Figure 4 and the issue of over-smoothing.\n- Table 6 shows that three stages of frame-action modeling yield optimal results, yet the authors do not adequately explain why this stage limit would prevent oversmoothing, despite assuming it as an issue.\n\n### 2. Limited Novelty and Borrowed Ideas\nThe paper presents limited novelty, appearing to draw heavily on ideas from prior works. Notably:\n- The use of multiple temporal resolutions within an encoder-decoder model, along with multi-scale outputs for prediction, has already been explored in previous work (Singhania et al., 2023).\n- Similarly, the implementation of segment-level learnable queries and cross-attention closely resembles techniques described in Behrmann et al. (2022).\nThe authors should clarify how their approach differs from or improves upon the multi-scale techniques used by Singhania et al. (2023) or the query-based methods proposed by Behrmann et al. (2022).\n### 3. Inadequate Explanation on Addressing Spatial and Temporal Misalignment\nThe paper claims to address the misalignment between spatial features and temporal modules in skeleton-based TAS, yet it does not provide a satisfactory explanation of how the proposed method mitigates this issue. Specific details on how the approach prevents or corrects spatial-temporal misalignment would strengthen the paper\u2019s argument.\n\n### 4. Inconsistent Ablation Study and Limited Scope\nThe ablations presented in Tables 4 and 5 are conducted on different datasets, which weakens the comparison. Additional issues include:\n- Table 5 appears to focus on skeleton data, suggesting that there is no ablation specifically on RGB-based action segmentation. It is necessary to see ablation results on the Breakfast dataset, a large RGB action segmentation dataset, to assess the robustness of the proposed method.\n### 5. Missing Benchmark Results\nIn Table 1, results are missing for MCFS-130 on the DiffAct, UVAST, and LTContext benchmarks, despite the authors of these approaches making code available. The inclusion of these results would provide a more complete comparison.\n\n### 6. Missing Ablation for Encoder and Decoder Layers\nAn ablation on the number of encoder and decoder layers is missing, which would be important to evaluate. Layer depth directly influences the granularity of temporal resolution, a factor critical to the proposed framework."
            },
            "questions": {
                "value": "Several important ablations and experiments are missing; see weaknesses for further details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}