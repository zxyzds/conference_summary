{
    "id": "vAuodZOQEZ",
    "title": "Physics-Informed Neural Predictor",
    "abstract": "Accurately predicting fluid dynamics and evolution has been a long-standing challenge in physical sciences. Conventional deep learning methods often rely on the nonlinear modeling capabilities of neural networks to establish mappings between past and future states, overlooking the fluid dynamics, or only modeling the velocity field, neglecting the coupling of multiple physical quantities. In this paper, we propose a new physics-informed learning approach that enables the prediction of coupled physical states, under a partially observed data environment. Central to our method lies in the discretization of physical equations, which are directly integrated into the model architecture and loss function. This integration enables the model to predict future states of observable data while simultaneously inferring and predicting hidden physical quantities (e.g., velocity and pressure) purely from visual observations. By incorporating physical equations, our model demonstrates temporal extrapolation and spatial generalization capabilities. Experimental results show that our approach achieves the state-of-the-art performance in spatiotemporal prediction across both numerical simulations and real-world extreme-precipitation nowcasting benchmarks.",
    "keywords": [
        "Fluid dynamics",
        "Spatiotemporal prediction",
        "Physics-informed learning"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "We integrated PDEs into the network and loss function, enabling the prediction of observable physical quantities and the inference of future latent physical quantities as interpretation.",
    "creation_date": "2024-09-23",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vAuodZOQEZ",
    "pdf_link": "https://openreview.net/pdf?id=vAuodZOQEZ",
    "comments": [
        {
            "summary": {
                "value": "This paper proposed the PINP method for fluid prediction. The method predicts future fluid fields by learning velocity and pressure simultaneously from partial observations. The authors employ a physical inference neural network to predict several physical quantities of the flow field at a particular moment. For the next timestep, they utilizes discrete PDEs predictor and correction network to generate the flow field. The training of the model is refined through the application of MSE loss, equation loss, and a temporal constraint loss. The proposed method shows advantages compared to several baselines on both synthetic and real-world data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper combines equation loss with operator learning through the Navier-Stokes equation, integrating physics-driven and data-driven approaches by learning unobserved physical quantities.\n- An innovative point of the proposed method is incorporating the equation loss commonly used in PINN, including incompressible Navier-Stokes equations, into predicting potential physical quantities of the future flow field.\n- The figures provided in the paper can accurately reflect the characteristics of the model.\n- The ablation of the paper accurately explains the role played by each module."
            },
            "weaknesses": {
                "value": "This paper has some weaknesses, including:\n- Some datasets are too simple or may theoretically not match the methods to some extent.\n  - The fluid motion in the Flow 2D dataset is relatively slow, and the dynamics are not as complex as those encountered in more advanced fluid dynamics scenarios.\n  - The fluids in real datasets may not strictly adhere to the incompressible Navier-Stokes equations. Consequently, the physical constraints proposed in this paper might encounter limitations when applied to more diverse or complex fluid systems.\n- The improvements observed in specific datasets, such as Smoke3D, are modest. For example, the MAE and MSE metrics of Smoke 3D only demonstrate a marginal enhancement.\n- The paper's grammar and expression could be improved. In some instances, the clarity of the writing detracts from the overall quality of the paper, potentially hindering the reader's understanding of the research.\n\nSpecific issues and possible improvements will be discussed in the next section."
            },
            "questions": {
                "value": "- For the sole real dataset, SEVIR, raises several concerns:\n  - It is unclear why the MSE metric for the proposed method underperforms compared to most other baselines. A detailed analysis and discussion of this discrepancy would be beneficial.\n  - Given the potential phase transition of water in the SEVIR dataset, it is questionable whether the fluid satisfies the incompressible property. The authors are encouraged to discuss the applicability of the equation loss function to real datasets with such characteristics.\n  - I highly recommend the authors compare with the traditional numerical method pySTEPS[1], which predicts future fluid fields by estimating potential velocity fields and extrapolating optical flow. This method has the ability to accurately estimate extreme values.\n- The paper does not specify the fluid's Reynolds number, which is crucial for understanding the flow characteristics. The fluid in the Fluid 2D dataset appears to represent simple laminar flows. The authors are recommended to provide experiments with more turbulent datasets to enhance the paper's practical value.\n- The paper lacks information on how the baselines were trained, and some baselines exhibit abnormal flickering. The authors should recheck the training process for all baselines or explain these anomalies.\n- The visualization of velocity in the paper is not as intuitive as it could be. Utilizing tools such as *pyplot.quiver* in *matplotlib* to depict the velocity field based on flow field observations as supplementary material is suggested.\n- The grammar and expression throughout the paper should be improved. A thorough review and enhancement are advised.\n\n\n[1] https://pysteps.github.io/"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work presents a new physics-informed learning approach that enables the prediction of coupled physical states, under a partially observed data environment. It applies the discretization of physical equations, integrating into the model architecture and loss function. The superior performance is shown in four benchmarks including a real-world data."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method enhances the simulation capacity of PDEs, especially on the long-term prediction.\n2. The proposed method is tested on multiple benchmarks across different scenarios, especially on the real-world measured dataset.\n3. The authors vividly demonstrated the simulation process through videos."
            },
            "weaknesses": {
                "value": "1. The reviewer believes that there are significant issues with the introduction of the method. The method is complex and lacks an overview of the proposed method. The reviewer understands that the proposed method first outputs $p(t')$, $u(t')$, and $c(t')$ through a physical inference network, where these three outputs are constrained by physical and temporal conditions. Then $\\hat{c}'(t+1)$ is computed through discretized PDEs, after which $\\hat{c}'(t+1)$ and $c(t)$ are fed into another network for prediction, while simultaneously incorporating a data loss with the label. If this understanding is correct, the reviewer questions the novelty of this work, as it merely sandwiches numerical FDM calculations between neural networks. Moreover, the motivation for this approach remains unclear.\n2. In line 039, the statement is inaccurate and needs to be referenced to the literature. The reviewer points out that velocity fields can be observed through techniques such as PIV and PTV.\n3. In line 069, what does the past observable data mean. Authors should introduce more about the settings.\n4. In line 102, \"often difficult to obtain in practical applications\". The reviewer considers the statement is inappropriate, as initial conditions are typically obtainable when solving PDEs.\n5. In Table 1, the reviewer appears to have misinterpreted the meaning of the three categories in this table. If 'velocity' refers to velocity fields, then this table is not appropriate, as FNO (Fourier Neural Operator) is equally capable of predicting both velocity and pressure fields.\n6. In Eqn. 3, why does this equation still integrate from t to t+1? A more detailed derivation process is needed to help readers understand. This is crucial for comprehending the motivation behind the problem. What is the meaning of $\\Delta t$?\n7. In Sec. 3.4, the introduction is oversimplified, merely stating which networks are used. This raises two concerns for the reviewer: first, why was U-Net chosen over more advanced transformer architectures, and second, too many network structural details are omitted, forcing readers to consult the appendix for understanding.\n8. In Sec. 3.5, author should carfully introduce the training process as there are many networks and parameters. Are they trained in an end-to-end manner? This raises a question about how the physials inference network can simultaneously learn Pe and output flow fields. These two components might interfere with each other, potentially making the network untrainable. Has the use of stop-gradient operations like VQVAE been considered?\n9. What is the PDE for the real-world data? Is it explicitly known? Real data often comes with noise - has this method considered noise effects, or are there any approaches proposed to address the influence of noise?\n10.  In Sec. 5, especially in Fig. 9(a), the authors need to specify the number of experimental trials conducted and report the confidence levels, as it appears that the two constraints overlap for an extended period of time.\n11. What is the detail setting of the fluid 2D data, including $\\nu$, $dx$, $dt$, and boundary conditions?\n12. The reviewer does not find the link of code and dataset from the paper. Code and data are important criteria for verifying the rationality of results. Will the author make them opensource\uff1f"
            },
            "questions": {
                "value": "Please check the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper's core idea is to combine a data-centric deep learning approach with physics by incorporating the discretised Navier-Stokes equations into the neural network architecture and constraining the loss function. By explicitly incorporating the governing equations and the associated physical quantities, the authors try to model the system and help with consistency, interpretability, and extrapolation capabilities. The extensive proposed experiments show good performances and generalisation to unseen domains."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper is very well written and explains complex problems clearly.\n- While the idea of incorporating PDE-based constraints in the network architecture and loss function is not new, the author presents a set of methods, tricks, and ideas that make the technique work better than previous literature."
            },
            "weaknesses": {
                "value": "- Interpretability depends on the other physical quantities' models. While there are theoretical reasons to believe the quantities are interpretable, there is little experimental evidence.\n- The pertinence of benchmarking nowcasting and the advantage of this method over other neural operator-based methods for this task is unclear."
            },
            "questions": {
                "value": "- The gradient discretisation used here is a second-order central difference approximation. Could you elaborate on whether there were specific architectural reasons for choosing this method over other discretisation schemes? Additionally, it would be helpful to understand if you considered alternative discretisation approaches\nYou compare two different sets of baseline: one for now-casting and one for Navier-Stoke simulation. Why is your model capable of doing both, as other neural operator-based models are not? That seems like a significant advantage that has yet to be developed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new physics-informed fluid predictor, named PINP. PINP firstly estimates the underlying pressure and velocity filed from observed fluid, which is constrained by a discretized physics loss. Then it employs an interpolation formalization of integral for future prediction, where an additional correction network is presented to reduce the error of discretized PDE predictor. Experimentally, PINP performs well in 2D and 3D flows and weather prediction tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper is overall well-written.\n\nThe idea of incorporating physics loss into fluid prediction is reasonable.\n\nThe authors have provided comprehensive experiments to verify the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1.\tThe title is kind of overclaimed. \n\n\nSince this paper is tailored to fluid prediction, I think \u201cphysics-informed fluid predictor\u201d is more suitable. Otherwise, it is a little bit overclaimed, where there are extensive prediction tasks that PINP cannot solve, such as rigid body movement (controlled by classical physics) or magnetic field (governed by electromagnetism).\n\n2.\tA series of technical designs are underexplored or not well supported.\n\n(1)\tPINP adopts the discretized PDE loss for physics constraint, which may bring serious approximation error. The current design is based on the assumption that the differential operator can be approximated by spatial or temporal difference, which cannot be satisfied, especially in low-resolution data. Note that I am not saying that being physics-informed is a bad idea. The canonical physics-informed neural works employ the auto differential in neural works for approximation, which is much more precise than the discretization in PINP.\n\n(2)\tI cannot figure out that why additionally predicting the pressure field can boost the performance. As shown in Figure 2 (b), the predicted pressure field is only used in physical constraint loss, which cannot affect the future prediction process. This means that predicting the pressure field is just to fit the physical loss, which brings a new meaningless task. According to my experience, I think this design can only bring extra load to the model instead of benefiting the prediction. Besides, as shown in Figure 9(a), removing physical constraints will not bring a serious decrease. Further, How about keeping the second equation in Eq.(12) but removing the pressure-related one? I believe that the benefit of physics loss is mainly brought by the incompressible term loss. \n\n(3)\tThe design of the correction network is also weird. As formalized in Eq.(10), the inputs and outputs of the correction network are both expected to be close to the ground truth. Under this constraint, why correction network is necessary? (Minor: Eq.(10) may have a typo, where the comma should be \u201c-\u201d).\n\n(4)\tAbout the temporal loss. I am curious about how likely is this loss function to work. Some statistical results on how many times this loss is non-zero are expected.\n\nGoing further from (2), I doubt that the prediction of pressure field is useless in the current design, which is listed as one of the main contributions w.r.t. other papers. I think compared with Helmfluid, the advantage of PNIP lies in the physical loss, which can provide a more direct and explicit constraint to the velocity field.\n\nIn summary, I think there are many unsupported designs in the proposed method, which may affect the claim of the main contribution of this paper.\n\n3.\tAbout the efficiency. \n\nI am curious about the training overload. Since the calculation of loss in Eq.(16) may also cause extra computation costs than other baselines."
            },
            "questions": {
                "value": "1.\tAbout implementation of baselines.\n\nIn NowCastNet, ensuring eidetic prediction results is one significant contribution of this paper. However, as shown in Figure 8, its prediction is quite blurry. I am wondering how the authors experimented with this baseline.\n\nBesides, in the supplementary materials, the prediction results of LSM and FNO appear strange periodic shakes. Actually, I think a well-trained deep model will not make such weird predictions. Did the authors carefully tune these two baselines?\n\n2.\tAbout spatial generalization.\n\nWhy PINP can achieve spatial generalization? Can the authors provide some intuitive explanations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}