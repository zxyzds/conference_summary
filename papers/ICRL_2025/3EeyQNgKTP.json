{
    "id": "3EeyQNgKTP",
    "title": "Build Roadmap for Automated Feature Transformation: A Graph-based Reinforcement Learning Approach",
    "abstract": "Feature transformation task aims to generate high-value features and improve the performance of downstream machine learning tasks using the mathematical feature-feature crossing. \nCurrent frameworks rely on iterative sequence generation with exploration optimization through performance feedback from downstream tasks.\nHowever, these approaches fail to effectively utilize historical decision-making experiences and overlook potential relationships among generated features, thus limiting the flexibility of the whole process.\nMoreover, the decision-making process lacks dynamic backtracking capabilities for each feature, leading to insufficient adaptability when encountering inefficient pathways, adversely affecting overall robustness and exploration stability.  \nTo overcome these challenges, we present an innovative framework that employs a feature-state transformation graph to maintain the roadmap of feature transformation, with each node symbolizing a transformation state. \nDuring exploration, three cascading agents sequentially select nodes and mathematical operations to generate new transformation states.\nThis strategy leverages the graph structure's inherent properties, allowing for the preservation and reuse of sight-seen and valuable transformations. \nIt also enables back-tracking capabilities through graph pruning techniques, which can rectify inefficient transformation paths.\nTo validate the efficacy and flexibility of our approach, we conducted comprehensive experiments and detailed case studies, demonstrating superior performance in diverse datasets.",
    "keywords": [
        "Automated Feature Transformation",
        "Tabular Data",
        "Multi-Agent Reinforcement Learning"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=3EeyQNgKTP",
    "pdf_link": "https://openreview.net/pdf?id=3EeyQNgKTP",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces an automated feature transformation framework designed to enhance downstream machine learning model performance. The TCTO framework leverages a reinforcement learning-based graph structure to maintain a roadmap of feature transformations, enabling efficient exploration and backtracking of transformation pathways. TCTO uses a multi-agent reinforcement learning approach, clustering and encoding transformation states to strategically apply feature transformations. Experiments on multiple datasets demonstrate TCTO's performance over existing methods by improving robustness and flexibility in feature generation."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. While mostly clear, certain sections (e.g., cascading agent decision process) could benefit from additional details.\n\n2. The framework is well-supported by experimental evidence showing its adaptability across different datasets and improvement in downstream model performance.\n\n3. TCTO introduces a novel approach to automated feature engineering by employing a transformation-centric methodology with a graph-based roadmap, overcoming limitations of existing feature transformation methods.\n\n4. The approach\u2019s ability to backtrack and optimize feature transformations dynamically makes it highly applicable in real-world ML tasks where feature diversity and stability are crucial."
            },
            "weaknesses": {
                "value": "1. While effective on a range of datasets, it is unclear how well TCTO scales with extremely high-dimensional data or very large datasets, as the pruning strategy may require fine-tuning in these cases.\n\n2. The cascading decision-making process is intricate, and further simplification or additional visuals might aid understanding.\n\n3. The reward structure combines performance and complexity, but further discussion on how these metrics are weighted could improve transparency and replicability of the model\u2019s efficacy."
            },
            "questions": {
                "value": "1. Could the authors elaborate on how they determined the weights for performance and complexity in the reward function? More detail on this could clarify the balance between the two objectives.\n\n2\u3002 How does TCTO perform on high-dimensional datasets with over 10,000 features? Is the pruning strategy sufficient to maintain stability without compromising feature diversity?\n\n3. Were there any specific scenarios where TCTO\u2019s backtracking mechanism was particularly beneficial in terms of model performance or feature diversity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors present TCTO, a graph-based reinforcement learning framework designed for automated feature transformation. The approach addresses limitations in current methods, such as the lack of historical insight utilization and insufficient flexibility in transformation exploration. By constructing a transformation roadmap with nodes representing feature states, TCTO leverages a cascading multi-agent system to dynamically select transformations, reuse effective paths, and prune inefficient ones. The experimental results demonstrate that TCTO outperforms existing methods in generating high-quality features, suggesting its potential to enhance feature engineering in machine learning tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper has several notable strengths. Firstly, the authors present a well-motivated framework that addresses clear gaps in current automated feature transformation methods, such as the need for effective historical data utilization and robust backtracking. The proposed TCTO framework is innovative in its use of a graph-based roadmap and cascading multi-agent reinforcement learning, which enhance the flexibility and adaptability of the transformation process. Additionally, the authors provide a comprehensive experimental evaluation across diverse datasets, which convincingly demonstrates TCTO\u2019s superior performance compared to traditional methods. This solid empirical foundation supports the framework's potential for broad applicability in feature engineering for machine learning tasks."
            },
            "weaknesses": {
                "value": "While this paper offers a promising framework, it has some weaknesses. Firstly, the explanation of the cascading multi-agent system and its decision-making processes could benefit from more clarity and detail, as the current description may be challenging for readers to fully grasp without additional context. Additionally, the computational complexity of TCTO is not thoroughly analyzed, especially regarding scalability to larger datasets, which may impact its practical applicability. Finally, while the experimental results are extensive, the paper could further strengthen its claims by providing more insight into specific scenarios or datasets where TCTO may struggle, thereby clarifying the framework\u2019s limitations and potential areas for improvement."
            },
            "questions": {
                "value": "1.How does the computational complexity of TCTO scale with larger datasets, and are there any strategies to mitigate potential performance bottlenecks?\n2.Are there scenarios or specific types of datasets where TCTO\u2019s performance may be limited, and if so, what adjustments might be necessary to enhance its adaptability?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper deals with the automated generation of features. The generation process consists of several steps, which are represented as a graph. The graphs are to be optimized using multi-agent reinforcement learning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* It can be seen (among other things from the large number of specific illustrations) that a lot of effort was put into preparing the paper"
            },
            "weaknesses": {
                "value": "* I find the text very badly written. Examples follow. The novelty and benefits of the method are hard for me to understand.\n* It seems to me that there is too much material for a conference paper, the number of pages is simply not enough to present it in a convincing way.\n\nDetails, examples and further comments:\n* I don't think \u201croadmap\u201d is a suitable term, \u201cschedule\u201d or \"sequence\" would probably be better.\n* The title sounds strange. Wouldn't \"Optimization of transformation sequences for automated feature generation\u201c be better?\n* The abstract uses terms that are incomprehensible:\\\nmathematical feature-feature crossing\\\nthe roadmap of feature transformation\n* \u201eFeature transformation task aims to generate high-value features and improve the performance of downstream machine learning tasks using the mathematical feature-feature crossing\u201d needs to be reformulated.\n* \"Classic machine learning is highly dependent on the structure of the model, the activation function\" cannot be said in this way, it seems to refer exclusively to neural networks and not to classical machine learning in general.\n* A reference should be given for \"a cascading multi-agent reinforcement learning (MARL) algorithm\", because it is not generally known what \u201ccascading multi-agent reinforcement learning\u201d is.\n* \u201cwe present an innovative framework\u201d -> \u201cwe present a novel framework\u201d\n* In the loss function, Equation 8, the square is probably missing. \n* \"In this study, we introduce TCTO, an automated feature transformation framework. Our method emphasizes a transformation-centric approach, in which a transformation roadmap is utilized to systematically track and manage feature modifications.\" should be reworded. What is the information content? What should be expressed?\n* I think that the Abstract and Conclusion need to be completely rewritten."
            },
            "questions": {
                "value": "* How were the small uncertainties in Table 1 achieved? How often were the experiments repeated?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}