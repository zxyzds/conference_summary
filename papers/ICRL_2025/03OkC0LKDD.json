{
    "id": "03OkC0LKDD",
    "title": "The Vital Role of Gradient Clipping in Byzantine-Resilient Distributed Learning",
    "abstract": "Byzantine-resilient distributed machine learning seeks to achieve robust learning performance in the presence of misbehaving or adversarial workers.\nWhile state-of-the-art (SOTA) robust distributed gradient descent (Robust-DGD) methods were\nproven theoretically optimal, their empirical success has often relied on pre-aggregation gradient clipping.\nHowever, the currently considered static\nclipping strategy \nexhibits mixed results: improving robustness against some attacks while being ineffective or detrimental against others.\nWe address this gap by \nproposing a principled adaptive clipping strategy, termed Adaptive Robust Clipping (ARC).\nWe show that ARC consistently enhances the empirical robustness of SOTA Robust-DGD methods, while preserving the theoretical robustness guarantees. \nOur analysis shows that ARC provably improves the asymptotic convergence guarantee of Robust-DGD in the case when the model is well-initialized.\nWe validate this theoretical insight through an exhaustive set of experiments on benchmark image classification tasks.\nWe observe that the improvement induced by ARC is more pronounced in highly heterogeneous and adversarial settings.",
    "keywords": [
        "Byzantine resilience",
        "distributed machine learning"
    ],
    "primary_area": "optimization",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=03OkC0LKDD",
    "pdf_link": "https://openreview.net/pdf?id=03OkC0LKDD",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a novel strategy called Adaptive Robust Clipping (ARC) for Byzantine-resilient distributed machine learning. Empirical results show that using ARC can significantly enhance Byzantine resilience compared to the methods without clipping. Theoretical analysis of convergence is also provided to show the effect of ARC."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is generally well-written. \n2. The idea of adaptive clipping intuitively makes sense and has an excellent empirical performance in the experiments of this work.\n3. Byzantine resilience in distributed learning is an important and timely topic."
            },
            "weaknesses": {
                "value": "Although the proposed ARC strategy is generally not hard to implement and has a good empirical performance, there are major concerns about the theoretical analysis in this paper, which I specify point by point below. \n\n1. The theoretical results in section 3 show that $F\\circ ARC$ is $(f,3\\kappa)$-robust when $F$ is $(f,\\kappa)$-robust (Theorem 3.2). Although the property of $ARC$ is much better than trivial clipping (as shown in Lemma 3.1), the convergence guarantee obtained from Theorem 3.2 for $F\\circ ARC$ is worse than that for $F$ (without $ARC$). In other words, the theoretical results in section 3 show that $ARC$ has a better property than trivial clipping, but do not show that using $ARC$ can improve the convergence guarantees.\n\n2. The improvement of convergence guarantees for $ARC$ is mainly shown by Theorem 5.2. Theorem 5.2 says that when the maximum gradient norm of the initial point is not larger than $\\zeta$, using $ARC\\circ F$ can guarantee to find a point $\\hat{\\theta}$ such that the square norm of the gradient at $\\hat{\\theta}$ is not larger than $v \\epsilon_0$ in expectation. However, $v \\epsilon_0$ can be much larger than $\\zeta^2$ (which is specified in the next paragraph). Briefly speaking, the result of Theorem 5.2 can be even weaker than the conditions, which makes the theorem meaningless.  \n- Since $\\xi \\leq \\min(\\frac{v}{\\Phi(G,B,\\rho)},\\xi_0)$, it is obtained that $\\xi \\leq \\frac{v}{\\Phi(G,B,\\rho)}$, and thus $v\\geq \\xi \\cdot \\Phi(G,B,\\rho)=\\xi\\cdot 640(1+\\frac{1}{B^2})^2(1+\\frac{B^2\\rho^2}{G^2}).$ Therefore, \n$v\\epsilon_0 \\geq [\\xi\\cdot 640(1+\\frac{1}{B^2})^2(1+\\frac{B^2\\rho^2}{G^2})]\\cdot[\\frac{1}{4}\\cdot\\frac{G^2(f/n)}{1-(2+B^2)(f/n)}].$ The term $\\rho^2=\\exp (2\\frac{(2+B^2)\\Delta_0}{(1-\\xi_0)G^2}L)\\zeta^2$ can be much larger than $\\zeta^2$. Thus, $v\\epsilon_0$ can be much larger than $\\zeta^2$, which will make Theorem 5.2 meaningless.\n\nOverall, the idea of ARC is interesting. The ARC method is easy to implement and has a good empirical performance. However, the theoretical analysis in the current version does not show the improvement of convergence guarantees, and can be misleading."
            },
            "questions": {
                "value": "Please focus on the weakness of Theorem 5.2 in the rebuttal. Specifically, please compare the value of $v\\epsilon_0$ with $\\zeta^2$ in Theorem 5.2 (or address the concern in some different ways). I am willing to raise the score if the concerns are properly addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces an adaptive gradient clipping method applied to worker outputs before passing them through a robust aggregator in heterogeneous synchronous Byzantine settings. The authors address a practical issue, as they observe that while fixed gradient clipping can enhance performance in some cases, it may also impair it in others. To ensure robustness while utilizing gradient clipping, they propose an adaptive strategy that adjusts the clipping threshold according to the magnitude of worker outputs, applying clipping selectively to only a subset of them. Experimental results across various Byzantine scenarios and robust aggregators, tested on MNIST and CIFAR-10 datasets, demonstrate the effectiveness of this adaptive approach when combined with the established NNM method. The authors further support their method with theoretical guarantees."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper proposes an adaptive method that maintains the robustness guarantees of the aggregators it employs while improving their practical performance, especially under high heterogeneity. The authors provide valuable insights into selecting the clipping threshold, demonstrating that a fixed threshold for all workers, commonly used in practice, may be inefficient in some cases and does not meet robust criteria. They also emphasize the gap between Byzantine theory and practical applications, highlighting that existing theory may not fully capture real-world performance."
            },
            "weaknesses": {
                "value": "Considering the critical role that numerical evaluation plays in supporting the paper\u2019s claims,\n* The paper introduces an adaptive clipping approach designed to work with any robust aggregator independently of NNM. However, the numerical results primarily showcase its effectiveness only when combined with the NNM aggregator (and it is unclear if NNM was also used in Figure 6; if so, this single example may be insufficient). Since NNM has a computational complexity of $O(dn^2)$, it would be valuable to assess the performance of this approach with other robust aggregators (without integrating NNM) to explore potentially lower computational costs. For instance, the CWTM ($O(dn \\log{n})$) or the $\\epsilon$-approximation GM ($O(dn + d\\epsilon^{-2})$) might offer alternatives that may retain robustness in practice while reducing time complexity. Conducting such experiments could provide a more comprehensive evaluation and emphasize the approach\u2019s practicality.\n* The CIFAR-10 evaluation is somewhat limited, with only one Byzantine worker out of 17. Expanding the evaluation to include a higher proportion of Byzantine workers and testing on more complex datasets could better demonstrate the method\u2019s effectiveness in more practical scenarios."
            },
            "questions": {
                "value": "* How does NNM contribute to achieving the guarantees outlined in Theorem 5.2? Is it possible to attain similar results on robust aggregators without incorporating NNM?\n* Using a fixed clipping threshold can often be effective in homogeneous Byzantine settings. How does the adaptive approach perform compared to a fixed threshold in such cases?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper explores enhancing the robustness of distributed machine learning in the presence of Byzantine clients. The authors propose  Adaptive Robust Clipping (ARC) that improves the robustness of Robust-DGD beyond traditional static clipping techniques. ARC dynamically adjusts clipping thresholds based on gradient magnitudes, allowing it to better counteract adversarial impacts.\nThe authors provide experiments to demonstrate that ARC improves model robustness against various attacks compared to static clipping methods as well as theory showing that ARC has a similar convergence rate as the classical ones known in the literature."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The main strengths are: \n\n-The authors propose Adaptive Robust Clipping (ARC), a new mechanism to enhance robustness in adversarial settings.\n\n-The authors show that ARC almost retains the theoretical robustness guarantees of existing Robust methods while enhancing their practical performance. \n\n-The authors validate ARC through several experiments."
            },
            "weaknesses": {
                "value": "The main weaknesses are:\n\n-Increased complexity produced by ARC in practical implementation\n\n-ARC performance depends on good model initialization which may degrade the performance in the case of poor initialization.\nDid you try some experiments to assess this?\n\n-While ARC improves robustness by adaptively clipping gradients, its thresholding could risk clipping too aggressively in certain settings, potentially discarding useful gradient information."
            },
            "questions": {
                "value": "See section before. \n\nIn addition:\n\n-In Figure 1, C=2 for static clipping (SC) is too small. I think that is why you have a very bad performance of SC. You need to test with bigger values of C as well for SC.\n\n-Can you report the Adaptive C of ARC over steps in these plots?\n\n- Line 94, can you justify why one needs to clip this exact k number gradients? what happens if one clip less or more than this number of gradients?\n\n-The intuitive k is the number of potential malicious workers which is f?\n\n-Line 238, you require \\kappa B^2 < 1, (which means B should be small) can you give an example of loss where B is small?\n\n-Line 264, I disagree with the comment that \"ARC does not introduce a significant overhead\" especially in the case of large models. It will be good to have some experiments with runtime on the x-axis  \n\n-ARC theory requires that the model is well-initialized, it will be good to assess numerically the impact of the initialization on the performance of ARC"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce a variation on the static clipping technique used to overcome byzantine attacks in federated learning. Their algorithm makes the process dynamic by adapting the clipping value to the input gradients themselves; this algorithm, called ARC, or Adaptive Robust Clipping, is proved to be robust: (f, 3k)-robust. More importantly, the authors prove that static clipping breaks the standard (f,k)-robustness, which highlights the shortcomings of the empirical results demonstrated in the papers highlighted in paragraph five of the Introduction. These reasons motivate the need for a dynamic approach to gradient clipping. ARC was paired with and tested using the following techniques: coordinate-wise trimmed mean, geometric median, multi-Krum, and nearest-neighbor mixing. Various simulations were ran by the authors to show the utility of ARC, these include: simulations on varying degrees of data heterogeneity, simulations on varying f (the number of malicious agents), simulations showing the improved breakdown point. All of these simulations show how ARC can provide robustness.\n\nA current problem point is that the authors perform simulations and demonstrate against not using gradient clipping. In paragraph 5 of the Introduction, the authors clearly state that static methods are a problem that their approach, ARC, solves. Then, the authors proceed to perform simulations and do not compare their results against static clipping, but compare against no clipping. It is known, and evidenced by the cited work, that not clipping is a problem that is overcome by using some form of clipping. Therefore, results compared against not clipping yields no additional information. While the authors have shown that ARC has obvious utility that could help overcome known issues, readers cannot determine the excess utility over using static clipping. While I believe the paper holds merit, as the empirical results show, I do not believe the paper can proceed without the authors running the experiments again and showing the results with static gradient clipping. The comparison between static and dynamic clipping is the fundamental point of the paper and not having a comparison of the two makes the paper unqualified to proceed. If the authors can show those results, so readers, such as myself, can see how much improvement is gained by using a dynamic choice for clipping, then I believe the paper will contain enough merit to be accepted and to receive a higher score.\n\nAs a final, syntactic, comment, I believe the authors should move the Related Works section to an earlier spot in the paper so readers can more easily understand the historical context and how the motivation for the novel work. This swap will increase flow of understanding for the reader who will have to exert less mental effort to juggle the chronological and intellectual pieces together."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "The paper introduces dynamic gradient clipping as an improvement to its static counterpart. More importantly it proves that the static approach is not robust, in accordance with the definition of robustness given in the paper. Furthermore, the authors prove the robustness of their approach and provide empirical evidence of the utility of their algorithm."
            },
            "weaknesses": {
                "value": "The major weakness of the paper, which is a critical one, is the complete lack of comparison of ARC versus static clipping. The authors run experiments against not using clipping; this is rendered moot by prior work and therefore is not a necessary point of comparison. The authors must go back and run the same experiments they ran with with static gradient clipping and plot that against their dynamic approach. Without doing this, it is not possible to determine the benefit their work over prior work."
            },
            "questions": {
                "value": "1) Why were no experiments ran using static clipping?\n2) What is the reason for only using a network with 10 agents? Typically, networks with more agents that test for heterogeneity have a harder time than those with networks because there is a wider gap on intra and inter-class datasets.\n3) What was the reason for selecting 17 agents for the simulations in the section \"Improved robustness on CIFAR-10\"? Can you expand to more agents?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}