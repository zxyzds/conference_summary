{
    "id": "GOwNImvCWf",
    "title": "Structure and Behavior in Weight Space Representation Learning",
    "abstract": "The weights of neural networks (NNs) have recently gained prominence as a new data modality in machine learning, with applications ranging from accuracy and hyperparameter prediction to representation learning or weight generation. One approach to leverage NN weights involves training autoencoders (AEs) with contrastive and reconstruction losses. Indeed, such models can be applied to a wide variety of downstream tasks, and they demonstrate strong predictive performance and low reconstruction error. However, despite the low reconstruction error, these AEs reconconstruct NN models that fail to match the performance of the original ones. In this paper, we identify a limitation of weight-space AEs, specifically highlighting that structural weight reconstruction alone fails to capture some features critical for reconstructing high-performing models. To address this issue, we propose a behavioral loss for training AEs in weight space. This behavioral loss focuses on the features essential for reconstructing performant models, which are not adequately captured by structural reconstruction. We evaluate the capabilities of AE trained using this novel loss on three different model zoos: we demonstrate that when combining structural and behavioral losses, we can reconstruct and generate models that match the performance of the original models. With our exploration of representation learning in deep weight spaces, we show that a strong synergy exists between structural and behavioral features, and that combining them results in increased performance across all evaluated downstream tasks.",
    "keywords": [
        "weight space learning",
        "hyper-representations",
        "deep weight spaces",
        "representation learning",
        "model reconstruction",
        "model weights generation"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "We demonstrate how the combination of structural and behavioral losses improve the training of hyper-representation autoencoders in weight space.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=GOwNImvCWf",
    "pdf_link": "https://openreview.net/pdf?id=GOwNImvCWf",
    "comments": [
        {
            "summary": {
                "value": "This work proposes a new behavioral loss to enhance the performance of hypernetwork autoencoders trained to reconstruct neural network weights. It demonstrates improved results in reconstructing convolutional neural network weights on vision datasets. The study provides extensive validation of reconstruction quality, combining contrastive, structural, and behavioral losses to achieve this improvement."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "* The paper is well-written and easy to follow, with clear, well-organized sections that ensure a smooth flow throughout. Additionally, the captions for tables and figures are self-contained, making it easier for readers to understand them in context.\n\n* The results demonstrate a consistent improvement in both the performance of the reconstructed models and the richness of the information contained in the computed weight representations. The authors assess this information using linear probing to predict test accuracy and model generalization gaps, providing valuable insights into the learned representations.\n\n* The authors have released the codebase for this work, which enhances the paper's reproducibility and allows others to verify and build upon their findings."
            },
            "weaknesses": {
                "value": "* The experimental setup is primarily focused on convolutional neural networks on three vision datasets without exploring other types of architectures or data. Including a broader range of architectures and datasets could further validate the approach\u2019s generalizability. (See questions).\n\n* Table 2 shows that the proposed behavioral loss improves performance across all three datasets. However, it would be insightful to examine whether the representations produced by the original CNNs are similar to those generated by the reconstructed CNNs. This analysis could further strengthen the findings, clarifying whether the generated weights yield representations closely aligned with the originals and thereby contribute to the observed performance improvements.\n\n* The reported results do not include standard deviations, which could offer insight into the consistency and robustness of the proposed method across different runs. Including this information would enhance the reliability of the findings."
            },
            "questions": {
                "value": "* It would be valuable to explore how the proposed approach performs when applied to architectures other than CNNs, such as MLPs or larger models. This could provide further insights into the generalizability and robustness of the proposed method.\n\n* It would be interesting to examine the effectiveness of the proposed method on other data modalities, such as text or graph data. Testing across diverse modalities could help determine the broader applicability and flexibility of the approach.\n\n* It would be helpful to clarify whether all model zoos in the experiments were trained exclusively for image classification. Exploring the reconstruction of weights from models trained on other downstream tasks (e.g. image reconstruction) could provide insight into the versatility and task-specific performance of the method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduced a loss function called *behavioral loss*, designed to reduce the performance discrepancy between original neural networks and those reconstructed through a weight-space autoencoder. This behavioral loss minimizes the difference between the outputs of the original and reconstructed networks by reducing the norm between their predictions.\n\n\nThe authors claim the following contributions:\n- analyzing the error modes of weight-structure reconstruction.\n- Introducing the behavioral loss.\n- Demonstrating the improvement in loss performance across various experiments."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is well written and easy to follow.\n- The motivation for the proposed solution is well explained and investigated.\n- Simple solution."
            },
            "weaknesses": {
                "value": "- My main concern regarding this work is around its novelty the behavioral loss was already used in [1]. In [1] the authors calculated the loss based on the loss on the downstream task. In addition, there is no novelty (and it was not claimed) on the architecture side since the authors used SANE [2] for the weight space AE. How do the authors differentiate their work from [1]?\n- Limited experimental section. Given the fact that this work is mostly empirical, I expect the experimental section to be more extensive both in scale and learning setups. The authors focused on discriminative models and specifically only on small CNNs. There is no diversity in the reconstructed model architecture or the downstream tasks.\n- It would be interesting to see how significant are $\\beta$ and $\\gamma$ hyperparameters in the AE optimization.\n- The authors mentioned in the appendix that training with behavioral loss nearly doubles the training duration, which poses a challenge for large models.\n-Rather than using a common model zoo [3,4], the authors chose to create their own, which raises some questions.\n- The authors did not include confidence intervals in the experimental section. Moreover, in Tables 5 and 6 the authors provide additional results which are inclusive due to high std values. The same should be reported in the main text results.\n- The only augmentation used for $\\mathcal{L}_C$ is a random permutation, why the authors did not use augmentations from [5,6]? [6] should be cited in this work.\n\n--------------\n[1] Equivariant Deep Weight Space Alignment, Navon et al.\n\n[2] Towards Scalable and Versatile Weight Space Learning, Schurholt et al.\n\n[3] Model Zoo: A Dataset of Diverse Populations of Neural Network Models, Schurholt et al.\n\n[4] Eurosat Model Zoo: A Dataset and Benchmark on Populations of Neural Networks and Its Sparsified Model Twins, Honegger et al.\n\n[5] Equivariant Architectures for Learning in Deep Weight Spaces, Navon et al.\n\n[6] Improved Generalization of Weight Space Networks via Augmentations, Shamsian et al."
            },
            "questions": {
                "value": "- Based on the findings in Section 2, have the authors considered explicitly encouraging hybrid eigenvalue features? For example, they might incorporate a KL divergence loss relative to a predefined Beta distribution concentrated in the high and low values, effectively ignoring the intermediate range."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper considers the problem of constructing weight space encoders, i.e., learning an Auto-Encoder (AE) on the weights of trained NNs (for example, image classifiers). Previous works mainly considered two loss functions: a \u201cstructural\u201d reconstruction loss, e.g., MSE between the reconstructed and input weights, and a contrastive loss. The authors propose augmenting the two losses with an additional loss, which they term \u201cbehavioral\u201d: This loss is the MSE between the outputs of the original and reconstructed NN, evaluated on a set of inputs."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is generally well-structured and easy to follow.\n1. The empirical evidence for the effectiveness of behavioral loss is strong."
            },
            "weaknesses": {
                "value": "My main concern is the paper's limited novelty and contribution. The paper's main claimed novel contribution is the inclusion of behavioral loss.\n1. The proposed approach generally follows the SANE [1] paper, model arch, and experimental setup, with the only difference in the loss function. While the results presented show improvements over SANE, the contribution of the paper is limited.\n1. Previous works for weight space learning used similar loss functions or probing-based features. At the very least, this deserves some reference and discussion by the authors. A similar loss function, although not identical (and not always in the context of AE), was proposed in e.g. [2, 3, 4, 5]. The idea is to evaluate the reconstructed model on a set of inputs and compute the loss w.r.t ground truth labels. This is very close to the proposed approach, with the difference being that the proposed approach uses pseudo labels instead of GT labels. However, this is almost identical in the context of INRs [2, 3].\nAnother relevant literature that is not discussed, is the inclusion of probing-based features, which evaluate the original function on (fixed or learned) inputs to provide additional information on the input net and functional behavior [6, 7].\n1. Experiments are performed on small-scale NNs and datasets. It is not clear how this generalizes to real-world large-scale setups.\n1. Please also include some measure of variability (e.g., standard derivation) in Table 1.\n1. The results of Section 2 suggest that it is important to learn to match eigenvectors corresponding to both large and small eigenvalues, while that of mid-sized eigenvalues is less important. This provides a good motivation for augmenting the structural only loss, however:\n    - It is not clear to me that the proposed loss achieves this specific goal.\n    - Also, it would be beneficial to show some empirical evidence that including behavioral loss is improving the reconstruction of subspaces spanned by both the top and bottom eigenvectors.\n1. As also noted by the authors, the proposed approach increases the computational cost. This increase may be too expensive for large-scale models (which are not included in this work).\n\nReferences:\n\n[1] Sch\u00fcrholt et al. \"Towards Scalable and Versatile Weight Space Learning.\" ICML 2024.\n\n[2] Luigi et al. \"Deep Learning on Implicit Neural Representations of Shapes.\" ICLR 2023.\n\n[3] Navon et al. \u201cEquivariant architectures for learning in deep weight spaces,\u201d ICML 2023. \n\n[4] Zhou et al. \"Permutation Equivariant Neural Functionals.\" NeurIPS 2023. \n\n[5] Navon et al. \u201cEquivariant Deep Weight Space Alignment,\u201d ICML 2024.\n\n[6] Kofinas et al. \"Graph Neural Networks for Learning Equivariant Representations of Neural Networks.\" ICLR 2024.\n\n[7] Herrmann et al. \"Learning useful representations of recurrent neural network weight matrices.\", 2024."
            },
            "questions": {
                "value": "1. From Figure 3 and as pointed out by the authors, it appears that the behavior of reconstructed models does not necessarily reproduce that of the original model, rather, it is biased towards higher accuracies. Why do you think that is the case? These results suggest that the reconstruction of low performing models is not good, even with the added behavioral loss.\n1. In Table 2, selecting the Max statistics seems too convenient. Using the mean or median or Min, for example, would have shown significant differences between the original and generated models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper discusses autoencoding of weight-spaces. In this field of research, \nweights of deep models are viewed as an object (input and output) of learning systems. \nSpecifically, they look to improve the function of models encoded using weight-space AEs, \nby adding what they call, a \"behavioral\" loss, designed to improve network function. \nThat loss is simply an L2 loss over the output\u00a0of the model with the reconstructed weights.\u00a0\n\nThe paper runs meaningful\u00a0experiments largely following\u00a0the standards in the\u00a0field. On three model populations \"zoos\", they show that adding the new loss improves the AE, in terms of generating and reconstructing more faithful weights.\n\nMy recommendation is borderline reject, because of the limited technical novelty and conceptual contribution, which means the audience for this paper would be very narrow. I am willing to be convinced otherwise."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-- The paper tackles an important problem in the growing field of weight-space modality. \n\n-- The paper contains a large set of evaluation experiments for generation and reconstruction of weights in three model zoos."
            },
            "weaknesses": {
                "value": "W1:  The idea is very straight forward, and the technical contribution is quite limited. Basically, they run experiments like those done previously in the field, while adding the new L2 functional loss. I am not aware that others have done this for weights autoencoders, but using \"behavior\" (out put of model parameterized by weights) to select weights has been in other context. For example a loss over the function parametrized by the weights is the standard way to train hypernetworks. \n\nW2:  The PCA analysis of Figure 1 has two issues. (1) It is suspicious (see questions below) and (2) it is not clear how it connects to the contribution of the paper, since the analysis is not used as far as I can tell to motivate or guide the method or the experiments.   \n\nW3:  Every evaluation of the behavior loss involves 500 inference steps through the classifier model (250 samples x 2 models). How does this added compute compares with the total compute for training the AE? If it increases the overall compute required to train the AE, it should be explicitly stated.\n\nW4: Definition of behavioral loss. For classifiers, L2 is not a great choice. One should use the same loss that the models from the zoo cis trained with, . e.g. cross entropy for classification etc. \n\n\nSpecific and minor comments and suggestions \n\n-- Define key terms like \"structural reconstruction error\" and \"model zoo\" before using them. Add concrete definitions of all losses. \n    The paper should be made readable to researchers outside the weight-space community. \n\n-- I found Fig 3 totally confusing. Is there anything interesting insight to take from these histograms tat cannot be conveyed in a simpler way? Distributions are quite unimodal so a mean+std table would have been much simpler and easy to understand. \n\n-- Related work on generation of NN weights. It would make sense to mention Hypernetworks."
            },
            "questions": {
                "value": "Q1: Figure 1 looks highly suspicious, and many details are skipped. How come it is useful to add \"Bottom\" eigenvectors, which capture directions in space that have little to no information about the weights? How does the eigen spectrum look like? and what is the dependency of explained variance on the number of principal components? What is \"reconstruction accuracy\" in this figure? (the text said you measured test-set accuracy).  \nWhat was the size of the training data and weight-vector dimension? same as in line 254? I suspect that the covariance matrix was low rank, and that the correct x-axis in the figure is \"fraction of of eigen vectors taken\", not \"explained variance\". That may explain the totally flat curves on the middle and right panels.   And how comes the random accuracy in SVHN is 20%? \n\nQ2:  Not stated clearly how the loss weights were selected. Validation sets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}