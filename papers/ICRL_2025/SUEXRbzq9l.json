{
    "id": "SUEXRbzq9l",
    "title": "Estimating Statistical Similarity Between Product Distributions",
    "abstract": "We investigate the problem of computing the \\emph{statistical or total variation (TV) similarity} between distributions $P$ and $Q$, which is defined as $s_{\\mathrm{TV}}(P,Q) := 1 - d_{\\mathrm{TV}}(P, Q)$, where $d_{\\mathrm{TV}}$ is the total variation distance between $P$ and $Q$.\nStatistical similarity is a basic measure of similarity between distributions with several natural interpretations.\nWe focus on the case when $P$ and $Q$ are products of Bernoulli trials.\nRecent work has established, somewhat surprisingly, that even for this simple class of distributions exactly computing the TV distance (and hence statistical similarity) is \\#$\\mathsf{P}$-hard.\nThis motivates the question of designing multiplicative approximation algorithms for these computational tasks.\nIt is known that the TV distance computation admits a fully polynomial-time deterministic approximation scheme (FPTAS).\nIt remained an open question whether efficient approximation schemes exist for estimating the statistical similarity between two product distributions.\nIn this work, we affirmatively answer this question by designing an FPTAS for estimating the statistical similarity between two product distributions.\nTo obtain our result, we introduce a new variant of the knapsack problem, which we call multidimensional Masked Knapsack problem, and design an FPTAS to estimate the number of solutions to this problem.\nThis result might be of independent interest.",
    "keywords": [
        "total variation distance",
        "TV distance",
        "complement of total variation distance",
        "TV similarity",
        "statistical similarity",
        "aggregated experts",
        "FPTAS",
        "reductions",
        "Turing reductions",
        "Knapsack",
        "counting Knapsack",
        "Masked Knapsack",
        "counting Masked Knapsack"
    ],
    "primary_area": "learning theory",
    "TLDR": "",
    "creation_date": "2024-09-14",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=SUEXRbzq9l",
    "pdf_link": "https://openreview.net/pdf?id=SUEXRbzq9l",
    "comments": [
        {
            "summary": {
                "value": "The work addresses the computational problem of estimating the statistical similarity ($s_{TV}$) between two product distributions. Computing the exact $s_{TV}$ is #P-hard. The authors aim to develop an FPTAS for estimating $s_{TV}$ between arbitrary product distributions. To achieve this goal, they introduce a new variant of the knapsack problem called the multidimensional #MASKEDKNAPSACK and estimate the number of solutions to this problem. Their result is obtained by a chain of reductions: from the $s_{TV}$ estimation problem to the #MINPMFATLEAST problem, and then to the multidimensional #MASKEDKNAPSACK problem, which is supported by rigorous mathematical proofs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper addresses an important problem by attempting to develop an FPTAS for estimating statistical similarity between product distributions, which is a #P-hard problem. The introduction of the multidimensional #MASKEDKNAPSACK problem looks like a novel extension of the classic knapsack problem. The authors provide solid proof for the proposed reductions and approximations. The chain of reductions is logically sound. I recognize the theoretical contribution of this paper."
            },
            "weaknesses": {
                "value": "In general, I tend to accept this paper. I think the major concern is that this paper claims to develop an FPTAS for estimating $s_{TV}$ between product distributions but does not provide an explicit algorithm or pseudocode. Without such an example, it's hard to assess the practicality of the proposed schema."
            },
            "questions": {
                "value": "- Can the authors provide explicit algorithmic steps or pseudocode for the proposed FPTAS?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper considers the problem of estimating the statistical similarity between distributions that are product of n Bernoulli trials. Statistical similarity is simply 1-(total variation distance). This paper proposes a fully polynomial time approximation algorithm for the problem. It is noteworthy that there are additive and relative approximations for the total variation distance that run in polynomial time. I believe that an additive approximation of TV distance translates to an additive approximation of statistical similarity. However, this is not the case for relative approximations of TV distance and statistical similarity and there is no straightforward relationship between them. Thus, although closely related, relative approximations of TV distance cannot be directly used for solving relative approximation of statistical similarty.\n\nThe main approach of the paper is to reduce the problem of estimating statistical similarity to a variant of the knapsack problem (masked version) and then designing a relative approximation for this variant."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "TV distance as well as statistical similarity are relevant to ML community and progress on approximation algorithms for these measures are important."
            },
            "weaknesses": {
                "value": "* The authors do not explicitly compare their techniques with the existing techniques for additive and relative approximation of the TV distance. They compare them at the level of results but not at the level of techniques. Ideally, I would like to see an explanation of why prior work for TV distance cannot be used for solving for statistical similarity.\n* The algorithm requires a polynomial bit representation for probabilities. This is a somewhat surprising requirement for approximation algorithms (usually these kinds of requirements are mostly seen in weakly polynomial exact algorithms). Why is it hard to eliminate this requirement?\n* Presentation can be significantly improved. \n* Implementation and testing would have made the paper stronger\n\nI will raise my score if most of my concerns are addressed."
            },
            "questions": {
                "value": "Apart from addressing the weaknesses, I would also like to ask if there is any literature on the case where P and Q are product of one-dimensional continuous distributions and what we have is only samples from P and Q. This problem is also important in ML and I\u2019m not aware of the state-of-the art for relative and additive approximation for this problem. Could you shed some light on the results for this variation of your problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the hardness of computing the statistical similarity and shows that there exists an FPTAS for approximating the statistical similarity between product distributions. For two distributions $P$ and $Q$, the statistical similarity between $P$ and $Q$ is defined as $s_{TV}(P, Q) = 1-d_{TV}(P, Q)$, where $d_{TV}(.,.)$ is the total variation distance. In this work,\n\n1- The authors first reduced approximating $s_{TV}$ to the #MinPMFAtLeast problem in which, given two product distributions $P$ and $Q$ over $\\{0,1\\}^n$ and $C\\ge 0$, computes the number of $x\\in\\{0,1\\}^n$ such that $\\min\\{P(x), Q(x)\\}\\ge C$. \n2- Then, they reduced #MinPMFAtLeast to the 2-dimensional #MaskedKnapsack problem in which, given two instances $K_1$ and $K_2$ specified by weights $a_{i,1}, \\ldots, a_{i,n}$, capacity $b_i$, and mask vectors $u_i=(u_{i,1}, \\ldots, u_{i,n})$ for $i\\in{1,2\\}$, counts the number of solutions $x=(x_1, \\ldots, x_n)$ such that $\\sum_{j=1}^n a_{i,j}(x_j\\oplus u_{i,j}) \\le b_i for $i=1,2$.\n3- Next, they show that there exists an FPTAS for $O(1)$-dimensional #MaskedKnapsack problem.\n4- Finally, they approximately solved #MaskedKnapsack using techniques from [Gopalan et al (2010)]."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper shows that there exists an FPTAS for approximating the statistical similarity between product distributions."
            },
            "weaknesses": {
                "value": "- The paper does not motivate the problem well. There are some vague mentions of machine learning, probabilistic algorithms, information theory, Markov chains, and hypothesis testing with references to general source books on the topics, and it is not clear to me at all what are the actual applications of statistical similarity between product distributions. See my questions below.\n- There is an assumption that the probabilities of the Bernoulli random variables can be represented using poly(n) bits. This assumption is not stated in the main Theorem.\n- Unless there are specific use cases of relative approximation of statistical similarity that I am unaware of, I think this work would be more suited for the theory venues."
            },
            "questions": {
                "value": "1. Are there any papers or work specifically using (a relative approximation of) statistical similarity between product distributions? \n2. The following are the typos I could find, but there are probably more:\n\nLine 56: there a connection -> there is a connection\n\nLine 70: statistically similarity -> statistical similarity\n\nLine 70: related well-known -> related to well-known\n\nLine 287: product distributions with have -> product distributions which have\n\nLine 364: that start $u$ -> that start at $u$\n\nLine 365: the the -> the\n\nLine 417: $k$ -> $k_i$ (?)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors study the computation of the total variation similarity, s_TV (P,Q) = 1-d_TV(P,Q), between product distributions. The problem is  #P-hard following the analogous result about the computation of the total variation distance d_TV(P,Q). For the latter an FPTAS is known to exists, which does not directly carry over to the computation of s_TV. The paper shows an FPTAS for s_TV. This is done by reducing the problem in two steps to the computation of a variant of multiple Knapsack problems."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Since the total variation similarity is extensively used and the only known approximations are for the distance, the paper closes the gap between the two problems for the case of general product distributions, which also closes the gap of the complexity landascape for the total similarity.\nThe reduction used to the masked multi knapsack is neat and novel and might be of independent interest"
            },
            "weaknesses": {
                "value": "Approximation is for product distribution only, but on the other hand this gives an complete picture of the complexity for this case."
            },
            "questions": {
                "value": "In the statement of Proposition 2, it is not clear what is meant by an approximation of a polynomially many #MinPMFAtLeast instances. Do you mean \"... to the computing a (1+e)-approximation of polynomially many instances of...  \"?\n\nIt seems to me that the formula for m_{\\min}--- on page 5, the 2nd equation in disply in the proof od Proposition 2---provides a lower bound on the minimum non-zero value of min(P(x), Q(x)) over all x, rather than the  exact minimum non-zero value of min(P(x), Q(x)) over all x, which has been given as the definition of  m_{\\min}.\nI do not think this affects the result, but, if I am write, the definition should be correct.  \n\nSpecific Comments\nIn the statement of Lemma 15, the dimension parameter n should be explicitly defined."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper is about estimating statistical similarity between product distributions P and Q, which is defined by one minus total variation distance between P and Q, i.e. d_TV(P,Q). Estimating the exactly total variation distance between product distributions is #P hard, and hence estimating the statistical similarity is also #P hard. On the approximation side, there is an FPTAS for estimation the TV distance, however that would not give an approximation for the statistical similarity, as a multiplicative approximation for a function f does not give a multiplicative approximation for 1-f, and there are examples that such approx does not exist for 1-f. \n\nThis paper provides an FPTAS for estimating statistical similarity between product distributions. They use two reductions, the first reduce the problem to #MinPMFAtleast problem, which given C, asks for the number of inputs x such that min(P(x),Q(x)) >= C. Then they reduce this problem to a variant of the Knapsack problem that they introduce, called multidimensional #MaskedKnapsack. Finally they give an FPTAS for this variant of Knapsack."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "They provide enough motivations, the proofs seem simple."
            },
            "weaknesses": {
                "value": "There are a lot of typos in the manuscript, including a lot of inequalities that should be reversed, which didn\u2019t let me verify the proofs. I will pose my questions in the questions section. Besides this, I don\u2019t see this result as being very relevant to ICLR, both in strength, and in the fact that it might be more relevant to theory conferences like SODA or ICALP.\n\nSome typos:\nline 57: there \u201cis\u201d a connection \u201cbetween\u201d statistical similarity \u201cand\" the error of an optimal \u2026\nLine 69: Finally, the \u201cstatistical\u201d similarity can be\u2026\nLine 78:: Hence it is unlikely that an efficient algorithm \u201cexists\u201d \u2026\nLine 287: remove \u201chave\u201d\nLine 365: start \u201cat\u201d u"
            },
            "questions": {
                "value": "1) In proof of proposition 2, there are many typos which essentially make the proof wrong but I think that they are all fixable, so please provide the correct proof.\nLine 242: this expression for m_min does not make any sense to me. I think you probably mean  to use an inequality, not an equality. \nLike 245, you define V to be $min(P(x),Q(x))/m_{min}\\le V$. I think you mean to use $\\ge$, since then you get an upper bound for V by using the fact that min(P(x),Q(x)). But you also need to show that $V\\ge 1$, which means that the definition of V is not for all x, it is for x where min(P(x),Q(x)) is non-zero. This subtlety shows itself agin on line 272 where you say $n_u=2^n$.\nLine 259, the definition of B_i should be the sum of all Y_x where Y_x is in the $[(1+\\epsilon)^{i-1},(1+\\epsilon)^i)$ interval. Please specify this\n\n2) Please specify the running time of your algorithm.\n\n3) Please compare your techniques to the work before especially the work that provides a FPTAS for TV distance. How original are your techniques?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}