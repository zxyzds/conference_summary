{
    "id": "K7qurARDi1",
    "title": "SeaDiff: Delve into Underwater Image Generation with Symmetrical Parameter Control",
    "abstract": "With the advancement of diffusion models, the controllability of image generation has significantly improved. However, due to the refraction and absorption of light in water, underwater images often exhibit notable variations in luminance and color cast. This leads to challenges for generative models pre-trained on terrestrial images, as they struggle to produce underwater images with a diverse range of these variations, severely limiting the appearance diversity of generated underwater images. To address this issue, we focus on the precise control of appearance in underwater images. We model the appearance of underwater images using three attributes: luminance, dynamic range, and color cast. We propose a new method, SeaDiff, which introduces a Symmetrical Parameter Control structure to achieve precise control over the appearance of underwater images. The proposed method comprises two modules: Appearance Writer, which encodes and injects appearance attributes into the U-Net encoder, and Appearance Reader, which ensures that the generated images align with the desired appearance by analyzing the feature maps. Experimental results demonstrate that the proposed SeaDiff method significantly improves control over underwater image appearance while maintaining image quality, validating its effectiveness in underwater image generation.",
    "keywords": [
        "diffusion model",
        "controllable generation",
        "underwater"
    ],
    "primary_area": "generative models",
    "TLDR": "A novel method for precise control of underwater image appearance.",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=K7qurARDi1",
    "pdf_link": "https://openreview.net/pdf?id=K7qurARDi1",
    "comments": [
        {
            "summary": {
                "value": "This paper presents SeaDiff, an effective approach for controlling appearance attributes in underwater image generation using diffusion models. The authors model three key attributes (luminance, dynamic range, and color cast) and propose a Symmetrical Parameter Control framework consisting of an Appearance Writer (A-Writer) and an Appearance Reader (A-Reader). Evaluated on the RUOD dataset, the method demonstrates significant improvements over existing approaches in both appearance control and image quality."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper addresses controllable image attribute editing, which is a fundamental challenge. The focus on precise control of specific attributes (luminance, dynamic range, and color cast) demonstrates a clear understanding of key image manipulation needs. I think the research direction would leverage a wide range of applications."
            },
            "weaknesses": {
                "value": "In method section, I think the paper's unique contributions appear limited, primarily focusing on transferring existing pre-trained priors to a specific field. The proposed model is essentially a fine-tuned version of the pre-trained Stable Diffusion model. While leveraging pre-trained models is common practice, the core contributions and motivations of this work should be more explicitly highlighted to distinguish it from existing approaches.\n\nIn Table 1 of the experimental section, there is no analysis of the model's parameters or inference latency, which is essential given the reliance on a computationally heavy pre-trained model. Such an analysis would provide valuable insights into the method's efficiency and practical applicability.\n\nIn Section 5.1, the paper acknowledges a bias in existing datasets, which consist of similar frames extracted from the same video. However, the simple re-division of the dataset does not adequately address this distribution bias. Additionally, all experiments were conducted exclusively on the RUOD dataset, raising concerns about the method's generalization capabilities to other underwater datasets.\n\nMeanwhile, the experimental section highlights successful outcomes but lacks a systematic analysis of failure cases or the method's limitations. A thorough examination of these aspects is crucial for understanding the robustness and applicability of the proposed method in diverse scenarios."
            },
            "questions": {
                "value": "Underwater image attributes encompass more than just luminance, dynamic range, and color cast. Can the proposed method be adapted to handle additional attributes or support more extensive attribute editing? If so, how would this be achieved?\n\nThe results presented in the experimental section demonstrate the method's performance under relatively ideal underwater conditions. However, there is no testing under extreme lighting conditions or severe turbidity. How does the method handle extreme underwater conditions such as severe turbidity, low visibility, and uneven lighting? \n\nHow does the method perform on underwater datasets other than RUOD? Has any cross-dataset evaluation been conducted to assess its generalization capabilities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the challenge of managing underwater image appearance by focusing on three key attributes: illumination, dynamic range, and color cast. The method comprises two primary components: Appearance Writer (A-Writer) and Appearance Reader (A-Reader). The former encodes and injects appearance attributes into the U-Net encoder, while the latter ensures that the generated image aligns with the desired appearance by analyzing the feature maps."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper is structured in a clear and accessible manner, making it easy to follow for readers. The topic of generating diverse and realistic underwater images is particularly intriguing, as it addresses the challenges faced in underwater imaging and highlights the potential for advancements in this field."
            },
            "weaknesses": {
                "value": "1. The results presented are not satisfactory. As shown in Fig. 1, the images fail to meet the expected standards of realism. \n2. Why is it important to generate underwater images, particularly those of low quality (severely degraded)? Will this be beneficial for downstream tasks, or does it serve other purposes? \n3. The author creates new underwater images based on three attributes: illumination, dynamic range, and color cast. However, the degree of turbid, a key attribute of underwater images is neglected."
            },
            "questions": {
                "value": "1. Can the proposed method generate high-resolution underwater images? \n2. What is the inference efficiency of the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work models the appearance of underwater images from three aspects: luminance, dynamic range, and color cast,  achieving precise control over the appearance of underwater images. Additionally, this paper proposes a new method, SEADIFF, which comprises two primary contributions: the Appearance Writer, responsible for encoding and injecting appearance attributes into the U-Net encoder; and the Appearance Reader, which ensures that the generated images align with the desired appearance by analyzing the feature maps."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.This work models the appearance of underwater images across three aspects: luminance, dynamic range, and color cast. The idea is interesting.\n\n2.This paper is written with clarity and is highly accessible to readers."
            },
            "weaknesses": {
                "value": "1. The proposed method is relatively simple, lacking novelty and insight. This work appears to be more of an engineering effort rather than an academic innovation.\n\n2. Although the proposed method achieves superior results based on quantitative metrics, the visualizations make it difficult to discern its advantages. For instance, in Figure 1, it is challenging to observe that the images generated by our method exhibit higher quality compared to those produced by GeoDiffusion.\n\n3.The experiments are not robust, and additional studies are needed to demonstrate that the images generated by the proposed method are beneficial."
            },
            "questions": {
                "value": "1. Why do the input resolutions differ across the various methods presented in Table 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposed a new underwater data generation method, which can control the luminance, dynamic range, and color cast of the generated images. Experiments prove that this method achieves superior control over appearance while maintaining image quality and layout-consistency. However, its application is limited and its techniques have been widely studyed. Specific reasons are given in weakness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) This article achieves precise control over underwater image generation, and the performance is good.\n2) To some extent, I believe that this method can serve as an alternative to underwater image enhancement, but the paper itself did not discuss this point.\n3) This paper introduces the simultaneous use of luminance, dynamic range, and layout control for underwater image generation."
            },
            "weaknesses": {
                "value": "1) its application is limited. From my opinion, the underwater image enhancement and some downstream applications, e.g., object detection and semantic segmentation, are significant. Only generating underwater images is meaningless but this paper only discusses how the proposed method can effectively and controllably generate underwater images, but does not mention the significance of generating underwater images. Only generating images of a specific scene is meaningless. \n\n2) Besides, the techniques it used have been widely adopted. If this paper proposed a novel technique for underwater image generation, it will still be a valuable work. However, the A-Writer and A-Reader are not novel and interesting enough. Their key contributions are cross-attention and feature supervision. The layout control is also achieved by cross-attention. These techniques have been widely used and are not designed for underwater image generation.\n\nThis paper lacks application impact and technological innovation."
            },
            "questions": {
                "value": "1) The impact on mainstream applications should be fully discussed, including image enhancement and downstream applications. Generating underwater images only is not important.\n\n2) Underwater-oriented techniques should be studied. Considering the content of this task, I believe it would be more meaningful to design specialized generative components for underwater scenes."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}