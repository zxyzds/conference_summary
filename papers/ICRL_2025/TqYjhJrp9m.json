{
    "id": "TqYjhJrp9m",
    "title": "Forecasting chaotic systems with zero-shot learning",
    "abstract": "Time-series forecasting is a challenging task that traditionally requires specialized models custom-trained for the specific task at hand. Recently, inspired by the success of large language models, foundation models pre-trained on vast amounts of time-series data from diverse domains have emerged as a promising candidate for general-purpose time-series forecasting. The defining characteristic of these foundation models is their ability to perform zero-shot learning, that is, forecasting a new system from limited context data without explicit re-training or fine-tuning. Here, we evaluate whether the zero-shot learning paradigm extends to the challenging task of forecasting chaotic systems. Across $135$ distinct chaotic dynamical systems and $10^8$ timepoints, we find that foundation models produce competitive forecasts compared to custom-trained models (including NBEATS, TiDE, etc.), particularly when training data is limited. Interestingly, even after point forecasts fail, foundation models preserve the geometric and statistical properties of the chaotic attractors, demonstrating a surprisingly strong ability to capture the long-term behavior of chaotic dynamical systems. Our results highlight the promises and pitfalls of foundation models in making zero-shot forecasts of chaotic systems.",
    "keywords": [
        "chaos",
        "nonlinear dynamics",
        "forecasting",
        "physics",
        "scientific machine learning"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "Large language models zero-shot forecast chaotic dynamics",
    "creation_date": "2024-09-18",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=TqYjhJrp9m",
    "pdf_link": "https://openreview.net/pdf?id=TqYjhJrp9m",
    "comments": [
        {
            "title": {
                "value": "Clarifying questions at start of discussion period"
            },
            "comment": {
                "value": "**[Initial clarifying questions at start of discussion period]**\n\nThank you very much for your review and comments. We were a bit surprised by the low score given the content of the review, which we feel is generally positive. \n**We will address your other comments with additional experiments in our full response later, but can you clarify at this stage why you feel the paper lacks novelty?**\n\nTo our knowledge, our paper is the first to apply zero-shot learning to dynamical systems, and in particular to show that zero-shot forecasts can compete with specialized SciML models. As far as we know, there are very few prior works that systematically apply the zero-shot paradigm to SciML tasks, which can potentially open new avenues for solving many important questions in the sciences."
            }
        },
        {
            "title": {
                "value": "Clarifying questions at start of discussion period"
            },
            "comment": {
                "value": "**[Initial clarifying questions at start of discussion period]**\n\nThank you for your review! We are currently putting together our experiments based on your comments. We had two clarifying questions that would help us design our experiments:\n\n+ Q2: My understanding is that Chronos does not use positional encodings, but rather tokenizes time series and then defers embedding to an LLM. Since the trained Chronos models use T5 (encoder-decoder), they use relative positional embedding rather than rotary/sinusoidal. Since relative positional embeddings are learned during training, we can\u2019t ablate them without retraining Chronos. Besides describing this in greater detail in the text, are there other experiments  the referee would like to see here?\n\n+ Q4: I agree that this is a highly-informative point of comparison, but so far we haven\u2019t gotten strong results from our attempts to fine-tune Chronos. When we fine-tune Chronos with the original hyperparameters, the loss plateaus very quickly. My best guess is that we need to go up several orders of magnitude in compute and dataset size to see improvements, which would approach the scale of retraining Chronos. I expect that new experiments that meaningfully improve Chronos would require a level of effort and resources at the scale of training a new foundation model. In our revision, we can describe these limitations and our initial efforts in greater detail in the text; would the referee find this sufficient?\n\n**We therefore plan during the discussion period to add several new experiments addressing Q1 and Q3, along with clarifying language regarding Q2 and Q4. Would the referee find a revision along these lines sufficient?**\n\nThank you again for reviewing our paper."
            }
        },
        {
            "summary": {
                "value": "The article explores the application of foundation models, particularly zero-shot learning, to forecast chaotic systems. Using the foundation model Chronos, the study investigates whether these models can generate accurate short-term forecasts and capture the long-term statistical properties of chaotic attractors, which are characteristic of chaotic systems. Through an extensive evaluation on 135 chaotic systems, the authors found that, even without specific training on chaotic dynamics, Chronos provides competitive forecasts, preserving geometric and statistical attributes of chaotic attractors over the long term. The study presents these findings as a benchmark for the feasibility and limitations of using foundation models in scientific machine learning, especially in physics-informed tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Extensive Benchmarking: The authors conduct a thorough and extensive evaluation, with a dataset that includes 135 chaotic systems, providing statistically robust results.\n2. Foundation Model Scalability: By demonstrating the scalability of Chronos across varying chaotic systems, the study establishes the potential of foundation models for scientific machine learning in challenging domains.\n3. Zero-Shot Learning Feasibility: The findings validate that foundation models can make meaningful forecasts in chaotic systems with minimal domain-specific adjustments, a promising step for generalizing AI across diverse scientific domains.\n4. Insight into Long-Term Statistical Consistency: The study\u2019s focus on long-term attractor behavior offers a novel way to assess model performance, moving beyond conventional short-term forecast accuracy."
            },
            "weaknesses": {
                "value": "1. The article mentions that Chronos\u2019s forecast accuracy is sensitive to initial conditions, but the specifics of this dependency aren\u2019t deeply explored. Could the authors provide a more systematic investigation into how initial condition variability impacts model robustness? For example, have you considered evaluating Chronos\u2019s performance across a range of initial conditions sampled from different regions of the attractor, particularly comparing accuracy in central versus peripheral areas? Additionally, could you quantify how forecast accuracy shifts as the initial conditions deviate from those in the training data? Such analyses would offer valuable insights into Chronos\u2019s generalization capabilities and help identify any specific sensitivities related to initial condition variability.\n2. Positional Encoding and Temporal Structure: Given the chaotic nature of the systems studied, the choice of positional encodings (e.g., rotary embeddings) could significantly impact model performance, especially in maintaining temporal coherence over long horizons. However, the article lacks an in-depth discussion or ablation study regarding the choice of these encodings.\n3. Limited Explanation of Performance in Extreme Cases: The authors mention that larger models tend to perform better, yet details on why model size improves stability in chaotic systems are sparse. A theoretical or empirical justification of this scaling behavior, such as through model capacity for capturing non-linear dynamics, would improve understanding.\n4. Scalability of Model Parameters and Computational Requirements: Although Chronos shows promise in forecasting chaotic systems, the article could discuss practical limitations regarding computational costs, especially for larger model sizes, and the trade-offs compared to specialized models like NBEATS or TiDE."
            },
            "questions": {
                "value": "1. Impact of Initial Conditions: Can the authors elaborate on how initial conditions affect Chronos\u2019s zero-shot forecasting stability? Is there a significant dependency on starting points, especially when far from the attractor\u2019s typical state?\n2. Effectiveness of Positional Encodings: How critical is the choice of positional encodings for Chronos when applied to chaotic systems? Have other encoding methods been tested, and if so, how did they affect both short-term accuracy and long-term attractor preservation?\n3. Model Complexity and Forecasting Horizon: Given that larger models perform better in long-term forecasting, could the authors provide insights into the mechanisms by which increased model size aids in managing chaotic variability?\n4. Comparison with In-Weights Fine-Tuning: Since the study focuses on zero-shot learning, have the authors considered comparing this approach with in-weights fine-tuning on a few chaotic trajectories to assess the performance improvement?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a large-scale evaluation of the zero-shot learning capabilities of foundation models for chaotic systems. The authors investigate both short-term and long-term forecasting scenarios. They evaluate the foundation models against over 100 chaotic systems and observe several interesting findings. The key point is that foundation models not only generalize to new initial conditions but also to entirely new systems. This suggests the models have the capacity to capture the broader dynamical structures of chaotic systems."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper presents strong findings on the power of foundation models for zero-shot learning in chaotic systems. Firstly, it demonstrates that foundation models can perform as well as fully trained models across multiple scenarios, especially in long-term forecasting.\n\nAnother strength of the paper is its study and evaluation of the suitability of foundation models in the field of scientific machine learning. This proof of concept can definitely lead to new developments in the study of chaotic systems."
            },
            "weaknesses": {
                "value": "Further experiments are needed to assess sensitivity to initial conditions and real-world chaotic systems, as these factors currently weaken the proposed evaluation and findings.\n\nWhile the application and findings of the paper are important, I believe the work in its current state lacks novelty."
            },
            "questions": {
                "value": "The authors aim to evaluate the proposed approach on real-world data? Interesting characteristics can be observed. \n\nHow does foundations models forecast accuracy vary with different initial conditions within chaotic systems? This sensibility limits its generalization? \n\nI suggest the authors to state limitations of the zero-shot long-term prediction problem. Another possible limitation is how the foundation model zero-shot approach will behave when there is a drastic different dynamical behaviour between training and testing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The present paper proposes to use time-series generated from chaotic systems as a new benchmark in time-series forecasting.\nIt makes the case for time-series foundation models (Chronos) which were pretrained on diverse synthetic and real-world data which it finds to yield better results than customly trained algorithms. This is surprising given that Chronos is a univariate prediction model and therefore sees the x, y, z components of the chaotic systems independently."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The core contribution is a benchmark of foundation models on the evolution of different chaotic systems. I think this is a good contribution which goes into a similar direction as Chronos and ForecastPFN which use synthetic data (Chronos not exclusively) to pretrain their models and still obtain good performance. I agree with a reference in the conclusion stating that there appears to be common language shared by time-series as it's surprising that the existing synthetic data generators would result in such well performing models.\n- I see potential for this benchmark to be used itself for more expressive synthetic data in time-series foundation models.\n- I think the finding that chaotic systems can be learned better by foundation models from context rather than by a specific model is valuable and interesting."
            },
            "weaknesses": {
                "value": "- It would be good to give more details on the LSTM and transformer models shown in the paper in order to allow for a fair comparison. I couldn't find details on the number of layers used e.g. for LSTM after hyperparameter optimization like the number of layers or the state size of the LSTM.\n- Could you clarify your rational on choosing the models you evaluated in the paper? Given the recent interest in linear RNNs like Mamba 1 / Mamba 2 / Gated Linear Attention, could you provide some results in this model class? Maybe Mamba 2, as it's fast to train.\n- I think the paper in its current state is quite verbose and could benefit from a clearer structure. For example sections 5.1 and 5.2 could have individual paragraphs with titles indicating the finding which the authors would like to emphasize."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}