{
    "id": "QwrnH32tJV",
    "title": "Provably Learning Concepts by Comparison",
    "abstract": "We are born with the ability to learn concepts by comparing diverse observations. This helps us to understand the new world in a compositional manner and facilitates extrapolation, as objects naturally consist of multiple concepts. In this work, we argue that the cognitive mechanism of comparison, fundamental to human learning, is also vital for machines to recover true concepts underlying the data. This offers correctness guarantees for the field of concept learning, which, despite its impressive empirical successes, still lacks general theoretical support. Specifically, we aim to develop a theoretical framework for the identifiability of concepts with multiple classes of observations. We show that with sufficient diversity across classes, hidden concepts can be identified without assuming specific concept types, functional relations, or parametric generative models. Interestingly, even when conditions are not globally satisfied, we can still provide alternative guarantees for as many concepts as possible based on local comparisons, thereby extending the applicability of our theory to more flexible scenarios. Moreover, the hidden structure between classes and concepts can also be identified nonparametrically. We validate our theoretical results in both synthetic and real-world settings.",
    "keywords": [
        "Concept Learning",
        "Compositional Learning",
        "Interpretability"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "We establish theoretical guarantees for learning concepts in general settings, without assuming specific concept types, functional relations, or parametric generative models.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=QwrnH32tJV",
    "pdf_link": "https://openreview.net/pdf?id=QwrnH32tJV",
    "comments": [
        {
            "title": {
                "value": "We are profoundly thankful for your insightful feedback (3/3)"
            },
            "comment": {
                "value": "In light of your great suggestion, we have further highlighted these distinctions in the updated manuscript, such as\n\n> \u201c(Line 260) \u2026 Most latent variable identifiability works also face the same challenge dealing with partial assumption violation (Zheng et al., 2022; Kong et al., 2022; Zheng & Zhang, 2023, Hyv\u00e4rinen et al., 2024). Unlike our local or even pair-wise identification strategy, these methods lack the flexibility to recover arbitrary parts of the hidden process in a localized manner.\u201d\n\nWe have also added further discussion comparing our strategy with other works on identifiability from additional perspectives, while most of these studies do not address concept learning. Some examples include:\n\n> \u201c(Line 322) Different from various assumptions encouraging the sparsity of the structure in the literature (Rhodes & Lee, 2021; Moran et al., 2021; Zheng et al., 2022; Zheng & Zhang, 2023), our assumption only ensures necessary variability on the dependency structure and could also hold true with relatively dense connections. At the same time, we permit arbitrary structures between the class-dependent hidden concepts and the observed variables, while previous work has to assume a sparse structure on the generating process between latent and observed variables.\u201d\n\n> \u201c(Line 328) Additionally, another line of work on latent variable models requires $2n_A + 1$ distinct domains or classes to achieve latent variable identifiability (e.g., (Hyv\u00e4rinen & Morioka, 2017; Khemakhem et al., 2020a; Kong et al., 2022; Hyv\u00e4rinen et al., 2024)), a condition we do not impose.\u201d\n\nWe sincerely appreciate your constructive suggestion, which has greatly helped us improve the contextualization and clarity of our contributions. Please kindly let us know if there are any further ways we can enhance the manuscript.\n\n**Q7:** The intended audience for the paper is unclear. The primary area of \"interpretability and explainable AI\" may not be the best fit, and the work might align more closely with fields like causality.\n\n**A7:** Thank you very much for your feedback. We deeply appreciate your perspective on the intended audience and the paper\u2019s alignment with relevant fields. Since the identifiability of the hidden data-generating process provides a principled way to uncovering the underlying structure of observational data, we initially selected explainability as the primary area. Specifically, identifying concepts allows us to reveal the hidden generative factors and the latent compositional structures that underlie different classes of observations. The field of interpretable and explainable AI is broad, fundamental, and critically important. We aim to contribute to this field from a novel perspective and learn from the valuable feedback provided by the community.\n\nAt the same time, we agree that some of our results are also relevant to fields like causality, as both areas share the overarching goal of exploring and understanding the hidden mechanism. To reflect this, we have further highlighted additional fields that may find our results valuable in the updated manuscript:\n\n> \u201c(Line 375) As a result, part of the proposed results might also be of independent interest to other fields such as disentanglement (Hyv\u00e4rinen et al., 2024), causal representation learning (Sch\u00f6lkopf et al., 2021), object-centric learning (Mansouri et al., 2024), compositional generalization (Du & Kaelbling, 2024), and causal structure learning (Spirtes et al., 2000).\u201d\n\nThank you once again for your constructive input. Please feel free to let us know if you have any further feedback or suggestions.\n\n---\n\nReferences:\n\n[1] Hyv\u00e4rinen & Morioka, Unsupervised feature extraction by time-contrastive learning and\nnonlinear ICA, NeurIPS 2016\n\n[2] Khemakhem et al., variational autoencoders and nonlinear ICA: A unifying framework, AISTATS 2020\n\n[3] Sorrenson et al., Disentanglement by nonlinear ICA with general incompressible-flow networks (GIN), ICLR 2020\n\n[4] Lachapelle et al., Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ICA, CLeaR 2022\n\n[5] Hyv\u00e4rinen et al., Identifiability of latent-variable and structural-equation models: from linear to nonlinear, Annals of the Institute of Statistical Mathematics, 2024"
            }
        },
        {
            "title": {
                "value": "We are profoundly thankful for your insightful feedback (2/3)"
            },
            "comment": {
                "value": "To provide a more comprehensive background on causal representation learning and identifiable latent variable models, we have also introduced definitions of related identifiability objectives in the preliminaries:\n\n> \u201c(Line 138) We introduce several identifiability objectives (Hyv\u00e4rinen & Morioka, 2017; Lachapelle et al., 2022; Zheng et al., 2022; Kong et al., 2022; Hyv\u00e4rinen et al., 2024) that are common in the literature as follows:\u201d\n\n\n> \u201c(Line 141) Definition 1 (Element-wise Identifiable). The set of latent variables $\\mathbf{z} \\subseteq \\mathbb{R}^n$ are \\textit{element-wise identifiable} if there exists an invertible function $h_i: \\mathbb{R} \\rightarrow \\mathbb{R}$ and a permutation $\\pi$ s.t. $\\hat{\\mathbf{z}}_i = h_i(\\mathbf{z}\\_{\\pi(i)})$.\u201d\n\n\n> \u201c(Line 143) Definition 2 (Subspace-wise Identifiable). The set of latent variables $\\mathbf{z} \\subseteq \\mathbb{R}^n$ are \\textit{subspace-wise identifiable} if there exists an invertible function $h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ s.t. $\\hat{\\mathbf{z}} = h(\\mathbf{z})$.\u201d\n\n\nThank you again for your suggestion. We hope this added clarification will help make our theoretical framework more accessible to a broader audience. Please kindly let us know if you have any further feedback.\n\n\n**Q5:** It would be really great if the notation could be lightened in any way possible\n\n**A5:** Thank you very much for this valuable suggestion. We truly appreciate the opportunity to make our work more accessible, and we fully agree that simplifying notation is key to improving readability. Given the theoretical density of our work, we have made targeted adjustments based on your feedback to make the notation as clear as possible.\n\nBeyond the initial submission\u2019s simplifications\u2014such as introducing shorthands, adding visual aids to clarify the problem setup, and providing a notation summary\u2014we have also made the following updates in light of your suggestion:\n\n1. Simplifying the array slicing whenever possible in both the main paper and appendix, for example\n\t- \u201c$\\mathcal{D}\\_{:n_A,i}$\u201d -> \u201c$\\mathcal{D}\\_{:,i}$\u201d\n\t- \u201c$\\mathcal{D}\\_{:n_A,:}$\u201d -> \u201c$\\mathcal{D}$\u201d\n\n2. In addition to the existing shorthands (e.g.,  $\\mathcal{D}$ for $\\operatorname{supp}(D_\\mathbf{c} g)$), we have also changed the $(c,\\theta, \\epsilon)$ to $(c, \\theta)$, where $\\theta$ itself represents all other factors including potential noise.\n\nWe hope these refinements make the notation more accessible, and we greatly appreciate your suggestion, which has helped us improve the readability of our work.\n\n\n**Q6:** Perhaps the authors could do a better job contextualizing what makes the result surprising and notable.\n\n**A6:** Thank you very much for this helpful suggestion. We would like to contextualize our contributions from two key perspectives:\n\n**Related work.** As highlighted in the abstract and introduction, prior works on concept learning have primarily focused on empirical performance without offering theoretical guarantees. A few studies have explored the theoretical side, but these typically rely on specific parametric assumptions, such as linear relationships among all concepts or additivity in the generating process\u2014assumptions that may not hold in many real-world settings. In contrast, our theoretical framework operates without these constraints, aiming to establish identifiability in a broad, nonparametric setting.\n\n**Techniques.** Since our goal is to identify which concepts can be reliably recovered in the most general settings, we extend beyond traditional parametric assumptions by leveraging insights from fundamental learning mechanisms. Specifically, we introduce a flexible identifiability framework based on the cognitive process of learning by comparison. For instance, given any two pairs of classes, our approach allows us to disentangle latent concepts that represent each class\u2019s unique features.\n\nThis is fundamentally and technically different from most prior works on the identifiability of latent variable models, even though the underlying problem is distinct. Specifically, existing works (see e.g., a recent survey [Hyv\u00e4rinen et al., 2024]) focus on identifying all latent variables as a complete hidden representation and generally lack flexibility for localized insights. If any variables in the considered set do not satisfy their assumptions, these theories cannot guarantee any degree of identifiability. By contrast, we can always provide alternative identifiability guarantees as long as there exists diversity, even if only between two classes."
            }
        },
        {
            "title": {
                "value": "We are profoundly thankful for your insightful feedback (1/3)"
            },
            "comment": {
                "value": "We are profoundly thankful for your insightful feedback and the time you have dedicated to reviewing our work. Your suggestions have been invaluable in helping us improve the manuscript. In response, we have carefully revised the presentation, with particular focus on enhancing the clarity and accessibility of our theoretical results. Please kindly find our point-by-point responses below.\n\n\n**Q1:** Real-world examples of how the data-generating process may be instantiated.\n\n**A1:** Thank you very much for your constructive suggestion. We fully agree that providing real-world examples of the generative process will greatly aid readers in understanding the theory. While we have illustrated different types of variables throughout the manuscript (e.g., Fig. 1, lines 86, 229-236), your suggestion made us realize that a standalone, complete example would make it easier for readers to follow. Therefore, we have added the following example in the preliminaries:\n\n> \u201c (Line 119) Example 1. Consider images of animals in an aquarium, where the observed variables $\\mathbf{x}$ represent image pixels. The different animal types (e.g., \u201cshark\u201d and \u201cturtle\u201d) correspond to classes $c$. Class-dependent concepts might include attributes like \u201cpredator,\u201d \u201csleek body,\u201d and \u201cocean\u201d (see, e.g., Fig. 1), while class-independent concepts could be \u201clighting\u201d and \u201cposition.\u201d The hidden generative process of each image depends on all of these concepts, though only some are specific to each class.\u201d\n\nThank you again for this valuable input, which has helped us make the theoretical framework more accessible to readers.\n\n\n**Q2:** Why is there a distinction between classes and concepts? Both appear to be unobserved --- unless the classes are indeed observed and this is the difference?\n\n**A2:** Great point. You are correct: in our framework, the classes are observed, while the concepts remain latent. We have clarified this distinction further in the preliminaries to make it clearer for readers. Meanwhile, the class variables serve as \u201chigher-level\u201d elements relative to the concepts, with each class associated with multiple underlying concepts. This naturally forms a compositional structure that may be helpful for tasks such as compositional generalization and novel class discovery.\n\n\n**Q3:** What is the type of class variable $\\mathbf{c}$?\n\n**A3:** Thank you for reviewing the paper so carefully, and we apologize for any confusion. In the updated manuscript, we have clarified that $\\mathbf{c}$ is a real-valued surrogate variable representing the object\u2019s class. The partial derivative serves as a technical tool to capture the dependency structure between classes and concepts in the general nonlinear case. For practical cases involving only discrete values, a mask can be used to model this structure instead. In light of your constructive comment, we have emphasized this clarification in the updated manuscript to prevent potential confusion.\n\n\n**Q4:** Theorem 1 refers to \"estimated latent concepts\" --- what is the estimation procedure? If it is an identifiability result, why do we need to refer to estimated concepts at all?\n\n**A4:** Thanks for raising this point. Indeed, the work studies identifiability theory and thus is analogous to the estimator. The proposed theory does not specify a particular algorithm or estimator but rather addresses the conditions under which latent concepts can be identified from observations. In the identifiability literature, terms like \"estimated latent concepts\" or \"estimated latent variables\" are commonly used to describe the identifiability objective (e.g., [Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020; Sorrenson et al., 2020; Lachapelle et al., 2022; Hyv\u00e4rinen et al., 2024]). As such, the specific estimation procedure is introduced later in the experimental setup. To clarify, we have added the following explanations next to Theorem 1 and in the preliminaries:\n\n> \u201c(Line 193) It is worth noting that the identifiability theory remains agnostic to the choice of estimator, provided the marginal distributions of the observations are matched. The results demonstrate that for any pair of classes, the unique concepts specific to each class can be disentangled from the other concepts.\u201d\n\n> \u201c(Line 136) Since identifiability is one of the main concerns, the theory is agnostic to estimators and the goal is to fit the marginal distribution $p(\\mathbf{x})$ with model (learner) $\\hat{f}$ and estimated variables $\\hat{\\mathbf{z}}$ to achieve certain identifiability.\u201d"
            }
        },
        {
            "title": {
                "value": "We deeply appreciate the valuable insights you have shared (3/3)"
            },
            "comment": {
                "value": "**Q4:** More discussion on the distributional assumption in Theorem 2.\n\n**A4:** Thank you very much for raising this point. We realize that our initial explanation of the distributional assumption may have inadvertently made it appear stronger than intended, leaving some room for potential misunderstanding. We have clarified this in the revised manuscript to address this:\n\n> \u201c(Line 283) \u2026 there exist two values of $\\mathbf{c}$, i.e., $c^{(k)}$ and $c^{(v)}$ (which may vary across different $A_{\\mathbf{z}}$)\u201d\n\nSpecifically, for any $A_{\\mathbf{z}}$, although we require the probabilistic difference between classes $c^{(k)}$ and $c^{(v)}$, these two classes are not fixed and may change over different $A_{\\mathbf{z}}$, providing great flexibility. This assumption is common in recent identifiability works [Kong et al., 2022; Xie et al., 2022; Zheng & Zhang, 2023] and was originally introduced in [Kong et al., 2022]. Intuitively, this assumption holds as long as the probability distributions for each class are not overly similar, a condition empirically validated by Kong et al. For example, in a zoo setting, it would be highly unlikely for all animal species to exhibit identical behaviors and features, thereby satisfying this type of probabilistic variation across classes.\n\nTo further enhance clarity, we have added the following example in the manuscript:\n\n> \u201c(Line 353) Importantly, these two classes may vary across different $A_{\\mathbf{z}}$. Therefore, this assumption is highly likely to be satisfied in real-world scenarios, as it is virtually impossible for the measures corresponding to \\textit{all} classes (e.g., all kinds of animals in a zoo) to be almost identical.\u201d\n\nWe sincerely appreciate your feedback, which has been instrumental in improving the clarity and accessibility of our work. Please kindly let us know if there are any further suggestions.\n\n---\n\nReferences:\n\n[1] Hyv\u00e4rinen & Morioka, Unsupervised feature extraction by time-contrastive learning and\nnonlinear ICA, NeurIPS 2016\n\n[2] Khemakhem et al., variational autoencoders and nonlinear ICA: A unifying framework, AISTATS 2020\n\n[3] Sorrenson et al., Disentanglement by nonlinear ICA with general incompressible-flow networks (GIN), ICLR 2020\n\n[4] Lachapelle et al., Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ICA, CLeaR 2022\n\n[5] Hyv\u00e4rinen et al., Identifiability of latent-variable and structural-equation models: from linear to nonlinear, Annals of the Institute of Statistical Mathematics, 2024\n\n[6] Kong et al., Partial identifiability for domain adaptation, ICML 2022\n\n[7] Li et al., Subspace identification for multi-source domain adaptation, NeurIPS 2023\n\n[8] Zheng & Zhang, Generalizing nonlinear ICA beyond structural sparsity, NeurIPS 2023\n\n[9] Zhang et al., Causal representation learning from multiple distributions: A general setting, ICML 2024\n\n[10] Rajendran et al., Learning interpretable concepts: Unifying causal representation learning and foundation models, NeurIPS 2024"
            }
        },
        {
            "title": {
                "value": "We deeply appreciate the valuable insights you have shared (2/3)"
            },
            "comment": {
                "value": "**Q1.3:** What is the meaning of \"identifiable up to a subspace-wise invertible transformation\"?\n\n**A1.3:** Thanks for the comment. By \"identifiable up to a subspace-wise invertible transformation,\" we mean that variables can be identified up to an invertible mapping between subspaces instead of the entire space. This objective is prevalent in the identifiability literature [Kong et al., 2022; Lachapelle et al., 2022; Li et al., 2023; Zheng & Zhang et al., 2023; Hyv\u00e4rinen et al., 2024], where it is sometimes referred to as \"subspace-wise\" or \"block-wise\" identifiability.\n\nTo avoid any potential confusion, we have added the following definitions in the preliminary section for a more comprehensive coverage of the related background:\n\n> \u201c(Line 138) We introduce several identifiability objectives (Hyv\u00e4rinen & Morioka, 2017; Lachapelle et al., 2022; Zheng et al., 2022; Kong et al., 2022; Hyv\u00e4rinen et al., 2024) that are common in the literature as follows:\u201d\n\n\n> \u201c(Line 141) Definition 1 (Element-wise Identifiable). The set of latent variables $\\mathbf{z} \\subseteq \\mathbb{R}^n$ are *element-wise identifiable* if there exists an invertible function $h_i: \\mathbb{R} \\rightarrow \\mathbb{R}$ and a permutation $\\pi$ s.t. $\\hat{\\mathbf{z}}_i = h_i(\\mathbf{z}\\_{\\pi(i)})$.\u201d\n\n\n> \u201c(Line 143) Definition 2 (Subspace-wise Identifiable). The set of latent variables $\\mathbf{z} \\subseteq \\mathbb{R}^n$ are *subspace-wise identifiable* if there exists an invertible function $h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ s.t. $\\hat{\\mathbf{z}} = h(\\mathbf{z})$.\u201d\n\n\nTo further enhance clarity, we also reference these definitions in our theorems to assist readers who may be less familiar with this topic. Thank you again for your helpful feedback, which has allowed us to make these details more accessible to a broader audience.\n\n\n**Q2:** Assumption of conditional independence seems to be strong.\n\n**A2:** Thank you for your feedback. In our setting, the relationship between class and concepts makes conditional independence a natural formulation of the problem. For instance, although the concepts \"wings\" and \"feathers\" are semantically dependent, they become conditionally independent when given the class variable \"bird.\" This highlights a meaningful form of modularity that aligns with the structure of class-concept relationships in our framework.\n\nIntuitively, some form of modularity in latent variables is essential to recover them individually, and conditional independence is a well-established formulation, frequently used in statistical frameworks like independent component analysis. It is a common assumption in prior work on the identifiability of latent variable models [Hyv\u00e4rinen & Morioka, 2016;\nKhemakhem et al., 2020; Sorrenson et al., 2020; Lachapelle et al., 2022; Hyv\u00e4rinen et al., 2024]. Even in rare cases the latent variables are actually conditionally dependent, we can still make use of some other additional information, such as multiple domains [Zhang et al., 2024].\n\nMoreover, it may be helpful to note that our constraints are, in fact, less restrictive than those in prior works on identifiable concept learning such as [Rajendran et al., 2024]. Whereas previous studies often assume (conditional) independence across all concept variables $\\mathbf{z}$, our work allows for arbitrary dependencies among class-independent concepts, thereby accommodating more general scenarios.\n\nIn response to your excellent suggestion, we have incorporated examples like the following into the paper to illustrate this:\n\n> \u201c(Line 153) The conditional independence provides a form of modularity commonly adopted in prior work on identifiable latent variable models (Hyv\u00e4rinen & Morioka, 2016;\nKhemakhem et al., 2020; Sorrenson et al., 2020; Lachapelle et al., 2022; Hyv\u00e4rinen et al., 2024). It may be particularly suitable in our class-concept framework; for example, while the concepts 'wings' and 'feathers' are related, they become conditionally independent given the class variable 'bird.'\u201d\n\nThank you once again for your thoughtful feedback, which has helped us enhance the clarity and contextualization of this assumption.\n\n\n\n\n**Q3:** Can the class vector $\\mathbf{c}$ take continuous real values?\n\n**A3:** Thanks for this observation. You are absolutely correct; the class vector $\\mathbf{c}$ can indeed take continuous values. We have highlighted this in the updated manuscript to improve clarity. The derivative serves as a technical tool to represent the dependency structure between classes and concepts in the general nonlinear setting. In practical scenarios where only discrete values are available, a mask can be used to effectively represent the structure. We appreciate your feedback, which has helped us clarify this aspect in the paper."
            }
        },
        {
            "title": {
                "value": "We deeply appreciate the valuable insights you have shared (1/3)"
            },
            "comment": {
                "value": "We deeply appreciate the valuable insights you have shared, which have helped us enhance the quality and clarity of the manuscript. In light of your great feedback, we have carefully revised the manuscript, adding further clarifications and explanations. Please kindly find our detailed response below.\n\n\n**Q1:** The main weakness of the paper is its presentation. I list several issues about the presentation as follows.\n\n**A1:** Thank you very much for your comments, which have nicely inspired us to rewrite some paragraphs to make the messages more explicit for a broader audience. We hope your concerns have been properly addressed, and would be delighted if you find the key messages we aim to deliver interesting and exciting. We provide detailed responses to each of the comments as well as the corresponding updates as follows:\n\n**Q1.1:** Lack of a clear definition of what a learner is expected to output and how to measure the performance of a learner.\n\n**A1.1:** Thank you for highlighting this point\u2014we truly value the opportunity to clarify our focus. As mentioned in line 136 in the preliminaries, $\\hat{z}$ denotes estimated concepts, which represents the output of a learner. Our work centers on identifiability theory, specifically on establishing the conditions under which the latent data-generating process (model) can be identified (up to a certain indeterminacy) from observations. Since our study is grounded in theoretical foundations rather than specific implementation, it is designed to be learner-agnostic and does not specify a performance measure. The specific estimation procedure is thus described later in the experimental setup. In light of the comment, we have also added the following sentence in the preliminary:\n\n> \u201c(Line 137) \u2026 the goal is to fit the marginal distribution $p(\\mathbf{x})$ with model (learner) $\\hat{f}$ and estimated variables $\\hat{\\mathbf{z}}$ to achieve certain identifiability.\u201d\n\nFurthermore, we recognize that further emphasizing this scope could be beneficial and have added clarifications throughout the updated manuscript. For example:\n\n\n> \u201c(Line 193) It is worth noting that the identifiability theory remains agnostic to the choice of estimator, provided the marginal distributions of the observations are matched. The results demonstrate that for any pair of classes, the unique concepts specific to each class can be disentangled from the other concepts.\u201d\n\nWe hope this clarification helps make our task clearer. Thank you once again for your feedback.\n\n**Q1.2:** It is confusing what algorithm/estimator a learner uses to get such an estimation.\n\n**A1.2:** Thank you for raising this question. As mentioned in our response to Q1.1, our work focuses on the identifiability theory, which is intentionally learner-agnostic. The theory does not specify a particular algorithm or estimator but rather addresses the conditions under which latent concepts can be identified from observations. Therefore, the specific estimation procedure is included in the experimental setup, which is basically a MLE. In the identifiability literature, terms like \"estimated latent concepts\" or \"estimated latent variables\" are commonly used to describe the identifiability objective (e.g., [Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020; Sorrenson et al., 2020; Lachapelle et al., 2022; Hyv\u00e4rinen et al., 2024]). We appreciate your feedback and have further highlighted it in the updated manuscript:\n\n> \u201c(Line 136) Since identifiability is one of the main concerns, the theory is agnostic to estimators and the goal is to fit the marginal distribution $p(\\mathbf{x})$ with model (learner) $\\hat{f}$ and estimated variables $\\hat{\\mathbf{z}}$ to achieve certain identifiability.\u201d"
            }
        },
        {
            "title": {
                "value": "We are genuinely grateful for your insightful comments (2/2)"
            },
            "comment": {
                "value": "Following your valuable suggestions, we have added further discussion to emphasize these distinctions. Here are some examples:\n\n> \u201c(Line 322) Different from various assumptions encouraging the sparsity of the structure in the literature (Rhodes & Lee, 2021; Moran et al., 2021; Zheng et al., 2022; Zheng & Zhang, 2023), our assumption only ensures necessary variability on the dependency structure and could also hold true with relatively dense connections. At the same time, we permit arbitrary structures between the class-dependent hidden concepts and the observed variables, while previous work has to assume a sparse structure on the generating process between latent and observed variables.\u201d\n\n> \u201c(Line 260) \u2026 Most latent variable identifiability works also face the same challenge dealing with partial assumption violation (Zheng et al., 2022; Kong et al., 2022; Zheng & Zhang, 2023, Hyv\u00e4rinen et al., 2024). Unlike our local or even pair-wise identification strategy, these methods lack the flexibility to recover arbitrary parts of the hidden process in a localized manner.\u201d\n\n> \u201c(Line 328) Additionally, another line of work on latent variable models requires $2n_A + 1$ distinct domains or classes to achieve latent variable identifiability (e.g., (Hyv\u00e4rinen & Morioka, 2017; Khemakhem et al., 2020a; Kong et al., 2022; Hyv\u00e4rinen et al., 2024)), a condition we do not impose.\u201d\n\n    \nThank you once again for your insightful feedback, which has helped us contextualize our unique contributions. We hope these additions address your suggestions, and we would be grateful to hear if there are any further adjustments that could improve clarity or completeness.\n\n---\n\nReferences:\n\n[1] Zheng et al., On the identifiability of nonlinear ICA: Sparsity and beyond, NeurIPS 2022\n\n[2] Zheng & Zhang, Generalizing nonlinear ICA beyond structural sparsity, NeurIPS 2023\n\n[3] Kong et al., Partial identifiability for domain adaptation, ICML 2022"
            }
        },
        {
            "title": {
                "value": "We are genuinely grateful for your insightful comments (1/2)"
            },
            "comment": {
                "value": "We are genuinely grateful for the time you have dedicated and for your insightful comments. In response, we have added several new discussions in the updated manuscript, with a particular focus on comparisons to these prior works. Please find our detailed response below:\n\n**Q1:** Detailed comparison with earlier works such as [Zheng et al., 2022; Zheng & Zhang, 2023; Kong et al. 2024].\n\n**A1:** Thank you very much for connecting these seemingly different domains. Since both lines of research explore latent variable models, they indeed share insights toward building identifiability results. As mentioned in the discussion of implications (e.g., lines 372-377), our results might also be of theoretical interest to fields such as disentanglement and causal representation learning:\n\n> \u201c(Line 372) Despite being one of the essential pieces on learning the hidden concepts, our proposed theory also sheds light on understanding the latent variable models without additional knowledge, since the formulation is just based on the basic generating process between latent and observed variables. As a result, part of the proposed results might also be of independent interest to other fields such as  disentanglement (Hyv\u00e4rinen et al., 2024), causal representation learning (Sch\u00f6lkopf et al., 2021), object-centric learning (Mansouri et al., 2024), compositional generalization (Du & Kaelbling, 2024), and causal structure learning (Spirtes et al., 2000).\u201d\n\nAt the same time, there are some key distinctions:\n\n1. While [Zheng et al., 2022; Zheng & Zhang, 2023; Kong et al., 2024] also consider the identifiability of latent variables, our problem of concept learning differs from theirs. As highlighted in line 63, our work aims to answer the question of which concepts can be reliably recovered in the most general case. Our primary identifiability result is rooted in the cognitive process of learning by comparison: given any pair of classes, the unique concepts corresponding to each class can be identified. This forms the foundation of our local identifiability based on pairwise comparisons and extends to more general cases, including global identifiability. For example, given any two pairs of classes, we can always disentangle latent concepts that represent each class\u2019s unique features.\n\n\tIn contrast, [Zheng et al., 2022; Zheng & Zhang, 2023; Kong et al., 2022] focus on identifying all latent variables as a complete hidden representation and lack the flexibility to provide insights in a localized manner. If any variables in the considered set do not meet their assumptions, they cannot guarantee identifiability. In fact, it is common for these conditions to be partially unmet. For instance, structural sparsity in [Zheng et al., 2022; Zheng & Zhang, 2023] is rarely satisfied for all latent variables, as verified by [Zheng & Zhang, 2023]. Similarly, [Zheng & Zhang, 2023; Kong et al., 2022] require at least $2n_A+1$ environments for the changing variables, which may be infeasible in certain cases. Therefore, in practical scenarios where assumptions may not hold universally, our approach offers flexible identifiability results through the strategy of learning by comparison, which these previous works do not address.\n\n2. Our technical assumptions also differ in key ways:\n\n\t- [Zheng et al., 2022] assumes a sparsity structure between $\\mathbf{z}$ and $\\mathbf{x}$, disallowing dense Jacobians in the generative function $f$, while our approach places no constraints on $f$.\n    \n\t- [Zheng & Zhang, 2023] also consider the structural sparsity on the mixing procedure between invariant latent variables and observed variables, while we allow arbitrary mixing structure. Moreover, they require $2n_A+1$ distinct environments for the changing latent variables, which we do not impose.\n    \n\t- [Kong et al., 2022] addresses domain adaptation with a focus on content-style disentanglement, achieving component-wise identifiability for style variables but also requiring $2n_A+1$ distinct environments.\n\n\tTherefore, regarding assumptions on structures, [Zheng et al., 2022; Zheng & Zhang, 2023] assume a sparse structure in the generating function $f$ that maps latent variables $\\mathbf{z}$ to observed variables $\\mathbf{x}$ ($\\mathbf{x} = f(\\mathbf{z})$), whereas our approach does not impose any conditions on $f$. Instead, we focus solely on the structure between classes and concepts to determine which concepts can be reliably recovered. Furthermore, [Zheng & Zhang, 2023; Kong et al., 2022] require at least $2n_A+1$ distinct environments, an assumption we do not impose.\n\n**Summary:** Our work differs both in problem settings and technical conditions. Given the distinct objectives, we do not claim our theory is more general. Instead, our aim is to determine which concepts can be reliably identified with minimal assumptions in a broad setting. Our local identifiability theory can provide meaningful identifiability results with any pair of classes."
            }
        },
        {
            "summary": {
                "value": "The paper studies learning of a certain type of non-parametric hidden variable model. Theorems are given showing statistical identifiability, and some experiments are preformed.\n\nThe family of non-parametric hidden variable models is described on pp 2-3. In brief:\n- There are concept-dependent hidden variables $Z_A$ and concept-independent hidden variables $Z_B$. The distributions of $Z_A$ and $Z_B$ are not constrained to come from a specific distribution such as Gaussian. The concept-dependent variables $Z_A$ depend on the class $c$ of a given datapoint.\n- The hidden variables $(Z_A, Z_B)$ are mapped to the observed variable $X$ via some smooth function $g$. \n- It is further assumed that the Jacobian of $g$ satisfies certain full-rank assumptions in order to ensure an ability to recover the model based on observations.\n- Some sparsity assumptions are made on how many concept-dependent hidden variables correspond to each class $c$.\n- A \"structural diversity\" assumption is made stating roughly that each class has at least one hidden variable unique to this class and not shared with other classes.\n\nThe paper proves theorems that under the assumption listed above it is possible to recover the model (up to some transformation). \n\nExperiments are performed on synthetic datasets, as well as Fashion-MNIST, EMNIST, AnimalFace, and Flower102 datasets and model is fitted using a regularized maximum-likelihood method. Robustness of the recovered concept is tested by comparing the same concept across different angles and environments. \n\nThe paper also compares the performance of regularized maximum-likelihood method that encorporates the aforementioned assumptions vs the base method that does not incorporate the assumptions above. It is shown that the former achieves a better performance in terms of Mean Correlation Coefficient (MCC)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Non-parametric models of the type studied in this work have their uses and can be important if one is working with relatively low-dimensional data and needs high degree of interpretability.\n- The paper is carefully written and includes an appendix listing all notation, figures are well-made."
            },
            "weaknesses": {
                "value": "- The paper does clearly articulate how exactly it improves on a number of closely-related papers such as [Zheng et al., 2022], [Zheng & Zhang, 2023] and [Kong et al. 2022] among others. These works study non-parametric models that look quite similar to the ones given in this work in terms of assumptions on the Jacobian and structural sparsity. They also use very similar mathematical tools to analyze identifyability. The paper does not articulate clearly what exactly it believes are some specific shortcomings of these earlier works, and how the current work overcomes such shortcomings. I think it is important that this is done, and it is also convincingly argued that the current paper indeed overcomes such limitations."
            },
            "questions": {
                "value": "(See above)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper models and studies the problem of concept learning. Suppose that we are given observations $x$s from $k$ classes that are generated based on their concept vectors $z$, furthermore, each class has a set of associated indices of the concept vectors and a concept vector is generated according to the class, we want to recover the corresponding set of concept indices for each class. The paper tries to build a theoretic framework that can explain under certain assumptions, which kind of concept can be recovered. Besides the theoretic framework, the paper also performs experiments on both synthetic and real-world datasets based on their theoretic framework."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Concept learning is an important topic in machine learning. This paper builds a mathematical framework to help understand what concepts can be reliably recovered. Experiments are also provided to help justify the theory in this paper."
            },
            "weaknesses": {
                "value": "1. \nThe main weakness of the paper is its presentation. I list several issues about the presentation as follows.\n\nThe definition of the problem is not complete in the preliminary section. In the preliminary section, the paper only defines how observations are generated but does not give a clear definition of what a learner is expected to output and how to measure the performance of a learner.\nFurthermore, the statements of the main theorems are not mathematically formal enough. For example, the statement of Theorem 1 mentions \"estimated latent concepts\"\n> the estimated latent concepts for the set difference $\\hat{z}_{\\pi(A_i \\backslash A_j)}$...,\n\nI understand that the estimated latent concepts should be the output of a learner. However, before the statement of Theorem 1, the paper does not define the definition of estimated latent concepts. It is confusing what algorithm/estimator a learner uses to get such an estimation. Another example is the statement of Theorem 2. In the statement of Theorem 2, the paper mentions \n>$z_B$ is identifiable up to a subspace-wise invertible transformation.\n\nI think subspace-wise invertible transformation is an informal mathematical term. Furthermore, as the definition of identifiable is also not formally presented in the preliminary section, it is unclear the exact result that the theorem would like to convey.\n\n2. I think some of the assumptions made by the paper are not natural enough. For example, in equation (3), the paper assumes that the entries of the class-dependent concepts $z_A$ are conditionally independent. This seems to be a very strong assumption, but the paper does not provide natural examples to justify that the assumption is reasonable."
            },
            "questions": {
                "value": "1. \nIn the preliminary section, the classes are defined as a vector $c=(c_1,\\dots,c_u)$. It is not very clear to me whether the class vector $c$ can take continuous real values or can only take discrete values. If $c$ can only take discrete values, then in line 124, it is not reasonable to say one can take the partial derivative of $g$ with respect to $c$. Can you help clarify this?\n\n2. \nIn line 320, it says the distributional assumption in Theorem 2 necessitates the existence of at least two classes with differing conditional distributions and is highly likely to be satisfied. But it seems that the distribution assumption is much stronger because it requires the probability mass for the probabilities to be unequal for any subset $A_z$ that is not a product set of $B_{z_B} \\times z_A$. Can you provide any real-world example that satisfies the assumption?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies a new model of concept learning that works roughly as follows:\n- In any given setting (e.g. classifying images of animals), we have $u$ possible classes, such as \"cat\", \"dog\", \"mammal\", \"bird\" (not necessarily mutually exclusive), and $n$ possible real-valued concepts, such as \"furriness\", \"number of legs\", \"age\", etc. Of these, $n_A$ concepts are class-dependent (e.g. \"furriness\", \"number of legs\"), and the rest are not (e.g. \"age\").\n- A binary \"structure\" matrix $M \\in \\\\{0, 1\\\\}^{n_A \\times u}$ describes which concepts are related to which classes.\n- Data is generated as follows: we first generate a class vector $c \\in \\\\{0, 1\\\\}^u$ (e.g., \"cat\" + \"mammal\"), then we generate a latent concept vector $z$ based on $c$ (via a distribution $p(z|c)$ that follows the dependence structure given by $M$), and finally generate an observed vector $x$ based on the concept vector $z$.\n- It is important that no other parametric assumptions are made.\n- The goal is to identify $z$ based only on the observed data $x$.\n\nUnder this data-generating process, the main results are identifiability results:\n- Under some technical assumptions that essentially encode a kind of diversity and identifiability in the structure matrix (intuitively, for each concept $z_i$, there must be a set of classes such that $z_i$ is unique to one of those classes --- in a sense, each concept has a unique \"class signature\"), the concept vector $z$ is identifiable from the data up to permutation and invertible transformation (Theorem 2).\n- Extensions / variants of this result are also given (e.g. for pairwise comparison of classes, etc).\n- Some experimental results are also given."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "**Disclaimer:** while my background is in ML theory, I have very limited familiarity with this particular area (which I see as causal discovery / structure learning), and my perspective should be taken as that of a relative outsider.\n\nThis work tackles a broad and ambitious question in \"concept learning\": what are the mildest structural assumptions under which we can reasonably hope to identify underlying concepts from purely observed data? To do so, the paper introduces a rather generic non-parametric data-generating process and shows basic identifiability results under certain technical assumptions.\n\nOverall the paper scores well on ambition and originality, as this is certainly an important question to investigate, and it appears from the literature that prior work had not tackled the question in quite such generality (to my limited knowledge). Thus a nice contribution of the paper is the definition of the model and the approach to the question. It is also nice that the authors obtain results with very few parametric assumptions on the data-generating process. The result is likely of technical interest to an audience in causality and related areas."
            },
            "weaknesses": {
                "value": "(See disclaimer above.)\n\nBy far the biggest weakness of the paper is that it is written in a very obscure and technical fashion, and is IMO very hard to read and understand for anyone not working in causal discovery, structure learning or related areas. Remarkably for a paper that claims to study such a broad and basic question, essentially no examples whatsoever are given of how the main data-generating process is instantiated in real-world settings. In fact it took me a while even to extract enough understanding to write the summary above.\n\nIn general the paper seems jump between very technical statements and voluminous but vague exposition. For example, the main theorems are all quite technical and tricky to parse. The few examples given are entirely synthetic and hard to interpret. The notation is quite dense. See also some concrete questions below.\n\nI also have a lurking suspicion that the framework is so generic and the assumptions so strong that the main result is sort of tautological and primarily a mathematical exercise. Intuitively it seems quite reasonable to expect diversity assumptions of this type to lead to identifiability. Perhaps the authors could do a better job contextualizing what makes the result surprising and notable.\n\nOverall it is not clear who the intended audience really is. As interesting as the results may be, they certainly do not seem accessible to a broad machine learning audience like at ICLR. While the authors have placed it in the primary area of \"interpretability and explainable AI\", I am quite sure it is out of place here, at least as written. In fact I am not sure why it has not been framed more squarely as causal discovery or structure learning, or indeed submitted to a specialized technical venue or journal in that field."
            },
            "questions": {
                "value": "- I strongly recommend that the authors discuss real-world examples of how the data-generating process may be instantiated (e.g. for image classification in the context of Fashion-MNIST or AnimalFace, but also others). This includes clearly specifying what the classes, concepts, and observed values are in each example.\n- A high-level modeling question I am unclear on is why there is a distinction between classes and concepts. Any given observed vector is implicitly associated both with a latent vector of classes and a latent vector of concepts. Both appear to be unobserved --- unless the classes are indeed observed and this is the difference? If not it is not clear why we want to model them separately at all, and how they are playing functionally different roles.\n- What is the type of each class $c_i$? What space does it take values in? This does not seem clearly specified anywhere and is very confusing. The entire meaning of the partial derivative $D_c g$ rests on this.\n- Theorem 1 refers to \"estimated latent concepts\" --- what is the estimation procedure? If it is an identifiability result, why do we need to refer to estimated concepts at all?\n- It would really great if the notation could be lightened in any way possible. The array slicing notation $D_{:n_A, :}$ in particular adds a lot of visual noise and I am not sure why it is needed if $g$ anyway maps to $\\\\mathbb{R}^{n_A}$. At least some shorthand could be introduced."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}