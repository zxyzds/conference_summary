{
    "id": "tvLnYGAaY1",
    "title": "Rethinking the Roles of Time and Frequency Domains Before Tackling Time Series UDA",
    "abstract": "In time-series unsupervised domain adaptation (UDA), the adaptation of both temporal and frequency domain features has been relatively underexplored. To address this gap, we conduct a comprehensive series of experiments to revisit the roles of these domains in UDA. Our findings reveal that the temporal domain contains more diverse features, offering higher discriminability, while the frequency domain is more domain-invariant, providing better transferability. Combining the strengths of both domains, we propose TidalFlow, a UDA framework that synergistically integrates temporal and frequency domain features. TidalFlow enhances feature extraction and captures subtle, class-specific features without relying on traditional alignment strategies. By utilizing simple hyperparameter adjustments and using frequency embeddings from the source domain as reference points for domain adaptation, TidalFlow achieves nearly a 10% improvement across five benchmark datasets in time-series UDA. This research highlights the unique strengths of both domains and marks a paradigm shift in UDA methods, showcasing TidalFlow\u2019s robust performance in real-world applications.",
    "keywords": [
        "unsupervised domain adaptation",
        "time-series domain adaptation",
        "TSUDA"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=tvLnYGAaY1",
    "pdf_link": "https://openreview.net/pdf?id=tvLnYGAaY1",
    "comments": [
        {
            "summary": {
                "value": "This paper presents TidalFlow, a novel framework that aims to advance time-series unsupervised domain adaptation by leveraging both temporal and frequency domain features. The authors propose that temporal domain features offer superior discriminability while frequency domain features provide better transferability, leading to a complementary integration approach. The method employs a dual-backbone architecture processing temporal and frequency features separately, combined through a voting mechanism. The authors report significant performance improvements, achieving approximately 10% gains across five benchmark datasets"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Novel insight into the complementary roles of temporal vs frequency domains\n- Proposing a voting mechanism for feature fusion, is quite promising\n- Strong empirical results with ~10% improvement on benchmarks"
            },
            "weaknesses": {
                "value": "1- Core Claims Validation:\nThe fundamental claims about temporal features' discriminability and frequency features' transferability lack rigorous validation. Specific experiments should be designed to quantitatively measure these properties. The authors need to provide eithor theoretical justification or experimental evidence to support these central claims. Without such validation, the paper's foundational assumptions remain questionable.\n\n2- Literature Review and Positioning:\nThe authors' claim that time-frequency approaches in domain adaptation are underexplored is inaccurate. Several significant works, including FECAM and the Adaptive temporal-frequency network, have made substantial contributions in this area. The paper needs to acknowledge these works and clearly articulate how TidalFlow advances beyond existing approaches.\n\n3- Evaluation Methodology and Confounding Factors\nThe dual backbone architecture introduces potential confounding factors in performance evaluation. The paper lacks crucial baseline comparisons, particularly source-only performance for both backbones. This makes it difficult to isolate the contribution of the proposed method from architectural advantages.\n\n4- Feature Fusion Analysis\nThe voting mechanism's superior performance requires better justification. The paper should explore why voting outperforms individual components and compare it with alternative fusion strategies like averaging or summing the time and frequency features. The current analysis doesn't provide sufficient insight into why voting contributes more than the individual time and frequency components.\n\n5- Limited Ablation Studies:\nThe ablation studies are conducted on only one dataset, which is insufficient for drawing conclusive insights. The authors should extend these studies across multiple datasets to demonstrate the consistency and robustness of their findings. This limitation raises questions about the generalizability of the reported results."
            },
            "questions": {
                "value": "Nil"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new unsupervised domain adaptation framework (TidalFlow) for time series data. The authors revisit the roles of the time and frequency representations of time series data and suggest that the time domain offers higher discriminability, while the frequency domain provides better transferability.\nIn addition, the authors are interested in class-wise alignment between source and target domains besides the traditional global alignment."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is well written\n- The experiments are extensive"
            },
            "weaknesses": {
                "value": "1. First, I find that the paper is more suited to source-free UDA settings than traditional UDA. This is because source and target domains are not trained together. In contrast, the model is first pretrained on the source domain data, then adapted somehow to the target domain, which is similar to the source-free UDA settings.\n\n2. I have a concern about the preliminary study, i.e., relying on the WISDM dataset. The reason is that this dataset is too small and its results are not very stable, and you can easily get 100% accuracy. \nAlso, using the accuracy instead of the F1-score for this highly imbalanced dataset is concerning. \nTherefore, I find that the conclusions from this experiment unreliable.\n\n3. In the problem formulation section, you never mentioned what is the objective. What do we do with the datasets you defined?\n4. Most of the references are incomplete and missing the venue. This is common when you grab the citation from Arxiv as @misc. So please, get the references from the publishing venue source.\n\n4. Please consider the following:\n     - Fonts on figures, eg. Fig 1 are too small.\n     - Typo: until until"
            },
            "questions": {
                "value": "- I suggest that you reconsider the paper scenario to source-free UDA.\n- I suggest that you rely, in the Preliminary experiment, on another more reliable dataset. Also, it would be better to use F1-score in imbalanced datasets.\n- In the above study, you have one experiment adjusting the learning rate during the fine-tuning phase. What is the fine-tuning phase? And why do you need it? And what is the relationship between the frequency domain having transferable features and the learning rate value?\n- Define your objective in the problem formulation section.\n\n- What is the structure of the encoder G and how did you obtain z_{temp} and z_{freq}? Also, how does the encoder differentiate between domain-specific and domain-invariant features? Also, how does the concatenation of z_{temp} and z_{freq} help with domain adaptation?\n\n- why a hierarchical structure would be more effective for generalizing across domains?\n- What is e_h?\n- What is \u201csg\u201d operator in Eq. 4? It should be mentioned directly after the equation.\n- The main contribution here is relying on the frequency features to improve the adaptation/transferability between source and target domains. However, the extraction of these features is not clear and adopting them for adaptation is also not clear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces TidalFlow, a novel framework for unsupervised domain adaptation (UDA) in time-series data. TidalFlow strategically integrates both temporal and frequency domain features to enhance UDA prediction performance. The authors demonstrate that the temporal domain provides richer, more discriminative features, while the frequency domain offers better domain-invariant properties, enhancing transferability across domains. Through comprehensive experiments on five benchmark datasets, TidalFlow shows nearly a 10% performance improvement over existing methods. The paper also provides a detailed analysis of the complementary strengths of the temporal and frequency domains, offering a new perspective on their roles in UDA."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper rethinks the roles of time and frequency domains by conducting thorough experiments, offering valuable insights into the advantages of integrating frequency information into the MTS-UDA task, and effectively demonstrating its impact and rationale.\n\n2. The framework has been evaluated on five benchmark datasets, which provides sufficient validation."
            },
            "weaknesses": {
                "value": "1. In the related works section, it would be beneficial to provide a brief categorization or summary table that groups the related works by their primary application domain (e.g. video, speech, computer vision, time-series). \n\n2. Typo in line 175: repeat \"until\". \n\n3. Although the authors reassess the characteristics of temporal and frequency information in the 3.2 preliminary study, certain design elements in the main methodology are quite straightforward and not clearly explained. (please kindly refer to Quesiont (2))\n\n4. For reproducibility, could you please include a table in the appendix listing key hyperparameters (e.g. learning rates, batch sizes, number of epochs) for all models, including baselines, to ensure fair comparison?"
            },
            "questions": {
                "value": "(1) The Fourier transform is utilized, but it is unclear why this approach was chosen over alternatives like the wavelet transform. Could you briefly discuss the tradeoffs between Fourier transform and other time-frequency analysis methods like wavelet transform in the context of their specific task? This would encourage a more comprehensive justification of their methodological choices.\n\n(2) The reasoning behind the framework's design is not explained clearly. What are the dimensions of the frequency input and the output from each module? How is the structure of G encoded? What is the rationale for the 'reconstruction' in the adaptation process? \n\n(3) What does the training pipeline look like? Are the training and adaptation phases executed simultaneously, or does the adaptation phase occur only after the training phase is finished? If it's the latter, how is the completion of the adaptation phase determined?\n\n(4) In the appendices, tables 3, 4, 5, 6, and 7, why are the average and standard deviation calculated across all models for each source-target pair? Could you explain the rationale for this aggregation or revise the tables to show per-model statistics, which would indeed facilitate easier comparison between models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the challenge of time-series unsupervised domain adaptation (UDA) by exploring the roles of temporal and frequency domains, which have been relatively underexplored in this field. Through a series of experiments, the authors find that the temporal domain contains diverse, discriminative features but is sensitive to domain shifts, while the frequency domain offers more domain-invariant features that aid in transferability."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper presents a novel perspective on time-series unsupervised domain adaptation (UDA) by emphasizing the complementary strengths of temporal and frequency domains. While most existing UDA approaches primarily focus on aligning features between source and target domains, TidalFlow shifts the focus toward leveraging class-specific features from both domains without relying on traditional alignment strategies. This approach is original and opens up new avenues for UDA, moving beyond feature alignment to effective feature extraction and integration, which can be more robust to domain shifts.\n\nThe paper is clear and well-organized. The problem statement and motivation are explicitly articulated, helping readers understand why focusing on both temporal and frequency domains is essential. The descriptions of the TidalFlow framework, including its components like the dual-stream encoder, hierarchical embedding table (HET), and voting mechanism, are well-detailed. The visualizations and figures (e.g., PCA plots, performance charts) effectively support the explanations, making the results easy to interpret. The step-by-step presentation of the methodology and the logical flow between sections ensure that readers can follow the paper without confusion."
            },
            "weaknesses": {
                "value": "One of the main weaknesses of the paper is the absence of a thorough analysis of the computational cost associated with TidalFlow. Given the integration of both temporal and frequency domains, and the reliance on a dual-stream encoder and hierarchical embedding table (HET), there could be increased computational demands, especially when dealing with large-scale datasets or longer time series. For instance, it is not clear how the method scales when the number of categories \\(H\\) or the dimensionality of embeddings \\(\\Psi\\) grows. The authors should consider providing a detailed assessment of time and memory usage, especially when comparing TidalFlow against other baseline methods. This will help practitioners understand the potential trade-offs between performance and computational requirements.\n\nWhile the paper discusses the impact of different learning rates for temporal and frequency blocks, it does not comprehensively explore other hyperparameters. Key aspects such as the size of the embedding table, the number of nearest neighbors used in the voting mechanism, and the values of \\(\\alpha\\) and \\(\\beta\\) weights in the loss functions could significantly affect performance. Providing a more extensive sensitivity analysis on these hyperparameters would make it easier to understand the robustness of the model and help users in real-world applications to fine-tune the model effectively.\n\nThe effectiveness of certain components, such as the voting mechanism and the use of dissimilarity loss \\(L_D\\), is shown through experimental results, but there is limited explanation regarding why these components lead to performance improvements. For example, the voting mechanism is found to enhance classification performance, but the underlying reasons for its robustness are not thoroughly discussed. Similarly, it is unclear why the absence of the frequency block and \\(L_D\\) leads to such a significant drop in performance (as seen in the ablation study). Providing more theoretical insights or empirical explanations for these effects would strengthen the overall contribution of the paper and make the proposed model's design more justifiable.\n\nBy addressing these points, the paper can offer a more robust and practical understanding of TidalFlow, making it more appealing to both researchers and practitioners."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}