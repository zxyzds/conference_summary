{
    "id": "tqYx8DgL0u",
    "title": "Privacy-Preserving Federated Learning via Homomorphic Adversarial Networks",
    "abstract": "Privacy-preserving federated learning (PPFL) aims to train a global model for multiple clients while maintaining their data privacy. However, current PPFL protocols exhibit one or more of the following insufficiencies: considerable degradation in accuracy, the requirement for sharing keys, and cooperation during the key generation or decryption processes. As a mitigation, we develop the first protocol that utilizes neural networks to preserve privacy in federated learning, as well as incorporating an Aggregatable Hybrid Encryption scheme tailored to the needs of the PPFL. We name these networks as Homomorphic Adversarial Networks (HANs) which demonstrate that neural networks are capable of performing tasks similar to multi-key homomorphic encryption (MK-HE) while solving the problems of key distribution and collaborative decryption. Our experiments show that HANs are robust against privacy attacks. Compared with non-private federated learning, experiments conducted on multiple datasets demonstrate that HANs exhibit a negligible accuracy loss (at most 1.35\\%). Compared to traditional MK-HE schemes, HANs increase encryption aggregation speed by 6,075 times while incurring a 29.2-fold increase in communication overhead.",
    "keywords": [
        "Federated Learning",
        "Privacy Protection",
        "Homomorphic Encryption",
        "Homomorphic Adversarial Networks"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "Homomorphic Adversarial Networks, a neural network approach for privacy-preserving federated learning, emulate multi-key homomorphic encryption without key distribution or collaborative decryption, significantly enhancing efficiency.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=tqYx8DgL0u",
    "pdf_link": "https://openreview.net/pdf?id=tqYx8DgL0u",
    "comments": [
        {
            "summary": {
                "value": "The paper claims that it presents a novel privacy-preserving federated learning (PPFL) protocol that utilizes neural networks, specifically Homomorphic Adversarial Networks (HANs), to enhance data privacy without significantly sacrificing accuracy. It addresses key limitations of existing PPFL methods, such as accuracy degradation and key management issues, by introducing an Aggregatable Hybrid Encryption (AHE) scheme. This approach enables individual clients to maintain privacy while allowing efficient encryption and aggregation of model updates."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The article provides a wealth of formal definitions.\n\n2. A novel concept has been proposed."
            },
            "weaknesses": {
                "value": "1. It is difficult to quickly determine the details of the design AHE scheme, as the related definitions and statements are overly redundant.\n\n2. The experimental analysis provided seems insufficient."
            },
            "questions": {
                "value": "1. Why did the authors choose simple models to validate the security of the proposed scheme? What I mean is whether sufficient security can be demonstrated under these complex models.\n\n2. The security assessment lacks a systematic approach. Could you provide a more formal and systematic security analysis?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors develop the first protocol that utilizes neural networks to implement PPFL, as well as incorporating an Aggregatable Hybrid Encryption scheme tailored to the needs of PPFL."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Using neural network methods to implement MK-HE is a very interesting direction. The use of hybrid encryption can fully leverage the advantages of both symmetric and asymmetric encryption."
            },
            "weaknesses": {
                "value": "1. There is a lack of understanding of related work. Methods based on secret sharing inherently have strong resistance to collusion attacks, as demonstrated in works such as (Bell J, Gasc\u00f3n A, Lepoint T, et al. {ACORN}: input validation for secure aggregation[C]//32nd USENIX Security Symposium (USENIX Security 23). 2023: 4805-4822. Bonawitz K, Ivanov V, Kreuter B, et al. Practical secure aggregation for privacy-preserving machine learning[C]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 2017: 1175-1191.). However, the authors did not mention or compare these in the paper.\n2. According to the experimental results, although HANs are more computationally efficient than SecFed, the communication overhead increases by dozens of times, as shown by the experimental results in Table 6. This is unacceptable for a large number of users and would limit the practical application of HANs."
            },
            "questions": {
                "value": "1. How does the performance compare with other schemes that can also resist collusion attacks, such as (Bell J, Gasc\u00f3n A, Lepoint T, et al. {ACORN}: input validation for secure aggregation[C]//32nd USENIX Security Symposium (USENIX Security 23). 2023: 4805-4822. Bonawitz K, Ivanov V, Kreuter B, et al. Practical secure aggregation for privacy-preserving machine learning[C]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 2017: 1175-1191.)?\n2. The additional communication makes the proposed HANs unsuitable for most federated learning scenarios. Is there a way to reduce communication, or is the additional communication unavoidable?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a novel privacy-preserving federated learning method that attempts to integrate multi-key homomorphic encryption with neural networks. Each client generates a public key and two private keys using KeyGen with a security parameter $\\kappa$. During the encryption phase, plaintext and private keys are input into the encryption model held by each client for encryption. In the aggregation phase, the ciphertexts and public keys are input into the decryption model held by the aggregator for decryption. The training process employs adversarial training, aiming to maximize the error in attacker's data reconstruction while minimizing the loss after data aggregation. The authors define two attack models: Pseudo N-1 Collusion Attack based on the Original Model (PCAOM) and Pseudo N-1 Collusion Attack based on the Public Dataset (PCAPD), achieving privacy-protected federated learning under these attacks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- **Originality**: The paper introduces an innovative privacy-preserving federated learning method that combines homomorphic encryption with neural networks, enhancing the security and usability of the model.\n- **Effectiveness**: The research demonstrates the effectiveness of enhancing data privacy through adversarial training, increasing the model's robustness against complex attack scenarios.\n- **Clarity**: The article provides a detailed description of the transformation from the original model to a private model and demonstrates how to defend against two specific attacks.\n- **Practicality**: Compared to traditional encryption and decryption methods, the neural network's black-box nature increases the difficulty of attacks. The authors also claim that this method eliminates collaborative decryption, key sharing, and collective key generation among clients, optimizing processing time."
            },
            "weaknesses": {
                "value": "- **Accuracy**: Since the model is involved in the encryption and decryption process, it cannot guarantee that the parameters obtained by the decryptor are completely correct, only ensuring accuracy within a certain error rate, which is inconsistent with traditional homomorphic encryption standards.\n- **Insufficient Proof**: Despite the model's difficulty to be breached due to its black-box nature, there is a lack of rigorous formal proof to support its security claims.\n- **Incomplete Documentation**: The paper does not detail the specific implementation of KeyGen, how to ensure Perfect Key Uniformity, or how to resist chosen-plaintext attacks, limiting the method's verifiability and reliability."
            },
            "questions": {
                "value": "- The paper does not detail how KeyGen operates, whether it is generated by a model or some algorithm, thus we cannot verify how it eliminates key sharing. It is also unclear how Perfect Key Uniformity is ensured, thus it is uncertain how the method resists chosen-plaintext attacks.\n- The paper does not provide specific model structures or other information, making it impossible to verify and replicate the authors' experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the challenges of key sharing and collaboration in Privacy-Preserving Federated Learning (PPFL) protocols, which may lead to privacy risks and inconvenience. The authors propose a PPFL protocol implemented using neural networks, combined with an aggregatable hybrid encryption scheme. By accepting some trade-offs in communication overhead and accuracy, this approach significantly enhances the encryption aggregation speed."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The proposed method in this paper significantly enhances encryption aggregation speed, which is often a key factor influencing the overall efficiency of federated learning (FL) systems. The approach of using neural networks as a substitute for the MK-HE algorithm introduces a novel perspective with meaningful research value. Additionally, this method is robust against various forms of collusion, ensuring the privacy of both the model and users."
            },
            "weaknesses": {
                "value": "The paper contains a typographical error in the abstract\u2019s first word, which reads \u201cPrivacy-peserving\u201d instead of \u201cPrivacy-preserving\u201d.\n\nIn the Introduction, the main technique of the paper (using neural networks to simulate MK-HE) is not clearly stated, instead appearing in the contributions section, which makes the structure feel somewhat unbalanced. Additionally, the flow of the introduction could be improved for better clarity. It is recommended to briefly introduce the neural network simulation technique within the Introduction to set up the main idea clearly, while streamlining the first part of the contributions section. Structuring the Introduction by first presenting the problem context, followed by current challenges, and then the proposed solution would improve readability. Limiting the number of paragraphs and avoiding interleaved content would also enhance the flow.\n\nThe Method section lacks organization and could benefit from a more structured presentation. The neural network application, which is central to the proposed approach, is not discussed in the main paragraphs, resulting in a structural imbalance. Important content should be integrated into the main body rather than relegated to the appendix to improve the paper\u2019s clarity and readability. It is recommended to provide a more detailed description of the content from Appendix B and Appendix E in Section 3.6. If space constraints are a concern, consider simplifying the key concepts in Section 3.1 to make room for these additions.\n\nLastly, some equations in the Appendix B extend beyond the page boundaries. Attention to formatting standards would enhance the overall presentation."
            },
            "questions": {
                "value": "Proofreading for Spelling and Formatting: Could the authors carefully review the paper for any spelling and formatting errors to ensure accuracy and readability throughout?\n\nClarity of Introduction and Main Contributions: In the Introduction, could the authors clarify the primary method of their approach, particularly the use of neural networks as a substitute for MK-HE, rather than emphasizing this only in the contributions section? This adjustment may help readers understand the significance of the method from the outset.\n\nOrganization of the Method Section: The main outline of the proposed method is somewhat difficult to follow, and it is challenging to locate the main content regarding the neural network application. Could the authors consider reorganizing this section to more clearly outline the process and central elements? Moving the key explanations from the appendix to the main text may also improve clarity."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel approach to Privacy-Preserving Federated Learning (PPFL) by introducing Homomorphic Adversarial Networks (HANs). HANs utilize neural networks to emulate multi-key homomorphic encryption (MK-HE), addressing key distribution and collaborative decryption challenges. The proposed Aggregatable Hybrid Encryption (AHE) scheme is designed to balance computational efficiency, cryptographic security, and the distributed nature of FL systems. The paper claims that HANs exhibit robustness against privacy attacks with negligible accuracy loss and significantly improved encryption aggregation speed compared to traditional MK-HE schemes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Originality: The paper introduces Homomorphic Adversarial Networks (HANs), an innovative approach using neural networks for multi-key homomorphic encryption in federated learning, offering a new perspective on privacy preservation.\n2. Quality: This study is of fair quality. It achieved a notable 6,075-fold acceleration in encryption aggregation with minimal loss in accuracy, showcasing the practicality and robustness of HANs against a variety of attacks.\n3. Clarity: The paper is clearly written, with a well-structured presentation that effectively communicates the novelty of HANs and their advantages over existing methods.\n4. Significance: The work is significant for advancing privacy in federated learning, particularly in resisting collusion attacks and maintaining model accuracy."
            },
            "weaknesses": {
                "value": "1. The security of HANs is predicated on the presence of at least two honest clients, which may not always be feasible. The paper could be improved by discussing alternative security models that do not rely on this assumption or by exploring the implications of a higher number of malicious clients.\n2. While the paper provides a general discussion on the security aspects of Homomorphic Adversarial Networks (HANs), the analysis lacks the rigor and formality expected in a comprehensive security evaluation. \n3. The paper's comparison with traditional MK-HE schemes is compelling, but a more comprehensive benchmark against a broader range of state-of-the-art PPFL methods would strengthen the paper's claims. \n4. The experiments only focus on a few datasets and models. To strengthen the paper's arguments, the authors should consider demonstrating the versatility of HANs across a broader range of datasets (e.g., text datasets) and various model architectures.\n5. The paper mentioned the increase in communication overhead by HANs, but it indeed provided a detailed analysis, including performance under various network conditions.\n6. The paper does not demonstrate the adaptability and effectiveness of the AHE method in various federated learning scenarios, especially in environments with significant variations in data sensitivity and attack surfaces, which limits a comprehensive understanding of the performance and security of the AHE scheme in practical applications."
            },
            "questions": {
                "value": "1. The security of HANs relies on the presence of at least two honest clients. Can the authors discuss alternative security models that do not depend on this assumption, or explore the impact on HANs' security when the number of malicious clients increases?\n2. The authors should provide more rigorous security proofs or mathematical models to support the security claims made in the paper.\n3. Regarding the comparison with traditional MK-HE schemes, the authors should expand the comparison to include a broader range of PPFL methods.\n4. To strengthen the arguments in the paper, the authors should consider demonstrating the diversity and applicability of HANs across a wider range of datasets and various model architectures.\n5. Regarding the communication overhead issue of HANs, the authors can further discuss the impact of this increased communication overhead on practical deployment and consider whether it is possible to reduce these costs through optimization.\n6. Regarding the adaptability and effectiveness of AHE, the authors can provide more experimental data or theoretical analysis on the performance and adaptability of AHE in different scenarios."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes an empirical solution leveraging GAN to address the privacy challenge during federated model aggregation."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper focuses on one of the important privacy issues in federated learning. Aggregation data privacy has been a constant challenge, especially considering the tradeoffs among privacy, overhead, and performance.\n\n2. The paper proposes an empirical solution using GAN for privacy protection."
            },
            "weaknesses": {
                "value": "1. The paper misses a major related domain, which is threshold HE. Compared to MK-HE, threshold HE (1) in general does not incur additional overheads both in computation and ciphertext; (2) does not suffer from client dropout issues, which is a common challenge in practical FL systems.\n\n2. There is no formal rigorous security proof, as the authors stated themselves in the paper. The informal discussion in Appendix G does not satisfy the requirement needed for the claimed privacy guarantee, I would like to see security proofs under, for example, UC-Security, but it seems like GAN-based solutions would fail to be assessed this way. Regarding the collusion models, the paper introduces pseudo N\u22121 collusion attacks, but it does not fully address the potential vulnerabilities in scenarios with more sophisticated collusion strategies or when attackers can coordinate over time. Additionally, per my understanding of the paper, the assumed security is bounded and realized by obfuscating the training of the GAN, what if the adversary can train a similar GAN? This approach largely relies on security through obscurity, which is generally regarded as an unreliable security approach. The privacy guarantee of this paper is far from being convincing and considered as a serious privacy/security work.\n\n\n3. Even if the idea of using a GAN-like solution worked to satisfy the privacy guarantee, there would be limited novelty compared to the previous NN-based encryption systems referred in the related work, other than applying it in the federated learning setup.\n\n4. In a lot of FL systems in practice, the communication limitation is more of a bottleneck compared to the aggregation computation overhead which is relatively easier to solve by scaling up the server. This communication overhead for the computation improvement approach might not solve the more practical challenges. \n\n5. It is hard to follow the paper, especially given the confusing structures of Section 1 and Section 3. In Section 1, it is unclear what the major research challenge this paper tries to tackle regarding MK-HE and the research contribution of this paper following that. In Section 3, the threat model could have been precisely captured and a structured description of the proposed method is missing. The majority of the technical details of the proposed HAN are in Appendix (e.g. PPU in Appendix E) while the main paper contains little information on how and why HAN would work in terms of performance and privacy."
            },
            "questions": {
                "value": "1. Are all experiments a simulation of FL running on a single machine?\n2. Why not consider more recent stronger attacks than DLG? \n3. Did the authors perform analysis on the proposed method when applied to LLMs?\n4. What does \"Primarily, they focus on symmetric encryption without addressing homomorphic computation.\" mean? Symmetric encryption and homomorphic encryption are not two mutually exclusive concepts.\n5. Could you provide a more formal definition of AHE that complies with the standard security definition? Also, why does the $m_{agg}$ step only consider 3 ciphertexts?\n6. The paper mentioned that CKKS-based implementation would have a huge accuracy drop. Could you show the experimental results supporting this claim? In the FL setting, CKKS's approximation error will generally not significantly impact the performance due to the relatively simple aggregation operations, compared to a full-on end-to-end encrypted NN.\n7. Some of the experiments do not have error bars, for example, Table 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}