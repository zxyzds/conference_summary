{
    "id": "o9SuQXZvNA",
    "title": "ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?",
    "abstract": "Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. An emerging question is Can LLMs beat traditional ML models in clinical prediction? Thus, we build a new benchmark ClinicalBench to comprehensively study the clinical predictive modeling capacities of both general-purpose and medical LLMs, and compare them with traditional ML models. ClinicalBench embraces three common clinical prediction tasks, two databases, 14 general-purpose LLMs, 8 medical LLMs, and 11 traditional ML models. Through extensive empirical investigation, we discover that both general-purpose and medical LLMs, even with different model scales, diverse prompting or fine-tuning strategies, still cannot beat traditional ML models in clinical prediction yet,  shedding light on their surprising but critical deficiency in clinical reasoning. We call for caution when practitioners adopt LLMs in clinical applications. ClinicalBench can be utilized to bridge the gap between LLMs' development for healthcare and real-world clinical practice. Code is here.",
    "keywords": [
        "LLMs",
        "Clinical Prediction",
        "Benchmark"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "Through ClinicalBench, we discover that general-purpose and medical LLMs, with different scales, prompting or fine-tuning strategies, still cannot beat traditional ML models in clinical prediction yet, showing their deficiency in clinical reasoning.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=o9SuQXZvNA",
    "pdf_link": "https://openreview.net/pdf?id=o9SuQXZvNA",
    "comments": [
        {
            "summary": {
                "value": "This paper presents ClinicalBench, comparing traditional ML models with LLMs on clinical prediction tasks. While the experimental setup is thorough, I have significant concerns about the scientific value and broader impact of this work given the dramatic performance gap demonstrated between LLMs and traditional ML models.\n\nThe results show that even state-of-the-art LLMs perform substantially worse than basic ML models like XGBoost and SVMs across all tasks. For example, traditional ML models achieve Macro F1 scores of 65-70% on Length-of-Stay prediction while LLMs struggle to exceed 30%. Similar large gaps exist for mortality and readmission prediction. Even with extensive prompt engineering and fine-tuning, LLMs fail to approach traditional ML performance.\n\nGiven these results, it's unclear what meaningful insights this work provides beyond demonstrating that LLMs are currently inappropriate for clinical prediction tasks. The paper essentially confirms what one might expect - that specialized ML models trained directly on structured clinical data outperform general language models on specific prediction tasks. While the thorough empirical validation may have some value, the magnitude of the performance gap suggests this comparison may be unnecessary."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Thorough experiments"
            },
            "weaknesses": {
                "value": "The finding is obvious and negative. Unclear the value to the ML community."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper explores the capabilities of large language models (both general-purpose and medical-oriented models) in clinical prediction tasks (including length-of-stay, mortality, and readmission), comparing them with conventional machine learning-based models. The paper reveals that LLMs still cannot outperform traditional ML models in various settings (parameter size, different LLMs, prompting/finetuning strategies, etc.). The dataset employed in this research consists of code-based data extracted from MIMIC-III and MIMIC-IV. To better understand the code semantics, the authors convert codes to text."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper is well-presented and organized with clear motivation and writing flow. The paper addresses a key problem in the era of LLMs, where plenty of researchers are exploring the boundary capability of LLMs."
            },
            "weaknesses": {
                "value": "My main concern is the paper's novelty and contribution. There are already many works that explore LLMs' capabilities on diverse tasks, including those in the medical field. The findings are straightforward and predictable: machine learning models trained on specific medical tasks naturally surpass LLMs' zero-shot performance, and in real-world clinical practice, the simplest models (e.g., logistic regression, LASSO) are still widely used for their simplicity and interpretability. With the development of more advanced LLMs, the findings may change, as they only reflect current guidelines and cannot predict the future practical use of LLMs. The employed LLMs are mainly small in size; larger models of 70B parameters and beyond should be explored. These larger language models have much better prompt-following capabilities, so CoT and ICL approaches may work, rather than simply concluding that \"The effectiveness of typical prompting engineering techniques is generally limited.\" Additionally, no variance is reported in the benchmarking table, although LLMs' outputs can be sensitive to input prompts, temperature settings, and the sequence of input instructions."
            },
            "questions": {
                "value": "See weaknesses section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            }
        },
        {
            "summary": {
                "value": "This paper introduces ClinicalBench, a benchmark designed to evaluate the performance of 14 general-purpose LLMs, 8 medical LLMs, and 11 traditional ML models (e.g., XGBoost, Logistic Regression, RNN etc.) on three clinical classification tasks: Length-of-Stay Prediction (three-class classification), Mortality Prediction (binary classification), and Readmission Prediction (binary classification). On both the MIMIC-III and MIMIC-IV datasets, this paper shows that most LLMs currently still fall short in making accurate predictions for these real-world clinical tasks, underperforming by an obvious margin compared to traditional ML models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper is clearly written and easy to follow, and the figures are informative.\n2. This paper offers a head-to-head comparison between LLMs and traditional ML methods on three real-world clinical tasks, helping to clarify the current capabilities of LLMs in this domain. The three ways of enabling LLMs to make predictions utilized in this paper - direct prompting, engineered prompting (e.g. Chain-of-Thought, Self-Reflection, Role-Playing, In-Context Learning), and supervised fine-tuning using task-specific data - reflects the primary approaches for applying LLMs nowadays, making its insights broadly applicable and valuable for future research.\n3. The evaluation is quite thorough, and the findings offer interesting insights for this domain."
            },
            "weaknesses": {
                "value": "1. While named as a benchmark, this paper did not introduce or curate new datasets, or introduce novel ways of processing or derive new clinical tasks from the MIMIC-III and MIMIC-IV datasets. The main contribution is in developing the framework of comparing LLMs with traditional ML methods on standard clinical tasks in MIMIC-III and MIMIC-IV. Thus I would argue that the contribution may be slightly less significant compared to benchmarks which both introduce new clinical tasks closer to real-world clinical reasoning / decision-making and also develops the LLM evaluation framework.\n2. For Section 5 fine-tuning, the details about how the LLMs are fine-tuned are unclear in the main paper - is it by adding a classification head to the output of the transformer, or by next-token prediction on target outputs (from Appendix C it seems to be the latter)? I think adding this detail to Section 5 would help the readers understand how SFT was conducted and better understand the performance discrepancy compared to traditional ML methods.\n3. For In-context Learning, it seems that 3 examples are provided to the LLMs per the prompt example in Appendix D. Are these examples chosen randomly or selected to be representative of the patient population? I think it might be helpful to also analyze how the number of in-context examples and how the diversity of the in-context examples (e.g. different disease type, different age groups etc.) impact the LLM performance, as sometimes LLMs can be quite sensitive to that.\n4. The impact of parameter scaling is studied for direct prompting but not for engineered prompting, i.e., only 7B, 8B and 9B models are studied for engineered prompting but not 34B or 70B. I would assume that large models have better instruction following capabilities and thus may be better at reasoning or role play than smaller models, and would like to know your insights on this and why larger models are not used for engineered prompting."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper compares the performances of multiple LLM and traditional ML models on three clinical tasks (length of stay, mortality, readmission) on MIMIC III and IV. This paper contributes key conclusions on the underperformance of LLMs compared to traditional ML models. Furthermore, the authors demonstrate that specialised models do not always perform better and that advanced prompting strategies also do not help. Only fine-tuning strategies significantly improve the LLM performance on these tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "The paper explores the use of LLM in medical tasks clearly and thoroughly."
            },
            "weaknesses": {
                "value": "- The paper could discuss more in depth the different works that have aimed to use LLM for prediction and how the proposed paper differs.\n- One limitation could be the reliance on MIMIC used to train some of these models. However, the current underperformance of LLMs only further emphasises the limitations of these strategies, which may benefit from data leakage."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}