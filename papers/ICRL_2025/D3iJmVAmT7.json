{
    "id": "D3iJmVAmT7",
    "title": "Explain Like I'm Five: Using LLMs to Improve PDE Surrogate Models with Text",
    "abstract": "Solving Partial Differential Equations (PDEs) is ubiquitous in science and engineering. Computational complexity and difficulty in writing numerical solvers has motivated the development of machine learning techniques to generate solutions quickly. Many existing methods are purely data driven, relying solely on numerical solution fields, rather than known system information such as boundary conditions and governing equations. However, the recent rise in popularity of Large Language Models (LLMs) has enabled easy integration of text in multimodal machine learning models. In this work, we use pretrained LLMs to integrate various amounts known system information into PDE learning. Our multimodal approach significantly outperforms our baseline model, FactFormer, in both next-step prediction and autoregressive rollout performance on the 2D Heat, Burgers, Navier-Stokes, and Shallow Water equations. Further analysis shows that pretrained LLMs provide highly structured latent space that is consistent with the amount of system information provided through text.",
    "keywords": [
        "Multimodal",
        "Partial Differential Equation",
        "Neural Operator"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "Large language models can use text descriptions of systems to improve PDE surrogate models",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=D3iJmVAmT7",
    "pdf_link": "https://openreview.net/pdf?id=D3iJmVAmT7",
    "comments": [
        {
            "summary": {
                "value": "Solving PDEs is crucial in science and engineering, yet high computational demands have driven the adoption of machine learning for faster solutions. Traditional methods lack system-specific information, but recent LLMs allow text-based data integration. This study uses pretrained LLMs to embed system information into PDE learning, outperforming the FactFormer baseline in predictive tasks across multiple equations. Analysis shows that pretrained LLMs create structured latent spaces aligned with system data."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Completed work: The article is well-written, with clear explanations that make the complex material accessible. The charts and visuals used effectively enhance the presentation, making the findings easy to follow and engaging.\n\nWell-organized structure: The paper is structured thoughtfully, particularly in the methodology section. The clear separation of system descriptions and model details adds clarity, as does the organization of the experimental setup, which is presented in four different experiment setting clearly.\n\nSufficient experiments: The experiments are extensive and thorough, as sufficient support for the method."
            },
            "weaknesses": {
                "value": "Data generation graph: It would be helpful to clarify why the data generation section appears so early in the paper. Explaining the rationale behind its positioning could improve readability and guide the reader through the study\u2019s flow.\n\nMathematical Support: The paper only illustrates the method part in section 4.2 which makes it hard for me to understand the whole theory behind the proposed method. More detailed mathematical backing could provide readers with a deeper understanding of the methods and strengthen the study\u2019s credibility.\n\nNotation formatting: There are some inconsistencies and minor errors in notation and formatting that could be polished. For example, \n\n(1) In line 184, the notation $256x256$ is represented as character \"$x$\" which looks not professional. Instead, it should be $256\\times256$. \n\n(2) The text descriptions in Section 4.1 are middle, where I think left-aligned might enhance readability. \n\n(3) In line 250 has a typo where \u201cleaning\u201d should be \u201clearning.\u201d\n\nExperiment Labeling: In the experiment section, it would be clearer if your method were explicitly labeled with \"Ours\", making it easier for readers to identify and interpret the results related to your approach."
            },
            "questions": {
                "value": "In line 52, the author claims that \u201cwe aim to more fully utilize LLM understanding in PDE surrogate modeling and incorporate text information into neural operators.\u201d suggests a comprehensive integration of LLM capabilities in PDE modeling. However, based on my understanding, the role of the LLM is limited to converting text descriptions into embeddings. How this step \"fully utilized LLM\"? I may ask for more illustrations about that.\n\nIn section 4, The paper gives an example of \"full sentence descriptions of systems\" for Burger's equation,  then what about not \"full description\u201d within this context? How would the model handle cases where only partial or incomplete information is available for an equation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This submission follows the line of work on neural-network-based surrogate models. The proposal is a technique for enhancing neural PDE solvers with large language models, called a \"multimodal surrogate model\".\nConcretely, the algorithm goes as follows: the LLM is prompted with a textual description of the PDE and generates embeddings. These embeddings are combined with the data (via cross-attention) and a FactFormer architecture.\n\nThe driving question for assessing this new method is now whether or not the LLM-generated embeddings improve the reconstruction, compared to (i) a \"raw\" FactFormer and (ii) existing methods for combining LLMs and neural PDE solvers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The submission's biggest strength is that the LLM embeddings consistently improve the reconstruction compared to the FactFormer without LLM augmentation. For example, Figure 3 and Table 1 demonstrate how the LLM-generated embeddings improve the reconstruction error for both next-step prediction and autoregressive rollout compared to the FactFormer.\nIn other words, point (i) from my summary above is answered with a strong \"yes\".\n\nHowever, the answer to point (ii) is less clear. I discuss this under \"Weaknesses\" below."
            },
            "weaknesses": {
                "value": "The submission's strength is that the algorithm improves the reconstruction compared to a FactFormer. However, I consider the following weakness to be significant enough so that I recommend rejection:\n\nEven though the idea of combining LLMs with PDE solvers has not been explored much in the literature, it is not new; for example, Shen et al. (2024) proposed something similar to the submitted manuscript.\nI find that the main weakness of the submission is that it does not compare thoroughly to Shen et al.'s (2024) work on \"Universal Physics Solver\" (UPS). \nThe only mention of UPS is in Line 044 on page 1; however, I believe that a thorough discussion in Section 2 and direct comparisons in all experiments is essential to assessing the performance of the suggested algorithm.\nOther related works are also not discussed prominently enough, like Zhou et al.'s (2024) Unisolver, but the lack of discussion of UPS stood out the most.\nSimilarly, the context of other state-of-the-art surrogate models, e.g., the Fourier Neural Operator, would be helpful for the experiments but is omitted in the submission. \n\nIn other words, the comparison to the FactFormer is relevant, but more baselines are needed. Concretely, I would like to see methods similar to those reported by Takamoto et al. (2023b) or Shen et al. (2024). Without benchmarks involving those algorithms, I cannot recommend acceptance. \n\nTo change my mind, I would have to be convinced that I misunderstood something in that UPS or Unisolver did something fundamentally different to the submission and that neural operators and other neural-network-based surrogate models are not meaningful comparisons. Another way to change my assessment would be to run these benchmarks with a competitive performance of the submitted algorithm. I suspect that re-running the benchmarks thoroughly using all these new baselines is too much work for a revision period. However, I am looking forward to possibly being proven wrong."
            },
            "questions": {
                "value": "Sometimes, I find the presentation a bit difficult to follow. For example, Section 4.2 is difficult to contextualise to prior work: how much of Section 4.2 is the FactFormer, and how much is new? The section might be easier to read if it came with a figure or an algorithm box. However, since this stylistic point is subjective (and would be relatively easy to fix if the authors agree with me), it is less relevant to my acceptance/rejection decision than the weakness outlined above.\n\nIf time and rebuttal space allow, I would also like to see the answers to the following questions.\nThey are less critical for my recommendation than everything written above, but I think their answers might improve the paper's clarity. \n\n- Why are there no whitespaces before all \\citep's? E.g. Lines 041f\n- Figure 1: Is it on purpose that data input and data output are identical?\n- Line 074: To me, it is not apparent whether more instances of PDE problems make the dataset harder or easier. What is the motivation for this statement?\n- Figure 3: What does the figure look like with a logarithmic y-axis?\n- Line 307: Are three random seeds sufficient? There seems to be significant variation in Figure 3.\n- Line 304: Is the autoregressive rollout error MSE normalised in any way? The accumulated RMSEs are surprisingly large. Related:\n- Table 1: Why is the 10^2 removed from the table values? It simply shifts the comma by two digits, and it seems that no digits are saved. \n- Table 1 (again): Since the MSEs are so large, can we say anything's been learned reliably? It would be interesting to see plots of the predicted PDE solutions (for a test data point, for example, using all involved methods).\n- Line 345: Where do these percentages come from? I might be missing something obvious, but I struggle to link them to the values in Tabe 1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces a multimodal framework for solving partial differential equations by embedding numerical data with FactFormer and encoding textual information (such as governing equations, boundary conditions, or coefficient information) through a pre-trained language model. The framework employs a cross-attention module to fuse embeddings from both modalities, facilitating the integration of system information into the numerical surrogate model. The authors provide several numerical experiments to validate the performance of the proposed method."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper tackles the integration of textual and numerical data within PDE surrogate models. By using a cross-attention module to combine FactFormer\u2019s numerical embeddings with language model embeddings of system information, the framework provides a structured approach to incorporate diverse sources of information. The experiments demonstrate improvements in next-step prediction and autoregressive rollout tasks, showing the potential of multimodal frameworks for PDE applications."
            },
            "weaknesses": {
                "value": "1. The approach does not compare with existing state-of-the-art methods for solving PDEs, such as the Fourier Neural Operator and DeepONet. Additionally, numerous transformer-based methods have been developed for PDEs, but these are not referenced or compared here.\n2. Multimodal models for solving PDEs already exist. For instance, the Unified PDE Solver (https://arxiv.org/abs/2403.07187) leverages both numerical and textual embeddings to solve PDEs. The lack of a direct comparison with existing models makes it challenging to assess the effectiveness of the proposed method over prior multimodal approaches.\n3. The testing data includes only five relatively simple PDEs, which restricts the evaluation of the model\u2019s capabilities. The paper would benefit from testing on more complex PDE data, such as those in the PDEBench, PDEArena, or CFDBench datasets, to better validate its performance and generalizability.\n4. There are other multimodal approaches (numerical and textual data) that solve differential equations, such as FMint (https://arxiv.org/abs/2404.14688) and PROSE-FD (https://www.arxiv.org/abs/2409.09811). A discussion of such related work would enhance the impact of this paper\u2019s contributions."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes leveraging a large language model (LLM) to incorporate multimodal information in training a machine learning (ML) surrogate model for partial differential equations (PDEs). Unlike prior studies that provided only brief or limited text descriptions of the target system, the authors argue that a more comprehensive text description enhances model performance. Their claims are partially supported by experimental results on various 2D datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "S1: The paper attempts to include more detailed text descriptions of the target system compared to previous work, such as PDE parameters, PDE descriptions, and boundary conditions.\n\nS2: The effectiveness of the comprehensive text descriptions is at least partially validated by experimental results."
            },
            "weaknesses": {
                "value": "Major Concerns: The following issues should be addressed before acceptance:\n\nW1. $\\textbf{The parameter ranges used to generate data may not be adequately described for the chosen resolution.}$ The authors employ relatively small diffusion-type coefficients for the heat equation and Navier\u2013Stokes equation, even at a low resolution of 64x64. Generally, numerical viscosity is estimated using the system's Reynolds number, and the resolution should exceed the Reynolds number to accurately capture physical viscosity or diffusion coefficients. Based on this principle, the chosen viscosity and diffusion coefficients are too small for the current resolution, meaning the generated data may reflect numerical rather than physical viscosity. The authors should provide a convergence check results for all the generated data (or at least small dissipation coefficient regime) to ensure that the generated data are resolution-independent and properly reflect the used PDE parameters.\n\nW2. $\\textbf{The analysis of the impact of the text descriptions is insufficient.}$ According to Appendix A, only one type of sentence description was explored. This makes it difficult to assess the contribution of the text description, which is a key claim of the paper. A more systematic investigation of how the detailed system descriptions affect the model's performance is needed, such as testing different sentence formats, identifying important words, and exploring how shorter or longer descriptions influence outcomes.\n\nW3. $\\textbf{A more systematic ablation study is needed.}$ Related to W2, the ablation study (Section 5.4) lacks depth in analyzing sentence descriptions. While Table 2 offers interesting information (e.g., BCQ is ineffective in most cases), the authors provide only a brief discussion (one sentence). A more thorough analysis of this part would strengthen the paper's impact and rigor.\n\nMinor Concerns: The following are suggestions for improvement:\n\nW4. It would be beneficial to include another backbone model. Currently, only FactFormer is used, and it is unclear whether the results are specific to this architecture. Testing with different backbones would allow for a more general analysis.\n\nW5. FactFormer is not a conditional model and does not accept PDE parameters, which weakens the baseline comparison with the proposed model. A more convincing evaluation would include comparisons with recent models, such as UPS or a conditional model like the Neural PDE Solver (Brandstetter et al., 2022).\n\nW6. Internal author comments (e.g., at line 165 [height] and line 444 [analyze further?]) remain in the manuscript. These should be removed before submission.\n\nW7. In the introduction, the final sentence of the first paragraph lacks citation and the term \"optimally\" is unclear. Additionally, in the second paragraph, it is unclear if the phrase \"these models\" includes physics-informed neural networks (PINNs), which are not data-driven models. The authors should refine the English and provide appropriate citations."
            },
            "questions": {
                "value": "Q1. Figure 3: Why does BCQ information not work for the Navier\u2013Stokes case? Does performance change with different text descriptions? It is also unclear why the more challenging autoregressive case in Table 1 does not follow the trend seen in Figure 1 (BCQ improved performance in the Navier\u2013Stokes case in Table 1, which is difficult to reconcile with the present explanation).\n\nQ2. Figure 6: How do the authors conclude that the embedding of \"Equation + BCQ\" is superior to \"Equation\" alone based on this figure? The distribution of different equation embeddings appears uniform, which could confuse downstream task layers.\n\nQ3. Section 5: The definition of \"transfer learning\" is missing in the main body. It would be helpful to include a brief explanation of what was done for transfer learning in the main body.\n\nQ4. Page 3, line 159 (Sec 3.1): What is meant by \"2 seconds\"? Does this refer to physical time or computational time unit? If the former, why is 2 seconds considered a meaningful timescale?\n\nFor additional comments, please refer to the \"Weaknesses\" section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}