{
    "id": "CKXul9iX77",
    "title": "A Deep Generative Learning Approach for Two-stage Adaptive Robust Optimization",
    "abstract": "Two-stage adaptive robust optimization (ARO) is a powerful approach for planning under uncertainty, balancing first-stage decisions with recourse decisions made after uncertainty is realized. To account for uncertainty, modelers typically define a simple uncertainty set over which potential outcomes are considered. However, classical methods for defining these sets unintentionally capture a wide range of unrealistic outcomes, resulting in overly-conservative and costly planning in anticipation of unlikely contingencies. In this work, we introduce AGRO, a solution algorithm that performs adversarial generation for two-stage adaptive robust optimization using a variational autoencoder. AGRO generates high-dimensional contingencies that are simultaneously adversarial and realistic, improving the robustness of first-stage decisions at a lower planning cost than standard methods. To ensure generated contingencies lie in high-density regions of the uncertainty distribution, AGRO defines a tight uncertainty set as the image of ``latent'' uncertainty sets under the VAE decoding transformation. Projected gradient ascent is then used to maximize recourse costs over the latent uncertainty sets by leveraging differentiable optimization methods. We demonstrate the cost-efficiency of AGRO by applying it to both a synthetic production-distribution problem and a real-world power system expansion setting. We show that AGRO outperforms the standard column-and-constraint algorithm by up to 1.8% in production-distribution planning and up to 11.6% in power system expansion.",
    "keywords": [
        "robust optimization",
        "stochastic optimization",
        "discrete optimization",
        "deep learning",
        "unsupervised learning"
    ],
    "primary_area": "optimization",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CKXul9iX77",
    "pdf_link": "https://openreview.net/pdf?id=CKXul9iX77",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces AGRO, a novel method for two-stage adaptive robust optimization (ARO) using a variational autoencoder (VAE) to generate adversarial and realistic uncertainty sets. The authors demonstrate that AGRO reduces planning costs in ARO tasks, outperforming classical approaches."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed AGRO framework is innovative, embedding a VAE within a column-and-constraint generation (CCG) scheme to achieve high-dimensional adversarial generation with cost efficiency.\n2. It seems that the empirical results highlight an over 10% cost reductions over classical methods."
            },
            "weaknesses": {
                "value": "1.\tThe introduction lacks a comprehensive motivation for using a VAE for uncertainty sets over other generative models. The authors should justify why a VAE was chosen and discuss the potential advantages over alternatives, like GANs or normalizing flows, which may also be suitable.\n2.\tThe discussion on the choice of the VAE bottleneck dimension (parameter L) could be expanded. The authors should provide more insight into how different L values affect the uncertainty set\u2019s coverage and the balance between computational cost and model fidelity.\n3.\tWhile the experiments are detailed, there is no mention of computational time for VAE training or comparison with other ARO solutions. Including such results would enhance transparency about AGRO\u2019s feasibility in larger-scale applications.\n4.\tThe paper does not explore alternative formulations for the adversarial subproblem. A comparison with different optimization methods or a discussion on the limitations of projected gradient ascent could further clarify AGRO's robustness."
            },
            "questions": {
                "value": "1.\tWhy did you choose a VAE over other generative models (e.g., GANs, normalizing flows) for constructing uncertainty sets in AGRO? Would these models offer any advantages or limitations compared to VAEs in this application?\n2.\tHow does the bottleneck dimension (L) influence the overall performance and reliability of AGRO? Could you elaborate on any trade-offs between computational cost and uncertainty set coverage as L varies?\n3.\tThe paper discusses using VAE-based uncertainty sets to achieve tighter approximations. Could you clarify how you ensure these sets are both realistic and adversarial? Are there any specific quantitative or qualitative metrics that assess the accuracy of these generated uncertainty sets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel deep generative approach using Variational Autoencoders (VAE) to tackle two-stage adaptive robust optimization (ARO) under high-dimensional uncertainty. Traditional ARO approaches for constructing the uncertainty set $\\mathcal{U}$ tend to be overly conservative, often leading to excessive resource allocation in scenarios with high-dimensional and irregularly distributed uncertainties. The proposed AGRO method mitigates this issue by incorporating VAE embedding and column-and-constraint generation (CCG). The method also uses projected gradient ascent to solve the formulated subproblem. Experiments on two problems demonstrate the advantages of this method over conventional CCG approaches."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The primary contribution of this work is the innovative application of VAE to construct a tighter uncertainty set, thereby reducing over-conservatism in high-dimensional decision-making, which is then addressed through CCG. The paper is clearly presented, with informative visuals such as Figure 2, and well-organized notation and formulations. The experimental results highlight the promise of the proposed method."
            },
            "weaknesses": {
                "value": "The proposed approach involves training a VAE, whose performance might be sensitive to hyperparameters, computational resources, and the amount of available training data. Additional experiments and discussion could enhance the paper\u2019s applicability. Please see the following questions for further details."
            },
            "questions": {
                "value": "- In Figure 1, the authors use two 3D visualizations to illustrate the two-stage operations on $\\mathcal{U}$ and $\\mathcal{Z}$. Could the authors provide a brief description of the specific main problem addressed here to give the audience a better understanding?\n\n- In the experiment on the production-distribution problem, the authors observed a reverse effect of the bottleneck dimension in the low-dimensional case of $|\\mathcal{J}|=3$. Could the authors elaborate on possible reasons for this?\n\n- Based on the experiments, could the authors provide practical guidelines for selecting the appropriate bottleneck dimension for VAEs according to the dimensionality or complexity of the uncertainty set?\n\n- For tabular results such as those in Figure 3 (left) and Table 1, could the authors also report the standard deviation across trials? This would help readers understand the robustness of AGRO in different practical scenarios.\n\n- Could the authors provide more details on the VAE architecture and training settings used in each experiment? Such as layer dimensions, normalization, optimizer, and learning rate,  for better reproducibility."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper addresses the two-stage adaptive robust optimization (ARO) problem, where a key challenge is constructing an effective uncertainty set. The authors propose using a deep generative model to learn the uncertainty set, aiming to avoid overly conservative optimization. The method is evaluated on a synthetic production-distribution problem and a regional power system expansion problem."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written and clear.\n\n2. Leveraging deep generative models to learn the uncertainty set is a promising approach."
            },
            "weaknesses": {
                "value": "1. The Projected Gradient Ascent (PGA) method does not guarantee convergence to the worst-case uncertainty realization. Although the authors propose randomly initializing PGA with different samples of $z$ for empirical performance, providing some theoretical analysis on the approximation error would be beneficial.\n\n2. The performance improvement of the proposed method is minimal."
            },
            "questions": {
                "value": "1. The paper suggests that the framework is general and could also be applied to diffusion models. However, diffusion model training involves matching the score of the noised distribution, and samples cannot be easily obtained during training. Could you elaborate on how diffusion models would integrate with your proposed framework?\n\n2. How do you ensure the uncertainty set learned by the VAE is sufficiently tight? When optimizing over the latent space, are there any constraints? If not, is there a risk that the algorithm could select an overly conservative worst-case realization?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes the AGRO algorithm, which performs adversarial generation for two-stage adaptive robust optimization using a variational autoencoder. By decomposing the optimization problem to solving the 'main' problem and the adversarial subproblem iteratively, AGRO can provide tighter uncertainty estimation and lead to better optimization outputs."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well-written, easy to follow, and understand.\n\n2. With VAE-learned uncertainty, the proposed AGRO method does tighten the uncertainty bounds and leads to better optimization outcomes. An intuitive example in Figure 2 and experimental results clearly demonstrate this."
            },
            "weaknesses": {
                "value": "1. In Section 3.2, the author proposes a projected gradient ascent heuristic method to optimize $q$. Although this PGA method is well-explained in the article and I understand why the author uses it, I still expect an ablation study on directly optimizing $q$ to show if PGA could still guarantee some level of optimization quality and if there are any speed improvements.\n\n2. Although the proposed AGRO method is an improvement based on the CCG method, in the experiments section, the author should compare with more baselines for the two-step optimization problem, which I believe is a well-studied problem with many methods proposed to solve it."
            },
            "questions": {
                "value": "My main question for this work is: Is the optimization problem the author wants to solve exactly a linear optimization problem (see Eq. 1, 7, 9, 10)? If so, there are already many tools for solving linear optimization problems, so why is the proposed method better than those?\n\nIf not, what kind of optimization problem does AGRO solve? Only convex?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}