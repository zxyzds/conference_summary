{
    "id": "Pj2qEVzufH",
    "title": "Efficient Structure-Aware 3D Gaussians via Lightweight Information Shaping",
    "abstract": "3D Gaussians, \nas an explicit scene representation, \ntypically involve \nthousands to millions of elements per scene. \nThis makes it \nchallenging to control \nthe scene in ways \nthat reflect the underlying semantics, \nwhere the number of independent entities \nis typically much smaller. \nEspecially, \nif one wants to animate or edit objects in the scene, \nas this requires coordination among the many Gaussians\ninvolved in representing each object. \nTo address this issue, \nwe develop a mutual information shaping technique \nthat enforces resonance and coordination\nbetween correlated Gaussians \nvia a Gaussian attribute decoding network. \nSuch correlations can be learned \nfrom putative 2D object masks in different views. \nBy approximating the \nmutual information with \nthe gradients concerning the network parameters, \nour method ensures consistency \nbetween scene elements \nand enables efficient scene editing \nby operating on network parameters rather than massive Gaussians.\nIn particular, \nwe develop an effective contrastive learning pipeline\nwith lightweight optimization to shape the attribute decoding network,\nwhile ensuring that the shaping (consistency) is maintained during continuous edits, \navoiding re-shaping after parameter changes. \nNotably, \nour training only touches \na small fraction of all Gaussians in the scene \nyet attains the desired correlated behavior \naccording to the underlying scene structure. \nThe proposed technique \nis evaluated on challenging scenes and demonstrates significant performance improvements \nin 3D object segmentation and promoting scene interactions, \nwhile inducing \nlow computation and memory requirements. \nOur code and trained models \nwill be made available.",
    "keywords": [
        "Mutual Information Maximization; 3D Reconstruction; 3D Editing"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Pj2qEVzufH",
    "pdf_link": "https://openreview.net/pdf?id=Pj2qEVzufH",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a method for correlating Gaussians that belong to the same semantic group. It leverages a network to decode feature Gaussians into attributes and approximates mutual information via gradients with respect to network parameters. This approach enables editing operations through adjustments to the network parameters rather than direct manipulation of numerous Gaussians. The mutual information between Gaussians is approximated by shaping activations from perturbed network weights."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Previous approaches embed semantic features directly within each Gaussian primitive, requiring extensive manipulation of individual Gaussians to edit scenes. This paper instead proposes encoding mutual information within an attribute decoding network, allowing scene edits to be made by directly adjusting the network parameters."
            },
            "weaknesses": {
                "value": "The paper is generally challenging to follow, with many points lacking clear explanations. For example, Equation 7 and Line 304 state that \"we find that \u2202h corresponds to repeated activations \u03c3(h(l\u22121)).\" However, this lacks sufficient context, as does Line 317, which mentions that \"shaping activations \u2202h within the attribute decoding network \u03a6a supports a sequence of editing operations.\" Further explanation on why shaping these activations enables multiple edits would improve clarity.\n\nThe proposed method uses an MLP network to model mutual information between Gaussians, where the Gaussians primarily serve to splat features onto images used as inputs for the MLP. The primary contribution appears to be an enhancement to the JacobiNeRF framework, rather than a significant innovation in the context of 3D Gaussian Splatting (3DGS).\n\nThe contributions of Section 3.5 on coarse mask guidance and Section 3.6 on smoothness regularization seem minor, primarily focused on refining supervision masks. These sections could potentially be merged, as similar techniques have been explored in prior work.\n\nThe method depends on a 2D video mask tracker for grouping Gaussians. Based on the experimental results, it is difficult to determine if performance improvements arise from the mask tracker or the proposed approach. For instance, in Figure 4, the poor mask quality generated by Gaussian Grouping may stem from suboptimal 2D masks."
            },
            "questions": {
                "value": "Please refer to the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes information shaping for the 3D Gaussian field, following NeRF-based work JacobiNeRF. By contrastive learning between Gaussian primitives, the resulting Gaussian primitives on the same entities have a strong correlation while primitives on different entities have a weak correlation. The technical part follows the basic idea of JacobiNeRF and is tailored to 3D Gaussian with a attributes decoding network.  The learned Gaussian field is easier to edit, such as object removal and object movement."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper adapts the basic idea of JacobiNeRF to 3DGS and makes it work in terms of scene editing.\n- The method achieves good performance in the open vocabulary segmentation task.\n- The application of object removal seems have good qualitative performance."
            },
            "weaknesses": {
                "value": "- The technical novelty is limited. The Jacobian-based mutual information learning is the core part of this paper, which mainly follows JacobiNeRF. The authors are suggested to emphasize the unique designs that are different from the JacobiNeRF and demonstrate the effectiveness of the unique designs. The mask guidance and smoothness regularization differ from the DINO adopted in JacobiNeRF. However, these components seem to be incremental techniques, and their effectiveness is not well validated in the experiments.\n- The writing should be improved. Many concepts lack a clear definition. For example, what are the exact definitions of perturbation and the sequential of perturbations (e.g., 1st/2nd/3rd perturbation). What are the exact parameters perturbated and how are they perturbated (i.e., perturbation direction and norm).\n- The demonstration is weak. The object movement in Figure 6 is not impressive and it seems to be a sample handpicked with effort. It would be better to present more object movement demonstrations, using the main components of a 3D scene, such as the earthmover toy in the kitchen scene. Can you move the earthmover to anywhere else on the desk? Furthermore, the demonstrations have low diversity, mainly adopting the scene of kitchen and bear.\n- The method outperforms JacobiNeRF and JacobiGS. However, the authors do not show the reasons via an apple-to-apple comparison with JacobiNeRF and JacobiGS. As I suggested in the first item, the authors are encouraged to show the performance roadmap from the JacobiGS baseline (or other reasonable baseline) and add the unique components one by one, offering a better understanding of the inner workings to readers."
            },
            "questions": {
                "value": "Does the decoding network reduce the rendering efficiency?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a mutual information technique based on 3D Gaussian splatting. Building upon JacobiNeRF, the authors present a more efficient training pipeline that optimizes activations instead of Jacobians. This approach ensures that the correlations between Gaussians are correctly shaped and remain consistent through successive parameter changes. Experiments on open-vocabulary segmentation and scene editing demonstrate the efficiency and significant capabilities of the proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well-written and organized, the authors provide a thorough theoretical analysis of the proposed method.\n2. Experiments demonstrate that the proposed method outperforms other baselines while maintaining robustness to incorrect masks."
            },
            "weaknesses": {
                "value": "1. Compared to methods that edit the scene after obtaining the labels for each Gaussian, such as Gaussian Grouping, the direct manipulation of network parameters appears less flexible. For instance, while Gaussian Grouping can achieve style transfer, the proposed method seems limited to modifying the colors of selected Gaussians to be uniform.\n\n2. The authors conduct open-vocabulary segmentation in only three scenes, evaluating just one object per scene if I understand correctly. Including more experiments would enhance the robustness and credibility of the results."
            },
            "questions": {
                "value": "1. Aside from JacobiGS in the paper, which utilizes the same mutual information shaping loss as JacobiNeRF, why was the original JacobiNeRF not included as a baseline for comparison?\n\n\n2. Regarding weakness 2, is it possible for the proposed method to edit the color of an object to a textured color? Additionally, for the object movement task, can the method modify the trajectory of a selected object to follow a position-related trajectory, such as rotation?\n\n\n3. Besides open-vocabulary segmentation tasks, would it be feasible to conduct experiments on semantic or instance segmentation tasks to further enhance the credibility of the findings?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}