{
    "id": "z9j7wctoGV",
    "title": "Non-parametric Kernel Relative Test for Machine-generated Text Detection",
    "abstract": "Recent studies demonstrate that two-sample test can effectively detect machine-generated texts (MGTs) with excellent adaptation ability to texts generated by newer LLMs. \nHowever, the two-sample test-based detection relies on the assumption that human-written texts (HWTs) must follow the distribution of seen HWTs. As a result, it tends to make mistakes in identifying HWTs that deviate from the \\textit{seen HWT} distribution, limiting their use in sensitive areas like academic integrity verification.\nTo address this issue, we propose to employ \\textit{non-parametric kernel relative test} to detect MGTs by testing whether it is statistically significant that the distribution of \\textit{a text to be tested} is closer to the distribution of HWTs than to the distribution of MGTs. \nWe further develop a \\textit{kernel optimisation} algorithm in relative test to select the best kernel that can enhance the testing capability for MGT detection.\nAs relative test does not assume that a text to be tested must belong exclusively to either MGTs or HWTs, it can largely \\textit{reduce the false positive error} compared to two-sample test, offering significant advantages in practical use. \nExtensive experiments demonstrate the superior detection performance of our method, compared to state-of-the-art non-parametric and parametric detectors.",
    "keywords": [
        "Large language models",
        "Machine-generated text detection",
        "Relative test"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "A robust detection method for LLM-generated texts using relative test",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=z9j7wctoGV",
    "pdf_link": "https://openreview.net/pdf?id=z9j7wctoGV",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a non-parametric kernel relative test to detect machine generated text (MGTs) by testing whether it is statistically significant that the distribution of a text to be tested is closer to the distribution of human written text (HWTs) than to the MGTs\u2019  distribution. It improves the current two-sample test-based detection methods, which assumes that HWTs must follow the distribution of seen HWT. The authors further develop a kernel optimization algorithm in relative test to select the best kernel that can enhance the testing capability for MGT detection."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The proposed relative test can reduce the false positive rate that has been observed in current two sample tests. \n\nIt also proposes a novel method to optimize kernels in relative tests for MGT detection, which significantly improving the effectiveness and efficiency of the detection process."
            },
            "weaknesses": {
                "value": "While this paper presents some innovative ideas, its significance appears limited. There has been some similar studies such as the ICLR'24 paper \"Detecting machine-generated texts by multi-population aware optimization for maximum mean discrepancy.\". \n\nThe proposed method requires the preparation of both the MGT and HWT datasets. In that case, simply comparing the method with Bino in the experiment is insufficient, and may even be unfair because Bino is a zero-shot method. It is essential for the authors to engage in a comprehensive experimental study, comparing their proposed method with various other detection algorithms.\n\nThe method leverages Roberta based GPT-2 as feature generator (line 200).  Please explain the reason, and provide a comparison of this choice with other potential alternatives in both text explanation and experimental results."
            },
            "questions": {
                "value": "The method relies on several assumptions coming from empirical results (line 88, line 280-). The authors are encouraged to provide additional clarifications, both intuitive and theoretical, to further explain those assumptions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This submission proposes to address the limitation of existing non-parametric LLM detector approach that tends to make mistakes in identifying HWTs that deviate from the\nseen HWT distribution. The authors suggest to employ non-parametric kernel relative test to address the issue. Basically, the idea has some novelty to some extend. The paper highly follow the method in paper \u201cDETECTING MACHINE-GENERATED TEXTS BY\nMULTI-POPULATION AWARE OPTIMIZATION FOR\nMAXIMUM MEAN DISCREPANCY\u201d from both methodology style and the experimental design."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1). Basically, the idea has some novelty to some extend. \n\n2). The problem to address is important.\n\n3). The writting is somehow clear and easy to follow."
            },
            "weaknesses": {
                "value": "My major concerns are as follows:\n\n1). The limitation of these MMD-based approach is obvious. The appraoch by nature is not Zero-Shot aaproach. As the approach needs to prepare HWT and MGT in advance, I would say the approach is not training free by nature. Especially, the paper proposes kernel optimisation algorithm to select best kernel. This by nature is somehow \u201ctraining\u201d. Thus, the approach only compare times with Bino is not sufficient, as it also needs to compare time with training/classifier based approach (Table 2)\n\n2). The experiments are far from complete. Bascially, the datasets used are obviously too simple. Why not use the RAID datasets (in the following paper) that includes 22 different LLMs with different settings?\n\u201cRAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors, ACL\u201924\u201d\n\n3). Need to validate the robustness of the detection algorithm under adversial attack. \n\n4). Need to provide non-english dattasets\u2019 results to see the effectiveness on non-english settings.\n\n5). As mentioned in 1), the paper needs to provide comparisons to other classification based approaches as well other metric-based/ logits-based approaches. Such as:\nClassification-based: \nFEW-SHOT DETECTION OF MACHINE-GENERATED TEXT USING STYLE REPRESENTATIONS. ICLR\u201924. https://arxiv.org/pdf/2401.06712\nThreads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs. ACL\u201924. https://arxiv.org/pdf/2402.10586. \nLogits-based:\nDetectGPT (ICML\u201923) \nFast-DetectGPT (ICLR\u201924) \nDNA-GPT [ICLR\u201924]\nDALD: Improving Logits-based Detector without Logits from Black-box LLMs. [NeurIPS\u201924]\n\n6). The paper also highly depends on the feature extractor, that is \u201cfine-tuned a RoBERTa model on GPT-2-generated\u201d. What\u2019s the performance for other feature extractors? (need experiements). Need to explain the major different and advantage of proposed approach over training-based approaches.\n\n7). The literature review is far from sufficient. Pl refer to the recent surveys such as:\nA Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization\nA Survey on Detection of LLMs-Generated Content, EMNLP\u201924.\nOn the Possibilities of AI-Generated Text Detection"
            },
            "questions": {
                "value": "refer to the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concerns"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper examines the issue of how to detect machine-generated texts. It suggests that previous methods are unable to identify human-written texts when there is a change in distribution. It proposes to employ non-parametric kernel relative test to detect machine-generated texts by testing whether it is statistically significant that the distribution of a text to be tested is closer to the distribution of human-written texts than to the distribution of machine-generated texts. A kernel optimization algorithm is proposed to select the best kernel that can enhance the testing capability for machine-generated text detection. Some experiments support the effectiveness of the method proposed in this paper."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The motivation of the paper is reasonable, and the problem it addresses has practical application value.\n\n2. The method proposed in the paper is simple and effective, with a coherent logic, and the description of the algorithm is very clear.\n\n3. The paper has a solid theoretical foundation, its arguments are logically sound, and the method is highly interpretable.\n\n4. The experiments indicate that the algorithm performs well."
            },
            "weaknesses": {
                "value": "1. The assumptions on which the method is based are too strong and do not align with reality. Firstly, there is significant overlap between machine-generated language and human language; they do not exist in completely separate domains. Additionally, the subspace assumption is overly idealized and lacks a solid foundation, which greatly undermines the paper's validity.\n\n2. The method proposed in the article resembles a general text anomaly detection approach and is not closely related to large language models or machine-generated language detection. It appears to be a universal solution for text anomaly detection rather than a targeted one, as the specific characteristics of the problem have not been discussed or reflected in the method's design.\n\n3. The comparative methods in the experiments are relatively few and not comprehensive enough. Many anomaly detection solutions could also address this issue, so more comparisons and discussions should be provided."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}