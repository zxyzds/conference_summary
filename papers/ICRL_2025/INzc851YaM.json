{
    "id": "INzc851YaM",
    "title": "Enhancing Multi-Objective Offline RL with Adaptive Preference Integration",
    "abstract": "Multi-objective reinforcement learning (MORL) is crucial for real-world applications where multiple conflicting goals must be optimized, such as in healthcare or autonomous systems. Offline MORL extends these benefits by using pre-collected datasets, allowing for effective learning without continuous interaction with the environment. However, existing offline MORL algorithms often struggle with scaling across large preference spaces and handling unknown preferences during evaluation. To address these challenges, we propose the Preference-Attended Multi-Objective Decision Transformer (PA-MODT), a novel architecture that integrates a preference-attention block with a modular transformer structure. This design enables effective generalization over different preferences and trajectories, providing a more robust approach to generating optimal Pareto fronts. We tested PA-MODT on five D4MORL datasets with millions of trajectories representing various objectives and found that it consistently outperforms existing models, achieving Pareto fronts that align closely with behavioral policy. This demonstrates PA-MODT's potential to effectively manage complex multi-objective reinforcement learning tasks.",
    "keywords": [
        "Reinforcement Learning",
        "Multi-objective Optimization",
        "Offline Reinforcement Learning",
        "Decision Transformer"
    ],
    "primary_area": "reinforcement learning",
    "TLDR": "We introduce a new transformer based architecture which provides suitable preference integration with decision transformer for multi-objective reinforcement learning tasks.",
    "creation_date": "2024-09-23",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=INzc851YaM",
    "pdf_link": "https://openreview.net/pdf?id=INzc851YaM",
    "comments": [
        {
            "withdrawal_confirmation": {
                "value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."
            }
        },
        {
            "summary": {
                "value": "The paper presents an empirical analysis on how will the advances in transformer architecture affect the model\u2019s performance on MORL tasks. Specifically, Preference-Attended Multi-Objective Decision Transformer (PA-MODT), a new architecture based on MODT is proposed to facilitate the preference encoding problem."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper shed some light on how will the modification of the transformer architecture will affect the performance of MODT models in MORL.\n- PA-MODT achieves good performance."
            },
            "weaknesses": {
                "value": "- There are many typos in the paper.\n- The motivations of modifying the transformers\u2019 architecture are not clarified clearly.\n- The explanations of Pareto efficiency in Section 3 is incorrect. A point $\\beta$ is Pareto efficient if and only if there exists no other point $\\alpha$ that behaves no worse than $\\beta$ for any objectives, while satisfying $R^\\beta_i < R^\\alpha_i$ for some $i$.\n- The novelty of the proposed method and contributions are very limited.\n- Formulas Eq.(1)-(5) should be more formalized.\n- The paper does not contain any discussion on limitations. In my opinion, this paper exhibits very limited novelty and applicability, since the methods only fits the transformer-based architectures in MORL, and their properties are not clarified clearly."
            },
            "questions": {
                "value": "- In line 198 and the title of Section 5.3, should \u2018matrices\u2019 be \u2018metrics\u2019 ?\n- Are the error bars in Figure 5 of Appendix A.1 lost ? Which may lead to unreliable argument in the methods of Section 4.\n- In Section 5.1 and 5.2, how do the results reflect the property and superiority of the proposed methods ?\n- What do the results in Section 5.1 indicate about the feature or advances of the methods compared to the baselines ?\n- What is the relationship between the experiments in Section 5.3 and the proposed methods ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes the Preference-Attended Multi-Objective Decision Transformer (PA-MODT), a new Offline MORL architecture that outperforms existing models on D4MORL."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The experimental results of PA-MODT are able to surpass the baseline algorithms.\n2. The related work is fairly comprehensive."
            },
            "weaknesses": {
                "value": "Overall, the reviewer believes that this paper falls far short of the quality necessary for acceptance at ICLR. The writing is disorganized and the definitions are unclear, as exemplified by line 283. The main contribution, adding a new attention module to the existing MODT framework, lacks innovation. Additionally, the reviewers cannot understand why the proposed method is effective, as the presentation is very confusing. Finally, the content of the article is insufficient, with the actual method description and explanation taking up less than a page, while the figures are too large and lack information."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates Multi-Objective Reinforcement Learning (MORL). Specifically, authors propose Preference-Attended Multi-Objective Decision Transformer (PA-MODT), a new architecture that introduces a preference-attention block to decision transformer. Experiments on the D4MORL benchmark illustrates the effectiveness of PA-MODT."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is clearly written and easy to follow.\n2. A number of empirical experiments are conducted."
            },
            "weaknesses": {
                "value": "1. Lack of serious explanations and analysiss on the reasons why the proposed new architecture works better.\n2. Taking variance into account, the results shown in Table 1 may be insufficient to demonstrate that PA-MODT significantly outperforms the baseline methods."
            },
            "questions": {
                "value": "1. In Table 5, the training steps of PA-MODT is not pre-fixed. You claim that evaluation will be conducted every 5k steps. I wonder whether the final evaluation result (presented in Table 1) is the best score selected from all the evaluations. If so, are all the baselines evaluated in this same way?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes the Preference-Attended Multi-Objective Decision Transformer (PA-MODT) to facilitate the learning across large preference spaces and handling unknown preferences during evaluation. Specifically, a preference-attention block is integrated into the MODT architecture to enhancing preference encoding."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper provides the insight that promotes a transformer-based model\u2019s performance by modifying the architecture of the transformer."
            },
            "weaknesses": {
                "value": "- The reference format and the format of the caption of Figure 1 are not consistent with ICLR formatting instructions.\n- The discussions on the modification of transformers are better moved to the Related Works section, while also introduce the application of transformers in RL.\n- The symbols for vectors are better expressed with bold font in the notation section.\n- In Pareto Optimality of Section 3, the explanations of Pareto efficiency is incomplete. Consider a Pareto solution set {[0.25, 0.75], [0.75, 0.25]}, where the two points exceeds the other on one of the objectives, but they are all Pareto efficient, being not consistent with the explanations.\n- The \u2018key features\u2019 for PAMODT\u2019s construction are proposed without sufficient evidences or reasoning. The novelty and contributions are very limited.\n- The expressions of Eq.(1)-(5) are not concise."
            },
            "questions": {
                "value": "- In line 168, is s_{t+t} a typo? The expression of E in line 191 is better expressed with commas, like E=[p_1, p_2, \\ldots, p_m]; In line 198 and the title of Section 5.3, should \u2018matrices\u2019 be \u2018metrics\u2019 ?\n- Are the error bars in Figure 5 lost ? And sparsity metric is better evaluated to provide enough evidences and understandings.\n- In Section 5.1 and 5.2, how do the results reflect the property and superiority of the proposed methods ?\n- How do the experiments in Section 5.3 relate to the main ideas and contributions of this paper ?\n\nLimitations: The limitations are not discussed in the paper. I think the proposed method has very limited novelty and contributions. Besides, the method\u2019s applicability is also limited since it only suits the transformer-based architectures in MORL."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}