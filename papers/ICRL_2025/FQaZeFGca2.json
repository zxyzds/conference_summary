{
    "id": "FQaZeFGca2",
    "title": "EXPLORING FEW-SHOT IMAGE GENERATION WITH MINIMIZED RISK OF OVERFITTING",
    "abstract": "Few-shot image generation (FSIG) using deep generative models (DGMs) presents a significant challenge in accurately estimating the distribution of the target domain with extremely limited samples. Recent work has addressed the problem using a transfer learning approach, i.e., fine-tuning, leveraging a DGM that pre-trained on a large-scale source domain dataset, and then adapting it to the target domain with very limited samples. However, despite various proposed regularization techniques, existing frameworks lack a systematic mechanism to analyze the degree of overfitting, relying primarily on empirical validation without rigorous theoretical grounding.\nWe present Few-Shot Diffusion-regularized Representation Learning (FS-DRL), an innovative approach designed to minimize the risk of over-fitting while preserving distribution consistency in target image adaptation. \nOur method is distinct from conventional methods in two aspects: First, instead of fine-tuning, FS-DRL employs a novel scalable Invariant Guidance Matrix (IGM) during the diffusion process, which acts as a regularizer in the feature space of the model. This IGM is designed to have the same dimensionality as the target images, effectively constraining its capacity and encouraging it to learn a low-dimensional manifold that captures the essential structure of the target domain. Second, our method introduces a controllable parameter called sharing degree, which determines how many target images correspond to each IGM, enabling a fine-grained balance between overfitting risk and model flexibility, thus providing a quantifiable mechanism to analyze and mitigate overfitting.\nExtensive experiments demonstrate that our approach effectively mitigates overfitting, enabling efficient and robust few-shot learning across diverse domains.",
    "keywords": [
        "few shot learning",
        "generative model",
        "diffusion model"
    ],
    "primary_area": "generative models",
    "TLDR": "We present a novel representation learning framework for Few-Shot Image Generation, featuring a tunable parameter to explicitly mitigate overfitting while adapting a specific domain.",
    "creation_date": "2024-09-18",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=FQaZeFGca2",
    "pdf_link": "https://openreview.net/pdf?id=FQaZeFGca2",
    "comments": [
        {
            "withdrawal_confirmation": {
                "value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new formulation for using diffusion models in few-shot image generation and introduces a novel method. Experiments show that the generated results outperform existing methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper presents an interesting new formulation for few-shot image generation using diffusion models, viewing Few-Shot Image Generation (FSIG) as a conditional generation problem and deriving a direct learning approach for an  Invariant Gradient Matrix (IGM) to achieve FSIG, which is innovative.\n2. Experiments show that the generated results outperform existing methods."
            },
            "weaknesses": {
                "value": "1. My main concern is that the method proposed in this paper is highly sensitive to hyperparameters, specifically \\gamma. From Figure 3, it can be observed that as \\(\\gamma\\) increases, the FID first decreases and then increases, and the optimal value varies across different datasets. I suspect that even within the same domain, the optimal value may differ between datasets, which would significantly limit the applicability of this method.\n2. This paper does not discuss how the sharing mechanism works when \\gamma is less than the number of images. This is worth exploring.\n3. When \\gamma is not large enough, the model underfits, which may be related to the number of learnable parameters or the capacity of the model. This part could explore other ways to alleviate the issue of underfitting."
            },
            "questions": {
                "value": "Please refer to the \"Weaknesses\" section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the challenges of deep generative models (DGMs) in few-shot image generation, particularly focusing on the issue of overfitting with extremely limited samples. It introduces Few-Shot Diffusion-Regularized Representation Learning (FS-DRL), which utilizes an Invariant Guidance Matrix (IGM) and a controllable parameter called \"sharing degree\" to mitigate overfitting risks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe use of the IGM as a regularizer in feature space offers a novel perspective on addressing overfitting in few-shot scenarios.\n2.\tThe theoretical analysis of IGM enhances the interpretability of the method and provides a basis for future research.\n3.\tThe introduction of the sharing degree parameter allows for a quantifiable balance between overfitting risk and model flexibility, improving adaptability."
            },
            "weaknesses": {
                "value": "1.\tThe method's reliance on both IGM and sharing degree might complicate the implementation process. Users may face challenges in tuning these additional parameters.\n2.\tThe selection of the sharing degree is crucial, yet the paper does not provide comprehensive guidelines on how to choose this parameter effectively.\n3.\tAlthough the method shows improvements in representation learning, the computational cost associated with training and tuning, especially with higher resolutions and batch sizes, may limit its practical application in resource-constrained environments."
            },
            "questions": {
                "value": "1.\tThe paper would benefit from clearer guidelines or methodologies for selecting the sharing degree. Is there a way to simplify or automate the process of selecting this parameter?\n2.\tSince MC-SSIM is used as a metric, why were only the evaluation results for MetFaces provided?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Focusing on the overfitting problem for few-shot image generation tasks, this paper proposes a framework for the few-shot diffusion-regularized representation learning (FS-DRL). Specifically, this framework consists of two novel parts: (1) A novel scalable Invariant Guidance Matrix (IGM) during the diffusion process, which acts as a regularizer in the feature space of the model; (2) A controllable parameter called sharing degree, which determines how many target images correspond to each IGM. Extensive experiments demonstrate that the proposed framework can effectively mitigate overfitting, enabling efficient and robust few-shot learning across diverse domains."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(+) The topic of this paper, i.e., few-shot image generation with diffusion model, is interesting and significant.  \n(+) This paper is easy to follow and the presentation of this paper is clear."
            },
            "weaknesses": {
                "value": "(-) The concept of overfitting in this paper seems confusing. The term \"overfitting\" is commonly associated with discriminative tasks rather than generative tasks. Specifically, in the training GANs with limited data, existing approaches only demonstrate the overfitting of the discriminator (D) issue, with no mention of the overfitting in the generator (G). Instead, the generator usually suffers from the gradient vanishing or instability problem. Furthermore, in diffusion models, denoising score matching is used to update the parameters of the diffusion model, which indicates that the diffusion model also suffers from the gradient issue rather than the so-called overfitting problem. The effectiveness of the proposed gradient clipping in Line 94 also demonstrates that alleviating the gradient problem is useful. Thus, only using the term \u201coverfitting\u201d without clearly establishing its relevance to diffusion models is inappropriate.\n\n(-) The authors repeatedly claim that their method can analyze the degree of overfitting in diffusion models. However, concrete evidence to support this cannot be found in the paper. Which specific metric does the author use to analyze the degree of overfitting in diffusion models? One clear example, in the ADA paper, the probability p is used to indicate the overfitting degree of the discriminator. I suggest that the authors provide more supporting evidence for their claim.\n\n(-) The authors state that their proposed method also acts as the regularizer in the diffusion model. Given that applying a regularizer to alleviate overfitting is commonly used, the novelty of this paper is not strong enough. Furthermore, I cannot find the comparison experiments between the proposed regularizer and the existing regularizer to demonstrate that the proposed method is indeed effective."
            },
            "questions": {
                "value": "Please see the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents Few-Shot Diffusion-regularized Representation Learning (FS-DRL), an innovative approach designed to minimize the risk of over-fitting while preserving distribution consistency in target image adaptation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method is neat and seems to be effective.\n2. The theoretical support is solid."
            },
            "weaknesses": {
                "value": "1. The experiments are mainly about face, which is a not very challenging task. Although a few results are provided in the supplementary, more expeirmental results about more scenes and categories should be provided.\n2. There is no efficiency comparision with baselines. \n3. The discussion on the related works of few-shot image generation is not comprehensive.\n4. The authors only compare with three few-shot image generation baselines, which is far from enough. More recent methods should be compared.\n5. There is no discussion on the failure cases."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}