{
    "id": "LYHEY783Np",
    "title": "Neuron based Personality Trait Induction in Large Language Models",
    "abstract": "Large language models (LLMs) have become increasingly proficient at simulating various personality traits, an important capability for supporting related applications (e.g., role-playing). To further improve this capacity, in this paper, we present a neuron based approach for personality trait induction in LLMs, with three major technical contributions. First, we construct PERSONALITYBENCH, a large-scale dataset for identifying and evaluating personality traits in LLMs. This dataset is grounded in the Big Five personality traits from psychology and designed to assess the generative capabilities of LLMs towards specific personality traits. Second, by leveraging PERSONALITYBENCH, we propose an efficient method for identifying personality-related neurons within LLMs by examining the opposite aspects of a given trait. Third, we develop a simple yet effective induction method that manipulates the values of these identified personality-related neurons, which enables fine-grained control over the traits exhibited by LLMs without training and modifying model parameters. Extensive experiments validates the efficacy of our neuron identification and trait induction methods. Notably, our approach achieves comparable performance as fine-tuned models, offering a more efficient and flexible solution for personality trait induction in LLMs.",
    "keywords": [
        "Neuron",
        "Personality",
        "Large Language models"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We introduce a novel method that leverages the memory capabilities of neurons in multilayer perceptron (MLP)  layers to alter personality traits efficiently and stably, without retraining or prompt induction.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=LYHEY783Np",
    "pdf_link": "https://openreview.net/pdf?id=LYHEY783Np",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a neuron manipulation approach to inducing Big Five personality traits in LLMs without retraining or altering model parameters. The paper introduces PersonalityBench, a large-scale generative dataset based on real-world scenarios and grounded in the Big Five personality traits. By identifying specific personality-related neurons, the work enables neuron manipulation that allows the models to exhibit targeted personality traits."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper proposes a new neuron manipulation method that effectively induces diferent personality traits in LLMs by providing two prompts with contrasting personality levels. The approach also demonstrates the feasibility through three different evaluations.\n\nThe paper is clearly written, with diagrams that are easy to follow and overall pleasing to look at."
            },
            "weaknesses": {
                "value": "1. The situational questions used for automatic evaluation are generated by ChatGPT, yet they have not been verified by human reviewers. Additionally, details on how SocialIQA data contributed to constructing these questions are not provided. This raises concerns that SocialIQA may already embed certain personality biases, which could compromise the validity of the automatic evaluation.\n\n2. A similar work outlined here: https://arxiv.org/abs/2308.10248 appears to closely resemble the neuron manipulation method proposed in this paper. Including this work as a baseline would provide a more comprehensive comparison.\n\n3. The paper only provides a general scaled rating for generation fluency, and the scores in Table 17 seem uniformly close to 10 across all methods. This might reflect overly lenient evaluation criteria, rather than true performance. A single GPT-based metric is also not reliable enough. To address this, the authors should evaluate the model on broader benchmarks, e.g., assessing general instruction-following capabilities and factual knowledge retention to ensure the approach does not degrade overall performance.\n\n4. There are no details about the human evaluation setup and results. For example, the paper does not mention the expertise levels of the evaluators, nor does it discuss inter-annotator agreement. Given that subtle differences between personality expressions might be challenging for laypeople to detect, it would help to specify if raters are experts or had specialized training. Additionally, the current task setup requires ranking five items, which is more complex than rating them individually. See question (4).\n\n5. The IPIP-NEO-120 and IPIP-NEO-300 assessments overlap, which weakens the credibility of the multiple-choice evaluation. This issue is evident in Table 3, where the PAS method (based on IPIP-NEO-300) also yields a low score, suggesting that overlapping data could affect the accuracy of the personality alignment test."
            },
            "questions": {
                "value": "1. Could you clarify the motivation and the validity of the automatic evaluation method? For example, is there a strong correlation between the benchmark results and the IPIP-NEO-300 personality test?\n2. What data was used for the supervised fine-tuning process? Was it drawn from PersonalityBench, or were other datasets involved?\n3. It appears that neuron manipulations are applied across all layers. Have you conducted any ablation studies focusing on manipulating neurons in specific layers only, and if so, how does this impact performance?\n4 A rating-based evaluation might provide clearer insights into model performance. Could you elaborate on why a rating-based approach was not chosen?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes \u201cNPTI\u201d (Neuron-based Personality Trait Induction), a method for inducing personality traits in LLMs by identifying and manipulating specific neurons associated with the Big Five personality traits (openness, conscientiousness, extroversion, agreeableness, neuroticism). The authors introduce three main contributions: (1) PERSONALITYBENCH, a dataset of 180,000 instances designed for evaluating and inducing specific personality traits in LLMs through generative tasks; (2) an identification method for personality-related neurons based on activation differences between opposing trait aspects; and (3) a targeted neuron manipulation technique to shift personality expressions, offering an efficient alternative to model fine-tuning."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Precision in Personality Control: The neuron manipulation approach offers fine-grained control over specific traits in LLMs, presenting a compelling alternative to traditional prompt-based or full-model fine-tuning methods.\n- PERSONALITYBENCH Dataset: PERSONALITYBENCH is designed for generative personality evaluation rather than traditional multiple-choice, providing a rich framework for testing personality consistency in LLMs.\n- Method Efficiency: NPTI is more efficient than training-based personality manipulation methods, preserving the base model\u2019s parameters and computational requirements.\n- Cross-Model Testing: The evaluation on multiple models (LLaMA, Mistral, Gemma) illustrates NPTI\u2019s compatibility across architectures, strengthening its practical significance."
            },
            "weaknesses": {
                "value": "- Ambiguity in Neuron Selection Thresholds: The neuron selection relies on a fixed 10% activation difference threshold (\u03b4), but the justification for this choice is unclear. How this threshold affects neuron specificity and personality expression is not fully explored. Varying \u03b4 and showing results on a range of thresholds would provide insight into its impact on model behavior.\n- Evaluation of Personality Consistency: While PERSONALITYBENCH includes 180,000 instances, it is unclear if the dataset covers enough variation to reflect nuanced personality traits in diverse contexts. More details on the dataset\u2019s situational diversity would clarify its robustness in testing consistency.\n- Stability and Fluency Trade-off: The paper briefly mentions a trade-off between personality expression and response fluency as \u03b3 varies but lacks a systematic evaluation of how different \u03b3 values affect output quality across traits. A more detailed analysis of this trade-off, potentially with fluency ratings per personality trait, would make the choice of \u03b3 more transparent and reproducible.\n- Evaluation Metric Transparency: Automatic evaluations rely on ChatGPT\u2019s trait and fluency ratings but lack details on how consistency and reliability are ensured across responses. Clearer definitions of these evaluation metrics and consistency checks would increase confidence in the method\u2019s performance."
            },
            "questions": {
                "value": "- Can the authors clarify the selection of the 10% activation threshold (\u03b4) for neuron identification? What rationale led to this value, and how does it impact the specificity and reliability of selected neurons?\n- How does the chosen \u03b3 value impact the trade-off between personality intensity and fluency? Could the authors provide an empirical breakdown of how personality traits change with varying \u03b3 values and corresponding fluency scores?\n- Could the authors explain the consistency checks in the automatic evaluation setup? Since ChatGPT rates personality intensity and fluency, are there mechanisms to ensure consistency across varied prompts?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper addresses the task of using large language models (LLMs) to simulate various personality traits and how to improve upon this task. They present three contributions: a dataset (PersonalityBench) consists of personality descriptions and situational questions to identify and evaluate personality traits; a method for identifying neurons in the LLMs that lead to desired traits in the models' response; and a method for modifying the values of the identified neurons to gain control over the traits generated in the response. They used ChatGPT to evaluate the responses from the LLMs and concluded that their method outperforms baseline methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "Originality:\nThe paper's original idea mainly relies on their focus on neurons as the target modification needed to improve the LLMs capability to create a response with a desired personality trait. They propose identifying these neurons by measuring their activation when prompting the LLMs to generate responses. After this process, they increase the activation value of positive neurons while decreasing that of negative neurons, thus amplifying their effects on the output response. The idea of using prompting to target the activation of neurons is not new in the literature, but their approach to modifying their values seem to be a novel one. The other parts in the process seem to be standard convention within training and prompting LLMs.\n\nQuality:\nBased on their evaluation process, they claim their method outperforms the baselines in most of the traits in both the quality of the personality traits and also the stableness of the response. They used both automatic and human evaluations in order to substantiate these claims.\n\nClarity:\nThe authors' writings are clear on their approach and process. They described in great detail most of the work in the paper, and also provided a good amount of references on the literature and the methods that they use from other works.\n\nSignificance:\nThe results of the paper could be implemented in many downstream tasks in the research area, such as personalized chatbots, gaming, entertainment, etc. The method of identifying and modifying influential neurons in the LLMs could also be applied across broader range of use cases for LLMs outside of simulating personality traits."
            },
            "weaknesses": {
                "value": "The paper lacks some experiments and evaluation results that could help substantiate their validity. The authors did not describe how they know the dataset they constructed is a \"good\" dataset appropriate for this task other than a reference to one other paper. They also did not explain why using ChatGPT in the data generation and response evaluation process, although they did include a brief mention of some citations in the related work section."
            },
            "questions": {
                "value": "The authors should elaborate on the evaluation of the quality of the constructed PersonalityBench dataset. They could also include some experiments to compare training time and efficiency of their method compared to prompting-based and training-based methods; currently, they only compare their performance results rated by ChatGPT. On the same line of thought, they should give some explanations as to why ChatGPT would be a valid evaluation mechanism to provide personality trait scores for the models; only some references for personality assessment using LLMs are provided. \n\n\nIn terms of the presentation of the paper, the authors made some errors that could benefit from a slight revision. There are many empty spaces on page 16 that seem out of place. Furthermore, table 14 and table 15 are duplicates."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}