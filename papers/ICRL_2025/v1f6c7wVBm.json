{
    "id": "v1f6c7wVBm",
    "title": "AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction",
    "abstract": "Neural radiance fields have recently revolutionized novel-view synthesis and achieved high-fidelity renderings. \nHowever, these methods sacrifice the geometry for the rendering quality, limiting their further applications including relighting and deformation. \nHow to synthesize photo-realistic rendering while reconstructing accurate geometry remains an unsolved problem. In this work, we present AniSDF, a novel approach that learns fused-granularity neural surfaces with physics-based encoding for high-fidelity 3D reconstruction. Different from previous neural surfaces, our fused-granularity geometry structure balances the overall structures and fine geometric details, producing accurate geometry reconstruction. \nTo disambiguate geometry from reflective appearance, we introduce blended radiance fields to model diffuse and specularity following the anisotropic spherical Gaussian encoding, a physics-based rendering pipeline. With these designs, AniSDF can reconstruct objects with complex structures and produce high-quality renderings. \nFurthermore, our method is a unified model that does not require complex hyperparameter tuning for specific objects. \nExtensive experiments demonstrate that our method boosts the quality of SDF-based methods by a great scale in both geometry reconstruction and novel-view synthesis.",
    "keywords": [
        "Surface Reconstruction",
        "Neural Radiance Field"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-13",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=v1f6c7wVBm",
    "pdf_link": "https://openreview.net/pdf?id=v1f6c7wVBm",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a high-quality 3D surface reconstruction method- AniSDF, which learns fused-granularity neural surfaces with physics-based encoding. The authors propose fused multi-resolution grids for geometry modeling, and adopt Anisotropic Gaussians for appearance modeling. With these designs, AniSDF can reconstruct objects with complex structures and produce high-quality renderings on benchmarked datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well written and easy to follow. The idea is clean and the pipeline do not introduce additional hyper-parameter tuning and selection compared to some other recent methods for neural surface reconstruction / rendering.\n2. The idea to fuse multi-resolution grids for detailed surface reconstruction is novel. AniSDF\u2019s fused-granularity structure balances high- and low-resolution information to improve convergence and accuracy. This approach allows for a more adaptive reconstruction that captures both overall structure and fine details, which is validated by their good geometry quality (chamfer) in the experiments.\n3. The use of ASG encoding in appearance modeling seems to be effective and handles specular reflections very well."
            },
            "weaknesses": {
                "value": "1. Experiments for reflective surfaces mainly come from synthetic data, it would be helpful to understand the model\u2019s ability if we could see results of more real-world reflective surface data, such as trucks from Tanks and Templates, sedans from Refnerf, The Glossy-Real dataset from Nero.\n2. The appearance modeling involves blending view-based and reflection-based radiance fields, however, the method's ability to decompose base color and reflection color is unknown.  It would be better if the author could add a visualization of view-based color, reflection-based color, and the blending weight.\n3. Some details of the methods are missing. The derivation of normal and the method for mesh extraction are not discussed.\n4. The reason behind the choice of grid level `m` and `l`  is not clear. It would be clearer if an ablation study about grid resolution were added."
            },
            "questions": {
                "value": "1. Add real-world experiments and more benchmark datasets (with larger scene scale).\n2. Add visualizations to the decomposed appearance throughout the figures in the paper.\n3. Add missing details in the method section.\n4. Add some comparison on the train - test efficiency and memory footprint.\n4. Revised the discussions and ablation studies as suggested in the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper provides a fused-granularity neural surfaces with physics-based anisotropic\nspherical Gaussian encoding for high-fidelity 3D reconstruction. The authors show state-of-the-art novel-view rendering and geometry reconstruction results on several datasets, including NeRF-Synthetic, Shiny Blender, and DTU datasets. The proposed method shows very convincing reconstruction of challenging specular and furry objects."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to follow. \n2. Qualitative and quantitative results of the proposed method seems very strong, beating prior baselines like NeuS, RefNeRF, RefNeuS. Reconstructed meshes look clean with high-quality surface normals. \n3. The authors validate the proposed method on both synthetic datasets (Nerf-synthetic and Shiny-blender), and real datasets (DTU), and it's nice to see improvements."
            },
            "weaknesses": {
                "value": "1. To further convince me about the method's performance on reconstructing specularity, I would need to see the view synthesis videos, as opposed to the static frames shown in the paper and project page. Unfortunately, I could not find such videos (except the relighting ones). \n\n2. For the proposed blended radiance field (Eq. 12), I think it would be great to provide some visualizations of the individual components: w, c_view, c_ref, to better understand what each learnt components look like. \n\n3. I'm unsure why the fused-granularity hash grids actually works better than a plain multi-resolution hash grids. It seems to me that the major difference of it from a plain one is the additional handcrafted equation (6) that says the final SDF is an addition of coarse and fine SDF. In the plain multi-resolution hash grid, the final SDF is predicted by a MLP from concatenated multi-resolution features. This could benefit some justification."
            },
            "questions": {
                "value": "1. For Eq. 10, why would both c_view and c_ref depend on view directions? Would it encourage better diffuse-specular separation if one makes c_view view-independent?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces AniSDF, an approach to enhance the quality of SDF-based methods in geometry reconstruction and novel-view synthesis tasks, enabling the physically-based rendering ability. Firstly, AniSDF uses the parallel branch structure of coarse hash-grids and fine hash-grids, replacing the former sequential coarse-to-fine training strategy, to learn a fused-granularity neural surface to improve the quality of SDF. Secondly, AniSDF uses Anisotropic Spherical Gaussian Encoding to learn blended radiance fields with a physics-based rendering, disambiguating the reflective appearance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality:\nThe paper explores the potential of parallel using coarse and fine hash-grid to replace the general sequential coarse-to-fine structure, demonstrating the effects of experiments. Besides, this paper combines SDF learning with blended radiance field learning with anisotropic spherical Gaussian encoding to distinguish material information.\n\nQuality:\nThe quality of the paper is good, evidenced by detailed experiments and comprehensive comparisons with state-of-the-art methods. \n\nClarity:\nThe paper is well-structured and organized. \n\nSignificance:\nThe good geometry that disambiguates the reflective appearance is helpful in 3D reconstruction. The possible relighting application makes this research meaningful."
            },
            "weaknesses": {
                "value": "1. Reference is insufficient: From Lines 130 to 135, the Sec. 2.1 is related to the attempts to improve the reconstructed geometry of Gaussians. Since 2DGS is used to compare, it is no reason to cite some papers focused on doing similar jobs: improving the surface reconstruction of 3DGS, like $\\cite{guedon2023sugar, lyu20243dgsr, chen2023neusg}$.\n\n2. The ablation study of the fused-granularity neural surface is not enough. The ablation study shows the comparison with the sequential coarse-to-fine method, but the technique with only coarse hash-grid and only fine hash-grid should also be demonstrated to prove the observations shown at the beginning of Sec.3.2. It could be better if the training time comparison is also shown in this part.\n\n@article{guedon2023sugar,\n  title={SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering},\n  author={Gu{\\'e}don, Antoine and Lepetit, Vincent},\n  journal={CVPR},\n  year={2024}\n}\n@article{lyu20243dgsr,\n  title   = {3DGSR: Implicit Surface Reconstruction with 3D Gaussian Splatting},\n  author  = {Xiaoyang Lyu and Yang-Tian Sun and Yi-Hua Huang and Xiuzhe Wu and Ziyi Yang and Yilun Chen and Jiangmiao Pang and Xiaojuan Qi},\n  year    = {2024},\n  journal = {arXiv preprint arXiv: 2404.00409}\n}\n@article{chen2023neusg,\n  title   = {NeuSG: Neural Implicit Surface Reconstruction with 3D Gaussian Splatting Guidance},\n  author  = {Hanlin Chen and Chen Li and Gim Hee Lee},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2312.00846}\n}"
            },
            "questions": {
                "value": "1. Modify the typo in Line 093 (\u2018Oue\u2019) to \u2018Our.\u2019\n\n2. The physical-based rendering method via ASG is similar to $\\cite{yang2024spec}$. Is this work also inspired by similar works using ASG to learn the specular representation in 3DGS?\n\n3. The blended radiance fields with ASG encoding are composed of $c_{view}$ and $c_{ref}$ though a learnable weight. According to Eq. 4, the light field is modeled by $c_d$ and $c_s$, diffuse color and specular color. So, can $c_{view}$ be regarded as purely diffuse and $c_{ref}$ as the pure composition of specular? If so, can the radiance fields be considered purely diffuse when $\\omega$ is 1? If not, can this work disentangle the light field to only diffuse or specular field?\n\n4. Refer to $\\cite{han2023multiscale}$, they control the final color by adding the scale to the color calculated from ASG when retaining the diffuse color term calculated from the first three orders of SH. So, what motivates adding weight to diffuse and specular in this work? What are the differences between your light field calculation in the blended radiance fields with $\\cite{han2023multiscale}$?\n\n@article{han2023multiscale,\n  title     = {Multiscale Tensor Decomposition and Rendering Equation Encoding for View Synthesis},\n  author    = {Kang Han and Weikang Xiang},\n  journal   = {Computer Vision and Pattern Recognition},\n  year      = {2023},\n  doi       = {10.1109/CVPR52729.2023.00412},\n  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/aa41843888fffada6335b6c5cdbcd2d4bb5cf9da}\n}\n\n@article{yang2024spec,\n  title={Spec-gaussian: Anisotropic view-dependent appearance for 3d gaussian splatting},\n  author={Yang, Ziyi and Gao, Xinyu and Sun, Yangtian and Huang, Yihua and Lyu, Xiaoyang and Zhou, Wen and Jiao, Shaohui and Qi, Xiaojuan and Jin, Xiaogang},\n  journal={arXiv preprint arXiv:2402.15870},\n  year={2024}\n}"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The reviewer would like to raise awareness of possible breach of double blind review rules.\n\nThe reviewer found a twitter page:\n\nhttps://x.com/zhenjun_zhao/status/1842119223646302292\n\nThis page introduces their paper with authors names explicitely shown."
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents AniSDF, a novel SDF-based method for high-fidelity 3D reconstruction that incorporates fused-granularity neural surfaces and anisotropic spherical Gaussian (ASG) encoding. AniSDF aims to achieve accurate geometry reconstruction and photo-realistic rendering by addressing challenges in neural radiance fields, such as geometry-appearance trade-offs. The approach uses parallel fused-granularity neural surfaces to balance coarse and fine details, and blended radiance fields with ASG encoding for modeling both diffuse and specular appearances. Extensive experiments demonstrate AniSDF's superiority in both geometry reconstruction and novel-view synthesis over prior methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tInnovative Approach: The use of fused-granularity neural surfaces combined with ASG encoding for 3D reconstruction is novel and effective in balancing both coarse and fine details, leading to improved geometry and appearance quality.\n2.\tHigh Performance: Experimental results show significant improvements in rendering quality and geometry reconstruction, with better handling of reflective, luminous, and fuzzy objects compared to existing methods."
            },
            "weaknesses": {
                "value": "1.\tLimited Real-Time Capability: AniSDF cannot perform real-time rendering, which limits its applicability in time-sensitive applications such as interactive graphics or augmented reality.\n2.\tComputation Cost: The use of multiple neural networks and high-resolution hash grids could be computationally expensive, which may hinder scalability."
            },
            "questions": {
                "value": "Questions:\n1. I compared the chamfer distance metric of the Neuralangelo method reproduced on the DTU dataset in the paper, and there is a significant gap. The original paper reported an average of 0.61 (which surpasses your method), while the reproduced result in the paper is 1.07. Could the authors clarify the reasons for this discrepancy? Specifically, did you maintain the same hyperparameter settings as Neuralangelo? Please provide detailed information on your experimental setup.\n2. Section 3.2 of the paper lists some issues related to coarse grid and fine grid training, but there are no corresponding experimental supports for these claims. Regarding the use of the coarse to fine method, you pointed out that thin structures may be discarded in the early training stages. Could you provide visualizations of surface reconstruction at different training stages, along with corresponding quantitative metrics, particularly for Neuralangelo and Neus2? This would help us assess the advantages and disadvantages in the reconstruction of detailed structures. I noticed your experiments in the ablation study, but they do not specify the experimental settings and only show the final results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The AniSDF paper introduces an innovative approach to high-fidelity surface reconstruction and photo-realistic rendering from multi-view images. This is achieved through a synergistic geometry network and appearance network, which together enable high-quality 3D reconstruction. Additionally, the authors propose a fused-granularity neural surface that aims to balance overall structural integrity with fine detail preservation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Pros:\nThe paper is well-written and generally easy to follow.\nExperimental results demonstrate incremental improvements in PSNR, which support the proposed approach."
            },
            "weaknesses": {
                "value": "Cons:\nThe fused-granularity neural surface structure may lack novelty, as it essentially uses two parallel structures with different resolutions. It seems likely that resolution choices could impact the final reconstruction quality. Including experiments that vary resolution settings would clarify their effect. \n\n\nDespite claims of high-quality mesh reconstruction, Chamfer Distance results reveal performance gaps on certain objects (e.g., \"Chair\" and \"Mic\" categories) compared to methods like Neus and NeRO. Explaining these discrepancies would help elucidate the limitations."
            },
            "questions": {
                "value": "It\u2019s unclear whether the larger network or the fused-granularity neural surface structure is responsible. What would happen if we set both the fine and coarse grids to the same resolution, either that of the coarse grid or that of the fine grid?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}