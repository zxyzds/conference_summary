{
    "id": "KUX2T1cY8w",
    "title": "PRE-TRAIN WITH BACKPROPAGATION AND FINE-TUNE  WITH A BIO-PLAUSIBLE LEARNING RULE",
    "abstract": "Backpropagation (BP) has long been the cornerstone of deep neural network training. While neural networks trained with backpropagation typically have high accuracy and precision, they suffer from limitations in their robustness to adversarial perturbation. Biologically plausible (bio-plausible) learning rules, on the other hand, are more robust. Yet, they typically underperform in terms of accuracy and precision, which has limited their widespread adoption. In this work, we aim to bridge this gap. We propose a novel approach where neural networks are pre-trained using backpropagation and fine-tuned using bio-plausible learning rules. We use several types of Sign-Symmetry learning methods to fine-tune models pre-trained using backpropagation. We explore the effectiveness of this approach in two tasks, image classification and image retrieval, then demonstrate that it improves robustness against gradient-based adversarial attacks while offering comparable accuracy and precision compared to the use of backpropagation alone. These findings show the benefit of mixing backpropagation and bio-plausible learning rules, suggesting the need for further research by the community to evaluate this approach on other tasks.",
    "keywords": [
        "Bio-plausible",
        "credit assignment",
        "backpropagation",
        "sign-symmetry",
        "adversarial robustness"
    ],
    "primary_area": "learning theory",
    "TLDR": "Biologically inspired fine-tuning of neural networks for enhanced robustness and effective performance.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=KUX2T1cY8w",
    "pdf_link": "https://openreview.net/pdf?id=KUX2T1cY8w",
    "comments": [
        {
            "title": {
                "value": "Questions Response"
            },
            "comment": {
                "value": "Response Q1:\n\nThanks for pointing this out, indeed after submission we noticed that we had made a mistake that included training data in our test split (data contamination) for the case of ImageNet in image classification, however in Deep Hashing we have based our train/val/test on the same split used in the literature of Deep-Hashing (see HashNet/pytorch/data/imagenet/test.txt at master \u00b7 thuml/HashNet - https://github.com/thuml/HashNet/blob/master/pytorch/data/imagenet/test.txt).\nWe\u2019re working on replacing ImageNet with NUS-WIDE and MSCOCO for the classification task, for the camera-ready version, this would avoid any confusion when it comes to the potential effect pre-training on ImageNet could have on our claim.\n\n\nResponse Q2:\n\nThe motivation behind using these backbones is that they already have established biologically plausible definitions for their respective architectures. In our approach, we propose a new method for training neural networks rather than a biologically plausible version of AlexNet or VGG-16 (work that has already been done). Adapting biological plausibility to new neural network architectures is another research topic, many architectures have no biologically plausible implementation (Transformers, for example). \nThe results of our work motivate research on proposing biologically plausible versions of recent architectures (a topic that has yet to see much activity due to the performance problems we have mentioned).\n\n\n\nResponse Q3: \n\nWhile we lack formal mathematical proofs or neuroscientific evidence, there are compelling theoretical arguments supporting this method's efficiency:\n\n - Regarding robustness compared to backpropagation: Biologically plausible methods operate without complete weight information, which is typically required for gradient-based optimization attacks. The effect of using noised weights (brSF/frSF) or only the sign of the amplitude of the weights(uSF) \u201cfools\u201d gradient-based attacks, and makes them perform less effectively. \n\n- Concerning performance relative to BP: Our hypothesis suggests that while BP demonstrates superior capability in representation learning during the pre-training phase (which has already been shown in [1]), both BP and sign-symmetric methods achieve comparable results in task adaptation (transfer learning) during fine-tuning. Furthermore, biologically plausible methods exhibit an inherent advantage in robustness.\n\n[1] Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures - https://proceedings.neurips.cc/paper_files/paper/2018/file/63c3ddcc7b23daa1e42dc41f9a44a873-Paper.pdf"
            }
        },
        {
            "title": {
                "value": "Questions Response"
            },
            "comment": {
                "value": "Q1: Can you elaborate on the choice of datasets used for testing? Were they selected based on specific characteristics that highlight the strengths of your approach?\n\nResponse: The choice of dataset was not constrained by any specific requirements, as our approach is designed to be generalizable across all datasets. While we tested our method on ImageNet (which was used for pre-training), we also evaluated it on other datasets including CIFAR10, NUS-WIDE, and MS-COCO. We are currently working on incorporating NUS-WIDE and MS-COCO for the classification task in the camera-ready version.\n\nQ2: How does your method perform in scenarios involving non-gradient-based adversarial attacks?\n\nResponse: These types of methods were not tested due to the nature of these attacks, which don't rely on gradient knowledge. We argue that bio-plausible methods are inherently more robust to gradient-based attacks only. However, we agree that including these methods would help provide more insights into the behavior of such learning approaches.\n\nQ3: What are the potential limitations or drawbacks of using bio-plausible methods in other domains or applications?\n\nResponse: previous works have only pointed out performance issues [1], To the best of our knowledge, we\u2019re the first to apply sign-symmetry to other task than Image Classification, and we show that it performs relatively at the same scale as BP with a robustness advantage when used in the fine-tuning step.\n\n[1] Assessing the Scalability of Biologically-Motivated\n Deep Learning Algorithms and Architectures -  https://proceedings.neurips.cc/paper_files/paper/2018/file/63c3ddcc7b23daa1e42dc41f9a44a873-Paper.pdf"
            }
        },
        {
            "title": {
                "value": "Questions Response"
            },
            "comment": {
                "value": "Q1: Could you clarify the choice of pre-training on ImageNet and fine-tuning on ImageNet100? This choice seems unconventional, as it might introduce overfitting concerns or limit the evaluation\u2019s generalizability.\n\nResponse: The choice of pre-training on ImageNet was primarily motivated by established practices in the Deep Hashing image retrieval literature (see Section 3.1.1 - Network Architecture) [1]. Similarly, our benchmarking on ImageNet100 followed precedents from this literature [2]. We acknowledge that for our claims, this approach might raise concerns about potential overfitting affecting robustness and performance. To address these concerns, we evaluated our method on additional datasets (such as CIFAR10) for classification tasks. Furthermore, to strengthen the generalizability of our claims, we considered image retrieval as an additional task, using two datasets independent of ImageNet (NUS-WIDE and MSCOCO). For the camera-ready version, we are working to replace the ImageNet classification benchmark with NUS-WIDE and MSCOCO to eliminate any potential confusion in our results. \n\nQ2: When you refer to \"fine-tuning,\" are you adjusting all model weights, including the backbone, with bio-plausible methods? Or is this term meant to describe training for downstream tasks with specific layers?\n\nResponse: All the model parameters are fine-tuned using the bio-plausible learning rule (see Method - Learning Method and Model Architectures section).\n\nQ3: Figure 1\u2019s arrow representation of weight transport is somewhat ambiguous. What does the arrow signify in terms of the amount of weight transport across methods?\n\nResponse: The arrow indicates the amount of weight information used in the backward pass. Backpropagation uses 100% of the weight information, thus being at the most extreme right. uSF uses only the sign of weights, thus using less information than BP, but more than brSF/frSF which uses the sign while adding some noise to the amplitude. FA (Feedback Alignment) doesn't use any weight information (0%).\n\nQ4: Could you confirm that accuracy and mean average precision are presented in percentage terms in the tables?\n\nResponse: Yes we do confirm it\u2019s in percentages, thanks for pointing this out, we\u2019ll consider mentioning this to avoid any confusion.\n\nQ5: The robustness analysis includes standard gradient-based attacks like FGSM and PGD, but no specialized attacks for bio-plausible learning methods. How might these attacks perform differently if evaluated against attacks tailored specifically to the Sign-Symmetry methods?\n\nResponse: Indeed, gradient-based attacks are not specifically tailored for bio-plausible learning rules. Therefore, we hypothesize that the adversarial robustness comes inherently from the noise added to the weights, as compared to exact methods like backpropagation (BP). The literature has not yet proposed any attacks specific to bio-plausible learning rules; this is an open research question that we mention in the discussion section (see the last sentence of the last paragraph).\n\nQ6: Could you provide an alternative visualization comparing learning rules and weight transport? Perhaps a comparison matrix or schematic diagram that delineates key differences?\n\nResponse: Thanks for pointing this out, we are working on a more comprehensive figure, one that would show each matrix and the difference between each method in terms of weight transport, we\u2019re also considering a more intuitive representation of the axis.\n\n[1] A Survey on DeepHashing Methods - https://dl.acm.org/doi/pdf/10.1145/3532624\n\n[2] HashNet: Deep Learning to Hash by Continuation - https://openaccess.thecvf.com/content_ICCV_2017/papers/Cao_HashNet_Deep_Learning_ICCV_2017_paper.pdf"
            }
        },
        {
            "summary": {
                "value": "The paper presents an approach combining traditional backpropagation for pre-training and bio-plausible learning rules, specifically Sign-Symmetry, for fine-tuning. The authors argue that this hybrid training method results in models that are more robust to gradient-based adversarial attacks compared to standard backpropagation-only models, while achieving similar accuracy and precision."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The experimental results convincingly demonstrate the approach\u2019s increased robustness against adversarial attacks. This aligns with the authors\u2019 intent to mitigate backpropagation's vulnerability, leveraging bio-plausible learning's inherent resilience.\n\nThe paper integrates backpropagation and bio-plausible methods, showing that such a hybrid model can preserve performance while enhancing security against adversarial examples. This is a promising area for further exploration in the community.\n\nThe experiments cover multiple backbone architectures, learning rules, and datasets, providing a comprehensive view of the proposed approach's effectiveness across different settings."
            },
            "weaknesses": {
                "value": "The motivation for pre-training on ImageNet and then fine-tuning on ImageNet100 could use clarification. It\u2019s unclear why a smaller dataset subset was chosen for fine-tuning, as this could introduce a slight overfitting risk with backpropagation, affecting robustness. It would also be helpful to see comparisons with results before fine-tuning, particularly regarding robustness metrics.\n\nThe term \"fine-tuning\" might be more accurately described if it involves \"training the downstream task with unfrozen backbone weights,\" as suggested by the unclear distinction between backpropagation and bio-plausible stages. Making this distinction explicit would clarify the contribution.\n\nThe work by Sanfiz & Akrout (2021), used as a basis for some assumptions, is not peer-reviewed. While this may not significantly affect the paper\u2019s core findings, it would be beneficial to rely on more robustly vetted sources where possible.\n\nFigure 1's visualization of weight transport methods is not intuitive. The arrow representation could be misleading, as it does not clearly illustrate the differences in weight transport between backpropagation and bio-plausible methods. A more structured schematic detailing learning rules and their weight transport levels would improve clarity.\n\nAlthough the paper claims to open-source the code, no direct link or supplemental is provided. Including a repository link would make replication easier for the community.\n\nAdding explicit units (e.g., [%] for accuracy) in the tables would improve clarity. While it\u2019s often implicit, making this explicit could aid comprehension.\n\nThis paper presents a legitimate and straightforward approach with practical relevance. The hybrid training method appears effective, and the results suggest it\u2019s a viable direction for increasing adversarial robustness in neural networks. Further refinements, particularly in clarifying the fine-tuning method and visualizations, would enhance the clarity and impact of this work."
            },
            "questions": {
                "value": "Could you clarify the choice of pre-training on ImageNet and fine-tuning on ImageNet100? This choice seems unconventional, as it might introduce overfitting concerns or limit the evaluation\u2019s generalizability.\n\nWhen you refer to \"fine-tuning,\" are you adjusting all model weights, including the backbone, with bio-plausible methods? Or is this term meant to describe training for downstream tasks with specific layers?\n\nFigure 1\u2019s arrow representation of weight transport is somewhat ambiguous. What does the arrow signify in terms of the amount of weight transport across methods?\n\nCould you confirm that accuracy and mean average precision are presented in percentage terms in the tables?\n\nThe robustness analysis includes standard gradient-based attacks like FGSM and PGD, but no specialized attacks for bio-plausible learning methods. How might these attacks perform differently if evaluated against attacks tailored specifically to the Sign-Symmetry methods?\n\nCould you provide an alternative visualization comparing learning rules and weight transport? Perhaps a comparison matrix or schematic diagram that delineates key differences?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper investigates an alternative training method for deep neural networks to address the robustness limitations of traditional backpropagation (BP). Specifically, it proposes a hybrid approach where neural networks are pre-trained with BP for initial accuracy and then fine-tuned using biologically plausible learning rules, particularly Sign-Symmetry methods (uSF, frSF, brSF). This fine-tuning method aims to enhance robustness against adversarial attacks without sacrificing the accuracy obtained through BP. The paper tests this method across multiple neural network architectures (AlexNet, VGG16, ResNet-18) on tasks including image classification and hashing-based image retrieval, demonstrating improved adversarial robustness while retaining accuracy levels comparable to standard BP training."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The approach of pre-training with BP and fine-tuning with bio-plausible learning rules is interesting and presents a promising path toward enhancing robustness in neural networks.\n\nThe experiments are well-designed, with comprehensive comparisons across different architectures, learning rules, and tasks.\n\nThe findings demonstrate that bio-plausible learning can play a critical role in improving adversarial robustness, which could inspire further research in bio-inspired ML methods."
            },
            "weaknesses": {
                "value": "The proposed method's robustness against adversarial attacks is limited to specific gradient-based attacks (FGSM and PGD). Testing on additional types of attacks, including non-gradient-based ones, would have helped in better understanding the limitation.\n\nSome sections on bio-plausible learning rules and their relationship to robustness could benefit from a more detailed explanation to provide a clearer understanding of why these methods improve adversarial robustness.\n\nWhile the chosen datasets are common benchmarks, including a wider range of datasets could enhance the robustness of claims\u2019 generalizability."
            },
            "questions": {
                "value": "Can you elaborate on the choice of datasets used for testing? Were they selected based on specific characteristics that highlight the strengths of your approach?\n\nHow does your method perform in scenarios involving non-gradient-based adversarial attacks?\n\nWhat are the potential limitations or drawbacks of using bio-plausible methods in other domains or applications?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper is an attempt to propose a biologically plausible alternative solution to backpropagation that has been dominating the deep learning training for a few decades. Although biologically plausible learning methods are more robust to perturbation and more insightful of human learning, they are known to be significantly worse than backpropagation in performance evaluated by standard metrics (accuracy for classification, dice score for segmentation, mIoU for detection, etc.). In this paper, the authors aim to design a biologically plausible learning method that performs on par with backpropagation. Specifically, they propose pre-training with backpropagation and fine-tuning with biologically plausible Sign-Symmetry learning rules, and show that on image classification and image retrieval, the resulting models are more robust to perturbations from gradient-based adversarial attacks while performing comparably in standard metrics."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe general topic of biologically plausible alternative to backpropagation is of interest to both machine learning and neuroscience communities.\n2.\tThe background on adversarial attacks and adversarial robustness is helpful.\n3.\tThe authors could further highlight the fact that they are directly tuning the publicly available models pre-trained on ImageNet, which means the proposed method is relatively efficient."
            },
            "weaknesses": {
                "value": "1.\tI find the results presented quite alerting. **If I understand it correctly, in Table 1, the authors claimed that they could achieve 100.0% accuracy on ImageNet classification using backpropagation with VGG16 backbone.** I strongly doubt they are either presenting the train accuracy instead of the test accuracy or they are making other serious mistakes. I would like to encourage the authors to double check that and provide justification if my suspicion does not hold.\n2.\tThe backbones being experimented are AlexNet, VGG16, and ResNet-18, and the first two are unfortunately no longer the mainstream backbones in recent years. I would recommend the authors provide rationale for choosing them rather than backbones such as Vision Transformer, ConvNeXT, etc.\n3.\tIt would be especially helpful if the authors can go deeper on the insights on why training from scratch using Sign-Symmetry methods are subpar whereas finetuning using Sign-Symmetry methods from backpropagation-based pretrained weights are showing competitive performance. Insights into this phenomenon, especially if can be explained from a neuroscience perspective could be extremely interesting. With that said, everything has to rely on the fact that the results are reliable --- refer to Weakness 1."
            },
            "questions": {
                "value": "Please see questions 1 and 2. I would encourage the authors to directly respond to them, especially 1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}