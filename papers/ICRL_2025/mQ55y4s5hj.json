{
    "id": "mQ55y4s5hj",
    "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
    "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have revolutionized visual content creation across various applications, including advertising, personalized media, and design prototyping. \nHowever, crafting effective textual prompts to guide these models remains challenging, often requiring extensive trial and error. \nExisting prompt inversion methods, such as soft and hard prompt techniques, suffer from issues like limited interpretability and incoherent prompt generation. \nTo address these limitations, we introduce Visually Guided Decoding (VGD), a gradient-free approach that leverages large language models (LLMs) and CLIP-based guidance to generate coherent and semantically aligned prompts. \nVGD utilizes the robust text generation capabilities of LLMs to produce human-readable prompts while employing CLIP scores to ensure alignment with user-specified visual concepts. \nThis method enhances the interpretability, generalization, and flexibility of prompt generation without the need for additional training. \nOur experiments demonstrate that VGD outperforms existing prompt inversion techniques in generating understandable and contextually relevant prompts, facilitating more intuitive and controllable interactions with text-to-image models. \nVGD's compatibility with various LLMs, including LLama2, LLama3, and Mistral, makes it a versatile solution for enhancing image generation workflows.",
    "keywords": [
        "text-to-image",
        "inversion",
        "gradient free hard prompt inversion",
        "language model guidance on latent diffusion model"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "Visually Guided Decoding (VGD) improves prompt generation for text-to-image models by using language models and CLIP guidance to create coherent, human-readable prompts aligned with visual concepts.",
    "creation_date": "2024-09-19",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=mQ55y4s5hj",
    "pdf_link": "https://openreview.net/pdf?id=mQ55y4s5hj",
    "comments": [
        {
            "summary": {
                "value": "In this paper, the authors tackle the problem of hard prompt inversion for text-to-image generative models, which is to find a piece of text input to these text-to-image models that can yield images that consist of similar visual concepts in some reference images. Unlike prior methods, which generate soft tokens or completely incomprehensible prompts, the authors propose to combine the language priors in LLMs and CLIP similarity objective to generate human-readable prompts. The authors provide some qualitative and quantitative experimental evidence to demonstrate their claims on the tasks of single image prompt inversion and multi-image concept combination."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors propose a pretty creative way to conduct gradient-free text-to-image prompt inversion and incorporate language priors in the process. The qualitative results also show some obvious improvement on CLIP-I scores when used with Llava."
            },
            "weaknesses": {
                "value": "My main concern about this paper lies in the experiments. In general, I am not very convinced by their result that this method significantly improves upon the existing literature.\n1. The authors mainly conduct qualitative comparison with PEZ and textual inversion, and not with CLIP-Interrogator, which is very misleading given that CLIP-Interrogator is the best performing baseline based on Table 1 and it can also generate prompts that have similar human interpretability in comparison to the proposed method when used with Llava or BLIP.\n2. The authors mention PH2P in their literature review but did not use it as a baseline. From the PH2P paper it seems that they can also obtain similar human interpretability.\n3. PEZ also has a variation that incorporates language fluency objectives (Section 5 in PEZ paper). Since this is the main contribution of this paper, the authors should consider comparing it with this variation too.\n4. Authors should also consider (at least conceptually) compare with PRISM (https://arxiv.org/pdf/2403.19103), which is another prompt inversion method that uses VLM in their process and can achieve pretty good human interpretability.\n5. The main contribution of this paper is to generate human readable prompts. However, the authors fail to provide a principle and quantitative way to measure this contribution. Metrics like perplexity can be easily implemented here.\n6. The authors only compare performance on one text-to-image model and fail to demonstrate the generalizability of the inverted prompts on different text-to-image models.\n7. The qualitative comparisons provided in this paper are very limited.\n8. No limitation section or ethic statement. Given the potential malicious usage of this method (e.g. to generate inappropriate contents), I would encourage the authors to include these sections."
            },
            "questions": {
                "value": "It would be great if the authors can address the weakness mentioned above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a gradient-free method, Visually Guided Decoding, that integrates LLMs and CLIP-based guidance to generate coherent and interpretable prompts for text-to-image generation. Compared to traditional methods, VGD can create readable prompts by using LLMs and optimizing these prompts with visual cues by CLIP scores. Experiments indicate that VGD outperforms existing techniques in prompt quality and interpretability on several datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- VGD produces coherent and human-readable prompts, facilitating user interaction and modification.\n- The training-free method allows easy integration with different LLMs, enhancing adaptability.\n- Demonstrates superior performance in generating contextually relevant prompts, as supported by both qualitative and quantitative results."
            },
            "weaknesses": {
                "value": "- This paper does not analyze bad cases. \n- The evaluation lacks depth, especially in semantic aspect evaluation. No human evaluation was conducted. Since image generation is a complex, semantically rich task, CLIPScore may not fully capture true image-prompt alignment, and its classification granularity is limited. Style transfer also requires human evaluation, but the paper only shows a few examples.\n- The paper evaluates only semantics without assessing image quality. There should be a discussion on whether using LLMs to create prompts could cause prompts to deviate from the training distribution, potentially lowering image quality."
            },
            "questions": {
                "value": "In what scenarios might the method generate inaccurate prompts?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduce Visually Guided Decoding (VGD), a gradient method that utilizes LLMs and CLIP-based guidance to generate coherent and semantically aligned texts. The experiment demonstrate that VGD outperforms existing prompt inversion techniques."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.  VGD generates fully interpretable prompts that enhance generalizability across tasks.\n\n2. VGD is a gradient-free method which is more flexible"
            },
            "weaknesses": {
                "value": "1. When apply to more complex open-source models with multiple text encoders like SDXL and SD3, as mentioned  in L220-222, the performance of the method would decline. What's more, when facing non-CLIP based models that utilize T5 as text encoders, the methods is quite limited.\n\n2.The current experimental analysis also appears insufficient.  While the method in the paper shows superior performance compare to previous method, it also should include the experiments about the time and cost for more comprehensive comparison."
            },
            "questions": {
                "value": "1. When using different model architecture like SDXL and SD3 for image generation, how to deal with the problem mentioned in L220-222.\n\n2. I would appreciate if you could conduct more experimental analysis about comparison between VGD and previous methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces Visually Guided Decoding (VGD), a gradient-free approach that leverages large language models (LLMs) and CLIP based guidance to generate coherent and semantically aligned prompts. VGD further uses LLMs to produce human-readable prompts while employing CLIP scores to ensure alignment with user-specified visual concepts. Experiments demonstrate that VGD outperforms existing prompt inversion techniques in generating understandable and contextually relevant prompts."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Nice written paper\n- The proposed approach is gradient-free which can save time.\n- Results in Fig 7 are good."
            },
            "weaknesses": {
                "value": "- Comparisons are missing with existing relevant methods which improve T2I generation by refining prompts  such as [1] and [2].\n- The score in Table are not consistent as LLaVA 1.5 + CLIP Interrogator is outperforming baseline in many cases.\n- CLIP can overly large similarity scores as is proved by many existing works. To get a sense of fine-grained similarity, other metrics should be tried.\n- Authors have shown that when different CLIP model is used, the approximation no longer holds. This is obvious because Diffusion model uses CLIP-ViT-B/16 which is aligned with Diffusion latent space, Some other CLIP model will not be in the same space and will ultimately not give good results. While this ablation is good, however, this is not novel and not necessary.\n- Overall, the paper is good, however, there are some concerns regarding the quantitative evaluations, missing comparisons with other existing works etc.\n\n\n\n\n\nReferences\n\n[1] Hao, Yaru, et al. \"Optimizing prompts for text-to-image generation.\" NeurIPS 2024.\n\n[2] Zhan, J., Ai et al. Prompt Refinement with Image Pivot for Text-to-Image Generation. ACL 2024."
            },
            "questions": {
                "value": "- Are baselines also evaluated across 5 runs like the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}