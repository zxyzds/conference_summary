{
    "id": "YR79EyejsG",
    "title": "Task-Unaware Lifelong Robot Learning with Retrieval-based Weighted Local Adaptation",
    "abstract": "Real-world environments require robots to continuously acquire new skills while retaining previously learned abilities, all without the need for clearly defined task boundaries. Storing all past data to prevent forgetting is impractical due to storage and privacy concerns. To address this, we propose a method that efficiently restores a robot's proficiency in previously learned tasks over its lifespan. Using an Episodic Memory (EM), our approach enables experience replay during training and retrieval during testing for local fine-tuning, allowing rapid adaptation to previously encountered problems without explicit task identifiers. Additionally, we introduce a selective weighting mechanism that emphasizes the most challenging segments of retrieved demonstrations, focusing local adaptation where it is most needed. This framework offers a scalable solution for lifelong learning in dynamic, task-unaware environments, combining retrieval-based adaptation with selective weighting to enhance robot performance in open-ended scenarios.",
    "keywords": [
        "Robotic Lifelong Learning",
        "Task-Unaware Continual Learning",
        "Episodic Memory Retrieval",
        "Visuomotor Behavior Cloning",
        "Error-driven Policy Adaptation"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=YR79EyejsG",
    "pdf_link": "https://openreview.net/pdf?id=YR79EyejsG",
    "comments": [
        {
            "summary": {
                "value": "This paper presents an imitation learning approach that enables a single network to learn from demonstrations of multiple tasks. It uses a vision language model and a local weighting mechanism to adapt the network towards the target task. The agent performs a few rollout episodes to assess policy performance, using this feedback for automatic selective weighting by comparing the rollouts with retrieved demonstrations without human intervention. The policy is subsequently adjusted to better align with the desired demonstrations."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The key idea has some merit, with some analogues to meta-learning approaches\n2. The related work is an interesting compilation of papers\n3. Figure 3 is well-illustrated, aiding in the exposition of the paper's ideas.\n4. PCA Visualization based on SS Model is quite interesting (Figure 4b)"
            },
            "weaknesses": {
                "value": "1. I have concerns regarding the overall presentation of the paper. While the idea holds merit as a novel imitation learning approach, the contributions are significantly overstated. In fact, I would argue that the paper does not fully address a lifelong learning setting. The authors should consider moderating their claims and clearly articulating the scope of their contribution.\n2. Many keywords are mentioned but not defined. For instance, what is meant by lifelong learning in this context? Evaluating a lifelong learning agent over only 20 episodes, as done by the authors, seems insufficient and misaligned with the intended concept.\n3. The discussion on unspecified task boundaries in real-world scenarios is also unclear and mischaracterized. Although the paper replaces a one-hot task encoding with an embedding from a vision-language model, this essentially still provides a form of task specification, albeit in a more implicit or 'fuzzy' manner. \n4. The related work section omits many papers that are highly relevant to the context. While the authors do include a few key references, surprisingly, there isn\u2019t a single paper cited from more than five years ago. I'd recommend the authors to look at the following: [1-6]\n5. There is no comparison of the concepts to meta-learning approaches such as [2]. I would argue that their approach resembles having a global network that is fine-tuned to the desired task during testing.\n6. The description of the experiments and their results is vague and difficult to follow. While I am confident that the authors are skilled and fully understand their work, I encourage them to consider readers like myself, who may be less familiar with it, by providing a more detailed explanation of their setup. For example, what specific tasks are being solved? Are the demonstrations focused on particular tasks? Does each task in the testing phase have a corresponding relevant demonstration?\n7. While the authors claim lifelong learning is important\u2014a sentiment I share\u2014it is unclear why their chosen evaluation setup suits this purpose. They could provide stronger justification for their design choices.\n\n\n**References**\n1. Finn, C., Abbeel, P., & Levine, S. (2017, July). Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning (pp. 1126-1135). PMLR.\n2. Finn, C., Yu, T., Zhang, T., Abbeel, P., & Levine, S. (2017, October). One-shot visual imitation learning via meta-learning. In Conference on robot learning (pp. 357-368). PMLR.\n3. Thrun, S. (1995, January). A lifelong learning perspective for mobile robot control. In Intelligent robots and systems (pp. 201-214). Elsevier Science BV.\n4. Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M., & Tuytelaars, T. (2018). Memory aware synapses: Learning what (not) to forget. In Proceedings of the European conference on computer vision (ECCV) (pp. 139-154).\n5. Aljundi, R., Kelchtermans, K., & Tuytelaars, T. (2019). Task-free continual learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11254-11263).\n6. Grollman, D. H., & Jenkins, O. C. (2007, April). Dogged learning for robots. In Proceedings 2007 IEEE International Conference on Robotics and Automation (pp. 2483-2488). Ieee."
            },
            "questions": {
                "value": "1. Please refer to the weaknesses section for responses to earlier questions.  \n2. Would you consider this approach a meta-learning method that aligns with the standard episodic reinforcement learning framework?  \n3. Isn\u2019t it true that the agent is aware of the task it\u2019s solving, meaning there\u2019s no true task boundary in the proposed evaluation?  \n4. How would this approach perform if only partial task demonstrations were available? Could it potentially combine these fragments to form a complete solution?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a framework for lifelong robot learning that operates without explicit task boundaries or identifiers. The approach combines retrieval-based adaptation with selective weighting to help robots maintain and restore previously learned skills. The method uses episodic memory for both experience replay during training and local adaptation during testing. When encountering a task, the system retrieves relevant past demonstrations based on visual and language similarities, identifies challenging segments through preliminary rollouts, and applies weighted local adaptation. The approach is evaluated on LIBERO benchmark variants."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "1. Originality:\n- Novel approach to handling task boundaries without explicit task IDs\n- Interesting combination of retrieval-based adaptation and selective weighting\n- Dual use of episodic memory for training and testing phases\n\n2. Quality:\n- Comprehensive experimental evaluation across benchmarks\n- Detailed ablation studies\n- Clear documentation of implementation details\n\n3. Clarity:\n- Well-structured presentation\n- Clear figures and visualizations\n- Detailed appendices\n\n4. Significance:\n- Addresses a relevant challenge in robotics\n- Shows potential for generalization across memory-based approaches\n- Demonstrates improvements over baselines in controlled settings"
            },
            "weaknesses": {
                "value": "1. Conceptual Contradiction:\n- Claims to be \"task-unaware\" but fundamentally relies on task-based retrieval\n- Still requires matching current scenarios with previously stored demonstrations\n- The evaluation is still conducted on clearly separated benchmark tasks\n\n2. Experiment:\n- All results are from simulation with no real-world validation\n- No analysis of failure modes or edge cases\n\n3. Technical:\n- Limited discussion of the impact of different hyperparameters\n- Memory requirements could become problematic with increasing task numbers\n- No discussion of potential catastrophic forgetting during local adaptation"
            },
            "questions": {
                "value": "- How is your approach fundamentally different from traditional task-based methods, given that it still relies on retrieving similar tasks?\n- What happens when encountering truly novel scenarios that don't match any stored demonstrations?\n- How do you justify the various manual thresholds in the selective weighting mechanism? Have you explored their sensitivity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work develops a novel approach for robotic control in a lifelong learning, multitask context without clear boundaries between tasks, suitable for real-world use. It uses episodic memory for experience replay and testing, allowing rapid adaptation to previously encountered tasks without explicit task identifiers. It is experimentally validated on the LIBERO benchmark and shows a significant improvement over baseline methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper focuses discusses a very important topic, that is robot learning in scenarios where there is no sharp boundaries between tasks, which is important for robots that operate in complex and noisy real world environments. The method is technically sound, and the empirical evaluation shows very good results."
            },
            "weaknesses": {
                "value": "My main concern is the magnitude of the uncertainties in Table 1. One of the main results is a difference between 45.17 \u00b1 31.86 and 34.08 \u00b1 28.55, which does not seem statistically significant - similar problems appear in the other results as well.\n\nPotentially related to that, lines 402-403 state that the algorithm is evaluated on three seeds: 1, 21, 42. This is a suspiciously arbitrary selection - why not 1, 2, 3? This makes me a bit concerned that the seeds were cherry-picked to select for the most convenient results."
            },
            "questions": {
                "value": "What is the practical computational cost of this method? As in, if I wanted to train a model using this approach, assuming I have all the code and hyperparameters, what kind of hardware and time would I need to go from nothing to replicating the paper's results?\n\nIs it viable to run additional experiments to tighten the uncertainties reported in Tables 1 and 2? As I understand, the standard deviation is based on the three seeds, and with a standard deviation this large, a larger sample and a proper statistical analysis would be very valuable.\n\nCan you comment on why the selected seeds are 1, 21 and 42? \n\n\nIf my concern about the uncertainty and potentially cherry-picking the seeds is answered, I will be happy to increase my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper investigates the problem of lifelong robot learning where catastrophic forgetting is a key issue. The paper proposes to do retrieval-based adaptation in lifelong learning process, finetuning the global policy model with memories of previous similar tasks. Despite the simplicity of the idea, the performance exceeds multiple baselines in the experiments. The paper is well-written, and the results support the claims well. I do have a few detailed questions hoping the authors could clarify during the discussion period."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well written and easy to follow, with the figures illustrative about core ideas. \n2. The idea proposed is simple yet effective, showing great potential. \n3. The results and benchmark comparisons are very well structured, clearly showing the support for certain questions outlined in Section 5. The ablation studies are also well structured with both quantitative and qualitative evidence. \n4. The introduction provides strong motivation for the lifelong robot learning problem."
            },
            "weaknesses": {
                "value": "1. Although the related work section is comprehensive, it lacks a clear description of how the current work distinguishes itself from the related work. I suggest authors add this information and the relationship between the current work with prior work in each subsection of the related work. \n\n1.1. Another work that looks into lifelong robot learning from demonstration is [1]. Could the authors possibly compare with it either conceptually or empirically? \n\n[1] Chen, L., Jayanthi, S., Paleja, R. R., Martin, D., Zakharov, V., & Gombolay, M. (2023, March). Fast lifelong adaptive inverse reinforcement learning from demonstrations. In Conference on Robot Learning (pp. 2083-2094). PMLR.\n\n2. The description about \u201cblurred task boundaries\u201d a little misleading. One would have thought blurred task boundaries mean there are no clear temporal boundaries between different task executions. However, the paper seems to take language-described robot tasks as blurred tasks as opposed to task labels, and there are clearly separated demonstrations among different tasks. I hope the authors could make the definition of \u201cblurred task boundaries\u201d clearer. \n\n3. I also find some parts of the methods are not precise. For example, it is unclear from Section 4.1 whether the retrieval is on the timestep-level or demonstration-level. It became clearer with later discussion that it should be demonstration-level, but adding a clearer pseudocode of the entire pipeline would be helpful. \n\n4. The abstract mentioned storing past data to prevent forgetting has privacy concerns. However, according to my understanding, the proposed method also requires storing the demonstrations in memory M for retrieval, thus having a similar problem. Can the authors discuss how this is handled in the proposed method?"
            },
            "questions": {
                "value": "Besides the points mentioned in weaknesses, \n1. How are the demonstrations generated? Did humans provide demonstrations or was the demonstrations generated by a well-trained RL policy? \n2. How are the hyperparameters tuned, especially the language and image distance weights $\\alpha_v$ and $\\alpha_l$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}