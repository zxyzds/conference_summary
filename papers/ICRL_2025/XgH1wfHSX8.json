{
    "id": "XgH1wfHSX8",
    "title": "Algorithmic Phases of In-Context Learning",
    "abstract": "In-Context Learning (ICL) has significantly expanded the general-purpose nature of large language models, allowing them to adapt to new tasks using merely the input context. While a series of papers analyzing synthetic domains have established a rich phenomenology of ICL, the use of relatively distinct setups makes it unclear how general the reported insights are. To address this, we propose a synthetic sequence modeling task defined by a finite set of Markov chains that simultaneously captures most well-known results on ICL, e.g., the task retrieval vs. learning dichotomy and emergence of induction heads, hence enabling a unified framework for studying the concept. As we show, the proposed task offers several new insights, such as an explanation for ICL's transient nature, and demonstrates subtleties in ICL's known phenomenology. For example, we find varying experimental conditions (e.g., data diversity) drives transitions between distinct algorithmic solutions, such as unigram vs. bigram models and Bayesian vs. non-Bayesian approaches, implying ICL is best thought of as a mixture of different algorithms, each with its own peculiarities, instead of a monolithic capability.",
    "keywords": [
        "In-Context Learning",
        "Circuit Competition",
        "Markov Chains",
        "Training Dynamics"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "In-context learning consists of phases of multiple algorithmic solutions, many phenomena are explained by this decomposition.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=XgH1wfHSX8",
    "pdf_link": "https://openreview.net/pdf?id=XgH1wfHSX8",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a new synthetic task, namely finite Markov mixtures, to study the properties of in-context learning (ICL) in Transformers. The authors present several analyses on top of finite Markov mixtures. First they show that this task alone can effectively recover known phenomena which were originally discovered on several different tasks like linear regression, classification, and finite automata. Then they contribute new insights, and argue that ICL is best thought of as a convex combination of several learning algorithms which emerge or vanish during training.\n\nOverall I found this work a well-written and interesting read, with several novel observations which are very relevant to the ICLR community. In particular, I appreciated the insight that ICL is best thought of as a mixture of learning algorithms, and that these algorithms are transient throughout training. It\u2019s main weakness is that It lacks a clear takeaway message for readers to act upon \u2014\u00a0see my questions below."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- **Well-written**. This expository work is well written and enjoyable to read. The authors do a good job at holding the reader by the hand through their analyses and provide adequate context even for non-ICL experts. The figure are easily understandable (mostly, see below for a nit) and the flow of the paper makes sense.\n- **Sound, novel, and unifying benchmark.** The benchmark is novel in the context of ICL studies and it is soundly derived (eg, using the expected KL as quality measure in Eq. 1). Some of the choices are arguable (eg, why Dirichlet?) but that\u2019s splitting hair. What\u2019s more interesting is that it reproduces known phenomena from the literature while also uncovering novel insights.\n- **Strong analysis revealing new insights**. The insight that ICL can be decomposed into several algorithms *at any point in training* is novel and deserves further thinking. Some may argue that the transient nature of ICL was known (the authors say so themselves) but this work goes one step further, showing the algorithms are not forgotten but rather superposed with different weighting coefficients (Fig. 6.b)."
            },
            "weaknesses": {
                "value": "- **Lack of actionable takeaway message**. Because the benchmark is synthetic, it\u2019s unclear how much it says about ICL for real-world LLMs. This is the main flaw of the paper. For example, l.81: it\u2019s good to know that Transformers can learn different algorithms \u2014\u00a0but which is it for LLMs / VLMs? Certainly not the unigram or bigram of l. 301, right? Similarly, I liked the flavor of paragraph on l. 301 but it\u2019s unclear how to replicate this study on real-world LLMs. This limits the insights into how real-world ICL really works, and so we\u2019re left with the question: what do we do with the discovery that ICL is best thought of as a mixture of algorithms? This work doesn\u2019t say which are the algorithms for real-world ICL, so we can\u2019t, e.g., prescribe which algorithm to surface and when.\n- **The Bayesian vs non-Bayesian discussion is unclear**. On l. 226 the authors argue that ICL first has a Bayesian and then a non-Bayesian behavior (they intentionally don\u2019t use the term frequentist), and that the Bayesian overfits to the training Markov mixtures. I think this distinction could be explained better. For example, one could make the argument that ICL is always Bayesian \u2014 otherwise what is transferred? \u2014 but the prior weakens as the model sees more diverse chains. In fact, the experiments support this line of thought: Fig. 5.b shows that as we increase the number of training chains, the prior weakens. In fact, I think believe this weakening of the prior is a property of how the Markov mixtures are constructed, and we would see a different behavior if the test chains where chosen differently. Note that this point  doesn\u2019t take away from the superposition analysis but it needs clearer explanations.\n- **Minor presentation issues**. The paragraph on l. 341 is not detailed enough, and doesn\u2019t explain what the Fig. 5 shows. It also doesn\u2019t help that Fig. 5 doesn\u2019t have clear legend on the heat map scales \u2014\u00a0is darker more Bayesian or less Bayesian for 5.b? Finally, some parameter choices in the analysis are weird: l. 187, why plot at train step 839 specifically? l. 192, why at n = 2^7? Can we have similar figures for later training steps and for larger n\u2019s in the Appendix?"
            },
            "questions": {
                "value": "See my questions in the weaknesses section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates the mechanisms of ICL under a unified framework. The authors developed a synthetic sequence modeling task using finite mixtures of MCs and studied various phenomena in this setting, including the task retrieval vs. learning dichotomy and emergence of induction heads. They were able to simultaneously reproduce most of these well-known results. Additionally, the authors proposed that ICL is best understood as a combination of different algorithms rather than a single capability -- model configurations and data diversity impact transitions between these algorithms. This shows that ICL behavior can shift based on training data properties."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Very detailed and sound study of the ICL mechanism: varying task diversity, training steps, context length, and evaluating on various metrics. This is a very empirically rigorous study that verifies previous literature by reproducing various well-known results within a single setting.\n\n2. Some analysis on how model design affects downstream performance on various metrics."
            },
            "weaknesses": {
                "value": "My main concern with this paper is its novelty: as the authors have correctly noted, many of the results presented here have already been explored in existing literature. While this paper offers a valuable unifying study that synthesizes and reproduces previous findings in a single framework, the setting itself has also been examined in prior work (e.g., Edelman et al.). Consequently, the overall message lacks new insights."
            },
            "questions": {
                "value": "The Bayesian vs. Non-Bayesian comparison: Generally, I think of Bayesian learning as a form of \"learning to learn,\" where a posterior is updated based on observed data according to Bayes' rule, with a prior typically established during pre-training. Therefore, it is unclear why the comparison between ID and OOD performance specifically reflects a shift between Bayesian and non-Bayesian paradigms. In particular, the analogy between \"task-retrieval\" vs. \"task-learning\" and Bayesian vs. non-Bayesian, in my view, does not fully capture the essence of Bayesian inference.\n\nIn a Bayesian approach, one would ideally follow Bayes' rule to update an implicit or explicit posterior or posterior predictive distribution. Given this, shouldn\u2019t the KL divergence be examined between the model prediction and the true posterior or posterior predictive distribution (according to Bayes' rule and the correct prior) at each context length (so given the same context of length $l$, examine at each step from $1,\\dots, l$)?\n\nI understand that you may be viewing task-retrieval vs. task-learning as a contrast between in-weight learning (IWL) and meta-learning. However, this distinction could also be seen as reflecting a finite, discrete prior versus a continuous or uniform prior. The true Bayesian vs. non-Bayesian distinction, perhaps, is whether the model has learned to correctly update a posterior (i.e., learned Bayes' rule) and has fitted an accurate prior."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce a new ICL synthetic task that consists of sampling from a finite mixture of Markov chains. Their setting reproduces several ICL phenomena, and through extensive analyses, the authors also report results on phase transitions between different algorithms."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "I think this is a nice, comprehensive paper that introduces a simple setting that unifies many recent papers on ICL and captures analogous phenomena (task diversity thresholds, transience of ICL). For example, Figure 3 basically reproduces the results of two previous papers. \n\nThe experimental protocols for assessing bigram utilization and proximity to the Bayesian solution were thoughtful and creative.\n\nI like the idea of approximating the transformer\u2019s behavior as a mixture of algorithms. It\u2019s interesting that this can be used to predict OOD and that it highlights a sort of \u201cpersistent competition\u201d between implementing different algorithms. This potentially provides a compelling explanation for phenomena like transience. \n\nThere\u2019s also a comprehensive set of ablations that study the impact of width and data complexity etc\u2026\n\nOverall, the paper was fairly clear."
            },
            "weaknesses": {
                "value": "First of all, I want to emphasize that I think this line of work is valuable and scientifically meaningful. However, it would be nice to discuss how these insights translate into practical design choices (e.g., predicting OOD performance using a similar approach to this paper). \n\nI think one major premise of the paper is that there\u2019s a transition between different algorithms. \nI think this is convincing. However, I think I want some kind of control condition where you use 3 or 4 different \u201csilly\u201d algorithms just to confirm that these kinds of phase transitions aren\u2019t some artifact of fitting some linear combination of algorithms and that, if your algorithms are not related to the task, you don\u2019t always see these interesting algorithm phase transitions. \n\nI think I also wanted a bit of better understanding on how well LCA predicts the performance of the transformer relative to some naive baselines just to confirm that LCM well approximate the transformer."
            },
            "questions": {
                "value": "This paper identifies a number of these interesting phenomena, but it would be nice if the authors could discuss a bit more about why these phase transitions occur. For example in the LCA analysis, why is there rich structure in these phase transitions when you might (naively) expect a smooth increase in the weights on the optimal solution (e.g., Bi-ICL) and roughly uniform weight on the other solutions? Can you study the properties of the loss function (e.g., Hessian) at these different phase transition points?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "With this paper the authors contribute the following:\n\n* The authors propose a new sequence modelling setting, namely learning to\n  predict sequences sampled from a Markov chain sampled from a finite mixture\n  of Markov chains.\n  * This is similar to the variable 'task-diversity' in-context linear\n    regression setting from Raventos et al., but using Markov chains rather\n    than a regression model to generate sequences following Edelman et al.\n\n* The authors list four idealised algorithms for solving this sequence\n  modelling setting, along two axes of variation, namely:\n  * observing either unigram statistics (states) or bigram statistics\n    (transitions), and then\n  * making predictions by leveraging knowledge of the latent mixture of\n    Markov chains, or based solely on the observed frequencies in the\n    context.\n\n* The authors devise a pair of tests for distinguishing a learned predictor\n  along these two axes, and in doing so reveal that depending on the degree\n  of task diversity, the sequence length, and the number of training steps,\n  small transformers trained for this task will behaviourally resemble each\n  of these four algorithms. This creates the titular 'algorithmic phases'.\n\n* The authors propose a behavioural analysis method, \"Linear Combination of\n  Algorithms (LCA)\" whereby they decompose a transformer's outputs (given\n  in-distribution inputs) into a mixture of the outputs of the four idealised\n  algorithms. The decomposition is made by projecting the outputs onto the\n  probability simplex spanned by the four algorithms in function space.\n  The authors track this decomposition over training and observe a close\n  alignment between trends in the weight of certain algorithms and trends in\n  out-of-distribution generalisation including the \"transience\" phenomenon.\n\n* This phase isolation methodology and auxiliary metrics replicates a number\n  of phenomena reported in prior works on ICL in similar and disparate\n  settings, and some new phenomena. In the main text, the emphasis is on the\n  following three phenomena:\n  * The authors find a 'task diversity threshold' at which transformers\n    switch from learning to leverage knowledge of the pre-training task\n    distribution to learning to generalises to unseen Markov chains. This\n    finding is analogous to that of Raventos et al. for in-context linear\n    regression.\n  * The authors find that in certain phases transformers develop statistical\n    induction heads, replicating the finding of Edelman et al. in a similar\n    setting based on infinite mixtures of Markov chains, but for finite\n    mixtures of Markov chains.\n  * The authors show that with increased training time individual\n    transformers shift from initially adopting a generalising method to\n    eventually preferring one that leverages information of the training\n    mixture. This is somewhat analogous to the \"transience\" phenomenon\n    reported by Singh et al.\n  * The authors also claim to replicate other phenomena, but I am less\n    familiar with these other phenomena and the details are excluded from the\n    main text, so I have not been able to evaluate them.\n\n* The authors argue that their finite mixture of Markov chains setting\n  offers a unified setting in which to study the emergence of in-context\n  learning, which has previously been studied in disparate settings.\n\n**Summary of my review:**\nI was impelled to write a long review. So, I also include a summary of my\nreview here.\n\n* I think the authors have made a strong contribution in an important area of\n  the science of deep learning. Their setting is elegant, expressive, and\n  permits an interesting variety of idealised solutions. The results from\n  their phase isolation and LCA analyses are interesting and informative.\n\n* However, I think the claims made in the paper at times overstate the\n  results or are overly confident given the limitations of the methodology,\n  which are not adequately discussed. In particular:\n  * The phase isolation methodology is incapable of ruling out plausible\n    alternative algorithms undermining the authors' claims that they have\n    knowledge of what algorithms the transformer is implementing.\n  * The \"linear combination of algorithms\" methodology, while revealing\n    interesting behavioural dynamics, does not seem to me to be worthy of\n    being called \"mechanistic\" nor an \"explanation\" of the transience of\n    particular algorithms or other phenomena.\n  * The motivation for proposing a new setting is to unify disparate studies\n    on the emergence of ICL, however the proposed setting is not uniquely more\n    appropriate for this purpose than alternative settings.\n\n* I believe that the framing is sufficiently misleading that I cannot\n  recommend the paper for acceptance in its current state. However, if the\n  authors are able to back up their confidence or if they commit to tempering\n  their claims then I would be happy to recommend the paper for acceptance\n  because I didn't note any major technical flaws and I think the work is\n  important and interesting.\n\n* In addition, I note a number of additional questions and more minor\n  concerns including about the naming of the \"-ICL\" algorithms and some\n  details of the setting and results, detailed in the questions section of\n  this review.\n\nI look forward to the discussion period."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "As I said I think this is a strong paper. I note at least the following\nstrengths.\n\n1. The paper is well-motivated by the importance of of understanding the\n   emergence of algorithmic structure inside transformer sequence models,\n   which is a priority for the science of deep learning.\n\n2. To this end the authors contribute a neat setting with a clean and flexible\n   data generating process and an interesting and rich collection of idealised\n   solutions.\n   * This setting can also serve as a solid basis for future work, experimenting\n     in the same setting or extending it to (for example) higher-order,\n     non-Markovian sequence modelling tasks, hidden Markov models, etc., all\n     of which are immediately suggested by the authors' framework.\n\n3. The authors have also conducted a comprehensive study of the numerous axes\n   of variation in this setting.\n   * The replications of phenomena found in prior work is valuable.\n   * The classification of the configuration space into qualitatively distinct\n     behavioural 'phases' is quite striking.\n   * The LCA analysis is thought-provoking.\n \n4. The LCA technique, carefully interpreted, is an elegant idea for\n   behavioural analysis of models in general, when plausible candidate\n   algorithms are known. I like it and I think I would use it (I have noticed\n   several opportunities to use this in my research since seeing it in this\n   paper.)\n\nOverall I think the paper makes a valuable contribution that enriches our\nunderstanding of ICL phenomenology and creates a rich framework for future\nresearch that can continue exploring this important topic."
            },
            "weaknesses": {
                "value": "### W1. Insufficient evidence for confidence in algorithmic phase identification\n\nThe authors chose to name their paper 'algorithmic phases of in-context\nlearning'. I am a believer in the importance of names and I think this gives\nme grounds to assume that the authors view their labelled phase diagrams as a\nmajor element of their contribution.\n\nI consider this labelled phase diagram to have two distinct parts. The first\nof which is the division of the hyperparameter space into regions where a\ntrained transformer displays distinct modes of behaviour as quantified by the\nbehavioural classification metrics outlined in section 4.2 'isolating\nalgorithmic phases'. I am impressed by this part of the contribution.\n\nI am concerned about the second part, namely the labelling of phases with\nspecific algorithms. The authors confidently association of each of the four\nbehavioural phases with one of the four algorithms described in section 4.1\n'the Bayesian and non-Bayesian solutions of finite Markov mixtures'. I am\nconcerned that the authors have not secured sufficient ground from which to\nconfidently present these algorithms as uniquely accurate descriptions of the\ntransformer's behaviour in each phase.\n\n**Phase isolation is not exhaustive:**\nThe phase identification methodology appears to assume a priori that these\nare the only plausible algorithms, as if that were the case, then it would be\nsufficient to associate these algorithms to each phase. However, these\nalgorithms do not appear to me to be *uniquely* principled ideal models of\nhow a sequence model might solve the Markovian prediction task, so I do not\nthink it appropriate to rule out *a priori* the many other possible\nalgorithms that could explain similar behavioural patterns and would be a\nbetter 'label' for each phase.\n\nA short list of other algorithms I can think of is as follows:\n\n* **Unigram- or Bigram-likelihood Bayesian Averaging with a different\n  prior:** An algorithm that functions like Uni-Bayes or Bi-Bayes, but uses a\n  different task prior probability vector as a starting point for formulating\n  its posterior predictive distribution.\n\n* **Unigram- or Bigram-likelihood MLE or MAP:** An algorithm that functions\n  like Uni-Bayes or Bi-Bayes in weighing the likelihood of each task for\n  describing the sequence in front of it, but then rather than performing\n  Bayesian averaging to make predictions, simply predicts based on the\n  most likely task (possibly accounting for the task prior).\n\n* **Slight modifications of frequency counting approaches:** An algorithm\n  that functions like Uni-ICL or Bi-ICL but uses slight modifications to\n  frequency counting such as starting the count for each unigram from epsilon\n  instead of zero or similar for bigrams, or increasing the predicted\n  proportions non-linearly in the counts.\n\nThese algorithms are close in function space to the proposed algorithms so\nthat it were the case that these were more accurate descriptions of a\ntransformer's behaviour, this would not show up in the phase isolation\nmetrics (nor in the LCA analysis which is based on projections in function\nspace---the above algorithms would be nearby in function space and so\nprojections would be similar). The only ways to rule out these alternatives,\nalong with every other algorithm, would be to devise specific tests to probe\nthe behavioural differences between these algorithms and the proposed\nalgorithms, or to probe the internal computational structure of the\ntransformers to seek to distinguish the mechanisms underlying their\nbehaviour.\n\n**On appendix E and mechanistic analysis:** I did notice that the authors\nalso include additional experiments in appendix E that investigate the\nactivation patterns in various locations inside the transformer. However,\nthese experiments are insufficient to rule out the alternatives to Bi-Bayes\nand Uni-ICL I have listed above, since for example counting transitions is\nalso consistent with these alternative algorithms. There are no mechanistic\nexperiments into Uni-Bayes. It appears the authors have more evidence\nconsistent with Bi-ICL than the other algorithms including the presence of\nstatistical induction heads, but the broader point stands.\n\n**Overall:**\nTo be clear, I believe that the algorithms proposed by the authors and their\nexperiments are novel and significant. Given the infeasibility of uniquely\nassociating a particular principled algorithm with a phase, it seems fine to\nme to start with approximate behavioural resemblance. I think this is what\nthe authors have grounds to claim they have contributed---a 'fuzzy' label for\neach phase that serves as an initial proxy for what the transformer is going,\nand this is worth sharing with the research community.\n\nHowever, I also strongly believe that the authors have an essential\nresponsibility to clearly articulate the status of their labels. I am\nconcerned that in the current form the reader will draw the as-yet\nunwarranted conclusion that, for example, transformers perform Bayesian model\naveraging (in the appropriate phases). While the algorithmic variations I am\nproposing are also deviations from 'optimality' as the authors have framed\nthe problem, it seems an open question to what extent transformers implement\n'optimal' algorithms and to me, modelling the specific variations from\noptimality in the pre-trained transformer is an important direction for\nfuture work and it is not yet time to declare that the algorithms have been\ndefinitively identified even in this simple setting.\n\n**Requested revisions:**\nI would be welcome the authors to correct my understanding of their\nmethodology and its limitations, or correct my reading of their confidence.\nOtherwise, until this framing issue has been addressed the paper is unfit for\npublication in my judgement. I would suggest that the authors commit to the\nfollowing revisions.\n\n1. The authors should amend their presentation to refrain from claiming that\n   the transformer implements these particular algorithms. Some examples of\n   language I think is unwarranted include (not exhaustive):\n   * Generally in the abstract and introduction any mention of the finding\n     that the transformer uses specific mechanisms such as \"use of unigram\n     vs. bigram context statistics\", though it is unavoidable that some\n     qualifications must be left to subsequent pages and this is not\n     necessarily a sufficient priority in the introduction.\n   * Line 222 \"we ... show ... the model selects between these solutions ...\"\n   * Line 295 \"We now demonstrate the four algorithms proposed above\n     perfectly delineate models trained on our task into explicit phases\".\n   * Line 345 (emphasis in original) \"*Based on these results, we claim our\n     proposed algorithmic solutions successfully explain the different\n     mechanisms employed by the model to solve our finite mixture of Markov\n     chains task.*\"\n   * Generally section 5 continues under the presumption that the transformer\n     \"is implementing\" the algorithms from section 4.\n   * Line 527/528: \"to write down four algorithmic solutions ... and identify\n     their existence in a trained model\".\n\n2. The authors should note prominently and explicitly in the paper (for\n   example when introducing their methodology, in the conclusion, or in a\n   dedicated 'limitations' section) that their methodology is insufficient to\n   rule out other algorithms as being a more accurate description of each\n   phase.\n\n\n\n### W2. LCA is not mechanistic and does not offer a new explanation\n\nThe proposed LCA techniques is described in the abstract, introduction and\nfigure 1 caption as a \"mechanistic analysis\" offering a \"new\" \"causal\nexplanation\" of transient OOD generalisation. The terms \"mechanistic\" and\n\"explanation\" are repeated throughout section 5. I do not see grounds for any\nof the terms \"mechanistic\", \"causal explanation\", or \"new explanation\" to be\nused in describing this methodology.\n\n**On \"mechanistic\":** It is inappropriate to call LCA a mechanistic\ndecomposition. The tool is clearly based on analysing (in-distribution)\nbehaviour, and it does not reliably reveal internal mechanisms (though it may\ndo so, or approximately so, in this case). Accordingly, this analysis should\nbe called \"behavioural\" rather than \"mechanistic\".\n   \nI suppose the authors are using the word \"mechanistic\" because they believe\nthat LCA has identified the algorithm implemented by the transformer, and\nthat this is confirmed by the fact that the in-distribution behavioural\ndecomposition is predictive of out-of-distribution behaviour. It may very\nwell be the case that the transformer implements a coherent mechanism and\nthat LCA has, in this case, identified it (or approximately identified it).\nHowever, LCA is incapable of revealing the mechanistic nature of a general\ntransformer, and so this reasoning is not sound.\n\n1. As I argue in the previous section I do not believe they have grounds for\n   this, and have only roughly categorised the behaviour rather than\n   identified the precise algorithm. LCA will find a decomposition in terms\n   of any list of algorithms given to it. If the true mechanisms inside the\n   transformer are not represented, it will identify the behaviourally\n   closest algorithms as comprising the behaviour.\n\n2. LCA actually makes it clear that the transformer in some sense implements\n   multiple algorithms, not one algorithm, at many points during training,\n   since the mixtures are not concentrated. While the authors call this a\n   'competition' between algorithms, they have not given any mechanistic\n   model of this apparent competition. There are many possible internal\n   mechanisms that would lead to such an apparent 'competition' appearing in\n   the LCA decomposition, some of which would not even correspond to a proper\n   competition but would rather be artefacts of the projection in function\n   space.\n\n3. In this case that the transformer's (lack of) reliance on pre-training\n   task statistics is recoverable from in-distribution behaviour and then\n   this prediction is validated on out of distribution behaviour, this does\n   indicate that the tool happens to have uncovered part of the transformer's\n   mechanism in this case. However, LCA would make the same predictions for a\n   transformer constructed or trained to follow one mechanism in-distribution\n   while following another mechanism out of distribution.\n\nBecause it only measures behaviour, LCA should not be called mechanistic. The\npredictive power in this case is not coming from LCA but rather from the\napparent fact that the transformer happens to have roughly the mechanism the\nauthors expect.\n\n**On \"new explanation\":** The authors also claim that tracking the LCA\ndecomposition over training reveals an explanation of the phenomenon of the\ntransience of out-of-distribution generalisation posed by Singh et al. This\nexplanation is described in the abstract as a \"new insight\".\n\nAs far as I can tell (the authors can correct me here if I have missed\nsomething), by \"explanation\", the authors refer to their observation that\nthe shift in generalisation coincides with a shift in the transformer's\nalgorithm from predominantly resembling Bi-ICL to gradually increasingly\nresembling Bi-Bayes later in training. The authors also observe that Bi-Bayes\nis a better solution according to the training distribution, so this shift is\nin turn explained by the learning algorithm pursuing better on-distribution\nperformance.\n\nI think there are a number of problems with the framing of these observations\nas a new explanation of Singh et al.'s transience derived from LCA.\n\n1. First, it is not clear to me that the observations go beyond what was\n   already reached in Singh et al.'s original paper. In that paper, they\n   already talk about one algorithm, ICL, being replaced with a different\n   algorithm, \"in weight learning\" (IWL) with worse generalisation\n   performance. The authors of the present paper are pointing to a similar\n   trend arising in their replication, but they now have slightly more\n   specific models of the algorithms.\n\n2. Second, note that actually there is an important difference between this\n   setting and that of Singh et al.'s transience. Namely, in Singh et al.,\n   the ICL and IWL algorithms by construction are equally performant on the\n   training distribution. This is a crucial difference in this case. As the\n   authors note, in this case, Bi-ICL giving way to Bi-Bayes is even less\n   mysterious than ICL giving way to IWL in Singh et al., beacause this is\n   driven by the in-distribution performance.\n\n   A closer analogy to the setting proposed in the present paper comes from\n   related work on in-context linear regression. Hoogland et al. (cited by\n   the authors) and (slightly earlier and in more detail under the name of\n   \"forgetting\") in the paper by Panwar et al. \"In-context learning through\n   the Bayesian prism\" (from 2023, on arXiv before Singh et al. was published\n   actually). These works observe that in the Raventos et al. setting, a\n   generalising algorithm gives way in favour of a training-task-dependent\n   algorithm, driven by improved in-distribution performance and with a\n   concomitant drop in out-of-distribution generalisation performance.\n\n3. Third, given this prior work, upon reading the abstract I was expecting\n   perhaps some deeper explanation for what actually drives this phenomenon.\n   For example, some insight into why the transition occurs at a given period\n   during training or at a given rate, or why the generalising performance\n   was preferred in the first place. I could not find any such deeper result\n   in this paper.\n\n4. Finally, I do not see a connection between LCA specifically and this\n   explanation. The transition from Bi-ICL to Bi-Bayes would also show up as\n   a shift in the proximity to Bayesian solution metric from the phase\n   isolation methodology in section 4. I see no reason to attribute this\n   explanation to LCA.\n\nI certainly believe LCA offers a particularly crisp behavioural perspective\non this transition. But given all this, I think a more appropriate framing\nfor the authors' contribution would be to say that in addition to replicating\nthe transience phenomenon, the authors have used LCA to offer a new and\ndetailed perspective on the (behavioural) competition between algorithms\nalready thought to underlie the phenomenon of transient generalisation.\n\n**On \"causal explanation\":** As far as I can tell, \"causal\" is only mentioned\nin the introduction. I don't see any grounds for its inclusion here at all. I\nsuggest it should be removed.\n\n**Overall:** I believe LCA is an interesting and useful behavioural\ntechnique, but unless the authors can persuade me otherwise I am strongly\nopposed to the framing in the introduction and throughout section 5 that the\ntechnique is capable of offering mechanistic insights or that it has offered\na new explanation of the phenomenon of transient generalisation in in-context\nlearning.\n\n\n### W3. The motivation in terms of unifying and generalising phenomena is inaccurate\n\nUpon first reading the abstract and introduction I understood this paper to\nbe claiming that there is a need for:\n\n1. an assessment of whether existing phenomenology are specific to the\n   settings in which they were first found or whether they generalise to\n   other settings and are thus more likely to be inherent features of ICL,\n   and \n2. a unified setting in which the various phenomena of ICL that have been\n   studied in prior work can all be studied in one place.\n\nThe authors don't seem to be positioning this as a motivating vision toward\nwhich they are contributing a 'first step' or something 'in this direction'.\nRather, they say for example in the abstract that their work \"enables a\nunified framework for studying\" ICL. In the introduction they claim that\nfindings from prior work may be \"disparate findings that manifest in specific\nscenarios\".\n\nI think this motivating story is not an accurate description of the state of\nthe field and I think the degree of unification achieved in the paper is\nstrong but not as strong as the authors claim on this first page.\n\n**On generalisation:** It appears to me that the authors have indeed provided\na novel contribution by 'generalising' several prior phenomena by exhibiting\nthem in a new setting. This is indeed a valuable contribution. However, it\nappears that most of these phenomena have already been exhibited in multiple\nsettings, so it is inaccurate to claim that the phenomena were previously\nonly known to hold in isolated settings.\n\n* In the case of the task diversity threshold, the authors have generalised\n  this to the Markovian sequence modelling setting. Previously, it was shown\n  for in-context linear regression (Raventos et al.), along with image\n  classification (Kirsch et al.) as cited by the authors. The same phenomenon\n  has recently been shown in a multi-task modular addition setting by He at\n  al. in a recent preprint \"Learning to Grok: Emergence of in-context\n  learning and skill composition in modular arithmetic tasks\".\n\n* In the case of the emergence of statistical induction heads, there is only\n  a very minor generalisation taking place since statistical induction heads\n  were already shown by Edelman et al. to arise in Markovian sequence\n  modelling with infinite mixtures of Markov chains. The generalisation to\n  finite mixtures of Markov chains is, in my opinion, valuable but not very\n  surprising especially given that the original exhibition of induction heads\n  by Elhage et al. and Olsson et al. was in the completely distinct setting\n  of language modelling.\n\n  Moreover, I am not aware of induction heads being found in other settings\n  such as in-context linear regression. If any ICL phenomenon is isolated to\n  certain settings, this suggests that induction heads represent such a\n  phenomenon.\n\n* In the case of transience, it's true that Singh et al. study a specific\n  scenario that is designed specifically to isolate this phenomenon, but it's\n  not true that their findings have not been replicated in other settings.\n  In the previous section I already noted work noting transient\n  generalisation for in-context linear regression including Hoogland et al.\n  (already cited by the authors) and the earlier work by Panwar et al.\n  Beyond in-context linear regression, He et al. \"Learning to grok\"\n  (mentioned above) have also demonstrated transience in in-context modular\n  arithmetic.\n\n  These examples actually seem more relevant to the present work than Singh\n  et al., as they concern transitions between two different ICL algorithms,\n  rather than between ICL and pure memorisation as in Singh et al.\n\n* (I have not evaluated the novelty of generalising the other phenomena, as I\n  am less familiar with these parts of the literature, and moreover the above\n  three phenomena are the ones the authors discuss in the main text.)\n\nOnce again, I believe the authors have made a strong contribution, but my\nconcern is that they have not accurately described it in their abstract and\nintroduction, and they need to reframe their contribution in a more accurate\nmanner in my opinion.\n\n**On unification:** Moreover, I did not find the motivation in terms of\nunification compelling.\n\nTo me it seems like the extent of a 'unification' achieved by the authors is\nthat they have combined multiple interesting axes of experimental variation\n(e.g. studying models at varying task diversity and training time) previously\nvaried individually in prior work. They have created one setting rich enough\nto include these axes of variation, and they have demonstrated that along\neach of these axes previously studied phenomena are replicated in their\nexperiments. I will repeat that I find this comprehensive investigation of\nthe axes and their combinations is a strong contribution.\n\nHowever, in describing this contribution, 'unification' seems too strong of a\nword. When I read the word unification, I think the prior settings should be\nrecoverable as special cases of a more general setting. Operationally, the\nfield should be able to continue forward by discarding previous settings in\nfavour of using a truly 'unified' setting. I think this standard has not been\nmet by the proposed setting. Rather, if the field universally adopted the\nproposed setting, at least the following research directions would be\nprecluded.\n\n1. Different settings encourage different mechanistic solutions in the\n   transformer's internals. For example, while the Markovian setting allows\n   one to study statistical induction heads, one does not have the ability to\n   study the particular mechanisms that emerge in order to perform in-context\n   linear regression or modular arithmetic. For the field to make progress on\n   mechanistic analysis of in-context learning in transformers, it seems\n   useful to be able to take advantage of the various constructions that have\n   been proposed for specific implementations of in-context linear\n   regression, for example. I don't see why we shouldn't try to keep our\n   range of interesting synthetic settings as broad as possible.\n\n2. Another example comes from the quite specialised setting studied by Singh\n   et al., where, by construction, ICL and IWL are equally performant on the\n   training distribution. Nevertheless, there is still an algorithmic\n   transition between these algorithms at some point in training. This gives\n   rise to questions that can't be asked or answered in a setting where the\n   main four algorithms achieve quite different performance in-distribution,\n   such as what drives the transition even in this case (when the need for\n   better in-distribution performance is ruled out as an explanation for\n   driving this transition).\n\nThe authors have included appendix G with some discussion on the perceived\nbenefits of studying Markovian sequence modelling tasks rather than modular\narithmetic or linear regression due to the lack of \"sequence space structure\"\nin these alternative settings.\nI must admit unfortunately I did not follow the discussion despite trying to\nsee their point of view. It is not immediately clear to me what sequence\nspace structure means. But if the authors refer to the fact that in Markovian\nsequence modelling in order to count bigrams the transformer must look at\npairs of tokens, I note that even though modular arithmetic and linear\nregression are usually formulated in-context using an i.i.d. sequence of\ninputs, it is still necessary for example in Raventos et al.'s setting for\nthe transformer to look at pairs of sequence items (one containing the x and\nthe next the corresponding y). It is not clear to me how this is less rich\nthan looking at bigrams.\n\n**Overall:** I can't emphasise enough, I really like the setting and the\ncomprehensive analysis along multiple axes. I am only concerned that the\nintroduction does not provide an accurate motivation for the work, and I\nwould like to respectfully challenge the authors to lay out a stronger case\nfor their contributions in their introduction. Doing so, in my opinion,\nshould not be too hard, because the authors have made some strong\ncontributions on an important topic."
            },
            "questions": {
                "value": "I collect various questions, minor concerns, or suggestions that occurred to\nme while reading the paper. Given the length of my review I don't expect the\nauthors to respond to all of these questions (though I would be happy for\nthem to do so). If the authors are interested in me revising my decision and\nhave limited capacity in the discussion period I would recommend that they\nengage with me on the three weaknesses before the contents of this section.\nMore importantly I hope that they might consider my questions and suggestions\nand consider revising the paper to improve the presentation as they find most\nappropriate.\n\n**Q1. The four algorithms have unclear and misleading names.**\nAs I said, I am a believer in the importance of names. I felt strongly that\nthe choice to use '-ICL' as a suffix in the names of 'Uni-ICL' and 'Bi-ICL'\nis a mistake that undermines the quality of the paper. By selecting these\nnames the authors have at the same time created the following two problems.\n\n1. They have conflated one half of their list of algorithms with the concept\n   of in-context learning, entrenching a false connotation that these two\n   algorithms are more exemplary instances of ICL algorithms than others, in\n   fact that the Bayesian solutions are not classified as ICL.\n   This contradicts the authors' stated message in the abstract and\n   conclusion, that ICL is an umbrella concept that encompasses multiple\n   concrete algorithmic instantiations. Recalling again the paper's title,\n   all four phases are supposedly 'of in-context learning'.\n   I do not think that the authors mean to hold up Uni-ICL and Bi-ICL as\n   'truer' examples of ICL than the 'Bayesian' algorithms, yet this is what\n   their naming choice achieves.\n\n2. They have missed an opportunity to communicate what is unique about these\n   particular ICL algorithms. This is the role played by 'Bayes' in the names\n   'Uni-Bayes' and 'Bi-Bayes' (in my reading this helpfully conveys that the\n   methods use Bayesian averaging). I leave it to the authors to decide what\n   would be an appropriate analogue of 'Bayes', but I invite them to consider\n   using the term 'frequencies' or 'induction' and I urge them to avoid\n   anchoring on induction *heads* themselves (a feature of transformers\n   rather than ideal algorithms) or using the misleading 'non-Bayesian'\n   terminology of Raventos et al.\n\nI respect the right of the authors to name the algorithms. I can't say this\nconcern alone would prevent me from recommending the paper's acceptance.\nHowever, in this case I feel strongly enough to register my protestation\nabout the names given my fresh perspective on the algorithms and the authors'\nchosen takeaway message.\n\n\n**Q2. Inconsistent summary of algorithms between main text and figure 4\ncaption:** In the figure caption, the Uni-Bayes and Bi-Bayes descriptions\ntalk about selecting a 'closest task' from the mixture. Based on the main\ntext, my understanding is that they do not select a single task but rather\nthey form a posterior distribution over all tasks and use the posterior\npredictive distribution to make their prediction. Using the 'closest\ndistribution' sounds more akin to using a maximum likelihood distribution,\nrather than using the posterior predictive distribution.\n\n**Q3. Questionable choice to use a nonuniform task prior:** If I understand\ncorrectly from the setting description, the authors sample a prior vector\nfrom a uniform Dirichlet distribution over task priors. The resulting prior\nwill be almost certainly non-uniform and with high likelihood for high task\ndiversity it will have a small number of tasks with quite large\nprobabilities and a large number of tasks with very small probabilities. It\nfollows that after a reasonable amount of pre-training there may be some\ntasks that have barely been sampled at all.\n\nThis seems to me to be a significant departure from the use of task diversity\nby of Raventos et al., for whom, if I remember correctly, the task prior is\nalways uniform. I believe that having a skewed task distribution may confound\nexperiments since what I would call the 'effective task diversity', meaning\nroughly the number of tasks the transformer has to 'memorise' in order to get\ngood performance on in-distribution evaluation (assuming tasks are sampled\nfrom the same skewed prior for ID evaluation) will be smaller than the\nspecified task diversity, since the transformer can get away with not\nremembering low-probability tasks.\n\nThe inclusion of this additional complication appears to be unjustified by\nany particular argument in the manuscript. I would be curious if the authors\nhave a strong reason for including this detail. Of course, it is a virtue of\nthe setting that one can consider different distributions of tasks, since\nthis might be an interesting direction for future work, but such work would\nsurely involve *systematically* varying the prior rather than abdicating\ncontrol over the prior by sampling it from a high-dimensional Dirichlet\ndistribution.\n\nFinally I note that it is regrettable that this detail appears to be\ndocumented only in the appendix.\n\n**Q4. Convoluted phase isolation tests:** These test seems very intricate. It\nis not clear to me that they are the clearest ways of isolating phases, and I\nwonder if you have considered and ruled out simpler alternatives.\n\n1. For the bigram utilisation test, it occurs to me that the predictions of a\n   model paying attention exclusively to unigram patterns would not vary much\n   depending on the current state (at least late in the sequence). On the\n   other hand, bigram-based models would vary their prediction based on the\n   state. Therefore, I wonder if you have considered a simpler test of\n   somehow quantifying uniformity in the set of rows of the revealed\n   transition matrix?\n2. For the proximity test, I wasn't able to think of a simpler test, beyond\n   the idea that perhaps something with generalisation performance could be\n   used.\n\n**Q5. Missing details for proximity test:** I was left wondering about some\ndetails of the proximity test. Unless I missed something, I would recommend\nclarifying the following points, if possible in the main text or otherwise by\nexpanding on the 'additional details' in the appendix.\n\n1. How is distance to a set of tasks defined? Is it the distance to the\n   closest member of the set?\n2. Does the measurement of distance to the training task set account for the\n   task prior at all? I am concerned that for example if the closest task in\n   the training set happens to be a task with very low prior probability,\n   then this task will not draw the model's posterior towards that closest\n   task, and the posterior may be more likely to be falsely detected as\n   closer to a random task than if the closest training task happened to be\n   one with higher prior probability.\n3. How is the chain that is not part of the training set or the control set\n   sampled?\n4. I think I can guess how you turn the procedure you outlined into a single\n   number used to colour your phase diagram, perhaps it involves repeating\n   this procedure several times, and estimating an empirical probability of\n   the closest task being from the training set, giving a number between 0\n   and 1. If this is correct, I think it is worth spelling out in the text,\n   as well as noting somewhere how many trials you take. If this is wrong\n   then it's definitely worth spelling out in the text.\n\n**Q6. Missing details about figure colour schemes:** \nThe phase isolation methodology and the LCA analysis are two distinct methods\nfor colouring a point on a phase diagram. I realised that it is not always\nclear which of these methods you are using in each of the diagrams. It is\nclear in Figure 4 and figure 5 where these techniques are explicated. For the\nremaining figures, I am not sure which methodology you use, and I couldn't\nfind it documented anywhere. Please consider clarifying this in each figure's\ncaption.\n\n\n**Q7. Why is LCA formulated in terms of L2 distance for probabilities?** It\nwould seem more natural to minimise cross entropy or KL as is used elsewhere\nin the paper, and this would allow a clearer comparison to other quantities\nsuch as model KL vs. LCA KL and so on. I don't think this is necessarily a\nmajor issue but I just wondered if the authors had a good reason for it.\n\n\n**Q8. What is the relationship between LCA and delta metrics from Raventos et\nal.?** Raventos et al. consider two setting-specific metrics, they denote\nthem 'delta ridge' and 'delta dMMSE', measuring the L2 distance between the\npredictions of their pre-trained transformer and those of their idealised\nlinear regression algorithms (ridge regression and dMMSE). These are\nessentially measures of how close in function space the transformer is to one\nof the algorithms. Have you thought about the relationship between these\nmetrics and LCA?\n\n\n**Q9. How close is the LCA fit?** LCA weights are defined via a least squares\noptimisation problem. In figures 6 and 7 the authors plot the argmin weights.\nWhat is the min? In other words, how large is the irreducible component of\nthe least squares loss representing the distance of the transformer from the\nsimplex spanned by the four algorithms in function space?\n\nIt is important that this metric remains low in order to believe that the LCA\nhas captured something meaningful about the behaviour, rather than a very\nlossy projection of the behaviour. Therefore I believe the authors should\nreport this metric in the paper, if not in the main text then at least in an\nappendix.\n\nA somewhat related metric appears to be the comparison between the LCA KL and\nthe Model KL in figure 6. However, if two models have similar KL from the\nground truth sequence that does not necessarily imply that they have low KL\nbetween them. It would be informative to add the KL between the LCA and the\nmodel to the two lines in these figures. This would play a similar role to\nthe residual.\n\n\n**Q10. Non-ICL algorithms early in training:** Figure 6 shows shifts in the\nmodel's development across training. One lesson from Hoogland et al. (a paper\ncited by the authors in the appendix) is that the choice of algorithms early\nin training might be even more unsophisticated than those that eventually\narise at convergence for a given task diversity and sequence length\nconfiguration.\n\nFor example, early in training, I hypothesise that some of these transformers\nmight behave in a way that is well-described by an algorithm that does not\ninvolve any in-context learning at all. Some particular algorithms that I\nwould consider searching for include the following:\n\n* **Unigram prior:** Learning the average stationary distribution from all\n  tasks and predicting tokens based on this distribution without looking at\n  context.\n* **Bigram prior:** Learning the average transition matrix and predicting\n  based on this without looking at context.\n\nHave the authors considered adding such non-ICL algorithms into the LCA\nanalysis? I would be curious whether doing so reduces the residual at all.\n\n\n**Q11. Questions about evaluation:** Two small questions about the methodology\nfor evaluation.\n\n1. During ID evaluation, what prior do you use for sampling the tasks from\n   the set of tasks? Do you use the training prior or a uniform prior? You\n   just say you 'choose one from a set.'\n2. During evaluation (for both ID evaluation and OOD evaluation), how many\n   tasks do you sample?\n\n**Q12. Sample implementation of data generating process:**\nCould the authors please clarify the relationship between the sample\nimplementation of the data generating process and the actual code used in\nexperiments?\n\nI take the description of the implementation to imply that this is not the\nimplementation used in the experiments. This opens the possibility that it\nmay actually differ in important ways from the actual methodology used in the\nexperiments. There are certain details, such as the fact that the sequences\ndrawn from each chain are initialised with a sample from the stationary\ndistribution of the chain, do not appear to be noted in the\nmanuscript in any form other than in the reference implementation.\n\nIf the authors intend to open source their codebase after the peer review\nprocess as noted in appendix J then I wonder if they intend to keep this\nreference implementation in the paper?\n\nHave the authors considered mentioning any details such as the initialisation\nof sequences in text form as well as in code form?\n\n\n\n**Q13. Paper structure:** On first read I found it slightly difficult to\nfollow the paper's first few sections. There is a lot going on in the paper,\nbetween the problem, the phenomena, the phases, and the explanations.\n\nI personally found understanding the phases helpful to my understanding of\nthe remainder of the paper. I wonder if the authors have considered promoting\nsection 4 to come before section 3? Of course, this is up to the authors.\n\n\n**Q14. Terminology and notation:** A small number of minor notes.\n\n1. Have you thought about whether the 'phases' are indeed phases in the sense\n   of physics?\n2. A bold \"1\" is overloaded as both a vector of ones (when describing the\n   configuration of the Dirichlet distribution) and also an indicator\n   function (line 232). I wonder if the authors have considered for example\n   using blackboard bold for indicators, to avoid any potential confusion,\n   not that I think the risk of confusion is particularly severe.\n\n**Q15. Typos:** (just the ones I happened to notice):\n\n1. Line 186/187: I think there is a stray closing parenthesis.\n2. Line 422: \"more experiments on this sorts\".\n3. Line 870--: The variables in this list look like they should be typeset in\n  math mode.\n4. Line 1638: unfinished sentence.\n5. Line 2024: \"BICL\", is this meant to be Bi-ICL?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}