{
    "id": "hXJrQWIoR3",
    "title": "Explainable Graph Representation Learning via Graph Pattern Analysis",
    "abstract": "Explainable artificial intelligence (XAI) is an important area in the AI community, and interpretability is crucial for building robust and trustworthy AI models. While previous work has explored model-level and instance-level explainable graph learning, there has been limited investigation into explainable graph representation learning.\nIn this paper, we focus on representation-level explainable graph learning and ask a fundamental question: What specific information about a graph is captured in graph representations? Our approach is inspired by graph kernels, which evaluate graph similarities by counting substructures within specific graph patterns. Although the pattern counting vector can serve as an explainable representation, it has limitations such as ignoring node features and being high-dimensional.\nTo address these limitations, we introduce a framework for learning and explaining graph representations through graph pattern analysis. We start by sampling graph substructures of various patterns. Then, we learn the representations of these patterns and combine them using a weighted sum, where the weights indicate the importance of each graph pattern's contribution.\nWe also provide theoretical analyses of our methods, including robustness and generalization. In our experiments, we show how to learn and explain graph representations for real-world data using pattern analysis. Additionally, we compare our method against multiple baselines in both supervised and unsupervised learning tasks to demonstrate its effectiveness.",
    "keywords": [
        "graph representation learning",
        "explainable graph learning"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "We introduce a framework for learning and explaining graph representations through graph pattern analysis.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=hXJrQWIoR3",
    "pdf_link": "https://openreview.net/pdf?id=hXJrQWIoR3",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a graph representation learning method leveraging graph pattern analysis. It presents a representation learning approach applicable to both supervised and unsupervised learning, utilizing various graph kernels to provide interpretable pattern information for post hoc analysis, effectively demonstrating its utility in experiments."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The notation is clearly defined, contributing to a well-articulated description of the proposed approach.\n- The use of visualizations enhances the accessibility of pattern-based explanations.\n- The paper effectively conveys the need to provide explanations based on graph patterns."
            },
            "weaknesses": {
                "value": "- The time complexity would be significantly higher than the time complexity analysis. However, it is difficult to say it is incorrect because details about kernel usage, such as the number of graphlets employed, and preprocessing requirements are missing. In particular, efficiently identifying graphlets with more than four nodes is a challenging task.\n- While the theoretical analysis is included, it lacks the intuition and analysis for understanding the proposed work.\n - The introduction mentions post-hoc interpretability methods, but the connection to the proposed approach is unclear, as they appear to address entirely different tasks.\n - As the paper addresses explanations at the representation level, comparisons with methods like UNR-Explainer [1] and MotifExplainer [2] would strengthen the related work or introduction section.\n - The paper employs graph sampling, yet details and sensitivity analysis are omitted.\n - GNNs typically struggle with modeling paths, trees, and graphlets due to limited expressive power. It remains unclear if this aspect is effectively visualized and well-learned in the training analysis.\n\n\n\nReferences:\n\n[1] Kang, Hyunju, Geonhee Han, and Hogun Park. \"UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models.\" The Twelfth International Conference on Learning Representations, 2024.\n\n[2] Yu, Zhaoning, and Hongyang Gao. \"MotifExplainer: a motif-based graph neural network explainer.\" arXiv preprint arXiv:2202.00519, 2022."
            },
            "questions": {
                "value": "Please refer to the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes explainable AI (XAI) in the graph domain from the perspective of graph representations. Existing XAI methods in the graph domain mainly focus on model-level or instance-level explanations and lack exploration of representation-level explanations. This paper introduces two methods: 1) PXGL-EGK and 2) PXGL-GNN, which combine representations of graph patterns within the input graph. These methods provide explanations through weight parameters that combine pattern representations to construct the overall graph representation. The authors propose both supervised and unsupervised versions for each method. PXGL-GNN addresses several limitations of PXGL-EGK, such as ignoring node features, high dimensionality, time complexity, and limited expressiveness. The paper includes theoretical analysis on robustness, generality, and complexity, with experimental results and t-SNE visualizations demonstrating the superiority of the proposed methods over existing approaches."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow.\n\n2. It explores representation-level explanations within the graph domain, an area that is not well-explored.\n\n3. The explanation is intuitive and effectively highlights dominant graph patterns using weight parameters."
            },
            "weaknesses": {
                "value": "1. The theoretical analysis suggests that the robustness of the method depends on the number of layers \\( L \\). A performance comparison across different values of \\( L \\) would be beneficial, as setting \\( L = 5 \\) appears to be heuristic.\n\n2. Since the representation of the input graph is directly influenced by the types of patterns used, the authors should demonstrate how different combinations of patterns affect the representation.\n\n3. A hyperparameter analysis regarding the number of samples \\( Q \\) is necessary."
            },
            "questions": {
                "value": "1. Regarding datasets that contain node attributes, as the authors argue that PXGL-GNN can address the issue of ignoring node features present in PXGL-EGK, it would be beneficial to directly compare the two methods on a dataset with node attributes.\n\n2. In the MUTAG dataset, each graph's label is determined by the presence of key tree-like substructures, such as \\( NO_2 \\) or \\( NH_4 \\). In other words, ring patterns do not influence the prediction of the input data. However, PXGL-GNN tends to capture dominant patterns within the input data, often assigning larger weights to cyclic structures. Given this tendency, how can PXGL-GNN outperform other baselines that focus on the critical substructures (i.e., \\( NO_2 \\) or \\( NH_4 \\)) needed to predict the label of the input graph?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "PXGL-GNN is an explainable graph representation learning method based on the analysis of graph patterns such as paths, trees, graphlets, cycles, cliques, wheels, and stars. It explicitly defines the important graph patterns of interest for analysis and learns the importance of each pattern with regard to supervised or unsupervised learning tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The proposed method is novel in employing graph pattern analysis to introduce an explainable graph representation learning model. It reveals the importance of pre-selected graph patterns and their impact on the learned representation vector. Furthermore, this method is applicable in both supervised and unsupervised settings. While maintaining explainability, the model's accuracy in predictive tasks is comparably superior to other black-box models. Additionally, the authors provide a theoretical analysis of the proposed method in terms of robustness, generality, and complexity."
            },
            "weaknesses": {
                "value": "W1. The Introduction's storyline is confusing. The authors primarily discuss post-hoc explainers, including GNN-Explainer and XGNN, in the second paragraph and set the research goal as \"What specific information about a graph is captured in graph representation learning?\" On first reading, this easily misleads readers into thinking the proposed method is similar to post-hoc explanations. However, this is not the case of PXGL-GNN which is a graph representation learning that incorporates explainability. \n\nW2. The authors claim the explainability of their GNN, but no evaluation of the explanations is conducted.\n\nW3. The explanation method for graph representation learning is more valuable to discuss in the context of PXGL-GNN. However, the discussion of post-hoc graph explanations for supervised learning models is sufficient (in my opinion, it's excessive). Additionally, the authors omit the recent UNR-Explainer method, which explains node representation learning, in the related works section.\n\nW4. Although PXGL-GNN is an explainable graph learning model, it lacks explicit explanations. While it provides the importance of pre-selected graph patterns, mapping these to specific subgraphs in the input graph is challenging. Users can understand the overall pattern for the output but struggle to map the insight into the real dataset. This becomes problematic when a certain graph pattern (e.g., a cycle) is important, but slight differences in its components lead to significant changes in prediction. Thus, providing only the graph pattern is insufficient to explain the prediction.\n\nMinor: In Tables 3 and 5, the second-best results for the COLLAB dataset and REDDIT-B are not highlighted."
            },
            "questions": {
                "value": "Please refer to the weaknesses W1, W2, W3, and W4, as well as the minor issue mentioned.\n\nQ1. What are the advantages of analyzing graph patterns for graph representation learning?\n\nQ2. How does understanding important patterns in graph representation learning tasks benefit real-world scenarios?\n\nQ3. Is it feasible to extend the proposed method to node representation learning?\n\nQ4. Have you considered extracting explicit explanations, given that the model already possesses knowledge of important graph patterns in the input graph?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a novel method for explainable graph representation learning based on graph pattern analysis. It aims to answer what information about a graph is captured in its representations by analyzing substructures within different graph patterns. The method includes two approaches: a graph ensemble kernel (PXGL-EGK) for explainable similarity learning and a graph neural network (PXGL-GNN) that combines learned representations from various patterns. Theoretical analyses cover aspects like robustness and generalization, and experiments demonstrate the proposed method\u2019s effectiveness in classification and clustering tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Novelty in Explainable Representation: By focusing on pattern-based explainability, the paper addresses a unique gap in graph representation learning, offering insights into the contributions of specific patterns.\n\nTheoretical Rigor: Theoretical analyses on robustness and generalization bounds add depth to the paper, strengthening the credibility of the proposed method.\n\nExperimental Validation: The method outperforms several baselines in both supervised and unsupervised learning tasks, showing its practical effectiveness and explainability in graph-based tasks."
            },
            "weaknesses": {
                "value": "1. Language, Formatting, and Text Issues:\n\nThere are numerous language and formatting issues throughout the manuscript. For instance, the citation formats at the beginning of Chapters 1 and 4 are incorrect. Some terms that should be consistent, such as \"generality\" and \"generalization,\" are not used uniformly. Additionally, some equations end with punctuation while others do not, and line 297 redundantly uses \"Eq. equation.\" Furthermore, the equation on line 332 exceeds the page length significantly and would benefit from a line break. While I do not typically have strict formatting requirements, the frequency of these issues greatly impacts readability. I recommend a thorough review of the entire manuscript for consistency and clarity.\n\n2. Structure of Chapters 4 and 5:\n\nI suggest a complete rewrite and restructuring of Chapters 4 and 5. I found Chapters 1 to 3 to be relatively clear and easy to follow, but the latter chapters are quite challenging to understand. I read through them multiple times to grasp the progression between theoretical sections, yet some parts remain obscure. I recommend the following:\n1.\tEmphasize the relationship between Definition 4.2 and Definition 4.3 and the subsequent sections of the manuscript, explaining why these definitions are highlighted at the beginning.\n2.\tAfter each section of theoretical derivation, include a statement summarizing the conclusions that can be drawn from that section.\n\n3. Limited Diversity in Pattern Selection: \n\nThe experiments focus on common graph patterns but lack exploration of more complex or specialized patterns, which may affect the method's generality and adaptability to various application domains.  More diverse and application-specific patterns could be explored to enhance the method\u2019s flexibility and relevance cross various domains. Furthermore, future work could expand on computational efficiency, providing empirical results on time and memory usage for large datasets.\n\n\n4. Scalability Concerns: \n\nAlthough the method discusses time and space complexity, it lacks empirical results demonstrating efficiency on large-scale graph datasets, which raises questions about its scalability."
            },
            "questions": {
                "value": "Please see Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}