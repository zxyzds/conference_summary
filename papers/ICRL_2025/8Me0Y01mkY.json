{
    "id": "8Me0Y01mkY",
    "title": "SIRA: Exposing Vulnerabilities in Text Watermarking with Self-Information Rewrite Attacks",
    "abstract": "Text watermarking is designed to embed hidden, imperceptible, markers within\ncontent generated by large language models (LLMs), with the goal of tracing and\nverifying the content\u2019s origin to prevent misuse. The robustness of watermarking\nalgorithms has become a key factor in evaluating their effectiveness, but remains\nan open problem. In this work, we introduce a novel watermark removal attack,\nthe Self-Information Rewrite Attack (SIRA), which poses a new challenge to the\nrobustness of existing watermarking techniques. Since embedding watermarks\nrequires both concealment and semantic coherence, current methods prefered to\nembed them in high-entropy tokens. However, this reveals an inherent vulnera-\nbility, allowing us to exploit this feature to identify potential green tokens. Our\napproach leverages the self-information of each token to filter potential pattern to-\nkens that embed watermarks and performs the attack through masking and rewrit-\ning in a black-box setting. We demonstrate the effectiveness of our attack by\nimplementing it against seven recent watermarking algorithms. The experimental\nresults show that our lightweight algorithm achieves state-of-the-art attack success\nrate while maintaining shorter execution times and lower computational resource\nconsumption compared to existing methods. This attack points to an important\nvulnerability of existing watermarking techniques and paves way towards future\nwatermarking improvements.",
    "keywords": [
        "LLM watermark",
        "robustness",
        "safety ai",
        "paraphrasing attack"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "A Lightweight Approach to remove LLM Watermarks by find the green token with self-information",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=8Me0Y01mkY",
    "pdf_link": "https://openreview.net/pdf?id=8Me0Y01mkY",
    "comments": [
        {
            "summary": {
                "value": "This paper introduce a novel watermark removal attack SIRA.\nCurrent watermarking methods often favoring high-entropy tokens to embed watermark patterns. High-entropy tokens usually have high self-information. SIRA utilized self-information to identify potential \u201dgreen list\u201d token candidates,  which are masked and then completed by LLM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1 SIRA can be implemented using a more lightweight model compared to other model-based paraphrasing attacks.\n2 This paper is well organized and discussions are relatively sufficient."
            },
            "weaknesses": {
                "value": "1 The semantic preservation of the proposed method is inferior compared to GPT Paraphraser.\nA clerical error:Line 24 \u201ctempering\u201d? I think it should be \"tampering\"."
            },
            "questions": {
                "value": "1 How to fairly evaluate the balance between the generated text quality and the attack effect? \n2 Will the attacker really care so much about the resource reduction as shown in Table 2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents the Self-Information Rewrite Attack (SIRA), a watermark removal method that targets vulnerabilities in existing watermarking techniques applied to LLM-generated text. By using self-information to identify and modify high-entropy tokens, SIRA effectively removes watermarks while preserving text quality. The authors conduct extensive experiments across multiple watermarking schemes and demonstrate that SIRA achieves a high attack success rate with minimal computational resources."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.\tThe paper addresses a widely recognized problem in the field of text watermarking. By leveraging self-information, it enables effective watermark removal without compromising text quality.\n2.\tThe experimental setup is comprehensive, covering various watermarking schemes and attack methods."
            },
            "weaknesses": {
                "value": "1.\tFigures 3 and 4 are incorrectly placed, with Figure 4 missing some information, and table formats in this paper are inconsistent.\n2.\tThe proposed method does not appear highly novelty, as it builds upon existing paraphrase attacks by using self-information to locate keywords.\n3.\tThe experiments lack comparisons between self-information and other metrics, such as entropy and token probability, which could help establish the advantage of self-information.\n4.\tThe proposed approach shares characteristics with watermark-stealing attacks [1,2,3], especially in the selection of keywords for targeted editing. A comparison with watermark-stealing attacks in both theoretical analysis and experiments would provide additional insights.\n[1] N. Jovanovi\u0107, R. Staab, and M. Vechev, \u201cWatermark Stealing in Large Language Models.\u201d http://arxiv.org/abs/2402.19361\n[2] Q. Wu and V. Chandrasekaran, \u201cBypassing LLM Watermarks with Color-Aware Substitutions.\u201d http://arxiv.org/abs/2403.14719\n[3] Z. Zhang et al., \u201cLarge Language Model Watermark Stealing With Mixed Integer Programming.\u201d http://arxiv.org/abs/2405.19677"
            },
            "questions": {
                "value": "1.\tWhat distinguishes self-information from entropy and probability, and what are the specific advantages of using self-information in this context?\n2.\tIn Algorithm 1, is the model M in line 14 the attack model M_attack?\n3.\tIn Figure 4(a), why does the word deletion method have a large impact on KGW-1\u2019s PPL? Additionally, why is this impact much more significant than that of other methods in Figure 4(b)?\n4.\tIn Table 1, the GPT Paraphraser shows a much higher attack success rate for Unigram watermarks than for DIPPER-based attacks, a phenomenon not observed with other watermarking methods. Additionally, SIR, a sentence embedding-based watermark scheme, should theoretically have robustness only second to Unigram, but this is not reflected in Table 1. Further discussion on these points is necessary."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a model-based paraphrasing attack. It identifies potential green words and provides a template for rephrasing."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The attack is performed in a black-box setting.\n\nThe semantics of the paraphrased text is preserved."
            },
            "weaknesses": {
                "value": "The paper has limited optimization for preserving semantics. The primary strategy for maintaining semantics is changing only potential \"green\" words while providing a masked template. However, the paper could be strengthened by presenting evidence on how the template contributes to semantic preservation.\n\nAdditionally, the method requires two paraphrasing steps: one to generate a reference text and another to create the attack text. The paper would benefit from explaining how it achieves shorter execution time.\n\nIn the ablation study, besides comparing the self-information mask with the random mask, it would be valuable to include a comparison between the self-information mask and no mask (paraphrasing twice)."
            },
            "questions": {
                "value": "Why does SIRA have a shorter execution time than GPT Paraphraser, considering that SIRA requires two paraphrasing steps? Table 2 indicates that the execution speed of GPT Paraphraser may vary depending on the network status and real-time OpenAI server load. Does this make for a fair comparison?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This is an interesting paper, it introduces the Self-Information Rewrite Attack (SIRA) as a novel watermark removal method targeting the robustness of text watermarking techniques used in content generated by large language models (LLMs). These watermarks allow tracing and verifying content origins to prevent misuse."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The proposed method, namely SIRA, leverages the high self-information of certain tokens where watermarks are often embedded, applying a lightweight masking and rewriting technique to evade watermark detection. The experimental results demonstrate that SIRA effectively disrupts watermarking in seven algorithms with minimal computational resources, achieving a 90% success rate, suggesting critical vulnerabilities in current watermarking techniques."
            },
            "weaknesses": {
                "value": "1. **Unclear motivation.** In lines 57-59, the authors point out the limitations of previous methods and later propose their method to overcome these challenges. One limitation is transparency, but why is transparency desirable for watermark removal attacks via paraphrasing? The second limitation is computational cost, but their method requires three models: one for masking, one to generate reference text, and a third one for paraphrasing given the masked reference text, which is not computationally efficient.\n\n2. **The method lacks soundness.** How can it be ensured that the LLaMA 3 rewriting can favor red tokens to achieve watermark removal? Why can this method remove SIR watermarking while existing methods fail?\n\n3. **Unclear experiment settings.** Which models are used as $ M_{\\text{attack}} $ (line 290) and the base LLM (line 307), respectively? How does LLaMA3-8b ensure the lightweight and usability of the proposed method? The lightweight aspect of LLaMA3-8b is questionable, considering the watermarked model in the experiment is OPT 1.3B.\n\n4. **The experimental results lack analysis and sometimes are even inconsistent.** Why does word deletion yield a high s-BERT score for KGW-1 (i.e., deletion preserves sentence-level embedding similarity) but low scores for other watermarks in Figure 4b? Why are the results in Figure 4b inconsistent with those in Table 8?\n\n5. **Minor issues:** \n   - Typo: `paraphase` in Figure 1 and its caption.\n   - The threshold in line 296 should be $\\epsilon$ instead of $\\sigma$."
            },
            "questions": {
                "value": "I have listed most of my questions associated with these weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}