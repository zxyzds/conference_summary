{
    "id": "zUlK1qMIcE",
    "title": "Active partitioning: inverting the paradigm of active learning",
    "abstract": "Datasets often incorporate various functional patterns related to different aspects or regimes, which are typically not equally present throughout the dataset. We propose a novel, general-purpose partitioning algorithm that utilizes competition between models to detect and separate these functional patterns. This competition is induced by multiple models iteratively submitting their predictions for the dataset, with the best prediction for each data point being rewarded with training on that data point. This reward mechanism amplifies each model\u2019s strengths and encourages specialization in different patterns. The specializations can then be translated into a partitioning scheme. The amplification of each model\u2019s strengths inverts the active learning paradigm: while active learning typically focuses the training of models on their weaknesses to minimize the number of required training data points, our concept reinforces the strengths of each model, thus specializing them. We validate our concept -- called active partitioning -- with various datasets with clearly distinct functional patterns, such as mechanical stress and strain data in a porous structure. The active partitioning algorithm produces valuable insights into the datasets\u2019 structure, which can serve various further applications. As a demonstration of one exemplary usage, we set up modular models consisting of multiple expert models, each learning a single partition, and compare their performance on more than twenty popular regression problems with single models learning all partitions simultaneously. Our results show significant improvements, with up to 54% loss reduction, confirming our partitioning algorithm\u2019s utility.",
    "keywords": [
        "Partitioning",
        "Pattern-recognition",
        "Clustering",
        "Active learning",
        "Modular networks"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "We propose an algorithm which partitions a dataset along functional patterns, based on competition and inverting the active learning paradigm.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=zUlK1qMIcE",
    "pdf_link": "https://openreview.net/pdf?id=zUlK1qMIcE",
    "comments": [
        {
            "summary": {
                "value": "The authors propose to partition the dataset by using predictions from multiple models.\n\nDuring training, each sub-model is allowed to submit their predictions for all points in the datasets. The datapoints are then assigned to the sub-model with the best performance, and the sub-model is trained only these datapoints. As training proceeds, the hope is that the process induces specialization in the models, which is then translated into a partitioning. There is some connection to active learning, where datapoints are chosen for which the model is most uncertain about; whereas here, the datapoints are assigned to the model with best performance.\n\nExperimental results are reported on 6 datasets, 3 of which are unidimensional datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "* The claims of the paper are easy to understand (though I dont quite believe them, see below)\n* The experimental results one of the datasets was interesting to read"
            },
            "weaknesses": {
                "value": "TLDR; I dont think the contributions of the paper meet the conference bar.\n\n* There are lots of existing work on MOEs, this paper feels like re-inventing them from scratch. There is minimal mention to existing literature, no comparisons.\n\n* The experimental results are quite unconvincing. The scale of the datasets are just too small. Why not have larger capacity models which can learn more. The scale of the datasets + model sizes (the latter I suspect is also small), makes me question if partitioning the dataset is needed at all. \n\n* Even if we assume that partitioning is required, why not compare with simpler baselines like run clustering algorithm first, and then train independent models on the clusters?"
            },
            "questions": {
                "value": "Please see weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper discusses a new learning paradigm called active partitioning, aiming to improve model performance by leveraging competition among models. The key idea is to separate and detect distinct functional patterns within datasets by rewarding models that provide the best predictions for specific data points with additional training on those points. This encourages each model to specialize in certain patterns, allowing the datasets to be divided into specialized partitions. Unlike traditional active learning, which focuses on training models based on their weaknesses to minimize training data, active partitioning emphasizes strengthening models' specialties. The approach is tested on datasets with distinct patterns (e.g., stress and strain data), showing how models can learn different partitions. The results demonstrate improved performance, with a 54% reduction in loss compared to single models handling the entire dataset, validating the effectiveness of active partitioning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Interesting new paradigm. Even though it's similar to the ideas of mixture of experts which are well-studies in current LLMs era, the idea of applying multiple experts and partitioning datasets are interesting in active learning literatures.\n2. The number of datasets in experiments section is impressive, including 2 two-dimensional datasets and 22 datasets from UCI Machine Learning Repository."
            },
            "weaknesses": {
                "value": "1. Lack of related works: The author mentions mixture of experts algorithm in Section 2.2. There is a rich body of related works regarding applications of mixtures of experts on LLMs [1, 2, 3].\n\n2. Lack of theoretical justifications. Most of partitioning experiments have theoretical guarantees and more theoretical understandings would be helpful in understanding this algorithm.\n\n3. Datasets are too simple and small scale. Code is not open-sourced. Datasets selected are mainly from UCI Machine Learning Repository where most of them are low-dimensional and small scale in terms of datasets size. Since there are no theoretical justifications, experiments should not be limited to regression tasks. \n\n4. Ablation study of network architectures. The tasks should be not limited to regressions settings and more experiments regarding various network architectures should be discussed. The authors claim active partitioning paradigm is better than active learning but many active learning algorithms have experiments showcasing there optimality across multiple networks architectures. For instance [4] performs experiments across network architectures including networks similar to LeNet and ResNet-18.\n\nReferences: \n1. Gross, Sam, et al. Hard mixtures of experts for large scale weakly supervised vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6865\u20136873, 2017.\n2. Zhou, Yanqi, et al. \"Mixture-of-experts with expert choice routing.\" Advances in Neural Information Processing Systems 35 (2022): 7103-7114.\n3. Riquelme, Carlos, et al. \"Scaling vision with sparse mixture of experts.\" Advances in Neural Information Processing Systems 34 (2021): 8583-8595.\n4. Ding, Zixin, et al. \"Learning to Rank for Active Learning via Multi-Task Bilevel Optimization.\" The 40th Conference on Uncertainty in Artificial Intelligence."
            },
            "questions": {
                "value": "No"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces an algorithm that leverages competition between models to partition datasets based on distinct functional patterns. Unlike traditional active learning, which focuses on minimizing data for weak areas, this approach amplifies the strengths of models, promoting specialization. The modular models, consisting of multiple expert models each focused on learning a specific partition, demonstrate significant improvements over a single model."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The writing in this paper is easy to understand, and the use of flowcharts and other visuals makes it easier to grasp the core methods and concepts.\n\n2. The authors provide pseudocode and detailed parameter settings in the paper, and the code is included in the supplementary materials, ensuring the reproducibility of the work."
            },
            "weaknesses": {
                "value": "1. The number of dataset partitioning baselines compared is insufficient. In the related work section, the authors discuss other dataset partitioning methods, while the authors did not compare active partitioning with any of these methods. The authors may supplement the baselines or explain why there is no comparison between them.\n\n2. The modular model tends to underperform compared to a single model when the split dataset using active partitioning exhibits one coherent pattern or when multiple patterns have significant overlap. A related work [1] that first attempts to solve a problem with a single network and handles the unsolved portion(s) of the input domain recursively seems to be superior to the proposed method.\n\n3. The authors claim that the novelty of this work lies in \u201cthe development of a flexible partitioning method through the competition of entire models,\u201d but what advantages does this approach offer compared to previous dataset partitioning methods? The motivation behind the proposed method needs further elaboration and clarification.\n\n4. The authors may provide a more detailed introduction to active learning and elaborate on how the proposed method invests in the paradigm of active learning.\n\n5. The paper is lack of detail in the dataset partitioning phase. The authors mention that competing models might exhibit differences, such as using \u2018wider neural networks or smaller learning rates\u2019 for different patterns, but they do not provide concrete details on how model diversity is implemented during this stage. It would be beneficial to elaborate on how these variations are chosen and how they impact the effectiveness of the partitioning process.\n\n6. The authors sometimes mix in-text and parenthetical citations throughout the related work section, such as \"Wu et al.adapted ... (Wu et al., 2004).\"\n\n[1] V Scott Gordon and Jeb Crouson. Self-splitting modular neural network-domain partitioning at boundaries of trained regions. In: Proceedings of the 2008 IEEE International Joint Conference on Neural Networks, pp. 1085\u20131091, 2008."
            },
            "questions": {
                "value": "1. I would like to know how much time the active partitioning and training of modular model will cost compared to training a single model.\n\n2. I wonder whether the competing models used for active partitioning can be directly used to combine a modular model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}