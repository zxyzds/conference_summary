{
    "id": "NgvL7aMaTI",
    "title": "Predicting episodic structure from overlapping input in binary networks with homeostasis",
    "abstract": "How neural networks process overlapping input patterns is a fundamental question in both neuroscience and artificial intelligence. Traditionally, overlaps in neural activity are viewed as interference, requiring separation for better performance. However, an alternative perspective suggests that these overlaps may encode meaningful semantic relationships between concepts. In this paper, we propose a framework where persistent overlap between input patterns represent semantic components across episodic experiences, and the statistics of these overlaps how each semantic element relates to the rest.\n\nTo explore this idea, we introduce an Episode Generation Protocol (EGP) that defines a mapping between the semantic structure of episodes and input pattern generation. Paired with our EGP, we use Homeostatic Binary Networks (HBNs), a simplified yet biologically-inspired model incorporating key features such as adjustable inhibition, Hebbian learning, and homeostatic plasticity.\n\nOur contributions are threefold: (1) We formalize a link between episodic semantics and neural patterns through our EGP. (2) We introduce HBNs as an analytically tractable model that directly connects episodic semantics to learning dynamics. (3) We show that HBNs perform robust pattern completion under noisy and masked inputs, aligning their performance with Maximum A Posteriori (MAP) and Maximum Likelihood Estimation (MLE) strategies depending on the homeostatic regime.\n\nThese findings shed light on how neural networks might extract and preserve semantic content from overlapping patterns, offering a pathway for unifying associative and predictive learning theories in both biological and artificial systems.",
    "keywords": [
        "Semantics",
        "Episodes",
        "Homeostasis",
        "Regularization",
        "Hopfield Network",
        "Synaptic Plasticity",
        "Predictive Learning"
    ],
    "primary_area": "applications to neuroscience & cognitive science",
    "TLDR": "We present a protocol for generating semantically-charged overlapping input patterns, and a binary network that can extract these semantics into its recurrent weights, then using these for prediction of the structure of corrupted input.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=NgvL7aMaTI",
    "pdf_link": "https://openreview.net/pdf?id=NgvL7aMaTI",
    "comments": [
        {
            "title": {
                "value": "Clarificiation regarding feedback"
            },
            "comment": {
                "value": "Dear Reviewer,\n\nThank you for your detailed feedback. We are now actively implementing your suggestions to enhance the manuscript.\n\nIn the meantime, we would like to ask for a few clarifications:\n\n****1****\n      \"Section structured for 2 is confusing. I find the methodology and results to be mixed. The issue with the section is it is difficult to understand the motivation of the paper and its concept if I have not read the paper fully. I believe the paper would benefit if these are laid out in the methodology with the results (probably 2.4 and 2.5?) in a separate section.\u201d\n\nJust to confirm, are you suggesting to have a \"Section 2 - Methods\" (including current 2.1 and 2.2) and then leave for \"Section 3 - Results\" the current 2.3, 2.4, and 2.5? We do think that would be a great idea and acknowledge that the current format might be confusing.\n\n***2***\n     \"Figure 1C (middle): I believe that the probability for the attribute relation between italy and pizza may have an error? (should be 0.25?)\"\n\nWe believe the probability shown is correct, but we would like to double-check with you in case we missed something! In Figure 1C (middle), we set the probability of the episode (Italy, pizza) to be 0.25. (shown in Figure). This probability is imposed for illustration and could have been assigned any other value. If you are referring to Fig. 1D, the conditional probability of pizza given Italy is 1, as all episodes containing Italy also contain pizza. The conditional probability of Italy given pizza is 0.5, as the probability of (France, pizza) is also 0.25, so half of the episodes that contain pizza contain Italy, and the other half France. Does this seem correct?\n\n***3***\n     \u201cI do understand that to add some extra variability,neurons are swapped active neurons with the inactive neurons. What does in this case?\u201d\n\nCould you please clarify this question? Indeed, after each neuron coding for an element is activated if that element is contained in the episode. Then, noise is injected by silencing a fraction of active neurons, and the same number of inactive neurons are activated. Is the question regarding the motivation for doing this?\n\n***4***\n     \u201cAlthough the experiment shown here considers a short episode, I would also evaluate    its performance on longer episodes (with more swaps) and consider how this system may perform.\u201d\n\nTo confirm, are you suggesting that during training we present the same input pattern across multiple steps, each with a different set of neurons swapped? If so, we would expect similar behaviour, as the number of training steps (5000) is very large compared to the combinations of episode elements, meaning the network already encounters many independent samples of each episode. However, we could run this experiment and add a supplementary figure."
            }
        },
        {
            "title": {
                "value": "Clarificiation regarding feedback"
            },
            "comment": {
                "value": "Dear Reviewer,\n\nThank you very much for the thorough feedback. We are already working to improve the manuscript in line with your suggestions.\n\nIn the meantime, we would like to ask for clarification on the following point:\n\n$\\textbf{The behaviour of the weights for the regimes with homeostasis does not seem to apply to the model (the dynamics are never reaching this regime). Can you explain your reasoning in more detail?}$\n\nCould you please specify which figure or piece of results this comment refers to? Additionally, could you clarify which specific regime is not being reached and under what conditions? We have implemented three synaptic homeostatic regimes\u2014outgoing homeostasis dominance, outgoing/incoming homeostatic balance, and incoming homeostasis dominance\u2014each of which is imposed through the network parameters prior to training.\n\n\nThank you very much in advance for your assistance!"
            }
        },
        {
            "summary": {
                "value": "The literature suggests the overlap in neural activity as a separation of meaningful semantic concepts, where the overlap is defined to be between episodic patterns. The literature proposed here considers activity patterns to correspond to the full content of episodes, and the overlaps between patterns represent common concepts in the episodes encoded by both patterns. Thus, the Episode Generation Protocol (EGP) system is introduced to map the semantic structures of episodes to input pattern generation. By using the inputs produced by the EGP, the literature uses a Homeostatic Binary Network as a method to train and recall episodes. These are motivated by the fact that the trained network will be capable of recalling even if the episode has concepts that are overlapping towards other attributes due to the semantic structure provided by the EGP."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The idea of using a semantic structure to define episodes based on a structure of concepts and attributes is great. What I really like about the paper is how this structure is used to train a network for recalling patterns, which points its focus towards the structure of the input rather than training the network to learn. This key idea is novel."
            },
            "weaknesses": {
                "value": "I do understand that some of the technical details to appendix helps shorten and simplify the explanation in the main text. I believe some of them are way too shortened on formal explanation and way too lengthened on an intuitive explanation, e.g. key concepts such as explanation of EGP is good but it would benefit from having explanations such as how the episode is mapped to an input would help. Another thing to note here is that instead of giving an intuitive explanation, it would be better to connect a formal explanation to some extent that refers to both the appendix and an intuitive explanation would provide a better understanding of the topic.\nSection structured for 2 is confusing. I find the methodology and results to be mixed. The issue with the section is it is difficult to understand the motivation of the paper and its concept if I have not read the paper fully. I believe the paper would benefit if these are laid out in the methodology with the results (probably 2.4 and 2.5?) in a separate section. The issue mainly persists in the methodology part of it."
            },
            "questions": {
                "value": "Figure 1C (middle): I believe that the probability for the attribute relation between italy and pizza may have an error? (should be 0.25?)\nI do understand that to add some extra variability, $N_swap/2$ neurons are swapped active neurons with the inactive neurons. What does $N_swap$ in this case?\nA.1: During explanation of eq (11),  does \u2018a\u2019 here represent an episode concept? Since an episode contains one episode concept per episode attribute, A is an episode attribute and thus \u2018a\u2019 is one episode concept rather than \u2018a\u2019 being a set of episode concepts. This may need clarification.\nA.2 The definition of i is a population of associated neurons as SEN_a as per episode-input mapping. Here, you define it as an episode concept? I believe the terms here need to be further clarified since it is very confusing.\nA.3.1: The definition of satellite objects and its relation to its features is key here. This needs to be cleared out to better explain the readers on EGP.\nConsider explaining the input mapping at the start. In my opinion it seems unclear until after going through the appendix.\nSection 2.2: The definition of top-K activation should define what region specifically means (neurons associated to attribute?)\nAlthough the experiment shown here considers a short episode, I would also evaluate its performance on longer episodes (with more swaps) and consider how this system may perform."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a method to encode the statistics of episodes in a memory network composed of binary units, connected with weights whose dynamics include Hebbian learning, homeostasis and synaptic depression. The first contribution is a method to  generate binary patterns encoding some semantic relationships defined as conditional probabilities on some finite space composed of concepts grouped in supersets called attributes (both constituting the episodes). The generation procedure consists of sampling the given concepts (one per attribute) and encoding them in a disjoint population of neurons. The network is then trained using some bespoke mechanisms for activity and synaptic homeostasis. The authors show how this process recovers the original semantic structure (defined as the conditional probabilities of concepts), performs pattern completion of concepts subject to noise; and claim that this process performs statistical estimation of missing or corrupted concepts in a given episode. They also present some mean field theory for the weights."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper shows an elegant reinterpretation of the semantic structure in episodes to be stored in memory. There are a variety of analyses that show the different, claimed results while keeping the explanatory complexity to the minimum. This makes this an attractive potential scientific theory that is interpretable from the beginning. The different mechanisms of the neural network are explained and length. The simplicity of the model is attractive but could be misleading in ways that I will explain later. I congratulate the authors for a great work, and the comments that follow are intended as my contribution to make this work stronger."
            },
            "weaknesses": {
                "value": "I will expose my concerns in no particular order:\n\n- I am worried about the lack of explanation about what K is (I mean, the actual value). It seems to be the size of each of the groups that encode the concepts. In this sense, this might be very restrictive to make this model useful. I imagine that, if K < N, the pattern completion might not work as expected. It would be useful to show how the model behaves for different Ks\n- I don't think the model contradicts Gastaldi et. al (2021). You still have a minimum amount of noise (which I interpret as the overlap), above which, the network can not recover. In this sense, I am not that sure the two schemas shown in figure 1A and 1B are that different, it seems that we have just renamed what the overlap is buy making those overlaps atomic units. This might be too strong of a constraint on the whole model, limiting the scalability. \n- Regarding scalability, the simplicity of the exposition leaves some doubts about how much the model is able to scale (and therefore be of any scientific or engineering use), both in the complexity of the semantic structure (nested relations, higher order correlation?) and the complexity of the patterns (would that support different encodings). \n- I have doubts about the strength of the conclusions drawn from the work in general, It is clear that the authors have a strong grasp of mathematics, however, I see no justification about the importance of each of the different mechanisms in achieving the ultimate result (homeostasis, depression). Even more, it seems that the Hebbian rule plus the top-K activation would unavoidably compute the covariance matrix of the input! (XX^T_ij = sum(d*xidxj))\n- Connected to this, some of the mechanisms are not well justified, why is homeostasis and depression important? I suppose it is the renormalization of the weights but the theoretical justification (necessity and sufficiency) are week. \n- The mean field analysis is interesting but also confusing. First, there is no coherent naming of the variables (sometimes Tout, Tpre), second it is not clear what the contribution to this analysis is to the full narrative of the paper (I can see the paper without the analysis and it would not change the end result). More on this later.\n- There are a fair amount of typos in notation and in the text in general\n- Figure 4 shows only 2 concepts for the attribute food but the caption says it is 4?\n- Labels are wrong in figure 5D\n- I disagree with the network performing MLE or MAP, or at least this claim should be qualified. Indeed, the model seems to oscillate! so, when do you know when to stop?\n- Finally, a general comment. It would be nice to have a discussion about how plausible this model is based on what is known from the structure of memory.\n\nIn general, I am unsure about the relevance of the work in the context put forward by the authors."
            },
            "questions": {
                "value": "- One of the properties of episodic memory is the ordering of events and creation of chains. It is not immediately clear to me how this could be implemented (is, I think, what differentiate the problem from mere pattern completion/storage). I suggest including an experiment in this regard as your results (in order to justify calling it episodic, and to show that the model agrees with observations from the literature)\n\n- The mean field theory seems to assume that the neurons are tracking the input statistics perfectly. I do not think you show that in the first place. The probability distribution you derive also seems to assume independence and disconnected neurons. Can you show this is a valid assumption, what are the implications of this assumptions for the rest of the claims of the paper.\n\n- I did not see the phase transition in the weights that you mentioned explained in detail.\n\n- The behaviour of the weights for the regimes with homeostasis does not seem to apply to the model (the dynamics are never reaching this regime). Can you explain your reasoning in more detail?\n\n\n\n-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No concerns"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes an Episode Generation Protocol (EGP) to generate vectors of binary numbers (each vector is an \u201cepisode\u201d) such that every episode contains one concept per episode attribute. As a clarifying example, the authors consider the attributes to be place and food, and the concepts to be Italy, France, pizza, and croissant. The overlap between different binary episode-vectors is a key feature of these synthetically generated episodes and corresponds to shared concepts across episodes. The authors study how these episodes are learned by a model that includes adjustable inhibition, Hebbian learning, homeostatic plasticity, and short-term synaptic depression; and then study how these episodes are recalled from noisy inputs (pattern completion)."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors propose a neural network model that touches on many areas of research across both biological and artificial systems. They write about its ability to perform pattern completion, Maximum A Priori Estimation (MAP), and Maximum Likelihood Estimation (MLE); while doing this with biologically inspired elements such as adjustable inhibition, Hebbian learning, homeostatic plasticity, and short-term synaptic depression. Given this breadth of scope, there are many connections that could be developed to either contribute to machine learning or to a better understanding of the brain."
            },
            "weaknesses": {
                "value": "The paper aims to make contributions across both biological and artificial systems but, while it is a good start, doesn\u2019t fully connect to modern machine learning or to the brain through, for example, neural or behavioral data.\n\nOn the biological side, the authors propose a model that incorporates adjustable inhibition, Hebbian learning, homeostatic plasticity, and short-term synaptic depression. Given all of these ingredients are there predictions that can be made about behavior or neural activity? Or can the model recapitulate known experimental findings? For example, the authors referenced papers by Anna Schapiro so this may be a good contact point to compare the model and experimental findings. \n\nOn the machine learning side, the model as it is currently implemented seems more like a proof of principle. So I\u2019m left wondering if this model can be applied to more realistic tasks or used to gain insight into modern machine learning models. Below are some suggestions.\n\n* The authors compare the pattern completion abilities of their model to the Hopfield-Tsodyks model from 1988. How does the model connect to other more recent literature on pattern completion? For example, modern Hopfield networks. See, for example, Krotov 2023 \u201cA new frontier for Hopfield networks\u201d and Krotov & Hopfield 2016 \u201cDense associative memory for pattern recognition\u201d.\n\n* In the Introduction, the authors highlight an interesting distinction between 1) models where \u201ceach pattern separately represents a concept, and the overlap is a consequence of the concepts being semantically related\u201d, and 2) models where \u201cactivity patterns correspond to the full content of episodes, and the overlaps between patterns represent common concepts in the episodes encoded by both patterns.\u201d\nMy interpretation is that models in class 1 might correspond to neural networks trained on image classification datasets like MNIST or ImageNet where there is generally only a single central object in the image and the pixel values between different images encode some sense of similarity. Models in class 2 might correspond to neural networks trained on semantic segmentation where different images share common objects or \u201cconcepts\u201d to use the terminology of the paper. Can the model in this paper be productively applied to datasets used to study semantic segmentation, and not just the toy dataset considered in the paper? Or, relatedly, can the ideas introduced in this paper be applied to networks that are used for semantic segmentation, for example, as a way of understanding the activity patterns in later layers of the network? At a more general level what I would like to see is some path forward for this model, to see the relevance on more realistic tasks.\n\n* The authors make an interesting claim that their model performs Maximum A Priori Estimation (MAP) and Maximum Likelihood Estimation (MLE). It seems to me that demonstrating this would require more work in showing the neural network recapitulates the Bayesian computation."
            },
            "questions": {
                "value": "Please see the previous section for a number of questions and suggestions for improving the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In their paper \u201cPredicting episodic structure from overlapping input in binary networks with homeostasis\u201d authors develop a new neural network, the Homeostatic Binary Network (HBN) which, through local leaning / updating rules learn to pattern complete noisy inputs. In the context of their investigations, they also develop a dataset that can construct multiple data examples from a fixed semantic relationship, by allowing for the representation of noise on top of class representations. They show that specific implementations of their model follow the principles of either Maximum A Posteriori (MAP) or Maximum Likelihood Estimation (MLE) when completing and unseen pattern."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The topic of Hopfield networks and other related architectures have regained in popularity in recent years, and it seems that in principle this paper might make an interesting contribution by introducing a new architecture which matches existing algorithms in performance but also allows for understanding of the networks internal mechanisms used for pattern completion. Additionally, their architecture can be configured to follow different pattern completion strategies."
            },
            "weaknesses": {
                "value": "I personally find that the presentation of findings and the contextualisation of finding is quite poor in this paper. I provide a detailed list of suggested changes below which I think will help to improve the author\u2019s work."
            },
            "questions": {
                "value": "I am voting against acceptance for the manuscript in its current form but if the writing and presentation is improved substantially, as suggested below, then I think the results should be worthwhile to be presented at the conference.\n\n*Major: description of their new methods*\n\nWhen introducing both their dataset and their model, I think it would help the general reader if they described their methodological advancements in context of established works that readers are likely familiar with. For example, their new dataset generation methods seem to essentially code for semantic relationships in a One-Hot coding way but instead of having each feature represented by a binary, it is represented by a list of binaries, which allows the authors to add noise to the representation of concepts? If I got that right, I think an explanation like that is going to make it easier to understand what the authors do and also what is new about their methods. This is also true when introducing their network. Authors discuss the whole idea of homeostasis in great detail but do not explain how their network is different from related (but well-known) network classes. In fact, the first time Hopefield networks are even mentioned is on page 6, even though they seem very relevant to the authors introduced architecture?\n\n*Major: contextualisation of results*\n\nThe point above leads to an additional related issue that the authors should highlight in more detail how their findings actually go beyond the existing literature. I am not an expert in this class of networks, but their task seems to be very related to tasks already used since the early days of PDP (e.g. see McClelland and Rogers, Nat Revs Neuro, 2003) but they represented each feature through a list of binaries? At the same time for their findings in networks, I am under the impression that Hopfield networks and Boltzmann machines can also be configured to use either MLE or MAP (please correct me if I am wrong about this, as that might very well be the case)? As authors do not provide a description of what they think makes their model stand out against established alternatives, I find it difficult to judge how observing this in their model is special. My hunch would be that in Boltzmann machines one would have to bring in a prior through the weights but for the paper here it is induced by the updating, but authors should really clarify this themselves in the text and not leave it to the reader to figure this out.\n\n*Major: presentation of results*\n\nI would recommend the following changes to make it easier to follow / interpret results:\n- Clearly state how many networks you train and what the dataset structure is\n- Where variances are presented (like Fig4C), state whether these are standard errors / deviations or else\n- Related to the deviation in 4C, in the text you seem to be interpreting the red line in 4C (Outgoing Dom) as being significantly different from the other lines, but the plotted variance suggest they might not be significantly different?\n- Generally, results plots like 4D and 5E should report standard errors and significance tests\n- Fig 5E seems to be a key analysis but the figure legend does not explain what the dots or bars actually refer to? I understand that authors want to argue that under different setup the different models mirror either the MAP or MLE prediction but to support that conclusion with a figure, they should present the expected pattern under each of these inference modes and then show how each of the models looks like either of these inference modes. As states above, the similarity should ideally be test for significance.\n\n*Minor: stylistic changes / corrections*\n\n- The in-text references should be in brackets, i.e. (O\u2019Reilly, 2000) instead of O\u2019Reilly (2000). The ICLR Latex file provides this as a citation option.\n- Generally speaking, across all figures, I think authors could increase the font size relative to other visual elements and could then make the figures overall smaller to save space. Additional space could be used to explain the ideas better and contextualise findings, as discussed above. \n- Figure 2B is already data / results recorded from the model, is that correct? In that case I find it confusing that it is labelled as \u2018B\u2019 and as such listed above the description of the actual network algorithm.\n- Line 417: \u201care be asymmetric\u201d, seems like there is an error there\n- Line 303: \u201cNow, we test whether these learnt weights can, during Test (recall) help recall during the test phase of the network.\u201d, that sentence seems off?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}