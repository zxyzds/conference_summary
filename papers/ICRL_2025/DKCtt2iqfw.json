{
    "id": "DKCtt2iqfw",
    "title": "Channel-wise Influence: Estimating Data Influence for Multivariate Time Series",
    "abstract": "The influence function, a robust statistics technique, is an effective post-hoc method that measures the impact of modifying or removing training data on model parameters, offering valuable insights into model interpretability without requiring costly retraining. It would provide extensions like increasing model performance, improving model generalization, and offering interpretability. Recently, Multivariate Time\nSeries (MTS) analysis has become an important yet challenging task, attracting significant attention. However, there is no preceding research on the influence functions of MTS to shed light on the effects of modifying the channel of MTS. Given that each channel in an MTS plays a crucial role in its analysis, it is essential to characterize the influence of different channels. To fill this gap, we propose a channel-wise influence function, which is the first method that can estimate the influence of different channels in MTS, utilizing a first-order gradient approximation. Additionally, we demonstrate how this influence function can be used to estimate the influence of a channel in MTS. Finally, we validated the accuracy and effectiveness of our influence estimation function in critical MTS analysis tasks, such as MTS anomaly detection and MTS forecasting. According to abundant experiments on real-world datasets, the original influence function performs worse than our method and even fails for the channel pruning problem, which demonstrates the superiority and necessity of the channel-wise influence function in MTS analysis.",
    "keywords": [
        "channel-wise influence function",
        "mutivariate time series"
    ],
    "primary_area": "learning on time series and dynamical systems",
    "TLDR": "",
    "creation_date": "2024-09-23",
    "original_date": "2024-10-04",
    "modification_date": "2024-11-15",
    "forum_link": "https://openreview.net/forum?id=DKCtt2iqfw",
    "pdf_link": "https://openreview.net/pdf?id=DKCtt2iqfw",
    "comments": [
        {
            "title": {
                "value": "Response to Questions"
            },
            "comment": {
                "value": "**Q1:** After channel pruning, does the final prediction use the pruned channels or the full set of channels? Clarifying this will help determine whether pruning directly improves prediction or simply reduces computational costs, and why are the pruned channels still accurately predicted? How does the model achieve this?\n\n**A1\uff1a** To ensure a fair comparison, the model\u2019s output during testing includes predictions for all channels. The main goals of channel pruning are twofold: first, by removing redundant channel information in the training set, we can accelerate model training; second, channel pruning allows us to identify an effective training channel subset for a specific model, supporting interpretability analysis. A larger subset (The proportion marked in red in Table 5 represents the size of the core subset.) indicates a stronger capability of the model to capture channel dependencies in time series data. The fact that pruned channels can still be accurately predicted is due to the presence of channels with similar patterns to those removed during training, revealing redundancy between channels. This redundancy enables the model to learn one channel\u2019s trend and generalize it effectively to accurately predict other channels. \n\n \n\n**Q2:** Given that PatchTST is channel-independent, how can we justify that removing channels enhances overall performance? For example, certain channels may have lower MSE due to higher predictability, while others may be more erratic, resulting in higher MSE. If more erratic channels are removed, this might artificially lower the overall MSE, which could be misleading.\n\n**A2\uff1a** Referring to the explanation in Q1, we did not test only a subset of the channels, but instead evaluated the prediction results for all channels. Therefore, you don't need to worry about this case.\n\n\n**Q3:** Rather than pruning channels, would it be more insightful to analyze the interactions between channels? For example, investigating how one channel affects another could provide a deeper understanding of channel dependencies in MTS.\n\n**A3\uff1a** Thank you for your suggestion. We have addressed this issue in Remark 3.2 of the paper. We believe that the channel-wise influence matrix indeed reflects how different models understand channel correlations. This is why iTransformer has a larger core subset\u2014it can more accurately distinguish and identify the relationships between different channels. This also explains why we conducted this experiment, as the core subset reflects whether the model is capable of understanding which channels are related and different from each other.\n\n**Q4:** Real-world MTS often exhibit dynamic relationships between channels, which may vary over time. For instance, two channels might show positive correlation at one point and no correlation at another. Could pruning lead to a loss of such dynamic, context-dependent information?\n\n**A4\uff1a** Thank you for your suggestion. Since we are focusing on the channels that are more important to the model's performance throughout the entire training process, rather than at a specific moment, it does not reflect the dynamic channel correlations. Addressing this issue could be a new research direction we may consider moving forward.\n\n**Q5:** From the results in Table 5, it appears that the pruned models only slightly outperform or match the full-channel models. This raises questions about the necessity and practical benefits of pruning. How does channel pruning substantively benefit the analysis or forecasting tasks, given these marginal differences?\n\n**A5\uff1a** Referring to our previous response to Q1, the purpose of pruning is not to improve model performance, but rather to accelerate training and facilitate interpretability analysis of the model's capabilities. If I have misunderstood your question, please feel free to clarify, and I would be happy to discuss it further.\n\n**Q6:** Based on the above Q1 and Q2, the biggest confusion is\uff1awe think all comparison experiments should maintain consistent output channels (i.e., the same number of channels) to ensure fairness and accuracy when evaluating the model's performance?\n\n**A6\uff1a** Referring to our previous response to Q1, we predict the results for all channels during testing, so the comparison is valid. If I have misunderstood your question, please feel free to clarify, and I would be happy to discuss it further."
            }
        },
        {
            "title": {
                "value": "Response to weaknesses"
            },
            "comment": {
                "value": "**Q1:** Figure 1 is not cited within the paper.\n\n**A1\uff1a** We have revised the paper according to your suggestions and re-uploaded it. The modified sections are highlighted in blue for your reference.\n\n**Q2:** Algorithm 2 could be polished.\n\n**A2\uff1a** We have revised the paper according to your suggestions and re-uploaded it. The modified sections are highlighted in blue for your reference. In addition, we would appreciate any further suggestions you may have for refining Algorithm 2. This would greatly assist us in better explaining our work to you."
            }
        },
        {
            "title": {
                "value": "Explanation of the contributions of the paper:"
            },
            "comment": {
                "value": "We appreciate your time to provide valuable comments and suggestions to improve our paper substantially. Before we begin addressing your questions, we would like to first clarify the primary contributions of our paper. Influence functions have demonstrated significant performance and value across various fields[4]-[10], with notable applications in outlier detection[7][8][9][10] and data pruning[4][5]. However, there is no preceding research on the influence functions of multivariate time series to shed light on the effects of modifying the channel of multivariate time series. To fill this gap, we propose a channel-wise influence function, which is the first method that can estimate the influence of different channels in multivariate time series. We conducted extensive experiments and found that the original influence function performed poorly in anomaly detection and could not facilitate channel pruning, underscoring the superiority and necessity of our approach. Additionally, we can further analyze the information learned by the model through the channel-wise influence matrix. For example, as mentioned in Section 5.2.1 of our paper, comparing the number of core channel subsets across different models reveals each model's capacity for capturing channel dependencies. A larger core subset indicates that the model has captured more effective information, which also highlights the interpretability of our approach.\n\n**Regarding the selection of tasks to verify our method:** Anomaly detection has long been a critical issue in multivariate time series analysis, with relevant studies including[1][2]. Data pruning is equally important as it raises the question of whether we can train a high-performing model with less data than predicted by scaling laws[3], with related work found in studies such as [3][4][5]. However, data pruning has not yet been extensively studied within the context of time series. By analyzing the characteristics of multivariate time series, we identified redundancy between channels and developed a channel pruning method based on our proposed channel-wise influence function, which outperforms traditional data pruning approaches. In addition, this method also supports the interpretability analysis of the model's ability to model multivariate time series.\n\n[1]Position paper: Quo vadis, unsupervised time series anomaly detection? ICML 2024\n\n[2]Anomaly transformer: Time series anomaly detection with association discrepancy. ICLR 2022\n\n[3]Beyond neural scaling laws: beating power law scaling via data pruning Neurips 2022\n\n[4]Data Pruning via Moving-one-Sample-out Neurips 2023\n\n[5]Dataset Pruning: Reducing Training Data by Examining Generalization Influence ICLR 2023\n\n[6]Self-influence guided data reweighting for language model pre-training. ACL 2023\n\n[7]Detecting adversarial samples using influence functions and nearest neighbors. CVPR 2020\n\n[8]Estimating training data influence by tracing gradient descent. Neurips 2020\n\n[9]Understanding Black-box Predictions via Influence Functions. ICML 2017\n\n[10]Resolving Training Biases via Influence-based Data Relabeling. ICLR 2022"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Channel-wise Influence Function, a novel method tailored for multivariate time series (MTS) data to enhance model interpretability and performance by assessing the impact of individual channels. While MTS data are pivotal in domains like healthcare, traffic forecasting, and finance, traditional deep learning approaches have primarily focused on architectural improvements rather than understanding the unique contributions of each channel. Existing influence functions, effective in areas with independent data, fall short for MTS due to their inability to differentiate channel-specific effects. The proposed Channel-wise Influence Function addresses this by using a first-order gradient approximation to evaluate each channel\u2019s contribution, proving especially useful in tasks like anomaly detection and forecasting. Extensive experiments show that this new approach outperforms traditional influence functions on real-world datasets, offering a more effective, interpretable tool for MTS analysis."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Innovation: The paper introduces the Channel-wise Influence Function, a novel method for analyzing the influence relationships between different channels in multi-channel time series (MTS) data. This approach is relatively rare in existing research and provides a new perspective for understanding and optimizing multi-channel data.\nFine-grained Dependency Analysis: Traditional influence function methods typically calculate only the overall influence, while the channel-wise influence function enables detailed quantification of each channel's influence on other channels. This fine-grained analysis is valuable in prediction and anomaly detection tasks for multi-channel data.\nBroad Application Scenarios: The proposed method holds potential for various tasks, such as anomaly detection, channel pruning, and feature selection. The channel-wise influence function can help identify key channels, simplify models, and improve prediction accuracy, making it highly practical in real-world applications."
            },
            "weaknesses": {
                "value": "Lack of Clarity in Presentation: Figure 1, intended as an overview of the framework, does not clearly correspond with the main text, leaving several critical points unexplained. For instance, the calculation of the \"Score\" in the figure is not detailed, nor is its derivation clearly defined in the \"CHANNEL-WISE INFLUENCE FUNCTION\" section. Additionally, the term \"well-trained model\" lacks a concrete description of what type of model is being referred to. The paper also mentions that the \"Channel-wise Influence\" can serve as an explainable method to assess the channel-modeling capabilities of different approaches; however, it lacks detailed explanations and specific case studies to illustrate this claim.\nLimited Datasets, Leading to Less Convincing Results: The experiments are conducted on a limited number of datasets, which reduces the generalizability and representativeness of the results. For example, in the time series forecasting task, only the electricity, solar-energy, and traffic datasets were used, without evaluating common benchmarks like ETTh, ETTm, and Exchange. Additionally, the forecast length was fixed at 96, which may restrict the credibility of the results and the method's broader applicability.\nInsufficient Comparison with Baseline Models: The paper lacks comparison with enough baseline models, especially current mainstream state-of-the-art (SOTA) methods. This limitation makes it difficult to fully assess the proposed method's effectiveness relative to existing approaches, thus limiting the demonstration of its advantages. For instance, in time series forecasting, only PatchTST and iTransformer were used for comparison, while other competitive models like GPHT, SimMTM, TSMixer, TimesNet, and DLinear were omitted. Additionally, while the authors designed a CHANNEL PRUNING experiment, it would also be valuable to see how the Channel-wise Influence method performs in a standard time series forecasting setup for a more comprehensive evaluation."
            },
            "questions": {
                "value": "1. The framework figure (Figure 1) does not clearly correspond with the main text, particularly in areas like the calculation and derivation of \"Score\" and the definition of \"well-trained model.\" Could you provide additional explanations or examples to clarify these components and better illustrate the core concept of the channel-wise influence function?\n2. You mentioned that \"it can serve as an explainable method to reflect the channel-modeling ability of different approaches.\" (6nd paragraph, line 293) Could you provide more specific explanations or examples, perhaps through case studies or illustrative examples, to demonstrate how the channel-wise influence function explains or evaluates different models' abilities to capture channel dependencies?\n3. The current experiment includes only a few baseline comparisons, especially missing mainstream SOTA models like GPHT, SimMTM, TSMixer, TimesNet, and DLinear in time series forecasting. Do you plan to add comparisons with these models in future work to better demonstrate your method's competitiveness?\n4. Given the limited datasets used in the experiments (electricity, solar-energy, and traffic) and the fixed forecast length of 96, the generalizability of the results might be limited. Would testing on additional datasets, such as ETTh, ETTm, and Exchange, with varied forecast lengths, help further validate the method's applicability?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the problem of influence function for multivariate time series (MTS), which is the first study of MTS in deep learning. To effectively estimate the influence of MTS, this paper proposes a first-order gradient approximation. Then, the authors propose two channel-wise influence function-based algorithms for MTS anomaly detection and forecasting, respectively."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- It is the first work of influence function for MTS in deep learning. \n\n- Two channel-wise influence function-based algorithms is proposed in this paper to be applied in MTS anomaly detection and forecasting tasks."
            },
            "weaknesses": {
                "value": "- The technical contribution of this paper is not very high. Only the influence function is proposed in MTS, which has been well-studied in other domains. \n\n- The experimental results are not very impressive. In Table 2, we can observe that by using of proposed influence the improvement is not very significant. And also the datasets used in this paper are not enough. \n\n- The time complexity of the proposed method is not analyzed in this paper. \n\n- The code of this paper is not provided."
            },
            "questions": {
                "value": "See above weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Channel-wise Influence Function, a method designed to analyze the influence of individual channels in MTS data on the performance of ML models. The authors argue that existing influence function methods, commonly applied in CV and NLP, are inadequate for MTS analysis due to temporal dependencies and diverse information contained within different channels of MTS data. The proposed method leverages a first-order gradient approximation, drawing inspiration from the TracIn method, to quantify how training with a specific channel in the MTS data affects the model's ability to predict another channel. This method is presented to provide insights into the relationship between data and model behavior."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(1) The proposed method addresses a limitation in existing influence function methods by studying the unique contributions of individual channels within MTS data. While traditional methods assess the impact of entire data samples on model performance.\n(2) By ranking channels based on their self-influence scores, the proposed method enables the selection of a reduced subset of channels without significant compromise to the model's predictive accuracy. This is particularly advantageous in scenarios where training with the entire set of channels is computationally expensive or infeasible."
            },
            "weaknesses": {
                "value": "(1) The paper primarily focuses on anomaly detection and forecasting, leaving the application to other relevant MTS tasks, such as classification, clustering, or imputation, unexplored. This limited scope restricts the paper's ability to fully demonstrate the potential of the proposed method in diverse MTS applications.\n(2) The method relies on gradient computations, which can become computationally demanding for complex models, particularly when applied to large-scale MTS datasets. To address this, the paper proposes using gradients from a subset of model parameters to improve efficiency. However, a more detailed analysis of the trade-off between computational cost and performance when employing a reduced set of gradients is warranted.\n(3) The paper employs an equidistant sampling strategy to select channels based on their ranked self-influence scores. This approach may introduce biases, particularly when the distribution of influence scores is uneven.  For instance, if a large number of channels have similar influence scores, the equidistant sampling might lead to the exclusion of potentially informative channels simply because they are clustered together in the ranking."
            },
            "questions": {
                "value": "(1) Several works have successfully applied influence functions to analyze MTS data. For instance, TimeInf (Li et al., 2024) utilizes influence functions to quantify the impact of individual data points on the model's predictions. It would be beneficial for the authors to explicitly discuss how the proposed method compares to, or builds upon, these existing approaches.\n\n1. TimeInf: Time Series Data Contribution via Influence Functions. https://arxiv.org/abs/2407.15247\n2. Interdependency Matters: Graph Alignment for Multivariate Time Series Anomaly Detection. https://arxiv.org/abs/2410.08877\n3. sTransformer: A Modular Approach for Extracting Inter-Sequential and Temporal Information for Time-Series Forecasting. https://arxiv.org/abs/2408.09723\n\n(2) The paper primarily focuses on comparing with the original influence function and naive channel selection methods. A more comprehensive evaluation would involve comparing with other channel selection techniques, such as those based on feature importance scores or attention mechanisms, to provide a more robust assessment of its effectiveness.\n\n(3) Computational complexity analysis of the proposed method as the number of channels increases  is crucial. Hence, an empirical evaluation using larger and more diverse datasets, such as the publicly available ETT, Electricity, and Traffic datasets (link: https://drive.google.com/file/d/1l51QsKvQPcqILT3DwfjCgx8Dsg2rpjot/view), would be beneficial.\n\n(4) While the paper emphasizes the potential of the proposed method for post-hoc model analysis, particularly in the context of channel pruning, it is worth exploring further applications. For instance, could metrics derived from the channel influence matrix, such as entropy or diversity of influential channels, be leveraged to compare and evaluate different MTS models? Such metrics might provide insights into a model\u2019s ability to capture complex channel relationships and its overall performance.\n\n(5) For the selection of representative channels, I'm wondering if methods like top-k selection or adaptive sampling based on the influence score distribution be more appropriate?\n\n(6) The 1-Layer MLP model in Table 3 appears to refer to a single-layer Multilayer Perceptron as the entire model architecture. It is intriguing that such a simple model can achieve comparable, and in some cases, superior performance to a more complex Transformer-based model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a new channel-wise influence function designed to address limitations in multivariate time series (MTS) analysis. Unlike previous model-centric methods, this approach provides a data-centric view, allowing the estimation of the influence of each channel within the MTS. The authors propose an influence function leveraging a first-order gradient approximation to improve MTS anomaly detection and forecasting tasks. Experimental results on various datasets indicate that the method outperforms traditional influence functions, especially in anomaly detection and channel pruning for forecasting."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality: Proposes a unique channel-wise influence function, filling an important gap in MTS analysis by focusing on data-centric rather than model-centric approaches.\n\nQuality:Demonstrates robust experiments across datasets, highlighting improvements in MTS anomaly detection and forecasting.\n\nClarity: Clear, structured explanations and well-supported claims for the impact of the influence function on downstream MTS tasks.\n\nSignificance: The model holds practical relevance across domains where MTS is essential, particularly in applications needing channel-wise insights."
            },
            "weaknesses": {
                "value": "1. Figure 1 is not cited within the paper.\n2. Algorithm 2 could be polished."
            },
            "questions": {
                "value": "1. After channel pruning, does the final prediction use the pruned channels or the full set of channels? Clarifying this will help determine whether pruning directly improves prediction or simply reduces computational costs, and why are the pruned channels still accurately predicted? How does the model achieve this?\n\n2. Given that PatchTST is channel-independent, how can we justify that removing channels enhances overall performance? For example, certain channels may have lower MSE due to higher predictability, while others may be more erratic, resulting in higher MSE. If more erratic channels are removed, this might artificially lower the overall MSE, which could be misleading.\n\n3. Rather than pruning channels, would it be more insightful to analyze the interactions between channels? For example, investigating how one channel affects another could provide a deeper understanding of channel dependencies in MTS.\n\n4. Real-world MTS often exhibit dynamic relationships between channels, which may vary over time. For instance, two channels might show positive correlation at one point and no correlation at another. Could pruning lead to a loss of such dynamic, context-dependent information?\n\n5. From the results in Table 5, it appears that the pruned models only slightly outperform or match the full-channel models. This raises questions about the necessity and practical benefits of pruning. How does channel pruning substantively benefit the analysis or forecasting tasks, given these marginal differences?\n\n6. Based on the above Q1 and Q2, the biggest confusion is\uff1awe think all comparison experiments should maintain consistent output channels (i.e., the same number of channels) to ensure fairness and accuracy when evaluating the model's performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}