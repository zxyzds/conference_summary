{
    "id": "CaexTRYaN6",
    "title": "CONCORD: Concept-informed Diffusion for Dataset Distillation",
    "abstract": "Dataset distillation has witnessed significant progress in synthesizing small-scale datasets that encapsulate rich information from large-scale original ones. Particularly, methods based on generative priors show promising performance, while maintaining computational efficiency and cross-architecture generalization. However, the generation process lacks explicit controllability for each sample. Previous distillation methods primarily match the real distribution from the perspective of the entire dataset, whereas overlooking conceptual completeness at the instance level. This oversight can result in missing or incorrectly represented object details and compromised dataset quality. To this end, we propose to incorporate the conceptual understanding of large language models (LLMs) to perform a CONCept-infORmed Diffusion process for dataset distillation, in short as CONCORD. Specifically, distinguishable and fine-grained concepts are retrieved based on category labels to explicitly inform the denoising process and refine essential object details. By integrating these concepts, the proposed method significantly enhances both the controllability and interpretability of the distilled image generation, without replying on pre-trained classifiers. We demonstrate the efficacy of CONCORD by achieving state-of-the-art performance on ImageNet-1K and its subsets. It further advances the practical application of dataset distillation methods. The code implementation is attached in the supplementary material.",
    "keywords": [
        "dataset distillation",
        "diffusion model"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-18",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CaexTRYaN6",
    "pdf_link": "https://openreview.net/pdf?id=CaexTRYaN6",
    "comments": [
        {
            "withdrawal_confirmation": {
                "value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."
            }
        },
        {
            "comment": {
                "value": "Dear reviewer,\n\nThanks again for your detailed reviews.\n\nIn addition to the previous clarification, we would also like to reply to some other weaknesses and concerns:\n1. For weaknesses 1, we intend to integrate the text concepts into the diffusion denoising process. CLIP here only serves as a tool to bridge the embedding space of text and images. It is true that we rely on CLIP's knowledge of the common embedding space, but I cannot see why it is a weakness. Instead of distilling CLIP's knowledge, we are distilling the corresponding text concepts into the images with the help of CLIP. \n2. For question 3, the discussion of model choices is presented in Section B of the supplementary material. Please kindly refer to it.\n\nBest,\n\nAuthors"
            }
        },
        {
            "title": {
                "value": "Clarification on the experiments"
            },
            "comment": {
                "value": "Thank you for the detailed and constructive comments!\n\nWe want to first clarify that the \"Efficient Dataset Distillation via Minimax Diffusion\" paper serves as one of the baselines in this paper, which is denoted as \"Minimax\" in tables. And our method shows improvement over the baseline, achieving state-of-the-art accuracy. \n\nAs it is listed in the questions, we assume this is one major factor that the reviewer gives us a score of 5. With this clarification, we would like to know whether the reviewer will reconsider the rating.\n\nBest,\n\nAuthors"
            }
        },
        {
            "title": {
                "value": "Clarification on the experiments"
            },
            "comment": {
                "value": "Thank you for the detailed and constructive comments!\n\nWe want to first clarify that the comparison with MTT and SRe2L is already included in Table 1. And the proposed method shows a clear advantage over these two methods in large-IPC settings. \n\nAs it is listed in the weaknesses section, we assume this is one major factor that the reviewer gives us a score of 3. With this clarification, we would like to know whether the reviewer will reconsider the rating.\n\nBest, \n\nAuthors"
            }
        },
        {
            "title": {
                "value": "Clarification on the page limit"
            },
            "comment": {
                "value": "Thank you for the detailed and constructive comments!\n\nWe want to clarify that the reproducibility statement doesn't count toward the page limit according to the instructions (https://iclr.cc/Conferences/2025/AuthorGuide).\n\nAs the reviewer mentioned \"is a possible concern and will negatively impact the evaluation score\", we assume this is one major factor that the reviewer gives us a score of 5. With this clarification, we would like to know whether the reviewer will reconsider the rating.\n\nBest,\nAuthors"
            }
        },
        {
            "summary": {
                "value": "This paper presents a study on enhancing the performance of knowledge distillation through a diffusion model by incorporating a concept-informing process. Using a large language model (LLM), a concept text is extracted, and during the denoising phase, CLIP-based image-text matching gradients are applied to embed concepts that accurately represent specific classes within a compressed dataset. Both positive and negative concepts are utilized to achieve a contrastive effect, refining the model\u2019s ability to capture essential class-specific concepts."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The proposed method utilizes diffusion models and CLIP to generate condensed images without the need for additional model training, streamlining the process and saving computational resources.\n- The method successfully automates the concept extraction process through the use of large language models (LLMs), enhancing efficiency and reducing the reliance on manual intervention.\n- The paper demonstrates reliable performance gains when integrated as an add-on to existing methods, showcasing its versatility and compatibility.\n- It delivers consistently strong results across both fine-grained and regular datasets, highlighting its robustness and adaptability to varying data complexities."
            },
            "weaknesses": {
                "value": "- The proposed approach primarily leverages backpropagation within the CLIP feature space, which gives the impression of being a minimal extension of existing diffusion-based methods with CLIP feature matching. Rather than integrating concept-informed insights, it appears to be focused on distilling CLIP's knowledge directly.\n- The method demonstrates unstable performance on IPC 1, raising concerns about its scalability to larger datasets or its generalizability across different dataset sizes with more class numbers.\n- The paper lacks comparative experiments with widely recognized open-source methods, such as MTT and SRe2L, which could provide a clearer benchmark of the proposed approach\u2019s performance."
            },
            "questions": {
                "value": "- The CLIP feature matching gradient in Equation 9 does not seem to correlate with the alpha parameter in the diffusion process, raising questions about the theoretical or empirical basis for this choice.\n- The LLM experiments appear to be restricted to closed models, which may limit the generalizability and applicability of the findings. Has this method been tested with open models?\n- Table 6 indicates that the proposed method may not inherently require an Img2Img structure, and even shows that DiT yields better performance. Could you clarify the rationale for selecting the current Img2Img-based structure?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "\"CONCORD: Concept-informed Diffusion for Dataset Distillation\" is the first to apply LLMs to dataset distillation. This approach leverages the conceptual knowledge from LLMs to guide the diffusion model, achieving a certain degree of instance-level control over image details and demonstrating significant effectiveness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This method demonstrates significant innovation, being the first to combine LLMs with Dataset Distillation (DD). It leverages the vast knowledge base of LLMs and guides the dataset distillation process through conceptual knowledge.\n\n- The method greatly enhances instance-level control, addressing the issue of insufficient detail control in existing approaches to a certain extent.\n\n- By using CLIP to verify the correlation between concepts and images, the method ensures the validity and accuracy of the concepts applied.\n\n- The approach incorporates the idea of contrastive matching, minimizing the similarity between generated samples and negative concepts, thus improving the stability and accuracy of the generation process."
            },
            "weaknesses": {
                "value": "- The experimental results are highly dependent on the concept information provided by LLMs, which may lead to instability in performance.\n\n- The performance improvements are limited, and there is a lack of detailed comparison with other methods in cross-architecture evaluations.\n\n- The introduction of contrastive matching and concept evaluation may increase computational costs."
            },
            "questions": {
                "value": "- Due to the reliance on concept information, you can evaluate the performance of different LLMs or different numbers/types of concepts, or analyze the sensitivity of the results to changes in the retrieved concepts.\n\n- We observed that using CONCORD significantly increases computation time, approximately 2-3 times that of without CONCORD. Could you explain in detail why the computation time increases so much? Are there any potential ways to effectively optimize this issue?\n\n- Why did you not compare your method with other diffusion + DD approaches, such as D$^4$M: Dataset Distillation via Disentangled Diffusion Model, and Efficient Dataset Distillation via Minimax Diffusion?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a new technique for diffusion-based data distillation by incorporating conceptual information. Specifically, large language models are employed to identify class concepts, which are then used to enhance the diffusion process for data distillation. Experimental results demonstrate that this method consistently improves the performance of data distillation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method is simple and easy to implement, making it easily integrable into existing generative-model-based data distillation approaches. Additionally, the use of large language models (LLMs) is straightforward and compatible with more advanced LLMs.\n   \n2. The experimental results show consistent improvements across multiple benchmark datasets. While the method does not outperform state-of-the-art techniques, it enhances the performance of baseline methods in nearly all cases."
            },
            "weaknesses": {
                "value": "1. The method appears heuristic, combining LLMs with diffusion models. Specifically, the concept-informed diffusion is based on the classifier-guided diffusion model, where the formulation is derived from conditional probabilities. However, this paper directly alters how conditional information is incorporated, replacing classifier guidance with concept information (the gradient of the loss function), which seems questionable. Providing explanations or justifications for these modifications in the formulas would be beneficial.\n\n2. The claims are not fully substantiated by the experiments. In the introduction, the paper makes several claims about the advantages of the method, such as offering personalization in data distillation. This concept is unclear, and there is no experimental evidence to support it. Including additional evidence or examples would strengthen the validity of these claims."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces CONCORD, a novel dataset distillation method that leverages large language models (LLMs) to guide the diffusion process for image generation. It incorporates contrastive loss to provide adequate guidance. It improves\t both controllability and interpretability without relying on pre-trained classifiers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper's visualizations clearly demonstrate improved image detail when using CONCORD.\n\nThe overall idea is innovative, as it utilizes LLM-generated content as prompts to guide the diffusion process during dataset distillation, showcasing novelty.\n\nCONCORD allows for explicit control during the diffusion process, offering a more interpretable approach compared to traditional dataset distillation methods.\n\nThe theoretical foundations are well-established, and the inclusion of code is a pleasant surprise.\n\nThe inclusion of the code is a pleasant surprise."
            },
            "weaknesses": {
                "value": "The performance improvements are quite limited, with some of the gains potentially attributable to variance.\n\nThis method depends on the quality of concepts retrieved from LLMs; if the descriptions are not sufficiently accurate or detailed, the quality of the generated datasets could suffer.\n\nThe introduction of LLMs and contrastive loss increases the complexity of training."
            },
            "questions": {
                "value": "The paper exceeds the 10-page limit, which is a possible concern and will negatively impact the evaluation score.\n\nFor some datasets and models, the improvements are minimal. For example, in Table 1 (IPC1, ResNet-101), the variance is greater than 1, yet the improvement is less than 1.\n\nIt might be useful to explore descriptions generated by a variety of LLM models for greater diversity.\n\nRelying solely on visualizations to demonstrate effectiveness could be strengthened by comparing loss changes with and without CONCORD."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}