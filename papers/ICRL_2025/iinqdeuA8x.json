{
    "id": "iinqdeuA8x",
    "title": "Towards Dynamic Graph Neural Networks with Provably High-Order Expressive Power",
    "abstract": "Dynamic Graph Neural Networks (DyGNNs) have garnered increasing research attention for learning representations on evolving graphs. \nDespite their effectiveness, the limited expressive power of existing DyGNNs hinders them from capturing important evolving patterns of dynamic graphs. \nAlthough some works attempt to enhance expressive capability with heuristic features, there remains a lack of DyGNN frameworks with provable and quantifiable high-order expressive power.\nTo address this research gap, we firstly propose the k-dimensional Dynamic WL tests (k-DWL) as the referencing algorithms to quantify the expressive power of DyGNNs. We demonstrate that the expressive power of existing DyGNNs is bounded by the 1-DWL test. \nTo enhance the expressive power, we propose Dynamic Graph Neural Network with High-order expressive power (HopeDGN), which updates the representation of central node pair by aggregating the interaction history with neighbor node pairs. \nOur theoretical results demonstrate that HopeDGN can achieve expressive power equivalent to the 2-DWL test. \nWe then present a Transformer-based implementation for the local variant of \\model.\nExperimental results show that HopeDGN achieved  performance improvement up to 3.12\\% on seven datasets, demonstrating the effectiveness of HopeDGN.",
    "keywords": [
        "Graph Neural Network",
        "Dynamic Graph",
        "Expressive power"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "We propose a dynamic graph neural network with provably high-order expressive power.",
    "creation_date": "2024-09-22",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=iinqdeuA8x",
    "pdf_link": "https://openreview.net/pdf?id=iinqdeuA8x",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a k-dimensional dynamic Weisfeiler-Lehman (WL) test as a novel approach to quantify the expressiveness of dynamic graph neural networks (DyGNNs) and unifies simpler DyGNNs under the 1-Dimensional WL (1-DWL) framework. Additionally, the paper proposes HopeDGN, which employs a more granular encoding method to achieve the expressiveness of a 2-DWL test. Experimental results indicate the method\u2019s effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is the first to propose a k-dimensional dynamic WL test to evaluate the expressiveness of DyGNNs, addressing a relatively underexplored area in DyGNN expressiveness.\n2. The proposed framework theoretically attains 2-DWL expressiveness by introducing a novel encoding scheme, which also shows potential for generalization to other models.\n3. The model includes an optimized local version for practical applications, demonstrating strong performance."
            },
            "weaknesses": {
                "value": "1. While prior DyGNNs may lack a unified framework, they have implemented numerous techniques to enhance expressiveness. Examples include DyGformer [1] with neighbor co-occurrence encoding, CAWN [2] with anonymous walk paths, and NAT [3] with neighborhood-aware encoding, etc. These methods are not addressed within the proposed framework, potentially making it appear somewhat isolated.\n2. The theoretical time complexity of the k-DWL framework, especially over longer time spans, may be a concern, as noted by the authors. While local variants are proposed, practical usability could still be limited by these computational demands.\n\n[1] Towards Better Dynamic Graph Learning: New Architecture and Unified Library https://arxiv.org/abs/2303.13047\n[2] Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks https://arxiv.org/abs/2101.05974\n[3] Neighborhood-aware Scalable Temporal Network Representation Learning https://arxiv.org/abs/2209.01084"
            },
            "questions": {
                "value": "1. In Table 2, integrating MITE with other baselines shows significant improvements. How is this integration implemented, and does MITE demonstrate clear benefits compared to other encoding approaches?\n2. Figure 5 highlights a notable efficiency improvement when reducing the neighbor length. What are the corresponding performance metrics associated with these efficiency gains?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a novel dynamic graph neural network that is theoretically inspired by a proposed dynamic-WL test. According to this framework, they show that existing DyGNNs are bounded by 1-DWL test and by using a multi-interaction time encoding (MITE), they can increase the expressiveness to up to 2-DWL test. Then, they propose HopeDGN, which updates the representation of a node pair by aggregating not just the historical interactions but also the elapsed times. Through a transformer-based implementation, they show improved performance across seven datasets, while demonstrating plug-and-play benefits."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed MITE matrix can be used in a plug-and-play fashion to provide gains in existing architectures. \n- Time complexity and efficiency analysis are provided.\n- HopeDGN leverages the strengths of the transformer and a theoretically motivated WL-test to propose a more effective method.\n- Empirical comparison is thorough in both transductive and inductive settings of link prediction against representative baselines."
            },
            "weaknesses": {
                "value": "- The DWL test is almost identical to the temporal WL test in PINT [1]. This is not acknowledged in the main paper and thus, can be flagged as plagiarism. \n- Discussion with existing related work is casual and not carefully positioned. \n  - It is mentioned that it is not clear how relative positional features provide theoretical benefits even though it was shown theoretically in Souza et al., 2022 [1]. \n  - It is mentioned that \"Souza et al. (2022) proves that adding a memory mechanism will not change the expressive power of DyGNNs. Therefore, the expressive power of DyGNNs can be fully characterized by the 1-DWL test.\" but this is wrong as they show that is true specifically when the architecture of the MP-GNN is deep enough. \n  - It is not clear whether what are the theoretical benefits of the proposed method as compared to [1] or [4]. It seems that the benefits are complementary but needs further discussion. Does the proposed method already provably reach the expressiveness of time-then-graph and PINT in their expressiveness tests.\n- Space complexity is not provided nor computationally compared. The additional cost of storing B matrix along with the transformer architectures may be prohibitive in many cases and limit the scalability of the proposed method. \n- MITE encoding is similar to the time projection for staleness as done in JODIE [2] and TGN [3]. However, these similarities are neither acknowledged nor discussed in the paper. It seems like MITE is an extension of the time projection to the neighbors' encodings in addition to only the interacting node's embeddings. \n- The proof of the main proposition 3 that shows the theoretical disadvantage of existing dyGNNs seems wrong. In particular, they only consider node b for graph (a) and node h in graph (b). On the other hand, Equation 9 denotes that they should have considered all historical neighbors w for both graphs. This would have meant considering nodes b, h, d for graph (a) and nodes b, h, f for graph (b). In that case, d and f seem to be the difference maker and not b and h. \n- Considering the MITE interactions for all historical neighbors seem unscalable as the size of the graph increases. \n- Running time of HopeDGN is not compared against the baselines, only the training time is compared. \n\n[1] Souza, Amauri, et al. \"Provably expressive temporal graph networks.\" Advances in neural information processing systems 35 (2022): 32257-32269.\n\n[2] Kumar, Srijan, Xikun Zhang, and Jure Leskovec. \"Predicting dynamic embedding trajectory in temporal interaction networks.\" Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. 2019.\n\n[3] Rossi, Emanuele, et al. \"Temporal graph networks for deep learning on dynamic graphs.\" arXiv preprint arXiv:2006.10637 (2020).\n\n[4] Gao, Jianfei, and Bruno Ribeiro. \"On the equivalence between temporal and static graph representations for observational predictions.\" arXiv preprint arXiv:2103.07016 (2021)."
            },
            "questions": {
                "value": "see above weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a novel Dynamic Graph Neural Network (DyGNN) framework called HopeDGN (Dynamic Graph Neural Network with High-order Expressive power). The primary focus of the paper is to address the limited expressive power of existing DyGNNs in capturing evolving patterns in dynamic graphs. The authors propose the k-dimensional Dynamic WL tests (k-DWL) as a theoretical framework to quantify the expressive power of DyGNNs, and introduce the Multi-Interacted Time Encoding (MITE) that captures the bi-interaction history of target node pairs with other nodes. MITE is integrated into the HopeDGN framework, and theoretical results show that HopeDGN can achieve expressive power equivalent to the 2-DWL test. Experimental results demonstrate that HopeDGN achieves superior performance on link prediction and node classification tasks compared to other baselines."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The Multi-Interacted Time Encoding (MITE) allows the model to capture indirect dependencies between node pairs, which is crucial for tasks like link prediction. This module is a plug-and-play component that can be integrated into various models, enhancing their expressive power.\n\n- The paper provides proofs that HopeDGN can achieve expressive power equivalent to the 2-DWL test, which is a significant improvement over existing DyGNNs. This theoretical grounding adds credibility to the practical results.\n\n- The authors discuss multiple model design details including Neighborhood encoding, patching and Transformer encoder. The authors conduct extensive experiments on both link prediction and node classification tasks across multiple datasets. The results consistently show that HopeDGN outperforms existing baselines, demonstrating its effectiveness."
            },
            "weaknesses": {
                "value": "- The paper could benefit from a detailed comparison with other high-order GNNs that have been proposed for static graphs since the basic idea of encoding node pairs comes from high-order WL tests, like https://arxiv.org/abs/1810.02244.\n- See questions below."
            },
            "questions": {
                "value": "- I am confused with the example in Figure 1. Suppose the graph is static, according to symmetry 1-WL test will give identical labels to C and D, then GNN cannot distinguish node pairs (A, C) and (A, D) using only node embeddings, which has no connection to graph dynamics. And since 2-WL works on node pairs, we can easily verify that (A, C) and (A, D) will get different labels in 2-WL test so methods derived from 2-WL can distinguish them (like MITE). Therefore I don\u2019t think that this example can well explain the expressive limitations of 1-DWL since it also works in static graphs. Can the authors provide more explanations?\n\n- Can the proposed method work on dynamic graphs in which edge interaction can both start and end?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work aims to address the gap in dynamic graph learning research concerning the theory of expressive power. The authors first introduce the $k$-DWL test and argue that the expressive power of existing DGNN models is bounded by the 1-DWL test. To advance this, they propose a new DGNN model that works analogously to the 2-DWL test and prove that the proposed model, Global HopeDGN, is equivalent to the 2-DWL test. The experiments show the local variant of HepeDGN can achieve superior performance across several datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This work is the first attempt at assessing the expressive power of dynamic graph learning and introduces the concept of the $k$-WL test. It intuitively points out the limitations of existing DGNN models and proves that the 1-WL test limits their expressive power.\n2. This work proposes a new DGNN model, HopeDGN, inspired by the 2-WL test. This model has greater expressive power than vanilla DGNN models, and the experiments show its superiority."
            },
            "weaknesses": {
                "value": "1. Although no research exists on the expressive power theory of DGNN, a few studies have considered the correlations between historical neighbors of two terminal nodes, such as DyGFormer, HOT [R1], and CAWN. HopeDGN is somewhat of an incremental study compared to DyGFormer. HopeDGN exhibits higher performance in the experiments but may incur much larger training costs.\n2. The discussions of the expressive power of existing DGNN models are not completely correct. \n   1. The abstraction of DyGNNs in Section 3 cannot cover existing studies. For instance, CAWN can leverage the information from high-order neighbors in a single layer if the length of the random walk is larger than 1.   \n   2. DyGFormer, HOT, and CAWN are able to distinguish AC and AD in Figure 1.\n3. Some notations are confusing. $l$ is used to represent the layer of AGG and UPDATE in Line 167 and the node labeling function in Line 239. And the layer of AGG and UPDATE of local HopeDGN in the experiments is not specified. In addition, the MITE of $w$ is denoted as $X_{B,w}$ in Line 369 and $X_{M,w}$ in Line 289.\n\n[R1] HOT: Higher-Order Dynamic Graph Representation Learning with Efficient Transformers"
            },
            "questions": {
                "value": "1. The expressive power of the 1-WL test and the 2-WL test is the same in static graphs, as argued in [R2]. Is the 1-DWL test equivalent to the 2-DWL test? Intuitively, it is.\n2. Could the authors provide the training cost of HopeDGN and the baselines?\n\n\n[R2] A Short Tutorial on The Weisfeiler-Lehman Test And Its Variants."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors present a new dynamic GNN model, HopeDGN, designed to exceed the expressive power limitations of current DyGNNs, which are capped by the 1-DWL test. HopeDGN aims to achieve higher-order expressive power by leveraging the 2-WL test."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper investigates an important problem.\n\n2. The paper thoroughly explores the expressive power of dynamic GNNs in relation to the 2-WL test."
            },
            "weaknesses": {
                "value": "1. Similarity to Existing Models: The model structure closely resembles DyGFormer, particularly in Section 4.4, where essential component, from node encoding to the patching-based transformer encoder, are almost identical. However, the authors did not correctly cite DyGFormer, referencing only Dosovitskiy et al. (2021) instead.\n\n2. Lack of Comprehensive 2-WL Analysis: While the paper\u2019s primary contribution is introducing 2-WL testing for dynamic graphs, it falls short of a thorough examination of prior dynamic graph models\u2019 failures under 2-WL. Some inaccuracies are noted; for example, in Figure 1, the claim that DyGNN cannot differentiate node pairs AC and AD is vague. With Neighbor Co-Occurrence Encoding, DyGFormer can indeed distinguish between these pairs. Additionally, the authors did not address scenarios where their model might also fail.\n\n3. Limited Experiments: 3. According to the experimental setup in DyGFormer, there are three different negative sampling configurations. However, this paper appears to only conduct one configuration. Additionally, What\u2019s the purpose of removing time encoding in the ablation study, as time encoding seems to be a common module in DyGNN frameworks and is not a contribution introduced by this paper.\n\n4. Ambiguity in Notation: Certain symbols and terms are unclear, creating readability issues. For instance, the symbol S appears frequently in the complex analysis section (line 398) without definition. Similarly, i and j in Equation 3 lack clear explanations, and there are other instances of undefined notation throughout the paper.\n\n5. Unclear Theoretical Framework: The authors state that they \"establish a theoretical framework to quantify the expressive power of DyGNNs,\" but it is unclear how this quantification is achieved or where this analysis is elaborated upon in the paper."
            },
            "questions": {
                "value": "Please refer to the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}