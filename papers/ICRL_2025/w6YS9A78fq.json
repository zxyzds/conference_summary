{
    "id": "w6YS9A78fq",
    "title": "A Simple Diffusion Transformer on Unified Video, 3D, and Game Field Generation",
    "abstract": "The probabilistic field models the distribution of continuous functions defined over metric spaces. While these models hold great potential for unifying data generation across various modalities, including images, videos, and 3D geometry, they still struggle with long-context generation beyond simple examples. This limitation can be attributed to their MLP architecture, which lacks sufficient inductive bias to capture global structures through uniform sampling.\nTo address this, we propose a new and simple model that incorporates a view-wise sampling algorithm to focus on local structure learning, along with autoregressive generation to preserve global geometry. It adapts cross-modality conditions, such as text prompts for text-to-video generation, camera poses for 3D view generation, and control actions for game generation.\nExperimental results across various modalities demonstrate the effectiveness of our model, with its 675M parameter size, and highlight its potential as a foundational framework for scalable, modality-unified visual content generation.",
    "keywords": [
        "Diffusion Probabilistic Fields",
        "World Model"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-15",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=w6YS9A78fq",
    "pdf_link": "https://openreview.net/pdf?id=w6YS9A78fq",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a transformer-based diffusion field model to better capture global structures and long-context dependencies. It does that by introducing a view-wise sampling algorithm and incorporating autoregressive generation. The proposed method is a general framework that can be applied to multiple modalities, such as video, 3D and game. Extensive experiments are conducted to validate the effectiveness of the proposal."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "S1. The paper is well-written and mostly clear.\n\nS2. The proposed view-wise sampling algorithm is interesting and novel.\n\nS3. Exploiting autoregressive generation to preserve global geometry is reasonable. \n\nS4. The experiments are extensive, especially including various tasks."
            },
            "weaknesses": {
                "value": "W1. As autoregressive generation is typically slower than parallel generation due to its sequential nature, the authors are encouraged to discuss the inference time of the proposed method and baseline methods.\n\nW2. As shown in Table 1, the proposed method achieves better performance against baseline methods on image and video, but worse FID and LPIPS scores on 3D generation task. The authors are encouraged to discuss this phenomenon."
            },
            "questions": {
                "value": "Please see the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposed a novel method for unified video, 3D, and game generation, by learning a DiT based mapping from metric space to signal space, which is able to process high-resolution inputs by the proposed view-wise sampling strategy, as well as maintaining global struture with introduced inductive bias such as text prompts. Results have demonstrated the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. With the view-wise sampling strategy, this method can scale up to high-resolution inputs\n2. By introducing long context conditioning, cross-view consistency can be avoided to some extent"
            },
            "weaknesses": {
                "value": "1. The novelty is limited. From my perpective, the method proposed in this paper simply alters the sampling strategy of existing approaches through a straightforward design change, which trades off a reduced number of sampled views for a higher input resolution. Though the introduction of long context conditioning can compensate the global structure, this operation is common, and i don't this operation is powerful enough to recover the information lost during the process of view-wise sampling.\n\n2. Since the method amis to learn a mapping from input coordinates to output properties, i think some other methods should also be compared, such as SIREN[1], and the difference between them should be clarified.\n\n3. I'm wondering that whether the proposed method can be applied to more complex scenes generation, instead of simple objects in the task of 3D novel view synthesis.\n\n[1] Implicit Neural Representations with Periodic Activation Functions, NeurIPS 2020."
            },
            "questions": {
                "value": "Please see weakness. I'm gald to increase my scores if my concerns can be addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper focuses on unifying data generation across various modalities, including images, videos and 3D geometry. It introduces a view-wise sampling algorithm along with autoregressive generation to improve the performance. The proposed framework can handle various modalities with good performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method is a unified framework for various modalities. This is a relatively new task that might benefit the community.\n\n2. Extensive experiments and ablation studies demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. **The motivation is unclear.** From the introduction section, the main motivation to use Diffusion Probabilistic Field (DPF) is handling various modalities together with a unified model. As for the unified models, what I understand is a single model that can generate different modalities. However, from the description in the method and experiment sections, each modality has different coordinate-signal pairs and the models are trained for each modality separately. If so, such a method cannot be regarded as a unified framework in my view.\n\n2. **Comparison with conventional diffusion models.** In Line 142-144, when comparing DPF with conventional diffusion models, the main difference is that DPF can be applied to sparse observation of fields. However, in the view-wise sampling subsection (Line 244), each time sample the tokens in n views, which is a dense modeling instead of sparse sampling. \n\n3. **Comparison with DPF.** In my view, the main contribution of DPF is the context query pairs sampling and optimization. However, in Line 502, this paper mentions that the context query pairs are not used, which confuses me about the training objective in this paper. Does this paper use the diffusion optimization objective like epsilon-prediction or velocity-prediction? If so, the method is almost the same with DiT.\n\n4. **Limited performance.** I do not see a part describing the dataset and hyperparameters used for training. So I assume the model is trained on each benchmark. If so, the performance is far from satisfactory since the compared methods are generalizable ones instead of fitting to a benchmark."
            },
            "questions": {
                "value": "I am not an expert in Diffusion Probabilistic Fields, and the writing of this paper makes me even more confusing. I hope the authors could improve the writing and explain more background and related work. In addition, most of my concerns are about the explanation of the method and motivation. Please refer to weaknesses for more details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}