{
    "id": "uGJxl2odR0",
    "title": "Dimension Agnostic Neural Processes",
    "abstract": "Meta-learning aims to train models that can generalize to new tasks with limited labeled data by extracting shared features across diverse task datasets. Additionally, it accounts for prediction uncertainty during both training and evaluation, a concept known as uncertainty-aware meta-learning. Neural Process (NP) is a well-known uncertainty-aware meta-learning method that constructs implicit stochastic processes using parametric neural networks, enabling rapid adaptation to new tasks. However, existing NP methods face challenges in accommodating diverse input dimensions and learned features, limiting their broad applicability across regression tasks. To address these limitations and advance the utility of NP models as general regressors, we introduce Dimension Agnostic Neural Process (DANP). DANP incorporates Dimension Aggregator Block (DAB) to transform input features into a fixed-dimensional space, enhancing the model's ability to handle diverse datasets. Furthermore, leveraging the Transformer architecture and latent encoding layers, DANP learns a wider range of features that are generalizable across various tasks. Through comprehensive experimentation on various synthetic and practical regression tasks, we empirically show that DANP outperforms previous NP variations, showcasing its effectiveness in overcoming the limitations of traditional NP models and its potential for broader applicability in diverse regression scenarios.",
    "keywords": [
        "Neural Processes",
        "varying dimension",
        "regression",
        "bayesian optimization"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "A new Neural Process model that can handle varying dimensional inputs and outputs.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=uGJxl2odR0",
    "pdf_link": "https://openreview.net/pdf?id=uGJxl2odR0",
    "comments": [
        {
            "summary": {
                "value": "The authors introduce Dimension Agnostic Neural Process (DANP) that incorporates Dimension Aggregator Block (DAB) to transform input features into a fixed-dimensional space, in an attempt to enhance the model's ability to handle diverse datasets. Leveraging a transformer architecture and latent encoding layers, the proposed approach learns a wide range of features, generalizable across various tasks. \n\nTo evaluate the approach the authors present a comprehensive evaluation, including synthetic and practical regression tasks. The empirical results, consisting of comparisons with exiting state-of-the-art methods and ablations show that the effectiveness of the proposed approach.  The authors outperforms past existing Neural Process methods, demonstrating advantages and improvements on GP regression, Image and Video Completion and Bayesian Optimization tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality \n - The paper seem it has an evident level of novelty, tackling the diverse input and output dimensions challenge in the uncertainty aware meta-learning methods such as neural processes. Two novelties seems to be the case here, the dimension aggregation block and the latent path, in a transformer-like arhitecture.\n\nQuality\n- The paper is well motivated, structured and presented, the problem is well introduces and connected to existing work. The writing is good. There is extensive and diverse evaluation over synthetic and publicly available data sets for the GP regression, Image and Video Completion, and Bayesian Optimization tasks. The Ablation study is also useful.\n\nClarity\n- The proposed approach is nicely presented and explained.\n\nSignificance\n- The approach shows effectiveness of such methods under evaluated dataset and seems to hold potential for applicability in diverse regression scenarios"
            },
            "weaknesses": {
                "value": "Presentation of the tasks/problems that the method addresses\n- The presentation is sufficiently clear. I find that more on the actual task considered here can help to appreciate more the significance and the benefits of this approach. In particular related how the GP regression and the image completion tasks benchmarks help to validate the broad applicability of the approach? \n\nEvaluations\n- Non consistent result and seem to be marginal improvements in the GP Regression (from-scratch case) and the image completion task."
            },
            "questions": {
                "value": "In Table 1, it seems that the proposed approach has only marginal advantage over the proposed methods, in the GP Regression in the from-scratch case. Since, I'm able to see and it appears that between TNP and DANP (proposed approach) across 1D RBF, 1D Matern, 2D RBF and 2D Matern at the target column the only difference (improvement) is at the second (third) decimal. \n\nWhat is the reason for that?\n\nI would have expected higher improvement (e.g. on the first decimal). I'm not sure I can consider this to be statistically significant. Can I ask also whether confidence intervals are available and would it be possible to share them?  \n\nSimilar performance is for the image completion task."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a new model, Dimension Agnostic Neural Process (DANP), which addresses the limitations of current Neural Processes (NP) in handling inputs with varying dimensions. DANP includes a Dimension Aggregator Block (DAB) that converts input features into a fixed-dimensional space, while also incorporating Transformer architecture and latent encoding layers to enhance adaptability across different tasks. Experimental results show that DANP performs well on multiple regression tasks, highlighting its potential as a versatile, general-purpose regressor."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Introduces the DAB module, enabling the model to handle inputs and outputs of varying dimensions, adding flexibility.\n2. Covers multiple tasks and scenarios, demonstrating the model's stability across different conditions.\n3. Performs well in regression, hyperparameter tuning, and other tasks, showing promise for broad applications."
            },
            "weaknesses": {
                "value": "1. Model Complexity. The design is complex, making replication and understanding challenging. \n2. Lacks Analysis of Computational Costs. There\u2019s no discussion of the model's time and resource requirements, impacting assessments for practical use.\n3. Limited Application Scope. Primarily validated on regression tasks, with little exploration of classification or other tasks."
            },
            "questions": {
                "value": "I mainly have concerns about the practical aspects of this work. It would be helpful if the authors could provide more concrete examples and relate them to more complex, real-world applications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces a novel approach to meta-learning, specifically addressing the challenges of accommodating diverse input dimensions and learned features in Neural Process (NP) methods. \n- The authors propose the Dimension Agnostic Neural Process (DANP), which incorporates a Dimension Aggregator Block (DAB) to transform input features into a fixed-dimensional space, enhancing the model's ability to handle varied datasets. \n- By leveraging the Transformer architecture and latent encoding layers, DANP is capable of learning a broader range of features that are generalizable across different tasks. \n- Through extensive experimentation on various synthetic and practical regression tasks, the authors demonstrate that DANP outperforms previous NP variations, effectively overcoming the limitations of traditional NP models and showcasing its potential for broader applicability in diverse regression scenarios."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- DANP is a novel extension of NP, that addresses the limitations of existing NP methods in handling diverse input dimensions and learned features.\n- This work not only points out the shortcomings of current NP methods but also proposes a robust solution through the DAB and the integration of Transformer architecture.\n- The paper is clear in its structure and presentation."
            },
            "weaknesses": {
                "value": "- The paper focuses on regression tasks, but its applicability to other tasks such as classification is not thoroughly explored. It could benefit from additional experiments or a theoretical discussion on how DANP might perform in non-regression tasks.\n- While DANP shows promising results, the paper lacks a detailed discussion on the model's interpretability. The paper should include an analysis or discussion on how the components of DANP contribute to its predictions, especially given its complex architecture involving the DAB and Transformer-based latent path."
            },
            "questions": {
                "value": "- How does the authors' proposed DANP model perform in tasks outside of regression, such as classification or time-series forecasting? Are there any modifications needed for effective application in these domains?\n- Are there any plans to conduct longitudinal studies to evaluate the long-term performance and stability of DANP in dynamic environments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper works on neural processes and studies the case when there exist diverse input dimensions and learned features. Tot this end, the Dimension Agnostic Block (DANP) is developed to transform input features into a fixed embedding and then combined with neural process modules. It conducts experiments in zero-shot and few-shot scenarios."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "I can easily follow this work and the layout is clear. However, there are severe writing and examination issues."
            },
            "weaknesses": {
                "value": "(1) Overall, this work includes several engineering tricks to handle diverse input dimension cases and lacks theoretical analysis to examine the proposal. \n\n(2) It seems the motivation of this work also considers the uncertainty, however, I did not see sufficient results to illustrate this part when the dimension of the output is high.\n\n(3) In the related work [1], it has been demonstrated the Eq. (19) is not a valid ELBO. Hence, Line 266-269 should be revised. In line279, I disagree that NP is the earliest to address uncertainty as CNP can also achieve this in experiments. It seems several related works [2-9] are not discussed in the literature.\n\n(4) In line 316 and the following experiments, I am afraid that the zero-shot and finetune scenarios are not appropriate in evaluation as NP families require the context and amortize the few-shot adaptation without gradient updates. I am not convinced by the meaning of fine-tune or zero-shot in the task concept.\n\n(5) The computational complexity towards the modules and other ablations are required in examining the performance. Meanwhile it seems a lot of results in the context are nearly the same in scales in Table2-3. Details about the number of shots are missing in experiments, further weakening the results.\n\n---\n\nReference:\n\n[1] Foong A, Bruinsma W, Gordon J, et al. Meta-learning stationary stochastic process prediction with convolutional neural processes[J]. Advances in Neural Information Processing Systems, 2020, 33: 8284-8295.\n\n[2] Ashman, Matthew, et al. \"Translation Equivariant Transformer Neural Processes.\" arXiv preprint arXiv:2406.12409 (2024).\n\n[3] Feng, Leo, et al. \"Latent bottlenecked attentive neural processes.\" arXiv preprint arXiv:2211.08458 (2022).\n\n[4] Bruinsma, Wessel P., et al. \"Autoregressive conditional neural processes.\" arXiv preprint arXiv:2303.14468 (2023).\n\n[5] Wang Q, Federici M, van Hoof H. Bridge the inference gaps of neural processes via expectation maximization[C]//The Eleventh International Conference on Learning Representations. 2023.\n\n[6] Tailor D, Khan M E, Nalisnick E. Exploiting inferential structure in neural processes[C]//Uncertainty in Artificial Intelligence. PMLR, 2023: 2089-2098.\n\n[7] Markou S, Requeima J, Bruinsma W P, et al. Practical conditional neural processes via tractable dependent predictions[J]. arXiv preprint arXiv:2203.08775, 2022.\n\n[8] Wang Q, Van Hoof H. Learning expressive meta-representations with mixture of expert neural processes[J]. Advances in neural information processing systems, 2022, 35: 26242-26255.\n\n[9] Feng, Leo, et al. \"Memory efficient neural processes via constant memory attention block.\" arXiv preprint arXiv:2305.14567 (2023).\n\n[10] Feng L, Hajimirsadeghi H, Bengio Y, et al. Efficient Queries Transformer Neural Processes[C]//Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems."
            },
            "questions": {
                "value": "See the above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper describes the existing challenges of Neural Processes (NP) when using a variable number of input dimensions and learned features. The authors proposed to tackle this problem by extending the Transformer Neural Process architecture with a Dimension Aggregator Block, using Positional Embeddings to take into account the different input dimensions before transforming the features into a fixed dimensional space. The paper tests the performance of the proposed method on zero-shot and fine-tuning settings using synthetic regression tasks and image completion datasets well-known in the NP literature."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper has a good and concise summary of the Neural Processes setting and it highlights clearly the problem of fixed dimensions, as opposed to variable ones.\n- The authors submitted the source-code to reproduce their experiments, which is a neat way to connect the ideas exposed on the main body with practical details of the implementation. Great work here.\n- The idea of leveraging positional embeddings on the dimensions axis is I believe novel, and interesting on itself."
            },
            "weaknesses": {
                "value": "**Limitations of positional embeddings on the proposed DAB module:**\n\nPositional Embeddings is a well-studied part of the transformer architecture, specially in Language Models. Generally speaking, while there has been progress since the original Transformer, the community agrees that length extrapolation is an open-problem and positional embeddings do not extrapolate on further sequence lengths, see [1] for example, where the sinusoidal embeddings used by DAB are the worst in extrapolation. In LLMs (arguably the biggest current application of transformers and positional embeddings) the community has largely moved on from Sinusoidal embeddings and into other approaches such as RoPE [2] [3]. Thereby, while the setting here is very different I see the following weaknesses with the current paper given that positional embeddings is a crucial part for the DAB module to be dimension-agnostic:\n\n- Concretely, Positional Embeddings have a hard time in transformers when extrapolating from small to large context lengths. This warrants a discussion on whether they\u2019re applicable to the setting on this paper.\n- There has been a substantial amount of work on newer and better positional embeddings, I believe this warrants at least a discussion and acknowledgement of recent work, and a stronger argument for using Sinusoidal Embeddings.\n- At best this warrants an ablation which justifies the choice in the architecture.\n- I believe highlighting the failure modes of using Positional Embeddings (sinusoidal or otherwise) do not diminish the contributions of the paper, quite on the contrary. But in my view, it\u2019s important to highlight the limitations of the proposed approach, and if there\u2019s evidence that these failure modes do not exist on the setting exposed here, it makes even an stronger paper.\n\n**Experimental weaknesses (dimension generalisation):**\n\nConnecting to the previous section, I believe that the experiments need to be more robust to analyse more carefully the failure modes of the proposed approach. In some cases, this is already in the appendix, but unfortunately this is not properly referenced from the main body. I urge the authors to present the failure modes of the approach in the main body more clearly, and when pushing results to the appendix, to reference them from the main body **explicitly,** calling out from the main body what are the strengths or weaknesses of the appendix results.\n\n- On the 0-shot scenario of GP regression (section 5.1), the model is either trained on {2,4} or {2,3,4} dimensions and evaluated on {1,2,3,4,5,7}. Given the above discussion about positional embeddings, I think that this setting benefits evaluating on dimensions {1,3} since they\u2019re covered by interpolation. A better experimental setting would involve fully non-overlapping dimensions in train and validation, such as {1,2,3} and {4,5,6}. Even better, would be to try different configurations and report the threshold where the performance breaks down or when the performance is better. I hypothesise this model is better when it is evaluated during interpolation. At the very least, there should be an open discussion about this in the paper; however, as this is core to the contribution of this work, I believe it\u2019s important to address these experimental weaknesses. Some of this is already in Appendix B.2 and in Table 16, however it is not clear if the kernels are the same (names are present in table 16 but not in table 2a); irrespective of this, given the arguments above, I strongly believe this discussion on the limitation of the approach belongs to the main body and should be **clearly stated on the conclusions** **and contributions sections** since it paints a full picture of the failure modes. The whole appendix B is barely referenced (it\u2019s very big with very different subsections), and it\u2019s very easy to miss the discussion of table 16.\n- For the fine-tuning section of GP regression, I have similar concerns. In the positional embedding LLMS literature, typically what you do to extend to longer contexts is to finetune on context lengths which are larger. Here, however, the finetuning happens on 1-dimensional tasks, after being pretrained on 2,3,4. Again, a likely failure mode is that when fine tuning on dimensions which are bigger than in pretraining the model won\u2019t extrapolate very well. Unfortunately, as opposed to the zero-shot section, the appendix does not have experiments which reflect this setting.\n\n**Experimental weaknesses (practical regression tasks)**\n\n- While I understand the engineering challenges of video datasets, I believe the authors should tone down section 5.2. The proposed adaptation of CelebA does not make it a Video dataset \u2014 hence I believe it\u2019s wrong to call this a Video Completion task, I suggest this is rephrased throughout the paper to reflect that this is just an image completion task with a synthetically generated extra dimension. Alternatively, it\u2019d be really interesting to test this on an actual short video dataset, such as [4], however I understand this can be fully out of scope. Perhaps it\u2019s useful to reference it as future work.\n- I believe the extra dimension added to CelebA is a rather weak task, since it\u2019s a very simple subtraction over the brightness. I wonder if using off-the-shelf dimensions such as CelebA landmarks [5] [6] would be a better task (there are 5 different landmarks locations for each face, tagged as 2d coordinates). This has the benefit of being an already established benchmark in the literature, and arguably a more real-world and practical regression task. If the proposed method does not work well on these harder tasks, it\u2019s still interesting to highlight the limitations of the model.\n- The core results of section 5.2 rely on pre-training on both the CelebA and EMNIST datasets, while interesting to see some positive transfer, after reading the framing of the paper and the GP regression section, I would have expected some zero-shot results on image tasks (for both pretraining and validation), which arguably is more relevant to meta-learning than fine-tuning. A Video Completion experiment in a zero-shot setting would make a stronger contribution, which is more consistent with the GP regressions section.\n\n**Experimental weaknesses (other)**\n\n- The log-likelihood is likely an incomplete picture of the results. As done in [7] I believe a stronger analysis should include other metrics such as calibration error.\n- The context provided about confidence interval coverage is worth mentioning on the main body, instead of being in the appendix where it\u2019s hardly accessible and referenced directly from the main body.\n- In general, Appendix B is too broad and many interesting conclusions that should be in the main body are there without a direct reference.\n- In my opinion, the details that have been mentioned to be in the appendix, deserve to be in the main body to have a better complete picture of the strengths and limitations of the proposed approach. While I understand the page-limit is a limitation, I\u2019d argue that what I have mentioned is of more relevance compared to the mostly positive results of section 5.4 \u2014 these can be in the appendix and mentioned briefly with a direct reference for interested readers. Another alternative is to leave the tables in the appendix but still mention the relevant conclusion in the main body.\n- NDP is mentioned as a relevant baseline and briefly tried on Appendix B - Table 11/12. Since this is the most relevant baseline according to the authors, I believe results with this relevant baseline from prior work should be in the main body as much as possible (it\u2019s clear that it\u2019s only comparable with dimension-agnostic methods for x when y=1) with a discussion about the quantitative results, not just qualitative as in section 4. There\u2019s clearly at least two settings where it\u2019s possible to do this, but they\u2019re in the appendix.\n\n**Misc:**\n\n- The Dimension Aggregator Block implementation uses a linear projection **with bias [8].** This renders equation 10 incorrect since the bias term is missing there. I believe this is a common blind spot because the bias is set by default to True in Pytorch, so I urge the authors to revise all linear layers and either update the manuscript or the code/results. Note that I do not expect this to change the results much, but it\u2019s better to address this for reproducibility and clarity.\n- Table 2a does not have the 2nd or 1st best performance marked with underline or boldfaced underline. This makes it harder to read.\n- Table 2a does not state which kernels were used, as compared to table 1 and table 16.\n- It\u2019s hard to read table 1 and table 2 separately, and as the authors mentioned, it\u2019s helpful to read them in context.\n- While I appreciate the detail problem setting on section 2, if there are concerns of page limits, I\u2019d suggest the authors to prioritise space for experimental results and discussion as suggested in the previous section \u2014 this can be either added as an Appendix and referenced directly from the main body, or just cite from previous work as appropriate.\n\n[1] https://openreview.net/forum?id=R8sQPpGCv0\n\n[2] https://arxiv.org/abs/2104.09864\n\n[3] https://arxiv.org/abs/2302.13971\n\n[4] https://svdbase.github.io/\n\n[5] https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n\n[6] https://www.kaggle.com/code/danmoller/inspecting-the-celeba-dataset-face-landmarks\n\n[7] https://arxiv.org/abs/2207.04179\n\n[8] https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear"
            },
            "questions": {
                "value": "- In the 0-shot evaluation on GP regression (section 5.1), why is dimension 6 not included in the validation? It seems straightforward to do and would paint a complete picture. Can this experiment be included? If it\u2019s a matter of space in the manuscript or computational resources, I believe dimension 6 is better than dimension 7.\n- What are your thoughts on the inherent limitations of Positional Embeddings extrapolation? Is the lack of extrapolation a concern in the dimension-agnostic setting?\n- Did you experiment with Zero-Shot on image tasks? Given that you had results for fine-tuning, I imagine it is possible to get zero-shot results, unless I\u2019m missing something."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}