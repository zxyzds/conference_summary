{
    "id": "ivs0xU9Ebg",
    "title": "An Efficient Unsupervised Framework for Convex Quadratic Programs via Deep Unrolling",
    "abstract": "Quadratic programs (QPs) arise in various domains such as machine learning, finance, and control. \nRecently, learning-enhanced primal-dual hybrid gradient (PDHG) methods have shown great potential in addressing large-scale linear programs; however, this approach has not been extended to QPs.\nIn this work, we focus on unrolling \"PDQP\", a PDHG algorithm specialized for convex QPs. Specifically, we propose a neural network model called \"PDQP-net\" to learn optimal QP solutions. Theoretically, we demonstrate that a PDQP-net of polynomial size can align with the PDQP algorithm, returning optimal primal-dual solution pairs.\nWe propose an unsupervised method that incorporates KKT conditions into the loss function. Unlike the standard learning-to-optimize framework that requires optimization solutions generated by solvers, our unsupervised method adjusts the network weights directly from the evaluation of the primal-dual gap.\nThis method has two benefits over supervised learning: first, it helps generate better primal-dual gap since the primal-dual gap is in the objective function; second, it does not require solvers. \nWe show that PDQP-net trained in this unsupervised manner can effectively approximate optimal QP solutions.\nExtensive numerical experiments confirm our findings, indicating that using PDQP-net predictions to warm-start PDQP can achieve up to 45% acceleration on QP instances. \nMoreover, it achieves 14% to 31% acceleration on out-of-distribution instances.",
    "keywords": [
        "Quadratic programming",
        "Learning to optimize",
        "Deep unrolling",
        "Primal-Dual Hybrid Gradient",
        "Unsupervised learning"
    ],
    "primary_area": "optimization",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ivs0xU9Ebg",
    "pdf_link": "https://openreview.net/pdf?id=ivs0xU9Ebg",
    "comments": [
        {
            "summary": {
                "value": "This paper explores the application of a machine learning-enhanced approach for solving quadratic programs (QPs); the method extends the primal-dual hybrid gradient (PDHG) method from linear programming to QPs. The authors introduce \"PDQP-net,\" a neural network model that integrates the PDHG algorithm for convex QPs. A key innovation in this work is the unsupervised training approach, which incorporates KKT conditions into the loss function, allowing the network to be updated based on primal-dual gap evaluation rather than requiring solutions from traditional solvers. \nSpecifically, the paper extends the PDHG method for linear programming problems introduced by \"Bingheng Li et al, PDHG-Unrolled Learning-to-Optimize Method for Large-Scale Linear Programming\""
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- the presented idea to incorporate KKT conditions in the learning to optimize setting is intuitive and well-motivated\n- the method is clearly described without ambiguity\n- the paper is mathematically rigorous, although I did not verify the validity of the proofs of the theorems in this paper\n- the experimental results of the paper are substantiated with large-scale QP problems"
            },
            "weaknesses": {
                "value": "The novelty of the proposed idea seems to be the main issue.\n- as far as I understand the method \"deep unrolling\" refers to the unrolled operations of the operator splitting method for successive projection operations for primal and dual variables. As far as I can see, this is equivalent to the ADMM method. However, there is no mention of prior work on ADMM or other operator splitting methods.\n- There are already existing works on differentiable or \"unrolled\" operator splitting methods as layers in deep neural networks for solving optimization problems in the learning to optimize setting\n- the paper would benefit from a related work section highlighting similarities and differences between recent learning to optimize methods for parametric QP problems\n- specifically, authors are encouraged to include recent advancements in differentiable optimization layers including QP-layers ADMM layers, and machine learning-based warm starting and operator splitting methods for QP and NLP problems\n- This method looks very similar to that presented in the paper:\n\"Differentiable Linearized ADMM\" https://proceedings.mlr.press/v97/xie19c.html\n- Other related work that uses differentiable Douglas-Rachford (DR) layers to warm-start QP is closely related but not mentioned in the paper\n\"End-to-End Learning to Warm-Start for Real-Time Quadratic Optimization\"\nhttps://proceedings.mlr.press/v211/sambharya23a.html\n- limitations of the proposed method are missing"
            },
            "questions": {
                "value": "- KKT conditions are known to be sensitive to small perturbations in the problem parameters, often leading to ill-conditioned problems. How are these issues avoided in the proposed method?\n- How does this method relate to the ADMM method and other operator-splitting algorithms such as Douglas-Rachford (DR)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a deep unrolling method for solving QP problems. Particularly, the authors choose a PDQP method (PDHG applied on QP), parameterize some components in PDQP, unroll PDQP and truncate it into finite iterations. The parameterized unrolled algorithm is then treated as a neural network and trained using a KKT-informed loss function. Finally, experiments are conducted to evaluate the performance of the proposed PDQP-net and to illustrate the effectiveness of the KKT loss function."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The KKT-informed training approach is an interesting idea, especially for primal-dual methods. It is simple, principle-informed, and does not require the optimal solution for training."
            },
            "weaknesses": {
                "value": "While the paper presents some interesting concepts, it feels somewhat incomplete.\n\n1. The theoretical results are limited. Theorem 3.1 is straightforward: by setting parameters in the unrolled method to mimic PDQP, the conclusion follows. Additionally, Proposition 3.1 directly follows from the PDHG convergence results [1].\n\n2. The experimental setup could be stronger. (i) For baseline comparisons, the proposed method is primarily compared with PDHG. A more recognized open-source solver is OSQP [2]. Additionally, as a first-order method, PDHG typically have very slow convergence for ill-conditioned problems (although its single-step complexity is cheap). More robust solutions like interior-point solvers (e.g., Gurobi) would be a stronger baseline. (ii) The dataset is insufficient to fully support the conclusions. For instance, the \"QPLIB-8845\" instance used in the paper is a single instance rather than a dataset [3], meaning the GNN is only trained on this one instance (along with some perturbed variations). If we want to solve another QP, we have to train another GNN for that. Typically, training GNN is more complex than solving a single QP, so we would want the trained GNN to generalize across multiple QP instances.\n\n3. References on unrolling are lacking. Surprisingly, even the first paper on unrolling [4] is not discussed. A more comprehensive review of unrolling techniques would be beneficial.\n\n[1] Chambolle and Pock. \"A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging.\" Journal of Mathematical Imaging and Vision 2011.\n\n[2] Stellato et al. \"OSQP: an operator splitting solver for quadratic programs.\" Mathematical Programming Computation 2020.\n\n[3] https://qplib.zib.de/QPLIB_8845.html\n\n[4] Gregor and LeCun. \"Learning fast approximations of sparse coding.\" ICML 2010."
            },
            "questions": {
                "value": "see \"Weaknesses\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces PDQP-net, a neural network architecture designed to learn the solution mappings for convex QPs. Inspired by first-order methods, PDQP-net is capable of emulating the PDQP algorithm. The authors also propose an unsupervised training approach based on the KKT conditions for training PDQP-net. Experiments on large-scale instances demonstrate that PDQP-net achieves faster convergence and smaller primal/dual errors."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "- The proposed PDQP-net architecture is well-motivated and grounded in the principles of first-order optimization methods.\n- The unsupervised training approach based on KKT conditions is efficient in training PDQP-net without requiring ground-truth optimal solutions.\n- The experimental results on large-scale instances showcase the superior performance of PDQP-net in terms of convergence speed and primal/dual errors."
            },
            "weaknesses": {
                "value": "- The technical contributions, such as the construction proof for neural network complexity, are incremental compared to previous work [1].\n- While the construction proof demonstrates that a PDQP-net exists that can recover the PDQP algorithm and achieve linear convergence, the convergence guarantee for PDQP-net with trainable parameters remains unclear. Providing convergence guarantees for the training process is crucial for the unrolling-based L2O scheme [2].\n- Given that the construction proof relies on the PDQP algorithm, which already achieves the optimal convergence rate among first-order methods, the authors should discuss the reasons behind the performance gain of PDQP-net. Theoretically, is there (constant factor) complexity improvement of PDQP-net compared with the PDQP algorithm?\n- The author provides a complexity of PDQP-net as $O(log(1/\\epsilon))$ in Prop. 3.1, but the dependence on the problem dimensions ($n$ and $m$) is unclear, which is also critical for understanding the scalability of this framework."
            },
            "questions": {
                "value": "- How does PDQP-net generalize across varying problem sizes (line 162), and are the trainable parameters invariant to the problem dimension?\n\n- In the experiments, the number of layers (K) used in PDQP-net is not specified. The authors should provide details on the choice of K and analyze how the performance changes across different values of K, as this is crucial for understanding the convergence behavior of the unrolling structure. It would also be helpful to present the practical parameter complexity of PDQP-net in experiments, especially for large-scale instances (e.g., n=10,000).\n\n- How about using recurrent neural networks to parameterize the learnable parameters at each layer [2], making the trainable parameters invariant to the number of layers?\n\n- In Prop. 3.2, the authors claim that supervised training could lead to a large primal-dual gap, as shown in the upper bound. How about directly minimizing the upper bound in the supervised training scheme? \n\n\n\n[1] Li, B., Yang, L., Chen, Y., Wang, S., Chen, Q., Mao, H., ... & Sun, R. PDHG-Unrolled Learning-to-Optimize Method for Large-Scale Linear Programming. In Forty-first International Conference on Machine Learning.\n\n[2] Liu, J., Chen, X., Wang, Z., Yin, W., & Cai, H. Towards constituting mathematical structures for learning to optimize. In International Conference on Machine Learning.\n\n\nI will adjust my scores if the concerns are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces PDQP-Net, a novel framework that leverages deep unrolling and unsupervised learning to efficiently solve convex QP. The neural network structure mimics the PDQP algorithm, with each network layer corresponding to an iteration step of PDQP. The loss function is based on KKT conditions to achieve a lower primal-dual gap and better primal and dual feasibilities. Compared to the supervised MSE of the solution, the KKT-based loss does not require labels (optimal solutions), thus not only avoiding time-consuming data collection but also resulting in better optimality gaps. \n\nFor numerical experiments, PDQP-Net is faster than traditional first-order methods, PDQP, and could be an effective starting point for better PDQP convergence. In addition, PDQP-Net achieves strong out-of-distribution generalization."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. **Novelty:** In my opinion, the primary contribution is the KKT-based loss function. This unsupervised approach not only removes the need for costly optimal solution data but also improves solution quality.\n2.  **Efficiency:**: Using model outputs as a warm-start of traditional PDGH significantly accelerates QP."
            },
            "weaknesses": {
                "value": "1. The PDQP architecture, including deep unrolling, trainable parameters, projection operators, and channel expansion, and its use as a warm start to accelerate convergence closely mirrors existing work, PDLP. While effective, these techniques do not constitute novel contributions in the context of this paper, as they are directly aligned with the PDLP paper.\n2. While the paper provides some foundational hyperparameter settings, such as the learning rate, optimizer, and training iterations, it lacks some details, such as the GNN architecture, the depth $K$, and the design of multi-layer perceptrons (MLPs) $f_x$, $f_y$, $g_x$, and $g_y$.\n3. Although the experiments provide comparisons regarding acceleration as a warm start against traditional pure QDHG, the paper does not include a direct runtime comparison between the neural network model and the traditional QDHG. Without this data, it is difficult to evaluate the efficiency of the neural network and assess the trade-offs between efficiency and optimality."
            },
            "questions": {
                "value": "1. I like the KKT loss. The concept shares similarities with the approach used in Physics-Informed Neural Networks (PINNs), which incorporate physical laws as constraints in the loss function to guide unsupervised learning. I suggest discussing connections with PINNs in related work.\n2. It is useful to report the feasibility ratio. Compared to the feasibility residual, the feasibility ratio would provide a more direct indication of reliability and effectiveness, as feasible solutions may hold little to no practical value.\n3. Is there potential for using the approach for nonconvex QP? Since nonconvex QPs are commonly encountered in practical applications but present additional challenges in terms of solution quality and convergence, the approach also seems promising for nonconvex cases.\n4. The section captain \"Comparing PDQP-Net Against GNNs\" could indeed be confusing, as PDQP-net itself is also based on a GNN. Additionally, \u201cGNNs\u201d alone does not clarify the baselines used in the comparison.\n5. Apart from \"Expressive Power of Graph Neural Networks for (Mixed-Integer) Quadratic Programs,\" there are other recent methods for solving (not only) convex QPs. For instance, \"DC3: A Learning Method for Optimization with Hard Constraints\" provides an unsupervised approach based on soft constraints penalty and projection techniques. Have the authors considered comparing PDQP-Net with additional learning baselines like DC3 to further validate its performance? \n6. The paper briefly mentions the network depth $K$ corresponding to the number of unrolled layers. Could the authors provide more insight into how different values of $K$ impact solution quality and computational efficiency?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an efficient unsupervised framework to accelerate the solving of convex quadratic programs (QPs) using the unrolling technique. In particular, the authors propose architectures mimicking the PDQP algorithm (possibly standing for \"Primal-Dual Quadratic Programming\"; its meaning is never explicitly mentioned in the paper), termed as PDQP-net, and an unsupervised training loss based on the KKT optimality conditions. Through theoretical and empirical argument, they show that not only does this proposal improve the primal-dual gap, but it also gets rid of the need for a solver, which might be potentially costly to obtain for large-scale QPs."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is of sufficient interest: Using deep learning techniques and architectures to accelerate optimization is an interesting idea; this paper belongs to this line of research and the problem it addresses is relevant for many communities in ICLR.\n- Integrating the unsupervised approach into the framework as in this paper is interesting since we no longer need a solver to generate training data (which also reduces the data preparation time, consequently)."
            },
            "weaknesses": {
                "value": "The presentation of this paper has several problems. Let me mention a few examples:\n- Several acronyms are not explained: PDQP, LPs (line 51).\n- A more detailed introduction is recommended for Section 2.2. This entire work is based on the so-called PDQP algorithm and the algorithm, its main intuition, and results have not been introduced thoroughly.  \n- In Algorithm 1, the IF condition in line 9 is not explained: the variable \"residual\" is not defined yet.\n- In line162, please specify the dimension of $W^k_x$ and $W^k_y$. In general, I think it is a good habit to mention the dimensions of variables when they are first introduced.\n- I suggest that Section 3.2 should be incorporated into Section 3.3: its content is not sufficiently rich enough to stand alone and its goal is to motivate why the authors propose an unsupervised loss function.\n- In Section 3.3, the definitions of three loss functions $r_{primal}, r_{dual}$ and $r_{gap}$ should be introduced in the main text, and not the Appendix. Same remark for their normalized version.\n- There is a double citation of the paper \"A practical and optimal first-order method for large-scale convex quadratic programming\" in lines 587 - 591.\n\nCertain formulations and arguments in the paper need adjustment, in my opinion. Here are several examples:\n- Proposition 3.2 and Section 3.2 are confusing. I think the authors want to convince us that the distance between the optimal solution and the predicted one is not a good training loss. This is debatable because in many situations such as image denoising, the distance is more important. Also, Proposition 3.2 does not seem to support their argument since it provides an upper bound.\n- Theorem B.1 in Appendix B analyses a different formulation from (1). I do not read this proof carefully but the author should re-check it.\n- In Appendix B, the training instances are generated by taking an instance from QPLIB, perturbing with Gaussian noise. However, the authors test with the same instances that they used to generate training data (see Tables 1 and 5). Is that fair?"
            },
            "questions": {
                "value": "- Why do the authors to have box constraints on $x$ (i.e. $l \\leq x \\leq u$)? Can we remove this condition since $Ax \\geq b$ already contains these box constraints?\n- Why do the authors unroll PDQP, and not other algorithms for convex quadratic programming? With this framework, I believe any first-order methods can be unrolled, in the same manner. Or maybe PDQP is the only first-order method for convex quadratic programming."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}