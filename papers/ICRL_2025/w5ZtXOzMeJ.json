{
    "id": "w5ZtXOzMeJ",
    "title": "Auto-GDA: Automatic Domain Adaptation for Efficient Grounding Verification in Retrieval Augmented Generation",
    "abstract": "While retrieval augmented generation (RAG) has been shown to enhance factuality of large language model (LLM) outputs, LLMs still suffer from hallucination, generating incorrect or irrelevant information. One common detection strategy involves prompting the LLM again to assess whether its response is grounded in the retrieved evidence, but this approach is costly. Alternatively, lightweight natural language inference (NLI) models for efficient grounding verification can be used at inference time. While existing pre-trained NLI models offer potential solutions, their performance remains subpar compared to larger models on realistic RAG inputs. RAG inputs are more complex than most datasets used for training NLI models and have characteristics specific to the underlying knowledge base, requiring adaptation of the NLI models to a specific target domain. Additionally, the lack of labeled instances in the target domain makes supervised domain adaptation, e.g., through fine-tuning, infeasible. To address these challenges, we introduce Automatic Generative Domain Adaptation (Auto-GDA). Our framework enables unsupervised domain adaptation through synthetic data generation.\nUnlike previous methods that rely on handcrafted filtering and augmentation strategies, Auto-GDA employs an iterative process to continuously improve the quality of generated samples using weak labels from less efficient teacher models and discrete optimization to select the most promising augmented samples. Experimental results demonstrate the effectiveness of our approach, with models fine-tuned on synthetic data using Auto-GDA often surpassing the performance of the teacher model and reaching the performance level of LLMs at 10 % of their computational cost.",
    "keywords": [
        "domain adaptation; NLI; RAG; document-grounded; NLP;"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "We present an automatic strategy to adapt NLI models for grounding verification to challenging inputs encountered in realistic RAG systems using synthetic data.",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=w5ZtXOzMeJ",
    "pdf_link": "https://openreview.net/pdf?id=w5ZtXOzMeJ",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a novel framework to enhance the performance of NLI models in verifying retrieved evidence within retrieval-augmented generation settings. The paper addresses the issue of performance drop in out-of-domain inputs. To alleviate this problem, the authors propose an automatic generative domain adaptation method to fine-tune NLI models in an unsupervised manner. In the proposed method, this framework considers both diversity and quality by using a sequential augmentation technique and optimizing a distribution-matching objective in the data generation process. Experimental results demonstrate that the NLI model fine-tuned with the proposed method achieves performance closer to that of LLM models without sacrificing efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed method is novel and practical in RAG scenarios.\n- This manuscript is clearly written and easy to follow.\n- The experimental results are well conducted, showing advantages in terms of accuracy and efficiency."
            },
            "weaknesses": {
                "value": "- The paper would benefit from a more detailed analysis to clearly demonstrate the robustness of the proposed method across various domains. In real-world scenarios, domain boundaries are often ambiguous, and it\u2019s common to encounter mixed or overlapping domain data. By evaluating the model in a multi-domain or domain-mixing setting, the authors could provide stronger evidence of its robustness and practical applicability in complex, realistic cases.\n\n- It would be valuable to include an analysis of how the model performance depends on the quality of the initial synthetic data generation. If initial data is inaccurately generated, it might negatively influence the model\u2019s performance. An examination of whether the model can correct or adapt to potential errors in this initial phase would clarify the method\u2019s resilience to suboptimal synthetic data.\n\n- The paper\u2019s selective objective function appears complex, suggesting that the model could be highly sensitive to hyperparameter choices. Observing large variations in hyperparameter values for each dataset implies that tuning these parameters may be challenging. Providing further insights into the model\u2019s hyperparameter sensitivity and offering guidelines for tuning could improve the approach's usability and reliability in diverse settings."
            },
            "questions": {
                "value": "See the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the issue of hallucinations in Large Language Models (LLMs) used in retrieval augmented generation (RAG) applications, where verification of generated outputs through natural language inference (NLI) models is essential. The authors propose Automatic Generative Domain Adaptation (Auto-GDA), an unsupervised framework that generates high-quality synthetic data to fine-tune lightweight NLI models for specific RAG domains. Key contributions include formalizing the unsupervised domain adaptation problem, developing the Auto-GDA framework for efficient sample selection, and demonstrating that models fine-tuned with Auto-GDA outperform weak teacher models and approach the performance of human-labeled references, all while achieving significantly lower latency than LLMs. This work presents a promising solution to enhance NLI model performance in real-time RAG applications."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed Automatic Generative Domain Adaptation (Auto-GDA) offers a novel approach to unsupervised domain adaptation, effectively generating high-quality synthetic data to fine-tune NLI models tailored for specific RAG contexts.\n- Empirical results demonstrate that models fine-tuned with Auto-GDA significantly outperform weak teacher models and achieve performance levels comparable to those using human-labeled data, indicating its effectiveness in improving NLI model accuracy.\n- The paper is well written and easy to understand."
            },
            "weaknesses": {
                "value": "- The effectiveness of the Auto-GDA framework relies heavily on the quality of the synthetic data generated. Poorly generated data could lead to suboptimal fine-tuning and negatively impact NLI model performance.\n- Although the framework aims to address domain mismatches, (in my own opinion) there may still be challenges in generalizing to highly diverse or previously unseen domains, potentially reducing the model's effectiveness in broader applications. I'm curious how well the proposed method performs under such extreme conditions?"
            },
            "questions": {
                "value": "Refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper considers the problem of domain adaptation of the natural language inference models (NLI) which are often used in retrieval-augmented generation (RAG) to judge the entailment of the generated response from the retrieved context. The paper proposes Auto-GDA, a method for generating synthetic data for a given domain, that can be used for finetuning an NLI model to improve its performance in this domain. The proposed method is iterative and consists of three steps: (1) seed data generation using an LLM; (2) data augmentation e.g. using paraphrasing or sentence deletion; and (3) data filtering, to minimize their proposed enhanced distribution matching objective; steps 2 and 3 can be repeated iteratively. The method is tested on several datasets that provide human labels for NLI, and compared versus existing off-the-shelf systems and several ablations."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* A relevant research direction of adapting RAG components to user domains\n* Comprehensive related work section\n* Detailed description of the proposed approach, used datasets, baselines, and experimental details\n* The proposed method is compared to a series of existing NLI solutions on several datasets, and inference time is also compared for various methods"
            },
            "weaknesses": {
                "value": "1. The presented Auto-GDA method is rather complex (involving multiple steps and components, including heuristic augmentation techniques) and has several important hyperparameters, such as $\\lambda_d$ and $\\lambda_u$ in eq. (2), population sizes M and K, or the number of iterations. Hyperparameter tuning requires running the proposed approach 50 times (line 446), including training of the NLI model on the generated data (from my understanding). At the same time, improvements over simply using LLM-generated data are quite modest (row 4 vs 2 in Table 2). \n    - Furthermore, the high cost of running hyperparameter optimization, augmentation, and data selection in the proposed approach, motivates the substantial increase of data points in the simple baseline of using LLM-generated data, to make their computational costs similar. This would make the baseline stronger and reduce its difference versus the proposed approach even further.\n    - Performance gains versus out-of-the-box NLI models are also rather small, e.g. comparing the best performing (domain-adapted) Auto-GDA versus the best performing \u201ccomplex\u201d method out-of-the-box (83.7 vs 80.5, 86.7 vs 85.4, 92.5 vs 90.4, 88.3 < 89.4), or Auto-GDA (Flan-T5) vs MiniCheck-T5 (75.6 \\approx 75.4, 68.7 < 74.1, 82.4 vs 79.1; only one high improvement 78.3 vs 64.0). \n2. I would expect more ablations of the proposed approach, e.g. testing the removal of each of the terms in eq. (2), or on the contrary using only one of these terms for filtering.   \n3. The motivation for the proposed approach is to improve RAG pipelines in domain-specific scenarios, however no experiments with domain-specific RAG are presented to demonstrate these improvements. For example, domain-specific RAG scenarios considered in [1] could act as potential testbeds, e.g. RobustQA [2].\n\n[1] Dongyu Ru et al. RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation. NeurIPS 2024\n\n[2] Rujun Han et al.  RobustQA: Benchmarking the Robustness of Domain Adaptation for Open-Domain Question Answering. Findings of ACL 2023"
            },
            "questions": {
                "value": "1. What is the time of running each step in Auto-GDA (steps 1-2-3 and NLI model training), for different datasets (with their sizes)?\n2. One of the arguments for the necessity of domain adaptation in the introduction is that \u201cinputs may follow a specific format due to the RAG prompt template\u201d (line 79). Why not pass evidence and claims to NLI models without this template, if it reduces domain shift and hence improves performance?\n3. What criteria is used to select optimal hyperparameters using optuna? Is it performance on some dataset (which one)?\n4. How do you tune hyperparameters of unsupervised domain adaptation baselines?\n5. Are there particular reasons why Vectara-2.1 outperforms AlignScore on RAGTruth and vice versa on other datasets? E.g. due to some specific training data or algorithm specifics.\n6. Do you plan to release open-source code for the proposed approach?\n\n\nComments\n* Due to the high amount of notations, it may be hard to follow the method sometimes, e.g. trying to remember what a particular notation means. \n* Line 43: \u201ceven when the most capable LLMs are used with RAG, hallucination rates of 20 \u2013 30% persist (Santhanam et al., 2021).\u201d  too old reference\n* Figure 1: \u201cRAG task performance (ROC-AUC).\u201d Unclear x label: it seems that it is RAG performance (unclear how measured with ROC-AUC), but it is NLI performance for RAG as far as I understand\n* Line 233: \u201cwe also generate realistic initial samples using LLMs\u201d. Use a more specific term than \u201csamples\u201d\n* Line 384: \u201cOptimizing the objective for a subset Q\u201d. What does Q refer to here?\n* Line 429: better define \u201ccomplex\u201d category"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}