{
    "id": "nW54N85eDT",
    "title": "Predicting User Behaviors with Scene via Dual Sequence Networks",
    "abstract": "Modeling sequential user behaviors for future action prediction is crucial in improving user's information retrieval experience. Recent studies highlight the importance of incorporating contextual information to enhance prediction performance. One crucial and typical contextual information is the scene feature that is often crafted by app or website designers, such as \"text2product search\" and \"recommendation\" within an e-commence app. Different scenes exhibit different usage habits and distinct product themes, leading to significant distribution gap in user engagement across them. Popular sequential behavior models either ignore the scene feature or merely use it as attribute embeddings, which could lead to substantial information loss or cannot capture the inter-dependencies between scene and item in modeling dynamic user interests. In this work, we propose a novel Dual Sequence Prediction network (DSPnet) to effectively capture the inter-dependencies between scene and item sequences for future behavior prediction. DSPnet consists of two parallel networks dedicated to predicting scene and item sequences, and a sequence feature enhancement module to capture the inter-dependencies. Further, considering the randomness and noise in learning sequence dynamics, we introduce Conditional Contrastive Regularization (CCR) loss to capture the invariance of similar historical sequences. Theoretical analysis suggests that DSPnet can learn the joint relationships between scene and item sequences, and also show better robustness on real-world user behaviors. Extensive experiments are conducted on one public benchmark and two collected industrial datasets. The codes and collected datasets will be made public soon.",
    "keywords": [
        "dual sequence networks",
        "scene-aware",
        "behavior prediction"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=nW54N85eDT",
    "pdf_link": "https://openreview.net/pdf?id=nW54N85eDT",
    "comments": [
        {
            "summary": {
                "value": "The paper addresses the challenge of predicting future user actions by effectively modeling sequential user behaviors with a focus on integrating contextual information, particularly the scene feature. Scene features, designed by app or website developers, significantly influence user engagement and exhibit distinct usage patterns and product themes. Traditional models often overlook the scene feature or treat it superficially, leading to potential information loss and failing to capture the complex interdependencies between scenes and items.\n\nTo tackle these issues, the authors propose a Dual Sequence Prediction network (DSPnet), a novel approach that simultaneously predicts scene and item sequences while capturing their inter-dependencies. DSPnet comprises two parallel networks for scene and item predictions and a sequence feature enhancement module to integrate these dependencies. To improve the model's robustness against the randomness and noise inherent in sequence data, the authors introduce a Conditional Contrastive Regularization (CCR) loss, which helps maintain the invariance of similar historical sequences during training.\n\nTheoretical analysis indicates that DSPnet can effectively learn the joint relationships between scene and item sequences, thereby enhancing the accuracy of future behavior prediction. The effectiveness of DSPnet is validated through extensive experiments on a public benchmark dataset and two proprietary industrial datasets. The authors plan to make the source code and datasets publicly available to facilitate further research."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The proposed Dual Sequence Prediction network (DSPnet) method exhibits several strengths:\n\n1. **Innovative Modeling of Inter-Dependencies**: DSPnet captures the inter-dependencies between scene and item sequences, addressing a critical gap in existing sequential behavior modeling methods. By using two parallel networks and a sequence feature enhancement module, it effectively integrates the dynamics of both scenes and items, leading to more accurate and comprehensive behavior predictions.\n\n2. **Theoretical Robustness**: The theoretical analysis demonstrates that training DSPnet is equivalent to maximizing the joint log-likelihood of both scene and item sequences. This ensures that the model can effectively learn and represent the relationships between scenes and items, enhancing its predictive power.\n\n3. **Conditional Contrastive Regularization (CCR)**: The introduction of CCR helps in capturing the invariance of similar historical sequences, which is crucial for dealing with the randomness and noise in user behavior data. CCR uses learned conditional weights to promote similarity among sequences, thereby improving the robustness and generalizability of the model, especially in scenarios with skewed user behaviors.\n\n4. **Rich and Diverse Datasets**: The authors have collected 37 days of sequential user behavior data from their e-commerce app, constructing two industrial datasets. These datasets, along with a public benchmark, provide a rich and diverse set of data for validating the effectiveness of DSPnet. The datasets contain chronological purchase behaviors on nearly thirty million items, addressing the research data gap in this field.\n\n5. **Empirical Validation**: Extensive experiments on three datasets\u2014one public benchmark and two industrial datasets\u2014demonstrate the superior performance of DSPnet compared to state-of-the-art baselines. The results highlight the importance of incorporating scene information in sequential behavior modeling and showcase the practical benefits of the proposed method.\n\nThese strengths collectively position DSPnet as a significant advancement in the field of sequential user behavior modeling, offering improved accuracy and robustness in predicting future user actions."
            },
            "weaknesses": {
                "value": "- The paper does not explicitly discuss the potential for integrating Conditional Contrastive Regularization (CCR) with other recommendation models."
            },
            "questions": {
                "value": "- Can Conditional Contrastive Regularization (CCR) be integrated with other recommendation models and be effective?\n\n- Please provide an analysis of the model's complexity and efficiency and how to tune the hyperparameters for the training loss?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces the Dual Sequence Prediction network (DSPnet) to improve future user action prediction by modeling interdependencies between \"scene\" features (like \u201ctext2product search\u201d) and item sequences. This paper claimed that traditional models often overlook these dynamics, leading to potential information loss. DSPnet addresses this by using parallel networks to capture scene and item dependencies and incorporates Conditional Contrastive Regularization (CCR) loss to handle sequence noise. The approach shows enhanced robustness and effectiveness on both public and industrial datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) This paper proposes a unique Dual Sequence Prediction network (DSPnet) that explicitly models both scene and item sequences. By focusing on the interdependencies between scenes and items, DSPnet captures a level of contextual nuance that is often overlooked in traditional sequential behavior models. This dual-focus approach is well-aligned with real-world applications where user behaviors are influenced by both the content itself and the surrounding context.\n(2) Moreover, the introduction of CCR loss is a good point, as it addresses the noise and randomness inherent in sequential user behaviors. By focusing on the invariance of similar historical sequences, CCR loss enhances the model robustness and improves its ability to generalize to diverse, noisy data. This addition is valuable in real-world applications, where user behavior data can be unpredictable.\n(3) The dataset may be valuable for the future research if it will be released as promised."
            },
            "weaknesses": {
                "value": "**Unclear Definition and Scope of \"Scene\"**: The paper does not clearly define what constitutes a \"scene\" in the context of user behavior modeling. While scenes are described as features crafted by app or website designers (e.g., \u201ctext2product search\u201d and \u201crecommendation\u201d), the criteria for selecting or categorizing these scenes remain ambiguous. It is also unclear how many types of scenes the model considers and whether these categories are generalizable to various platforms or domain-specific. A more precise definition would help readers understand the breadth of the model's applicability and the nature of the contextual features being leveraged.\n\n**Limited Comparison with Multi-Behavior Models**: If scenes are understood as representations of multi-behavior patterns, DSPnet could benefit from comparison with established multi-behavior modeling approaches, such as the work by Cho et al. on Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation (AAAI 2023). Multi-behavior models aim to capture diverse user actions within sequences, which aligns with the paper\u2019s goal to model interdependencies between scenes and items. A direct comparison could illustrate DSPnet\u2019s advantages (or limitations) over these approaches in capturing the nuances of dynamic user behavior.\n\n**Lack of Standard Metrics for Evaluation**: In evaluating DSPnet on the OutBrain dataset, the paper does not include Mean Average Precision @12, a widely recognized metric for this dataset. Including this metric would facilitate a more transparent and standardized assessment of DSPnet\u2019s performance, allowing comparisons with other models that have used this benchmark. This would also provide a clearer view of DSPnet's efficacy across different evaluation metrics relevant to the field.\n\n**Omission of Scene Prediction Accuracy**: Although DSPnet is designed to jointly predict both scenes and items, the accuracy of its scene prediction component is not reported. Providing this accuracy would clarify how effectively the model captures the contextual \"scene\" aspect in addition to item sequence modeling. Without this metric, it is challenging to evaluate the effectiveness of DSPnet\u2019s dual-stream approach in fully capturing the dependencies between scenes and items.\n\n**Limited Citation of Recent Works**: The paper\u2019s references do not include any work from 2024 or later, which may indicate that it has not incorporated the most recent advancements in the field. This omission is notable for an ICLR 2025 submission, as the field of sequential user behavior modeling is rapidly evolving. Including more recent literature would strengthen the theoretical grounding of DSPnet and ensure that it is evaluated within the current landscape of user behavior modeling techniques.\n\n**Commonality of Dual-Stream Architectures**: The paper presents DSPnet\u2019s dual-stream architecture, which separately models scene and item sequences, as a novel approach. However, dual-stream architectures have become relatively common for tasks with multiple related objectives, such as multi-task learning frameworks. The paper would benefit from a deeper exploration of how DSPnet\u2019s dual-stream setup is unique or offers advantages over other dual-stream or multi-task models. Additional insights on why DSPnet\u2019s architecture is particularly suited to user behavior prediction would highlight its contributions more effectively."
            },
            "questions": {
                "value": "(1) How many types of the scenes does this paper consider?\n(2) Please justify the lack of recent works and the comparison with multi-behavior recommendation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper focuses on using scene/behavior features to enhance sequential recommendation. The authors design a Dual Sequence Prediction network (DSPNet), constructing parallel item sequence encoders along with corresponding scene sequence encoders to form a dual-branch structure. They employ an improved contrastive learning approach to enhance the robustness of both sequence models, utilize adversarial loss for cross-branch alignment, and train the model by combining \"next item prediction\" with \"next corresponding behavior prediction.\" The effectiveness of the proposed DSPNet is validated on one public dataset and two internal datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Using behavior type features as contextual information indeed enhances the effectiveness of sequential recommendation.\n2. The paper is well-written and very easy to understand.\n3. It includes experiments on industrial-scale datasets."
            },
            "weaknesses": {
                "value": "1. **Limited novelty**. The effectiveness of using behavior features as contextual features in personalized recommendations is somewhat a consensus, so emphasizing this appears somewhat trivial. The proposed method is essentially a simple combination of existing practices, including contrastive learning, adversarial training, next-item, and next-scene/behavior prediction, which are lukewarm in this domain. Although a marginal technical contribution is made with conditional weights in contrastive learning, its superiority over standard contrastive loss does not seem supported by the experiments. While some theoretical results are provided, such as Lemma 1 proving that simultaneously predicting the next item and its corresponding scene/behavior minimizes ELBO, this does not appear significant enough to suffice as a novel technical contribution.\n\n2. **Inconsistency between the dual-branch approach and motivation**. Modeling item sequences and scene/behavior sequences with dual branches seems disconnected or even in conflict with the stated motivation. Lines 93-94 mention that item and scene *simultaneously* occur in Figure 1(c), yet the method here appears to overlook this point. This presents a contradiction\u2014how can independent modeling of item and scene sequences ensure their one-to-one correspondence? It is unclear whether the proposed **coarse-grained** sequence-level alignment/fusion is superior to a **fine-grained** alignment/fusion between item-scene/behavior pairs.\n\n3. **Insufficient experimental comparisons**. The paper lacks crucial baselines that would support the superiority of the proposed method, such as: (1) self-supervised sequential recommendation models, like SASRec, S3-Rec [1], ICLRec [2], and DCRec [3]; (2) baselines using scene/behavior features as attributes [4,5]. Additionally, a simple baseline could involve adding scene/behavior embeddings to item embeddings and using straightforward models like SASRec or BERTRec, often considered strong baselines in practice; (3) multi-behavior sequential recommendation models [6-11] and multi-behavior recommendation models [12-15].\n\n4. **Lack of context in related work**. This study's application is highly relevant to multi-behavior recommendations, particularly multi-behavior sequential recommendations [16], yet these works are overlooked without any discussion, reflecting a gap in the paper's background and depth.\n\n\n--------\n***References***\n\n[1] Zhou K, Wang H, Zhao W X, et al. S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization[C]//Proceedings of the 29th ACM international conference on information & knowledge management. 2020: 1893-1902.\n\n[2] Chen Y, Liu Z, Li J, et al. Intent contrastive learning for sequential recommendation[C]//Proceedings of the ACM Web Conference 2022. 2022: 2172-2182.\n\n[3] Yang Y, Huang C, Xia L, et al. Debiased contrastive learning for sequential recommendation[C]//Proceedings of the ACM web conference 2023. 2023: 1063-1073.\n\n[4] Wu L, Li S, Hsieh C J, et al. SSE-PT: Sequential recommendation via personalized transformer[C]//Proceedings of the 14th ACM conference on recommender systems. 2020: 328-337.\n\n[5] Rashed A, Elsayed S, Schmidt-Thieme L. Context and attribute-aware sequential recommendation via cross-attention[C]//Proceedings of the 16th ACM Conference on Recommender Systems. 2022: 71-80.\n\n[6] Elsayed S, Rashed A, Schmidt-Thieme L. Multi-Behavioral Sequential Recommendation[C]//Proceedings of the 18th ACM Conference on Recommender Systems. 2024: 902-906.\n\n[7] Su J, Chen C, Lin Z, et al. Personalized behavior-aware transformer for multi-behavior sequential recommendation[C]//Proceedings of the 31st ACM International Conference on Multimedia. 2023: 6321-6331.\n\n[8] Xia L, Huang C, Xu Y, et al. Multi-behavior sequential recommendation with temporal graph transformer[J]. IEEE Transactions on Knowledge and Data Engineering, 2022, 35(6): 6099-6112.\n\n[9] Yang Y, Huang C, Xia L, et al. Multi-behavior hypergraph-enhanced transformer for sequential recommendation[C]//Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining. 2022: 2263-2274.\n\n[10] Yuan E, Guo W, He Z, et al. Multi-behavior sequential transformer recommender[C]//Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval. 2022: 1642-1652.\n\n[11] Liu Z, Hou Y, McAuley J. Multi-Behavior Generative Recommendation[C]//Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. 2024: 1575-1585.\n\n[12] Jin B, Gao C, He X, et al. Multi-behavior recommendation with graph convolutional networks[C]//Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. 2020: 659-668.\n\n[13] Xuan H, Liu Y, Li B, et al. Knowledge enhancement for contrastive multi-behavior recommendation[C]//Proceedings of the sixteenth ACM international conference on web search and data mining. 2023: 195-203.\n\n[14] Xia L, Xu Y, Huang C, et al. Graph meta network for multi-behavior recommendation[C]//Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval. 2021: 757-766.\n\n[15] Wu Y, Xie R, Zhu Y, et al. Multi-view multi-behavior contrastive learning in recommendation[C]//International conference on database systems for advanced applications. Cham: Springer International Publishing, 2022: 166-182.\n\n[16] Chen X, Li Z, Pan W, et al. A Survey on Multi-Behavior Sequential Recommendation[J]. arXiv preprint arXiv:2308.15701, 2023."
            },
            "questions": {
                "value": "1. In Table 1, why does BERT4Rec encounter 'OOM' while the other models do not?\n\n2. During inference, how are the metrics calculated? Besides considering the accuracy of item prediction, was the accuracy of behavior prediction also considered?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}