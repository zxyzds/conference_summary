{
    "id": "28qOQwjuma",
    "title": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?",
    "abstract": "Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by focusing mainly on pairwise relationships, overlooking the high-order correlations found in real-world data. Hypergraphs, which can model complex beyond-pairwise relationships, offer a more robust framework but are still underexplored in the context of LLMs. To address this gap, we introduce LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems across eight low-order, five high-order, and two isomorphism tasks, utilizing both synthetic and real-world hypergraphs from citation networks and protein structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our benchmark\u2019s effectiveness in identifying model strengths and weaknesses. Our specialized prompt- ing framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks. This work establishes a foundational testbed for integrating hypergraph computational capabilities into LLMs, advancing their comprehension.",
    "keywords": [
        "LLMs",
        "Hypergraph",
        "Benchmark"
    ],
    "primary_area": "datasets and benchmarks",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=28qOQwjuma",
    "pdf_link": "https://openreview.net/pdf?id=28qOQwjuma",
    "comments": [
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 6/6)"
            },
            "comment": {
                "value": "### Response to Q1\n\nThanks for your suggestions. In response to your query on how the performance of Large Language Models (LLMs) depends on different hypergraph domains, we further conduct an additional set of experiments to evaluate the performance of LLMs across various hypergraph datasets.\n\nIn our supplementary experiments, we selected representative tasks to assess both low-order and high-order understanding capabilities of LLMs. Specifically, we chose the **Vertex Connection Check Task** as a typical low-order node understanding task and the **Vertex-Set-in-Hyperedge Check Task** as a representative high-order hyperedge understanding task. To encode the hypergraph structures, we employ four distinct hypergraph high-order encoding methods, ensuring a comprehensive evaluation of different encoding strategies. These experiments were conducted on two real-world datasets: the **Coauthorship dataset** and the **Protein dataset**. Upon statistical analysis, we find that the Coauthorship dataset has an average hyperedge degree of 3.34, while the Protein dataset has an average hyperedge degree of 2.75. For comparison, classic low-order structured graphs typically exhibit an average hyperedge degree of 2. This metric allow us to quantify the high-order nature of each dataset, with the Coauthorship dataset demonstrating a significantly higher order.\n\n\n\n|                           |      Low-Order Task     |      Low-Order Task     |        High-Order Task        |        High-Order Task        |\n|:-------------------------:|:-----------------------:|:-----------------------:|:-----------------------------:|:-----------------------------:|\n|                           | Vertex Connection Check | Vertex Connection Check | Vertex-Set-in-Hyperedge Check | Vertex-Set-in-Hyperedge Check |\n|                           |       Coauthorship      |         Protein         |          Coauthorship         |            Protein            |\n| Averaged Hyperedge Degree |           3.34          |           2.75          |              3.34             |              2.75             |\n|           N-Set           |           0.98          |          0.976          |             0.956             |             0.946             |\n|           HO-Inc          |          0.996          |          0.996          |             0.972             |             0.872             |\n|           Inc-Mat         |          0.798          |          0.728          |             0.912             |             0.946             |\n|          HO-Neigh         |          0.764          |          0.876          |             0.884             |             0.816             |\n|      Averaged Results     |          0.884         |        **0.894**        |           **0.931**           |             0.895             |\n\n\nOur experimental results reveal that for the high-order **Vertex-Set-in-Hyperedge Check Task**, the performance of LLMs improved as the hyperedge degree of the dataset increased, with an approximate enhancement of 3.6%. This indicates that our proposed high-order encoding methods effectively boost the LLMs' ability to handle complex high-order relational tasks, particularly benefiting from the richer high-order structures present in the Coauthorship dataset. \nFor the low-order **Vertex Connection Check Task**, we observe that the lower the hyperedge degree of the dataset, the better the LLM's performance. This is because lower-order datasets have structures that are closer to traditional graph structures, making high-order descriptive language more redundant. Consequently, this redundancy makes it more difficult for the LLM to comprehend the structure, leading to a decline in performance.\n\n\nFurthermore, our findings confirm that variations in domains indeed lead to differences in LLM performance. These differences are fundamentally due to variations in hypergraph data distributions across domains, such as the sparsity of connections and the number of hyperedges. To gain a deeper and more comprehensive understanding of these domain-specific impacts, we recognize the necessity of collecting and analyzing additional real-world hypergraph datasets from a wider array of domains in future work.\n\nIn summary, our extended experiments demonstrate that the performance of LLMs is influenced by the hypergraph domains, with higher-order structures in certain domains enhancing LLM capabilities for complex tasks, while lower-order structures facilitate better performance in simpler tasks. We will incorporate these detailed findings, along with the corresponding statistical data, into the revised manuscript to provide a clearer and more comprehensive understanding of how different hypergraph domains affect LLM performance."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 5/6)"
            },
            "comment": {
                "value": "### Response to W5 (Summary)\n\nThanks for your comments. We have the following response to your summary.\n\n#### Regarding \"Additional Synthetic Hypergraph Generators\"\n\nIn the current version, we have constructed a preliminary benchmark that includes over 20,000 hypergraph question-answer (Q-A) samples and 15 hypergraph tasks. To ensure diversity and representativeness within this benchmark, we employ four hypergraph generation methods:\n1. **Low-Order First Random Hypergraphs**: This approach assumes that real-world associations prioritize simple connections, aligning with the principle of Occam\u2019s razor.\n2. **Three Types of Structured Hypergraphs**:\n   - **Hyper Pyramid**: Simulates hierarchical high-order relationships.\n   - **Hyper Checked Table**: Simulates grid-like high-order relationships.\n   - **Hyper Wheel**: Simulates wheel-like high-order relationships.\n\nThese generation methods cover a range of typical high-order association patterns, ensuring structural diversity within the synthetic hypergraphs. However, we acknowledge that our current synthetic hypergraph models are not exhaustive. In future work, we plan to incorporate additional hypergraph generation models to further enhance the comprehensiveness and representativeness of our benchmark. This expansion will allow for a more robust evaluation of LLMs across diverse hypergraph structures.\n\n#### Regarding \"Detailed Statistics on Real-World Hypergraphs\"\n\nTo enhance the transparency and comprehensibility of our study, we have conducted detailed statistical analyses of the real-world hypergraphs used in our experiments. The results are summarized below:\n\n|              | Averaged Number of Vertices | Averaged Number of Hyperedge | Averaged Vertex Degree | Averaged Hyperedge Degree |\n|--------------|:---------------------------:|:----------------------------:|:----------------------:|:-------------------------:|\n| Coauthorship |            11.75            |             4.58             |          1.30          |            3.34           |\n|    Protein   |            10.06            |             16.55            |          4.53          |            2.75           |\n\nWe will include these detailed statistics in the revised manuscript.\n\n#### Regarding \"Scalability and Large-Scale Hypergraph Handling Challenges\"\n\n1. **Context Length Limitations of Prompting**: Current large language models (LLMs) have inherent limitations regarding the context length they can process. While hypergraphs can represent highly complex high-order relationships, the constraints of the context window necessitated our selection of hypergraphs with node counts ranging from 15 to 20. This ensures that all structural information of the hypergraphs can be fully inputted and processed by the models. This selection was made to balance the model\u2019s capacity with the need to comprehensively evaluate the LLM\u2019s understanding and reasoning capabilities within these constraints.\n\n2. **Complexity of Hypergraphs Relative to Node Count**: In hypergraphs, increasing the number of nodes exponentially increases the potential number of hyperedges. Specifically, a hypergraph with 20 nodes can have up to $2^{20}$ possible hyperedges, which far surpasses the $20^2$ edges typical in traditional graphs. This means that even with a relatively small number of nodes, hypergraphs can exhibit extreme complexity and diversity in their high-order structures. Therefore, despite the seemingly limited node count in our \"large-scale hypergraphs,\" the complexity and richness of the high-order relationships provide a substantial basis for effectively assessing the LLM\u2019s understanding and reasoning capabilities.\n\n3. **Complexity of Hypergraph Tasks and Future Research Directions**: Hypergraph tasks inherently possess greater complexity and challenge, especially when dealing with larger-scale hypergraphs. Currently, we have chosen a node range of 15-20 to balance complexity and manageability, ensuring the feasibility and validity of our experiments. However, as technology advances and model capabilities improve, we plan to explore and handle larger-scale hypergraphs in future work to further validate and extend the application potential of LLMs in understanding high-order structures."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 4/6)"
            },
            "comment": {
                "value": "### Response to W2.5\n\nThanks for your comments. Regarding your concern that \u201cit is unclear how the random walk approach for sampling sub-hypergraphs from real-world hypergraphs (Appendix A.2) ensures that the sampled hypergraphs 'retain the intricate and authentic correlations inherent in the original data,'\u201d we would like to provide a detailed response.\n\nIn our experiments, to sample sub-hypergraphs of varying sizes (ranging from 5 to 20 nodes) from real-world hypergraphs, we employed a random walk-based approach. The specific steps are as follows:\n\n1. **Random Walk Process**:\n    - We initiate the random walk from a randomly selected node within the hypergraph.\n    - At each step of the walk, each neighboring node of the current node has a 50% probability of being retained or discarded.\n    - This process continues until the predefined number of nodes (between 5 and 20) is reached.\n\n2. **Retention of Hyperedges**:\n    - Once the node set for the sub-hypergraph is determined, we retain all hyperedges that are associated with these selected nodes.\n    - These hyperedges capture the high-order relationships between the nodes, ensuring that the complex structural information of the original hypergraph is preserved within the sub-hypergraph.\n\n3. **Ensuring Authentic High-Order Structures**:\n    - By sampling around specific nodes and their respective domains, the random walk method effectively captures the actual association patterns present in the original hypergraph.\n    - This approach not only preserves direct relationships between nodes but also maintains the high-order associations represented by hyperedges, ensuring that the sub-hypergraphs retain the intricate and authentic correlations inherent in the original data.\n\nAdvantages of the Sampling Method\n\n- **Structural Diversity**: The random walk method allows for coverage of different parts of the hypergraph, resulting in sub-hypergraphs with diverse topological structures.\n- **Association Retention**: By retaining all relevant hyperedges, the method ensures that the high-order relationships within the sub-hypergraphs reflect those in the original hypergraphs, maintaining data complexity and authenticity.\n- **Scalability**: This approach is versatile and applicable to various sizes and types of hypergraphs, offering good generality and flexibility.\n\n\nTo address your suggestion, we will include a detailed description of the random walk sampling method and how it effectively preserves the high-order association structures from the original hypergraphs in the revised manuscript. Through these additions, we aim to clearly illustrate how our sampling method ensures that the sub-hypergraphs retain the intricate and authentic correlations inherent in the original data.\n\n\n### Response to W4\n\nThanks for your comments. You recommended that we discuss and cite the recent work \"When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks\" (CIKM 2024) in the related work section. We acknowledge that this paper is a valuable addition to our research.\n\nThis paper leverages Large Language Models (LLMs) to enhance node representations by integrating various dispersed information and external knowledge, thereby generating higher-quality data and significantly improving the performance of personality analysis. Additionally, the authors utilize Hypergraph Neural Networks (HGNNs) to analyze social networks, enabling the identification of human personalities. This aligns with our work in utilizing LLMs to understand hypergraph structures, both demonstrating the potential and advantages of LLMs in handling complex high-order relational data.\n\nTo further enrich our related work section, we will include a discussion and citation of this paper in the revised manuscript."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 3/6)"
            },
            "comment": {
                "value": "### Response to W2.3\n\nThanks for your comments. Regarding your concern that \u201cthe so-called \u2018large-scale hypergraphs\u2019 in the appendix contain only 15 to 20 vertices, which is too small to meaningfully capture the higher-order structures typically expected in hypergraphs,\u201d we provide the following detailed response.\n\n1. **Context Length Limitations of Prompting**: Current large language models (LLMs) have limitations on the context length they can process. Although hypergraphs themselves can represent extremely complex high-order relationships, the context window constraints necessitated our choice of hypergraphs with 15 to 20 nodes to ensure that all structural information of the hypergraphs could be fully inputted and processed. This selection was made to comprehensively evaluate the LLM's ability to understand and reason about hypergraph structures within the model\u2019s current capabilities.\n\n2. **Complexity of Hypergraphs Relative to Node Count**: In the context of hypergraphs, increasing the number of nodes exponentially increases the potential number of hyperedges. Specifically, a hypergraph with 20 nodes can have up to 2^20 possible hyperedges, which far surpasses the 20^2 edges typical in traditional graphs. This implies that even with a relatively small number of nodes, hypergraphs can exhibit extremely high complexity and diversity in their high-order structures. Therefore, despite the seemingly limited node count in our \"large-scale hypergraphs,\" the complexity and richness of the high-order relationships provide a substantial basis for effectively assessing the LLM's understanding and reasoning capabilities.\n\n3. **Complexity of Hypergraph Tasks and Future Research Directions**: Hypergraph tasks inherently possess greater complexity and challenge, especially when dealing with larger-scale hypergraphs. Currently, we have chosen a node range of 15-20 to balance complexity and manageability, ensuring the feasibility and validity of our experiments. However, as technology advances and model capabilities improve, we plan to explore and handle larger-scale hypergraphs in future work to further validate and expand the application potential of LLMs in understanding high-order structures.\n\nIn summary, although our current \"large-scale hypergraphs\" have a limited number of nodes, their high-order structural complexity provides sufficient challenge for evaluating the capabilities of LLMs. We will further clarify this point in the revised manuscript and aim to expand the scale of hypergraphs in our future research.\n\n\n### Response to W2.4\n\n\nThanks for your comments. Regarding your concern that \u201cthe synthetic hypergraphs are not sufficiently representative and that other synthetic hypergraph models (e.g., configuration models) are available,\u201d we provide the following detailed response.\n\nIn this study, we employ a **Low-Order First** approach to generate synthetic hypergraphs. This method assumes that real-world associations prioritize simpler relationships, aligning with the principle of Occam\u2019s Razor, which suggests that among competing hypotheses, the one with the fewest assumptions should be selected. Therefore, the Low-Order First approach effectively simulates and represents the common simple association structures found in real-world scenarios.\n\nTo encompass different types of typical hypergraph structures, we utilize three representative structures in our synthetic hypergraph generation process:\n\n1. **Hyper Pyramid**: Simulates hierarchical high-order relationships, akin to multi-layered connections in a pyramid structure.\n2. **Hyper Checked Table**: Simulates grid-like high-order relationships, similar to the intersecting connections in a table grid.\n3. **Hyper Wheel**: Simulates wheel-like high-order relationships, resembling spokes connecting to a central hub node.\n\nThese structures are prevalent in various application contexts, representing diverse high-order association patterns and ensuring diversity and representativeness in the structural composition of the synthetic hypergraphs.\n\n\nWhile the current synthetic hypergraph models effectively simulate various typical structures, we acknowledge the importance of incorporating additional synthetic hypergraph models (such as configuration models) to capture more complex and diverse high-order associations. Therefore, in future research, we plan to introduce a wider variety of synthetic hypergraph models, including configuration models, to further enhance the representativeness and comprehensiveness of our benchmark. This will allow for a more thorough evaluation of large language models\u2019 capabilities in understanding and reasoning across different types of hypergraphs.\n\n\nWe will outline our plans to incorporate more synthetic hypergraph models in future work in response to your suggestion. This will address your concerns and strengthen the completeness and persuasiveness of our benchmark."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 2/6)"
            },
            "comment": {
                "value": "### Response to W2.1 and W2.2\n\nThanks for your reviews. Regarding your concerns about the unclear definition of \"hypergraph size\" and the lack of specific sizes for both real-world and synthetic hypergraphs used in our experiments, we provide the following detailed clarification.\n\nIn our experiments, we define the **size of a hypergraph as the number of nodes** it contains, following the conventions outlined in related literature[1]. Based on the number of nodes, we categorize hypergraphs into three size classes:\n\n1. **Small-scale Hypergraphs**: Containing 5-10 nodes\n2. **Medium-scale Hypergraphs**: Containing 10-15 nodes\n3. **Large-scale Hypergraphs**: Containing 15-20 nodes\n\nSynthetic Hypergraphs\n\nFor synthetic hypergraphs, we utilize the `dhg.random.hypergraph_Gnm()` function from the DHG library to generate hypergraphs with a specified number of nodes. This function allows us to create hypergraphs of varying scales to meet different experimental requirements.\n\nReal-world Hypergraphs\n\nOur real-world datasets are derived from two categories:\n1. **Citation Network Dataset**: We randomly sample sub-hypergraph structures from the CoauthorshipCora dataset[2]. In these hypergraphs, **nodes** represent papers, and **hyperedges** signify co-authorship relationships.\n2. **Protein Structure Dataset**: Sourced from the Protein Data Bank (PDB)[3], we randomly select proteins and sample their substructures. In these hypergraphs, **nodes** represent protein residues, and **hyperedges** connect residues that have their **alpha carbon atoms within 10 \u00c5** of each other, centered around each residue.\n\nTo generate subgraphs of varying sizes (with node counts ranging from 5 to 20), we employ a **random walk** sampling method as follows:\n- During each random walk, each traversed node has a **0.5 probability** of being retained or discarded.\n- Once the predefined number of nodes is reached, all hyperedges associated with these nodes are retained to form the final subgraph hyperedges.\n\n\nWe will incorporate the above detailed descriptions of hypergraph size definitions, the specific scales of synthetic and real-world hypergraphs, and the sampling methods used into the revised version of our manuscript. This will ensure that readers have a clear understanding of the sources and construction methods of the datasets used in our experiments.\n\n\n[1] Fatemi B, Halcrow J, Perozzi B. Talk like a Graph: Encoding Graphs for Large Language Models[C]//NeurIPS 2023 Workshop: New Frontiers in Graph Learning.\n\n[2] Yadati N, Nimishakavi M, Yadav P, et al. Hypergcn: A new method for training graph convolutional networks on hypergraphs[J]. Advances in neural information processing systems, 2019, 32.\n\n[3] Bank P D. Protein data bank[J]. Nature New Biol, 1971, 233(223): 10-1038."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer rA8g (Part 1/6)"
            },
            "comment": {
                "value": "### Response to W1\n\nThanks for your reviews. We would like to further clarify and elaborate on our research motivations.\n\n1. Motivation for Researching Hypergraphs\n\nGraph representation and learning[1] have been pivotal research directions in computer science. Notably, this year\u2019s Nobel Prize in Chemistry was awarded to AlphaFold[2], whose achievements heavily relied on graph-based representations and computations of protein three-dimensional structures, demonstrating the powerful capabilities of graphs in modeling complex data. However, traditional graph models primarily focus on pairwise relationships, making it challenging to capture more intricate high-order correlations present in real-world data.\n\nHypergraphs, as a mathematical generalization of graphs, allow a hyperedge to connect more than two nodes, thereby enabling the representation of more complex data associations. High-order correlations in hypergraphs hold significant real-world importance across various domains:\n\n- **Social Networks**: A community or group inherently represents a high-order relationship[3] with an uncertain number of connected nodes, which cannot be effectively modeled using only pairwise edges. In contrast, a hyperedge in a hypergraph can naturally connect any number of nodes, accurately reflecting community relationships.\n  \n- **Life Sciences**: In the field of protein structures, catalytic triplets are typical high-order structures involving interactions among three nodes, present in important protein catalysts such as trypsin[4], playing a crucial role in protein degradation processes. Such high-order structures are essential for understanding biological processes, yet traditional graph models struggle to effectively represent and handle these complex relationships.\n\nThese real-world hypergraph structures motivate us to delve deeper into hypergraph research to better understand and apply high-order associations.\n\n2. Motivation for Using LLMs for Hypergraph Understanding\n\nWhile hypergraph neural networks (HGNNs)[5] can address tasks within hypergraphs, such as node classification and link prediction, these methods often require designing customized model architectures for different tasks, increasing the complexity of model design and limiting their applicability across multiple tasks.\n\nLLMs have recently demonstrated powerful knowledge bases and reasoning capabilities, showing potential for handling diverse tasks. By textualizing hypergraphs, we can leverage the general capabilities of LLMs to handle various hypergraph tasks without the need for designing specialized model structures for each task. This approach offers several advantages:\n\n- **Uniformity and Generality**: A single method (textualization) can be applied to multiple hypergraph tasks, simplifying the model design process and enhancing the method\u2019s generality and adaptability.\n  \n- **Cross-Domain Knowledge Integration**: LLMs possess extensive knowledge bases, enabling the integration and transfer of knowledge across different domains, thereby enhancing hypergraph task comprehension and reasoning.\n  \n- **Efficient Multi-Task Processing**: By designing different prompts, LLMs can be flexibly guided to accomplish various hypergraph tasks, such as structure recognition, link prediction, and isomorphism detection.\n\nTherefore, our research is not only inspired by similar graph studies but also driven by the critical importance of hypergraphs in various real-world applications, exploring how to harness the powerful capabilities of LLMs to enhance hypergraph understanding and application potential. We will further expand and clarify these motivations in the revised manuscript to strengthen the discussion and persuasiveness of our paper.\n\n\n[1] Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks[J]. arXiv preprint arXiv:1609.02907, 2016.\n\n[2] Jumper J, Evans R, Pritzel A, et al. Highly accurate protein structure prediction with AlphaFold[J]. **Nature**, 2021, 596(7873): 583-589.\n\n[3] Contisciani M, Battiston F, De Bacco C. Inference of hyperedges and overlapping communities in hypergraphs[J]. **Nature Communications**, 2022, 13(1): 7229.\n\n[4] Ravetz B D, Pun A B, Churchill E M, et al. Photoredox catalysis using infrared light via triplet fusion upconversion[J]. **Nature**, 2019, 565(7739): 343-346.\n\n[5] Feng Y, You H, Zhang Z, et al. Hypergraph neural networks[C]//Proceedings of the AAAI conference on artificial intelligence. 2019, 33(01): 3558-3565. **1400+ Citation**"
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (6/6)"
            },
            "comment": {
                "value": "### Response to Q4\n\nThanks for your comments. Regarding your question on whether Hyper-BAG and Hyper-COT outperform beyond the statistical variations attributed to variations in individual graph data and the stochastic behaviors of LLMs, we provide the following detailed response.\n\nIn our experiments, we employed over 20,000 question-answer pairs to evaluate model performance. This large-scale dataset helps mitigate statistical fluctuations caused by variations in individual graph data. Additionally, to ensure the reproducibility and stability of our experimental results, we set the temperature parameter of the LLMs to zero ($\\tau = 0$). This setting eliminates randomness in the generation process, ensuring consistent outcomes across experiment runs. Consequently, our results demonstrate a stable and reliable improvement in performance achieved by our proposed methods.\n\nSpecifically:\n\n- Hyper-COT enhances high-order reasoning and achieves an average performance improvement of 4% on structure classification tasks, with gains up to 9%. This indicates that Hyper-COT significantly boosts the model's ability to handle complex high-order reasoning.\n- Hyper-BAG attains a 2.8% improvement in the Vertex Set Connection task compared to the baseline. Although the improvement may appear modest, considering the inherent complexity and challenge of hypergraph tasks, this enhancement is substantial and meaningful.\n\nGiven that hypergraph tasks are more challenging than traditional graph tasks, involving more complex high-order relationships, the performance gains achieved by Hyper-BAG and Hyper-COT are effective."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (5/6)"
            },
            "comment": {
                "value": "### Response to Q3\n\n\nThanks for your reviews. For these computational tasks, we directly compare the output generated by the LLM with the ground truth results on a one-to-one basis. Specifically, if the two results are exactly equal, the response is considered correct; otherwise, it is deemed incorrect. We employ the strictest comparison method because these tasks have unique and definitive correct answers. Therefore, exact matching is essential to ensure fairness and accuracy in our evaluation.\n\nIn our prompts, we strictly limit the format of the LLM's responses. By providing clear question-answer examples, we guide the LLM to generate answers that adhere to the expected numerical formats. Based on the predefined response formats, we develop dedicated extraction functions tailored to each specific task. These functions accurately extract the numerical answers from the LLM's outputs, ensuring that the extracted values are ready for precise comparison with the true answers. After extracting the numerical answers, we perform a complete match between the LLM's output and the true results. This ensures that only perfectly accurate answers are marked as correct, maintaining the integrity of our evaluation process.\n\nHowever, we acknowledge that in certain scenarios, allowing a margin of error might be more reasonable. For instance, in tasks involving floating-point calculations, minor rounding errors could occur. In future work, we plan to explore more lenient evaluation methods, such as setting an error threshold within which results are considered correct, to better reflect the model's actual performance."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (4/6)"
            },
            "comment": {
                "value": "### Response to W6\n\nWe apologize for the insufficient description regarding the real-world graphs used in our experiments. To address this, we provide the following detailed explanation.\n\nOur real-world datasets primarily consist of two categories: citation network datasets and protein structure datasets.\n\n**Citation Network Datasets**:\n1. The data is sourced from the CoauthorshipCora dataset[1].\nWe randomly sample sub-hypergraph structures from this dataset.\n2. In these hypergraphs, nodes represent papers, and hyperedges represent co-authorship relationships.\n\n**Protein Structure Datasets**:\n1. The data is sourced from the Protein Data Bank (PDB)[2].\n2. We randomly select proteins and sample their substructures.\n3. In these hypergraphs, nodes represent protein residues, and hyperedges connect residues that have their alpha carbon atoms within 10 \u00c5 of each other, centered around each residue.\n\nTo generate subgraphs of varying sizes (with the number of nodes ranging from 5 to 20), we employ a random walk sampling method on both datasets as follows:\n\n1. During each random walk, each traversed node has a 0.5 probability of being retained or discarded.\n2. Once the predefined number of nodes is reached, all hyperedges associated with these nodes are retained to form the final subgraph hyperedges.\n\nIn the revised manuscript, we will include these detailed descriptions and selection criteria to ensure that readers have a comprehensive understanding of the sources and construction methods of the datasets used in our experiments.\n\n[1] Yadati N, Nimishakavi M, Yadav P, et al. Hypergcn: A new method for training graph convolutional networks on hypergraphs[J]. Advances in neural information processing systems, 2019, 32.\n\n[2] Bank P D. Protein data bank[J]. Nature New Biol, 1971, 233(223): 10-1038.\n\n-------------------\n\n### Response to Q1\n\nThanks for your comments. Regarding your question on why prompting is a promising research direction for hypergraph understanding in comparison to other techniques such as function calling, we would like to elaborate our perspective.\n\nThe strength of large language models (LLMs) lies in their vast knowledge base and powerful reasoning capabilities. Hypergraphs, as complex relational structures, present significant challenges in representing and reasoning about high-order relationships. Traditional hypergraph neural networks often require custom model architectures tailored to specific tasks when handling high-order relational data, which not only increases the complexity of model design but also limits their applicability across multiple tasks.\n\nBy leveraging LLMs to understand and reason about hypergraphs, we can employ a unified approach to address various tasks, thereby enhancing method generality and adaptability. However, the core challenge lies in enabling LLMs to comprehend and process the intricate structures of hypergraphs. This is precisely the focus of our study: how to textualize hypergraphs to enhance the understanding capabilities of LLMs.\n\nSpecifically, by converting hypergraphs into text formats suitable for LLM processing, prompting techniques can effectively guide the model towards efficient comprehension and reasoning. Once hypergraphs are successfully textualized, LLMs can directly apply to multiple tasks on hypergraphs, such as structure recognition, link prediction, and isomorphism detection, without the need for designing specialized model structures for each task. This approach not only simplifies the model design process but also fully leverages the strengths of LLMs in cross-domain knowledge integration and complex reasoning.\n\nTherefore, we believe that prompting techniques offer significant advantages and hold substantial promise for hypergraph understanding. They can synergize the powerful capabilities of LLMs with the intricate relational structures of hypergraphs, enabling efficient comprehension and reasoning.\n\n### Response to Q2\n\nSee the response to W6."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (3/6)"
            },
            "comment": {
                "value": "### Response to W4\n\nThanks for your comments. Regarding your point about the stochastic nature of LLMs and graph data, we understand the importance of reporting result variations (such as confidence intervals and standard deviations). In our experiments, to ensure consistency and reproducibility of results, we followed strategies from several classical works combining graphs and LLMs, such as NLGraph[1], Talk with Graph[2], and LLM4DyG[3], by setting the temperature parameter $\\tau = $. Additionally, the hypergraph data used in our experiments is fixed, ensuring that the results are reproducible. The stability and reproducibility of our experimental results are of utmost importance to us.\n\nRegarding your observation that the performance gains are \"slim,\" this is because tasks on hypergraph data are significantly more challenging than those on traditional graph data. In hypergraph tasks, the higher-order relationships make the problems more complex. For example, in a link prediction task on traditional graphs, the task is to determine whether there is an association between two nodes, as edges in graphs only connect two nodes. In contrast, in hypergraph link prediction tasks, the goal is to determine whether a single node is associated with a group of nodes because hyperedges can connect any number of nodes. This introduces uncertainty in the number of connected nodes during prediction, greatly increasing the difficulty of the task. Therefore, even modest performance improvements in such complex hypergraph tasks are highly meaningful and challenging.\n\nFor instance, in our experiments, Hyper-COT achieved up to a 9% performance improvement in structure classification tasks, while Hyper-BAG improved performance by 2% on low-order hypergraphs and by 2.8% on high-order hypergraphs. Given the high complexity of these tasks, these improvements demonstrate the effectiveness of our proposed methods in handling complex high-order relationships.\n\n[1] Wang H, Feng S, He T, et al. Can language models solve graph problems in natural language?[J]. Advances in Neural Information Processing Systems, 2024, 36.\n\n[2] Fatemi B, Halcrow J, Perozzi B. Talk like a Graph: Encoding Graphs for Large Language Models[C]//NeurIPS 2023 Workshop: New Frontiers in Graph Learning.\n\n[3] Zhang Z, Wang X, Zhang Z, et al. LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?[J]. arXiv preprint arXiv:2310.17110, 2023.\n\n\n### Response to W5\n\nThanks for your comments. Regarding your point about the imprecise claim that \"the benchmark represents the first instance that includes isomorphism checks,\" we sincerely apologize for the lack of clarity. In the original manuscript, we used \"in this domain\" to limit the scope but did not explicitly specify the particular domain, resulting in an unclear statement. Based on your recommendation, we will clearly define the scope in the revised version, specifically stating that our work is the first benchmark to include isomorphism checks in the hypergraph domain.\n\nExisting benchmarks, such as GraphArena[1], indeed cover isomorphism checks as instances of the Maximum Common Subgraph (MCS) problem within general graphs. However, our benchmark, LLM4Hypergraph, is the first to extend isomorphism checks to hypergraph structures. Hypergraphs, as a mathematical generalization of graphs, can represent more complex high-order relationships. Therefore, isomorphism checks within hypergraphs have not been adequately explored in existing research, and our work fills this gap.\n\nIn the revised manuscript, we will modify the relevant descriptions to ensure that readers clearly understand the unique contribution of our benchmark within the hypergraph domain.\n\n[1] Tang J, Zhang Q, Li Y, et al. Grapharena: Benchmarking large language models on graph computational problems[J]. arXiv preprint arXiv:2407.00379, 2024."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (2/6)"
            },
            "comment": {
                "value": "### Response to W2\n\nThanks for your comments. Graph representation and learning [1] have always been significant research areas in computer science. Recently, the Nobel Prize in Chemistry was awarded to AlphaFold[2], highlighting its use of graph structures to represent and compute the three-dimensional structures of proteins, demonstrating the powerful capabilities of graphs in modeling complex data. However, traditional graph models primarily focus on pairwise relationships, making it challenging to capture the complex high-order correlations found in real-world data.\n\nHypergraphs, as a mathematical generalization of graphs, allow a hyperedge to connect more than two nodes, thereby enabling the representation of more intricate data associations. High-order correlations in hypergraphs hold important real-world significance across various domains. For example, in social networks[3], a community or group inherently represents a high-order relationship, with an uncertain number of connected nodes, which cannot be effectively modeled using only pairwise edges. In contrast, a hyperedge in a hypergraph can naturally connect any number of nodes, accurately reflecting community relationships.\n\nIn the life sciences, catalytic triplets[4] are typical high-order structures involving interactions among three residues, present in important protein catalysts such as trypsin, playing a crucial role in protein degradation processes. Such high-order structures are essential for understanding biological processes, yet traditional graph models struggle to effectively represent and handle these complex relationships.\n\nResearch on hypergraphs is thus highly meaningful, and leveraging large language models (LLMs) to understand and process correlation structures has become a research hotspot in recent years. To fully harness the capabilities of LLMs, hypergraphs need to be textualized, allowing them to be expressed through language. This not only enables LLMs to tackle problems in hypergraphs such as structural recognition and link prediction but also promotes cross-domain knowledge integration and application.\n\nOur paper is based on this premise. By introducing the first hypergraph benchmark for large models (LLM4Hypergraph), we aim to assist researchers in systematically evaluating and understanding the capabilities of LLMs in the hypergraph domain. Compared to other techniques like function calling, prompting offers greater flexibility and adaptability, allowing for more natural handling of textualized hypergraph expressions and exhibiting promising potential for complex high-order reasoning tasks. Therefore, we believe that employing prompting is a promising research direction for hypergraph understanding.\n\n[1] Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks[J]. arXiv preprint arXiv:1609.02907, 2016.\n\n[2] Jumper J, Evans R, Pritzel A, et al. Highly accurate protein structure prediction with AlphaFold[J]. **Nature**, 2021, 596(7873): 583-589.\n\n[3] Contisciani M, Battiston F, De Bacco C. Inference of hyperedges and overlapping communities in hypergraphs[J]. **Nature Communications**, 2022, 13(1): 7229.\n\n[4] Ravetz B D, Pun A B, Churchill E M, et al. Photoredox catalysis using infrared light via triplet fusion upconversion[J]. **Nature**, 2019, 565(7739): 343-346.\n\n### Response to W3\n\nWe apologize for the inaccurate description in the abstract. To more accurately reflect our work, we will add a limitation on the Hyper-COT technique in the second sentence. The revised sentence will be: \"our specialized prompting framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT. Specifically, Hyper-COT enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks.\u201d We will include these modifications in the revised version to ensure accuracy in our descriptions."
            }
        },
        {
            "title": {
                "value": "Response to Reviewer d74r Part (1/6)"
            },
            "comment": {
                "value": "### Response to W1\n\nThanks for your comments. Currently, large language models (LLMs) demonstrate powerful capabilities in areas such as dialogue system[1] and text generation[2]. Hypergraphs, as a complex tool for modeling relationships, are also indispensable in fields like life science[3][4][5] and social science[6][7]. However, how LLMs can operate in the hypergraph domain to analyze and reason about hypergraph data remains unexplored. **Fundamentally, this field requires a benchmark to assist scholars in conducting research.** Our work, LLM4Hypergraph, fills this gap. We have also improved some existing graph techniques to enhance their effectiveness in understanding hypergraphs. Additionally, we propose a hypergraph prompting engineering framework and seven hypergraph text encoding methods that cover both low-order and high-order relationships. Overall, our contributions are as follows:\n\n1. **Introduced the LLM4Hypergraph benchmark**: This is the first benchmark designed to evaluate and test different hypergraph textualization methods for assessing LLMs' ability to analyze hypergraphs. It includes 15 low-order/high-order tasks and 21,500 question-answer pairs, covering various characteristics of hypergraphs.\n2. **Proposed the first hypergraph prompting engineering framework**: This framework is highly scalable and can be applied to hypergraph analysis tasks under different experimental settings.\n3. **Developed Hyper-BAG and Hyper-COT**: Compared to traditional BAG and COT, these methods better adapt to the characteristics of hypergraph data, enhancing LLM performance on hypergraphs.\n4. **Presented seven hypergraph text encoding methods**: These methods cover both low-order and high-order relationships, enabling the textualization of hypergraph data and providing a foundation for LLMs to analyze hypergraphs.\n5. **Evaluated the performance of six mainstream large models using the LLM4Hypergraph benchmark**: We identified shortcomings in LLMs' performance in understanding hypergraph isomorphism, highlighting areas for future research.\n6. **Derived nine observations based on the benchmark and extensive experiments**: These observations provide an in-depth analysis of LLM performance in hypergraph analysis and guide the development of related research.\n\n\n[1] Ouyang L, Wu J, Jiang X, et al. Training language models to follow instructions with human feedback[J]. Advances in neural information processing systems, 2022, 35: 27730-27744.\n\n[2] Achiam J, Adler S, Agarwal S, et al. Gpt-4 technical report[J]. arXiv preprint arXiv:2303.08774, 2023. \n\n[3] Hong D, Dey R, Lin X, et al. Group testing via hypergraph factorization applied to COVID-19[J]. **Nature Communications**, 2022, 13(1): 1837.\n\n[4] Contisciani M, Battiston F, De Bacco C. Inference of hyperedges and overlapping communities in hypergraphs[J]. **Nature communications**, 2022, 13(1): 7229.\n\n[5] Vi\u00f1as R, Joshi C K, Georgiev D, et al. Hypergraph factorization for multi-tissue gene expression imputation[J]. **Nature Machine Intelligence**, 2023, 5(7): 739-753.\n\n[6] Zhang Y, Lucas M, Battiston F. Higher-order interactions shape collective dynamics differently in hypergraphs and simplicial complexes[J]. **Nature communications**, 2023, 14(1): 1605. \n\n[7] Feng Y, You H, Zhang Z, et al. Hypergraph neural networks[C]//Proceedings of the AAAI conference on artificial intelligence. 2019, 33(01): 3558-3565. **1400+ Citation**"
            }
        },
        {
            "title": {
                "value": "Response to Reviewer vz6R"
            },
            "comment": {
                "value": "### Response to \"deeper analysis\"\n\nThanks for your comments. While the current version primarily showcases model performance through metrics, we recognize that an in-depth analysis of the models' limitations is essential for a comprehensive understanding of their capabilities and shortcomings. In the revised manuscript, we will include additional discussions that explore the challenges large language models face in comprehending and reasoning about hypergraph structures. This includes their ability to capture high-order relationships, limitations in modeling complex structures, and adaptability across different domains.\n\n### Response to \"diversity in real-world hypergraphs\"\n\nThanks for your comments. Our current real-world hypergraphs include citation networks and protein networks, representing data from the social sciences and life sciences respectively, to provide a representative preliminary validation. We acknowledge that diversity in data types is crucial for enhancing the generalizability of the benchmark. Therefore, our next steps involve expanding the LLM4Hypergraph benchmark to include a wider variety of real-world data, such as movie recommendation networks, product recommendation networks, and game player networks. This expansion will help to more comprehensively evaluate the ability of large language models to understand and process hypergraphs across different application scenarios.\n\n### Response to \"prompting techniques generalize to other complex data structures\"\n\nThanks for your comments. We acknowledge that this is a significant challenge in the current research landscape. The primary difficulty in extending to other complex data structures lies in effectively encoding the corresponding structures into text. In our study, we experimented with seven different encoding methods to evaluate their performance on hypergraph tasks, and we found that the task performance is strongly associated with the chosen encoding approach.\n\nFor structures with similar complex data structures, such as **simplicial complexes**, the regular and rule-based composition of simplices allows for consistent and systematic text encoding. As a result, the encoding methods we proposed, including HO-Neigh, HO-Inc, N-Set, and Inc-Mat, can be effectively applied to textually encode simplicial complexes. This demonstrates that our methods have good generalization capabilities when handling similarly high-order relational data structures.\nMoving forward, we plan to further explore and refine these encoding techniques to accommodate a wider variety of complex data structures. Additionally, we will consider developing encoding methods tailored to specific data structures to enhance the effectiveness and applicability of the prompting techniques in broader applications.\n\n### Response to \"potential scalability issues with increasingly large and complex hypergraphs\"\n\nThanks for your comments. We have conducted a preliminary analysis on this matter, as presented in Table 7 of our paper. Our findings indicate that as the scale and complexity of the hypergraph increase, the performance of large language models (LLMs) is indeed significantly impacted. This manifests in several ways:\n\n1. Context Length Limitations: When encoding hypergraphs into textual inputs for LLMs, larger and more intricate hypergraphs result in longer input texts. This can exceed the context window limits of LLMs, thereby affecting the models\u2019 ability to comprehend and reason effectively.\n2. Information Overload and Noise: As hypergraph size grows, the volume of information also increases. Effectively conveying key information within limited prompts becomes challenging, and models may struggle to extract useful patterns and relationships from the vast amount of data.\n\nTo address these scalability issues, we plan to explore the following directions in our future work:\n\n1. Hierarchical Processing Strategies: Introduce hierarchical processing mechanisms that decompose hypergraphs into smaller sub-structures for staged processing, thereby alleviating the burden of single-stage processing.\n2. Optimized Model Architectures: Investigate model architectures optimized for hypergraph tasks to enhance efficiency and performance when handling large-scale and highly complex data."
            }
        },
        {
            "summary": {
                "value": "The paper introduces LLM4Hypergraph, a benchmark designed to evaluate large language models' (LLMs) understanding of hypergraphs, which can capture complex, multi-way relationships beyond pairwise correlations found in traditional graphs. The benchmark includes 21,500 problems across low-order, high-order, and isomorphism tasks using both synthetic and real-world hypergraphs. The study evaluates six prominent LLMs and introduces novel prompting techniques to enhance LLMs' performance on hypergraph tasks."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Originality: The paper proposes a new benchmark and prompting techniques tailored for hypergraphs, addressing a gap in the assessment of LLMs' capabilities.\nQuality: The benchmark is comprehensive, covering a wide range of tasks and hypergraph types, which strengthens the validity of the findings.\nClarity: The paper is well-organized, with clear explanations of the hypergraph languages and prompting frameworks.\nSignificance: The work is significant as it pushes the boundaries of LLMs' understanding of complex data structures, which has implications for various real-world applications."
            },
            "weaknesses": {
                "value": "The paper could benefit from a deeper analysis of the limitations of the current LLMs in handling hypergraphs, beyond performance metrics.\nWhile the benchmark is comprehensive, it may lack diversity in terms of the types of real-world hypergraphs used, which could affect the generalizability of the findings."
            },
            "questions": {
                "value": "How do the prompting techniques generalize to other complex data structures beyond hypergraphs?\nCould the authors elaborate on the potential scalability issues of the prompting techniques with increasingly large and complex hypergraphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper provided a new benchmark to evaluate the LLM's ability to understand hypergraphs and developed a new prompting framework to improve the hypergraph comprehension. The prompting framework demonstrated that CoT and BAG, adapted to hypergraphs, can improve the LLM's performance on hypergraph tasks, especially for high-order tasks such as Vertex Set Connection Checks and Vertex-Set--in-Hypergraph Checks using synthetic hypergraphs."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper is easy to read and the experiments are comprehensive and thorough."
            },
            "weaknesses": {
                "value": "**Main arguments**:\n1. The paper adapts existing benchmarks and prompting techniques for hypergraphs. While the results offer some insights into the extent to which LLMs understand hypergraphs, they largely mirror findings for simple graphs---specifically, that CoT and BAG can enhance LLM performance. The only notable point is that using suitable language to describe hypergraphs can aid LLM comprehension, which is novel but trivial.\nGiven that the proposed techniques are naive adaptations of existing techniques and new insights specific to hypergraphs are not found, the contribution of the paper is incremental and not significant.\n2. The paper lays out a main motivation by the underexploration of (i) investigating the LLM's ability to understand hypergraphs and (ii) developing prompting framework for hypergraph understanding and argue that they are promising research directions. This is not a strong motivation, i.e.,  \"underexploration\" alone does not justify the promising research directions. More specific question is: why is prompting a promissing research direction for hypergraph understanding in light of other techniques such as function calling?\n3. Unsupported claim 1: In abstract, ``our specialized prompting framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks.'' This is not sufficiently supported by the empirical results. The performance improvement for Hyper-COT is 4\\% on average. However, for the Hyper-BAG, it is 2\\% for low-order hypergraphs and 2.8\\% for high-order hypergraphs.\n\n**Minor arguments**:\n1. Give the stochastic nature of the LLMs and the graph data, it is crucial to report the variation of the results across different runs (e.g., confidence intervals, standard deviations), given the performance gain of the proposed prompting techniques (Hyper-BAG and Hyper-COT) is slim.\n2. Unsupported claim 2: The paper claimed in the supporting information (B.4) that the benchmark represents the first instance that includes isomorphism checks. This is not precise. Isomorphism checks are a special case of Maximum Common Subgraph (MCS) problem, which is included in the existing benchmark cited in the paper (GraphArena Tang et al. (2024)). The author used \"in this domain\" to limit the scope of their claim, and it is crucial to spell out the \"domain\" (e.g., general graphs, or hypergraphs specifically) to be more precise.\n3. The paper did not provide descriptions about real-world graphs used in the experiments and their selection criteria."
            },
            "questions": {
                "value": "1. Why is prompting a promising research direction for hypergraph understanding in light of other techniques such as function calling?\n2. What are the empirical graphs used in the experiments? What are the selection criteria?\n3.  Some tasks involve computing tasks whose answers are numbers. How does the accuracy is computed for these tasks? Is it an exact match? Or allow some error under a certain threshold?\n4. Does the BAG and CoT outperform beyond statistical variations attributed to the variations of individual graph data and stochatic behaviors of LLMs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces LLM4Hypergraph, the first benchmark aimed at evaluating the ability of LLMs to understand hypergraph data. The authors design a series of tasks of varying difficulty levels and evaluate six different LLMs. Then, they identify their strengths and weaknesses. While this work represents a first step and provides a comprehensive study, there are several areas where improvement is needed."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This paper proposes the first benchmark for evaluating LLMs on hypergraphs.\n- The authors thoroughly address questions about hypergraphs.\n- The problems are well-structured and clearly categorized according to their objectives.\n- The code is released for reproducibility."
            },
            "weaknesses": {
                "value": "- The motivations for this research are not sufficiently discussed. Why is it important to enable LLMs to understand hypergraph structures? Are there potential practical use cases? Are there any motivations beyond the fact that similar research has been done with graphs?\n- The datasets used in the study are not comprehensive. To be specific:\n  - The definition of \"hypergraph size\" is unclear. Is it referring to the number of nodes, the number of hyperedges, or the sum of hyperedge sizes?\n  - The specific sizes of the hypergraphs (both real-world and synthetic) are not mentioned in the main content. How large are the synthetic hypergraphs used for evaluation?\n  - According to the appendix, even the so-called \"large-scale hypergraphs\" only contain 15 to 20 vertices, which is too small to meaningfully capture higher-order structures typically expected in hypergraphs.\n  - The synthetic hypergraphs are not sufficiently representative. There are other synthetic hypergraph models (e.g., configuration models) available.\n  - It is unclear how the random walk approach for sampling sub-hypergraphs from real-world hypergraphs (Appendix A.2) ensures that the sampled hypergraphs \"retain the intricate and authentic correlations inherent in the original data.\"\n- The definition of task \"difficulty\" is unclear.\n- The authors may consider discussing/citing the recent work \"When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks\" (CIKM 2024) in the related work.\n\n**In summary**, this paper makes a valuable contribution to LLMs and hypergraph analysis. However, the benchmark datasets lack comprehensiveness and have room to consider additional synthetic hypergraph generators. Also, the paper lacks detailed statistics on real-world hypergraphs. Scalability is also a concern; if large-scale hypergraph handling poses challenges for LLMs, these limitations should be clearly discussed."
            },
            "questions": {
                "value": "- How does the performance of LLMs depend on the hypergraph domains (e.g., emails, coauthorship)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}