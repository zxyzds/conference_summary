{
    "id": "9Wghi9fKFA",
    "title": "Multi-Atlas Brain Network Classification through Consistency Distillation and Complementary Information Fusion",
    "abstract": "In the realm of neuroscience, identifying distinctive patterns associated with neurological disorders via brain networks is crucial. Resting-state functional magnetic resonance imaging (fMRI) serves as a primary tool for mapping these networks by correlating blood-oxygen-level-dependent (BOLD) signals across different brain regions, defined as regions of interest (ROIs). Constructing these brain networks involves using atlases to parcellate the brain into ROIs based on various hypotheses of brain division. However, there is no standard atlas for brain network classification, leading to limitations in detecting abnormalities in disorders. Some recent methods have proposed utilizing multiple atlases, but they neglect consistency across atlases and lack ROI-level information exchange. To tackle these limitations, we propose an Atlas-Integrated Distillation and Fusion network (AIDFusion) to improve brain network classification using fMRI data. AIDFusion addresses the challenge of utilizing multiple atlases by employing a disentangle Transformer to filter out inconsistent atlas-specific information and distill distinguishable connections across atlases. It also incorporates subject- and population-level consistency constraints to enhance cross-atlas consistency. Additionally, AIDFusion employs an inter-atlas message-passing mechanism to fuse complementary information across brain regions. Experimental results on four datasets of different diseases demonstrate the effectiveness and efficiency of AIDFusion compared to state-of-the-art methods. A case study illustrates AIDFusion extract patterns that are both interpretable and consistent with established neuroscience findings.",
    "keywords": [
        "Brain Network",
        "fMRI Biomarker",
        "Graph Neural Network",
        "Graph Transformer",
        "Neurological Disorder"
    ],
    "primary_area": "applications to neuroscience & cognitive science",
    "TLDR": "We introduce AIDFusion, a multi-atlas method that improves brain network classification by atlas-consistent information distillation and cross-atlas complementary information fusion",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=9Wghi9fKFA",
    "pdf_link": "https://openreview.net/pdf?id=9Wghi9fKFA",
    "comments": [
        {
            "summary": {
                "value": "This paper aims to classify brain networks from fMRI BOLD ROIs using multiple (potentially conflicting) atlases. The authors resolve conflicts with a deep neural network (specifically a \"disentangle transformer\") alongside external prior information related to subject and population constraints.\n\nTo evaluate the efficacy of the proposed approach, the authors compare against several classical and current methods on four disparate datasets with a classification downstream task. Their method achieves the greatest quantitative results compared to all others in nearly all cases."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This approach is well-motivated, as there is no consensus on the number of atlases to use. Using a single atlas conforms to the biases induced that particular atlas, and using multiple atlases involves the use of novel methods which do not regularize consistency across multiple atlases. The proposed approach aims to achieve both consistency across multiple atlases as well as providing their model ROI-level \"information exchange.\" Accomplishing these two aims required the development and use of several techniques, including the proposed \"disentangle transformer\" and \"identity embedding\", the use of an orthogonality loss on a component of the representations, a nearly-linear learnable mapping for inter-atlas message passing, a bespoke contrastive loss for subject-level consistency, and a similarity loss for \"maintain the relationship of subjects across atlases.\"\n\nThis paper is well-motivated and fairly comprehensive with respect to the classification experiments. The contribution of the approach as an improvement for classification of brain networks is clear. I recommend this paper be accepted."
            },
            "weaknesses": {
                "value": "In addition to my recommendation for acceptance, I enumerate some concerns I have below:\n\n1. The technical claims are not fully supported. The \"identity embedding\" is either mis-named or its explanation is unclear. The embedding is not identity; it seems instead to simply be a learnable embedding. It is unclear whether the parameters of the MLP in Eq. 1 are learnable. If so, what is the purpose behind W_ID?\n2. The efficacy of the \"disentangle Transformer\" is not fully supported. How well are conflicting atlases disentangled? Was the orthogonal loss actually useful towards separating shared and conflicting information across atlases? An experiment to support the authors' intuition is missing.\n3. The same is true for both subject- and population-level consistencies as well as message-passing. The explanation is sensible in text, but the actual efficacy of the proposed architecture and losses is not described in the experiments and results. The reader sees that the downstream classification is improved in light of the proposed components, but it is unknown whether these components accomplish what they are intended to.\n4. Some figure and table captions are too terse. Figure1, table 1, table 3 could benefit from better description to help the reader understand their contents.\n5. Table 5 experiment times include training, validation, and testing across multiple cross-validation folds. This is unusual; instead, reporting training+validation time and then testing time (for a single subject) separately would be more conventional. This guides future users of the proposed method towards how much time and compute should be budgeted for training the approach as well as what hardware is necessary to use the proposed method at scale in their own work."
            },
            "questions": {
                "value": "These questions are adapted / copied from the weaknesses listed above:\n\n1. It is unclear whether the parameters of the MLP in Eq. 1 are learnable. If so, what is the purpose behind W_ID?\n2. The efficacy of the \"disentangle Transformer\" is not fully supported. How well are conflicting atlases disentangled? Was the orthogonal loss actually useful towards separating shared and conflicting information across atlases? An experiment to support the authors' intuition is missing.\n3. The same is true for both subject- and population-level consistencies as well as message-passing. The explanation is sensible in text, but the actual efficacy of the proposed architecture and losses is not described in the experiments and results. The reader sees that the downstream classification is improved in light of the proposed components, but it is unknown whether these components accomplish what they are intended to. What evidence do the authors have towards these claims?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Resting-state functional MRI is often used to predict behavioral phenotypes by measuring correlations between disparate regions/parcels of the brain. There are many different parcellation conventions (\u201catlases\u201d in this context) and downstream analyses are often quite dependent on the choice of atlas.\n\nSubmission 4706 presents a classification framework that integrates multiple different atlas conventions for a given subject. They propose a transformer that extracts complementary information and gain modest accuracy increases across four different datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The use of [transformer registers](https://arxiv.org/abs/2309.16588) (herein called \u201cincompatible nodes\u201d) for potentially filtering out incompatible information across atlases is a novel and interesting application.\n- The use of spatial distances between regions of interest in the brain when constructing the message-passing framework is interesting and, to my limited knowledge, not commonly done.\n- Generally clearly and straightforwardly presented."
            },
            "weaknesses": {
                "value": "I do not work in this specific subfield and would be happy to revisit my score and look forward to the discussion phase. I also did not read the appendix so please correct me if I missed something.\n\n### 1. Unclear motivation for transformer-based approach on processed connectomes\n\nThe datasets in fMRI connectomics are (understandably) limited in sample size, ranging here from N=60 to N=1300. \n\nHowever, it is unclear how the submission can adequately train transformers on 60 data samples. Without inductive bias (beyond permutation equivariance), transformers require several orders of magnitude higher training sets across the literature. I do not see any mention of pretraining either on larger datasets (e.g. UKBiobank) that would potentially enable few-shot finetuning.\n\nFurther, could the authors please elaborate on why they chose to work only with the processed connectomes instead of the high-dimensional raw data where there may be more potential for self-supervised pretraining?\n\n### 2. Using only two atlases in experiments\n\nThe submission motivates itself by claiming that multiple atlases provide complementary information (which is a reasonable hypothesis) but its experiments only use two atlases (Schaefer100 and AAL116). Given that there is a wide range of potential atlasing procedures and many other atlases are often used, could the authors please clarify why two atlases were used in the experiments?\n\n### 3. Unclear significance\n\nThe main comparative results (presented in Table 2) are largely well within each others\u2019 error bars without clear significance.\n\nIs there high inter-subject or inter-site variability s.t. standard deviations are inflated? Plotting per-subject performance as a supplemental figure should clarify this.\n\nFurther, could the authors please perform significance tests with corrections for multiple comparisons s.t. readers can assess whether these gains are meaningful?\n\n### 4. Baseline choices and clarifications\n\n#### 4.1. Iterative/conventional baselines\n\nThe only iterative baselines included for comparison are logistic regression and SVMs. It is not mentioned whether these methods were regularized in any form (e.g. LASSO) and, if so, whether the regularization hyperparameters were tuned at all. As far as I\u2019m aware, practitioners [largely use LASSO-style methods for behavior prediction](https://db.humanconnectome.org/megatrawl/HCP820_MegaTrawl_April2016.pdf) and find that the regularization weight strongly affects the results.\n\nFurther, to my knowledge, deep nets and methods such as kernel regression are largely equivalent on this task when tested on much larger sample sizes ( [reference](https://pubmed.ncbi.nlm.nih.gov/31610298/) ).\n\nAs all results are well within each other's error bars (see point 3 above), could the authors please detail why only two non-DL methods were benchmarked and whether these methods were regularized and tuned?\n\n#### 4.2 Transformer baselines\n\nSeveral transformer-based approaches to fMRI classification are neither cited nor benchmarked against. For example,\n- https://link.springer.com/chapter/10.1007/978-3-031-43993-3_28 (MICCAI\u201923)\n- https://link.springer.com/chapter/10.1007/978-3-031-72390-2_14 (MICCAI\u201924)\n\nAdditionally, while not a one-to-one comparison to these papers use of static splits vs. the submission using 10-fold CV, these papers report much higher performance on ABIDE (high-70s vs the paper\u2019s mid-60s accuracy). \n\nCould the authors please address differences relative to these works, whether they could be used as baselines, and what could explain the major performance differences?\n\n### 5. Missing ablations for key contributions\n\nThe paper has several moving parts, all of which are claimed as novel contributions. However, the core parts of Section 4.1 (the identity embedding, the \u201cdisentangle Transformer\u201d, and the orthogonal loss) are not ablated. Please do so in the rebuttal or future versions.\n\n### 6. Minor\nThese aspects do not affect my score.\n\n- The paper claims that not all regions of the brain are covered by all atlases and thus integrating multiple atlases may have benefits. Please correct me if I\u2019m wrong but don\u2019t atlases such as Shen and Craddock cover most of the brain? \n- Somewhat orthogonally, multiple atlas _harmonization_ can also be performed as with iterative methods like [CAROT](https://www.sciencedirect.com/science/article/am/pii/S136184152300124X). Could the authors please clarify the differences in motivation for their approach vs. atlas harmonization? I ask as much of the paper is motivated by the goal of integrating information across atlases and there are existing methods to do so."
            },
            "questions": {
                "value": "- How is transformer training feasible on tiny datasets with sample sizes of N=60 and N=1300 without any self supervised pretraining?\n- Why work with processed connectomes instead of raw data for transformer training?\n- Please perform significance testing with multiple comparisons adjustments.\n- Please describe how the conventional baselines were tuned and whether they were regularized\n- Please add ablations for the key contributions in 4.1"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, a novel method named AIDFusion is proposed to learn unified and informative representations of brain functional networks derived from multiple brain atlases, which are expected to facilitate the brain network based classification. The method consists of several modules including disentangle transformer, inter-atlas message-passing, subject-level and population-level consistency to learn atlas-consistent information. The proposed method has been evaluated on multiple datasets to demonstrate its effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The idea of learning unified representation from multiple brain networks is promising to improve classification performance.\n2. Multiple techniques are proposed to facilitate the unified representation learning, e.g., disentangle transformer, inter-atlas message-passing, and multi-level consistency."
            },
            "weaknesses": {
                "value": "1. The brain networks from different atlases will contain atlas-consistent information and atlas-specific information, both types of information may be informative for classification. While the proposed method adopts several techniques to get enhanced atlas-consistent information, the atlas-specific information may not be effectively captured. Not sure if the proposed disentangle transformer may discard atlas-specific information that are useful for classification.\n2. As demonstrate in the experimental results, the fusion of multiple arbitrary atlases may not improve classification performance. It is not clear and not verified what atlases should be fused."
            },
            "questions": {
                "value": "1. For the identity embedding in the disentangle transformer. It is not clear how the identity embedding was implemented. \"... a parameter matrix W_ID to encode nodes within the same ROI\", but it looks like one node corresponds to one brain ROI in the proposed method.\n2. The brain networks from different atlases will contain atlas-consistent information shared across atlases and atlas-specific information, both types of information may be informative for classification. While the proposed method adopts several techniques to get enhanced atlas-consistent information, the atlas-specific information may not be effectively captured. Not sure if the proposed disentangle transformer may discard atlas-specific information that are useful for classification.\n3. The Eq.(9) is not correct. I think i refers to ROI in atlas a or b, not cluster.\n4. The AAL atlas contains both cerebral cortex, subcortical structures, and cerebellum regions, while the Schaefer atlas only covers cerebral cortex regions. Not sure if it is proper to learn consistent representations from brain networks with different brain coverages.\n5. As demonstrate in the experimental results, the fusion of multiple arbitrary atlases may not improve classification performance. A principled way to identify what atlases should be fused is needed.\n6. When applied to more than 2 atlases, will the orthogonal loss, inter-atlas message passing, and subject/population-level consistency be computed for each pair of atlases?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method called AIDFusion, designed to improve brain network classification using rs-fMRI data. \n\nThe authors note that existing methods often rely on single atlases for classification, while approaches that utilize multiple atlases tend to overlook cross-atlas consistency and fail to facilitate information exchange at the ROI level. To address these issues, the authors first introduce a disentangled Transformer to learn atlas-level embeddings. They then propose an inter-atlas message-passing mechanism to fuse complementary information across brain regions. Additionally, subject-level and population-level consistency losses are employed to enhance cross-atlas coherence."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- Originality: This paper demonstrates some novelty. For instance, the concept of inter-atlas message-passing is interesting.\n- Quality: The methodology is validated across four datasets representing different diseases, effectively showcasing its effectiveness and efficiency.\n- Clarity: The paper is well-structured and easy to follow, enhancing comprehension for readers.\n- Significance: This research offers new insights into brain network analysis within the field of neuroscience."
            },
            "weaknesses": {
                "value": "**1. There are too many hyperparameters to tune, which undermines the credibility of the results.**\n\nFor example, the training loss comprises five components, with four parameters requiring tuning. Additionally, hyperparameters from other modules of the method, such as the k value in KNN (lines 258-259), the keeping ratio (lines 278-279), and the temperature parameter (lines 302-303), also need to be set appropriately.\n\n**2. The presence of numerous networks to learn complicates the training process, potentially leading to instability.**\n\nThis includes the transformers in lines 216-240 and three GCNs in lines 263-267 and 280-285.\n\n**3. The motivations for some modules are unconvincing.**\n\nFor example, in lines 216-221 and 242-245, the authors mention introducing incompatible nodes and using orthogonal loss to filter out inconsistent atlas-specific information, citing the [CLS] token in NLP as motivation. However, the relationship is not adequately established, and the effect of these incompatible nodes is not clearly illustrated or justified.\n\n**4. The comparisons are insufficient.**\n\nGiven that the atlas embedding learning is a transformer-based method, comparisons with additional transformer-based methods, such as [1], should be included. Additionally, other multi-atlas methods, like [2], should be considered. the manuscript may lack ablation studies that directly concatenate embeddings from single-atlas methods across different atlases similar in [2][3].\n\n*[1] Kan, X., Dai, W., Cui, H., Zhang, Z., Guo, Y., & Yang, C. (2022). Brain network transformer.\u00a0Advances in Neural Information Processing Systems,\u00a035, 25586-25599.*\n\n*[2] Wang, W., Xiao, L., Qu, G., Calhoun, V. D., Wang, Y. P., & Sun, X. (2024). Multiview hyperedge-aware hypergraph embedding learning for multisite, multiatlas fMRI based functional connectivity network analysis.\u00a0Medical Image Analysis,\u00a094, 103144.*\n\n*[3] Zhao, B. W., You, Z. H., Wong, L., Zhang, P., Li, H. Y., & Wang, L. (2021). MGRL: Predicting Drug-Disease Associations Based on Multi-Graph Representation Learning.\u00a0Frontiers in genetics,\u00a012, 657182. https://doi.org/10.3389/fgene.2021.657182*"
            },
            "questions": {
                "value": "Given the small sample sizes of rs-fMRI datasets, as stated in lines 325-330, how did you overcome the risk of overfitting during the training process and determine hyperparameters?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}