{
    "id": "kp8T7G9hIh",
    "title": "TDR-HGN:Residual-enhanced heterogeneous graph networks for topology-driven feature completion",
    "abstract": "Heterogeneous graphs are composed of multiple types of edges and nodes. The existing heterogeneous graph neural network can be understood as a node feature smoothing process guided by the graph structure, which can accurately simulate complex relationships in the real world. However, due to real-world privacy and data scarcity, some node features are inevitably missing. Furthermore, as model depth increases and multiple types of meta-paths are aggregated, node embeddings tend to be consistent, leading to semantic confusion and overfitting problems. To improve the quality of node embeddings, we propose topology-driven residual boosting network (TDR-HGN). It introduces one-hot encoding and node type encoding to generate initial features, uses topological structure features to guide feature completion, combines residual networks to deal with semantic confusion and over-fitting problems, and builds neighbor-based high-order graph networks through meta-paths to achieve feature enhancement. We conduct extensive experiments on three heterogeneous graph datasets, and the results show that TDR-HGN can significantly improve the performance compared to other methods.",
    "keywords": [
        "Heterogeneous graph networks",
        "feature completion",
        "topological features",
        "residual networks",
        "meta-path"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "TDR-HGN is a heterogeneous graph neural network that uses topology-driven feature completion and feature enhancement, combined with meta-path and residual network, and tested on multiple datasets to verify its effectiveness",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=kp8T7G9hIh",
    "pdf_link": "https://openreview.net/pdf?id=kp8T7G9hIh",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a topology-driven residual enhancement network (TDR-HGN) for heterogeneous graph neural networks (HGNNs) to address the challenges of feature completion and semantic confusion. The TDR-HGN introduces one-hot encoding and node type encoding to generate initial features and uses topological structure features to guide feature completion. The proposed model combines residual networks to deal with semantic confusion and overfitting problems, and builds neighbor-based high-order graph networks through meta-paths to achieve feature enhancement. Extensive experiments on three heterogeneous graph datasets demonstrate that TDR-HGN significantly outperforms some existing methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper introduces a topology-driven feature completion strategy that leverages one-hot encoding and node type encoding to generate initial features. This approach is new in its emphasis on using topological structure features to guide feature completion. \n2. The methodology is well-defined and logically structured. Further, this paper conducts experiments on several data sets to verify its effectiveness."
            },
            "weaknesses": {
                "value": "1. The novelty is trivial. The residual network structure and the feature completion method are off-the-shelf ideas. \n2. Some importance reference is missing, such as [1]. Compared with ref.[1], the proposed method achieves few improvements. \n3. Minor writing issues: the sentences between line 92-96 lack subjects. \n\n[1] Du C, Yao K, Zhu H, et al. Seq-HGNN: learning sequential node representation on heterogeneous graph[C]//Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2023: 1721-1730."
            },
            "questions": {
                "value": "None."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a feature completion model for heterogeneous graphs that alleviates semantic confusion and overfitting for long meta-paths. It introduces one-hot encoding to generate initial features and uses topological structure features to guide feature completion. Meanwhile, it combines residual networks to deal with semantic confusion and over-fitting problems to enrich the generated features with high-order neighbors. The experimental results show improvement."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. It proposes a feature completion model that incorporates high-order neighbors to enrich the generated features.\n2. It combines both structural embeddings and existing features of other nodes for missing nodes.\n3. it uses attention modules to model the importance of neighbors with only one-hot embedding and type embedding."
            },
            "weaknesses": {
                "value": "1. It's not reasonable to me that only one node embedding to calculate attention coefficients for all nodes starting from node $v$ and all nodes ending with node $u$ in Eq. (2), and then add them up to get the attention coefficient for an edge in Eq. (3) . Since the one-hot encoding and type embedding are both very sparse and $e_{v,u}^{src}$ or  $e_{v,u}^{dst}$ are identical to every neighbor of node $v$ or $u$. I doubt it can learn a good coefficient that can distinguish the importance. \n2. some typos. e.g., two $h_v^{in}$ at line 215, Transforme at line 294\n3. A similar issue also exists in Eq. (8), with no $h_v$ involved in the attention calculation.\n4. The experimental results are not significant."
            },
            "questions": {
                "value": "1. Do you include $h_v^{l-1}$ in Eq. (5) as well?\n2. Can you also explain why choosing weights as the residual target in Eq. (11)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents the topology-driven residual boosting network (TDR-HGN) for heterogeneous graphs, addressing key challenges such as missing node features, semantic confusion, and overfitting in existing graph neural networks (GNNs). The proposed approach integrates one-hot and node type encoding to enhance initial feature generation and employs topological structures for feature completion. It also incorporates residual networks to mitigate confusion and overfitting, alongside constructing high-order graph networks through meta-paths. The extensive experimental evaluation on three heterogeneous graph datasets demonstrates significant performance improvements over current methodologies, highlighting the effectiveness and potential of TDR-HGN in enhancing node embedding quality."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper compares against relatively new baseline methods, and the experimental results are impressive, enhancing the credibility and applicability of the research.\n2. The proposed method is easy to follow, with a clear overall structure that facilitates reader comprehension and potential application."
            },
            "weaknesses": {
                "value": "1. The method appears to be more about feature engineering, designing multiple features with prior knowledge to input into the heterogeneous graph attention network, potentially lacking deeper model innovation.\n2. Using one-hot encoding for certain features may lead to memory issues in large datasets, and the paper does not analyze the time or space complexity of the approach.\n3. The paper does not explore whether applying the used feature information to more advanced heterogeneous graph network algorithms could yield better performance.\n4. While ablation studies indicate that residual connections and topology-based attention have a significant impact on performance, the importance of the initial one-hot features and other features remains unclear."
            },
            "questions": {
                "value": "1. Have the authors considered testing the proposed features within more advanced heterogeneous graph network algorithms, and what insights could this provide regarding the robustness of their method?\n2. In the ablation studies, can the authors provide a more detailed analysis of the significance of the initial one-hot features and other feature types in relation to the performance outcomes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces SECSAGE, an extension of GraphSAGE for heterogeneous multiplex graphs, which refines layer-wise embeddings concurrently with downstream model training. Specifically, the model is optimized through joint encoder-classifier training, showing improvements over selected baselines on the Travel Dubai dataset. While technically robust and effective, it would be beneficial to include experiments on other datasets, code for reproducibility, expanded baseline comparisons, and improved writing clarity."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The topic is interesting and relevant, addressing challenges in representation learning for heterogeneous multiplex graphs.\n2. SECO combines prediction-level fusion with simultaneous optimization, resulting in improved task alignment in embeddings.\n3. The proposed model demonstrates improvement over selected baselines.\n4. The model\u2019s performance is validated with multiple metrics, including accuracy, F1, and ROC-AUC."
            },
            "weaknesses": {
                "value": "1. The reliance on GraphSAGE extensions and standard fusion techniques limits the novelty of the proposed architecture.\n2. The absence of code hinders reproducibility, reducing accessibility for researchers who may want to apply the proposed approach.\n3. Evaluating on only a single dataset may not capture sufficient diversity, thus limiting generalizability.\n4. While the model outperforms the chosen baselines, authors should expand the comparison to include a wider range of recent and diverse approaches.\n5. The manuscript would benefit from further refinement to improve clarity and readability."
            },
            "questions": {
                "value": "1. Are there specific models you believe should be included in the baseline comparisons, especially in the context of heterogeneous/heterogeneous multiplex/knowledge graphs?\n2. Do you have plans to make the code available publicly?\n3. Since the model is evaluated on a single dataset, can you discuss the potential challenges in applying your model to other datasets?\n4. Could you further clarify the novelty of the added components and explain how these modifications specifically address the unique challenges of heterogeneous multiplex graphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}