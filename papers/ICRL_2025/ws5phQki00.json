{
    "id": "ws5phQki00",
    "title": "The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions",
    "abstract": "Stance detection holds great potential to improve online political discussions through its deployment in discussion platforms for purposes such as content moderation, topic summarisation or to facilitate more balanced discussions. Typically, transformer-based models are employed directly for stance detection, requiring vast amounts of data. However, the wide variety of debate topics in online political discussions makes data collection particularly challenging. LLMs have revived stance detection, but their online deployment in online political discussions faces challenges like inconsistent outputs, biases, and vulnerability to adversarial attacks. We show how LLM-generated synthetic data can improve stance detection for online political discussions by using reliable traditional stance detection models for online deployment, while leveraging the text generation capabilities of LLMs for synthetic data generation in a secure offline environment. To achieve this, (i) we generate synthetic data for specific debate questions by prompting a Mistral-7B model and show that fine-tuning with the generated synthetic data can substantially improve the performance of stance detection, while remaining interpretable and aligned with real world data. (ii) Using the synthetic data as a reference, we can improve performance even further by identifying the most informative samples in an unlabelled dataset, i.e., those samples which the stance detection model is most uncertain about and can benefit from the most. By fine-tuning with both synthetic data and the most informative samples, we surpass the performance of the baseline model that is fine-tuned on all true labels, while labelling considerably less data.",
    "keywords": [
        "large language models",
        "stance detection",
        "data augmentation",
        "active learning",
        "online political discussions"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "We study and show how to leverage LLM-generated synthetic data for stance detection in online discussions, which is a challenging stance detection task because of the broad range of debate questions.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ws5phQki00",
    "pdf_link": "https://openreview.net/pdf?id=ws5phQki00",
    "comments": [
        {
            "summary": {
                "value": "The paper tries to improve transformer-based stance detection models by fine-tuning on LLM generated data. They compare the real-world data with the synthetic data to identify difficult samples from unlabelled data (active learning) to further improve the model. They show that both these steps improves the performance of the transformer-based baseline."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper leverages the data augmentation capabilities of LLMs to improve transformer based models which are better suited for online deployment as they are more reliable. \n- The presented method can be adapted to other text classification tasks and hence is a significant contribution.\n- It is well written and easy to follow, except for few instances mentioned in the comments."
            },
            "weaknesses": {
                "value": "- It\u2019s possible I\u2019m missing some key context here, but I\u2019m having trouble following the ablation study in Section 5.2. To test whether the performance gains come from dataset size or the generated content itself, the authors \u201cshuffle\u201d instances, apparently misaligning the posed questions with synthetic data. If the synthetic data consists of single text instances with labels, this shuffling wouldn\u2019t seem to affect outcomes. Perhaps the authors mean they\u2019re using different proportions of synthetic data in each run while keeping the total instance count constant, but this explanation feels somewhat unclear.\n- Even though authors acknowledge this as a limitation, fine-tuning a separate model for each question doesnot seem to be a scalable approach, especially when the main motivation for the research was in line with training robust models for online deployment. \n- The X-stance dataset is described as having around 48k annotated comments on various questions. However, an overview of the dataset\u2019s statistics\u2014such as the number of comments per question\u2014would greatly enhance readability. When you mention selecting 10 questions from the test set, it would be helpful to specify how many comments correspond to each question. While I see some statistics are included in the Appendix, a high-level summary within the main text would improve clarity and context for readers.\n- Section 4.2, General setup: Please review this section for more readability. Currently, it is a bit difficult to get a picture of what models are being tested and how the methods differ between them."
            },
            "questions": {
                "value": "- Why choose translation over adapting prompts directly? Is Mistral unable to generate responses in German, or were other multilingual models considered?\n\n- In the ablation study for \"Content vs. Size\", I am not sure I understand why you call the shuffled dataset \"misaligned\". Could you please explain the reasoning behind this? \n\n- In the generated dataset, did you find any instance where the LLM failed to generate the requested content? For instance, generate statements not in favor when requested for \"in favor\" content or LLM refusing to generate any relevant content at all."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes to use LLM-generated synthetic data to augment the training of stance classification models. It also proposes a synthetic data-based active learning method that uses synthetic data to facilitate the selection of unlabelled data for human annotation. Experiments are conducted on the German subset of the X-stance dataset (with the help of machine translation). The results demonstrate that including synthetic data in training can improve stance prediction. The synthetic data-based active learning method, however, is not clearly better than a random selection-based baseline active learning method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The proposed method is sound. I do not see any major issue with the method.\n- Although the idea of using synthetic data to augment models is not entirely new, it probably has not been widely explored for stance prediction.\n- The authors conducted extensive experiments to evaluate the method, including varying the size of the synthetic dataset, comparing with meaningful baselines, and the further experiments that compare with a LLM zero-shot baseline."
            },
            "weaknesses": {
                "value": "- The experiments are conducted using a German dataset, but translation into and back from English is used in order for the method to work (probably because of limited German language understanding and generation capabilities of the Mistral model that is used?) There is no explanation of why the authors do not evaluate the method using an English dataset.\n- The novelty and impact of the work is still limited. (1) Using synthetic data to augment models is not new. Although applying the idea to stance prediction might be new, it is one of many NLP tasks. The way synthetic data is generated and used during training in this paper is also standard, hence there is limited technical contribution. (2) The idea of using synthetic data for active learning is very interesting and is novel based on my knowledge. However, its effectiveness is limited based on the experiments. Therefore, overall, although the work is very solid in general, its novelty and impact may not meet the standard of this conference.\n- There is room for improvement in terms of presentation. In particular, the active learning method proposed can benefit from first presenting an overview of the high-level intuition behind the method before describing the method itself."
            },
            "questions": {
                "value": "- It would be very helpful to explain why only a German dataset is used for the experiments. Also, if German text is used, have the authors considered using a different LLM that has good German language processing capabilities for the experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Yet another synthetic data paper that shows modest improvements but doesn't quite nail why or how to make synthetic data actually useful. Some interesting ideas buried under conventional methodology.\n\nLook, I've seen enough \"let's use LLMs to generate synthetic data\" papers to last several conferences. What makes this one interesting - barely - is the political stance detection angle and the somewhat novel SQBC approach. But let's be real here: you're essentially using an LLM to generate slightly different versions of existing viewpoints, then acting surprised when this helps... a little bit.\n\nThe authors show that their approach improves F1 scores from ~0.69 to ~0.72 with synthetic data alone, and up to ~0.75 with their full pipeline. Sure, that's positive, but is it worth the computational cost of running Mistral-7B for hours to generate the synthetic data? (And don't get me started on the economic/environmental impact in general - though I suppose that's not this paper's specific sin since those models are small and this used only 1 A100 GPU.)\n\nThe most interesting part is actually buried in Section 5.1, where they show that using Mistral-7B directly for stance detection fails miserably. This suggests something important about synthetic data that the authors don't fully explore: it's better at generating plausible variations than at making decisive judgments. This deserved more analysis.\n\nWhat's missing here is any real investigation into what makes synthetic data actually useful. Are we just doing expensive interpolation between existing data points? Where's the analysis of entropy and diversity in the generated samples? The visualizations in Figure 3 are pretty, but they also show that the synthetic data mostly just fills in obvious gaps rather than introducing genuinely novel perspectives.\n\nThe active learning component feels tacked on, though I'll admit the SQBC approach is clever. Using synthetic data as a reference distribution for selecting informative samples is neat, but again - why does this work? The paper handwaves at \"ambiguous samples\" without diving deeper into the theoretical foundations.\n\nOne thing I'll give the authors credit for: they did their homework on the translation pipeline. Using NLLB-330M and actually caring about the quality of the German-English-German round trip is more than many papers bother with. The samples in Table 8 show reasonable quality political discourse generation.\n\nSUGGESTIONS FOR IMPROVEMENT:\n\n- Add analysis of entropy/diversity metrics for synthetic data\n- Provide theoretical justification for why synthetic data helps beyond just \"more data\"\n- Compare computational costs vs. benefits more explicitly\n- Explore what makes certain synthetic samples more useful than others\n- Consider alternative methods for introducing genuine novelty into synthetic data\n\nNITPICKS:\n\n- The abbreviation \"SQBC\" is used before it's properly defined\n- Figure 4 is information-dense to the point of being hard to parse\n- Some ablation studies feel perfunctory rather than insightful\n\nCONCLUSION:\n\nThis paper is fine. It's not going to revolutionize either synthetic data generation or stance detection, but it makes a modest contribution to both. The experimental work is solid if unexciting, and the results are positive if not earth-shattering. The biggest missed opportunity is not diving deeper into what makes synthetic data actually useful beyond simple interpolation.\n\nThe paper should be marginally accepted because it advances the field incrementally and might give others ideas for more innovative approaches. But let's not pretend this is more than a small step forward in a very crowded research space. I don't like these kind of papers\n\nI'd love to see a follow-up that really digs into the entropy question and provides proper theoretical foundations for synthetic data generation in political stance detection. Until then, this feels like another \"it works (a bit) but we're not quite sure why\" paper."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Clean experimental methodology with proper ablation studies\nGood visualization of how synthetic data aligns with real data distributions\nActually bothered to translate German political content properly instead of using Google Translate\nReasonable baseline comparisons and honest reporting of limitations\nThe SQBC approach is somewhat novel, even if not revolutionary"
            },
            "weaknesses": {
                "value": "Limited theoretical justification for why synthetic data helps beyond \"moar data good\"\nDoesn't address the entropy/diversity problem in synthetic data generation\nResults are modest (~2-3% improvements) for considerable computational overhead\nHeavy reliance on a specific dataset (X-Stance) limits generalizability claims\nThe \"active learning with synthetic data\" angle feels like two papers duct-taped together"
            },
            "questions": {
                "value": "Were there any computational/economic reasons for not scaling up your compute? I'm sympathetic to this as I understand the burden of even a single A100 - but if you do have more resources, why not use them?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}