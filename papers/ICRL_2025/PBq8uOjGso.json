{
    "id": "PBq8uOjGso",
    "title": "Unleashing the Potential of Unlabeled Data: Bidirectional Collaborative Semi-Supervised Active Learning for 3D Object Detection",
    "abstract": "To address the annotation burden in LiDAR-based 3D object detection, active learning (AL) methods offer a promising solution. However, traditional active learning approaches solely rely on labeled data to train an initial model for data selection, overlooking the potential of leveraging unlabeled data. Recently, attempts to integrate semi-supervised learning (SSL) into AL with the goal of leveraging unlabeled data have faced challenges in effectively resolving the conflict between the two paradigms, resulting in less satisfactory performance.\nTo tackle this conflict, we propose a Bidirectional Collaborative Semi-Supervised Active Learning framework, dubbed as BC-SSAL. Specifically, from the perspective of SSL, we propose a Collaborative PseudoScene Pre-training (CPSP) method that effectively learns from unlabeled data without introducing adverse effects. From the perspective of AL, we design a Collaborative Active Learning (CAL) method tailored for outdoor LiDAR scenes, which complements the uncertainty and diversity methods by model cascading, alleviating the dilemma of sampling rare classes. Extensive experiments conducted on KITTI and Waymo demonstrate the effectiveness of our BC-SSAL. Especially, on the KITTI dataset, utilizing only 2\\% labeled data, BC-SSAL can achieve comparable performance to the model trained on the full set.",
    "keywords": [
        "Autonomous Driving",
        "3D Object Detection",
        "Active Learning",
        "Semi-Supervised Learning"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=PBq8uOjGso",
    "pdf_link": "https://openreview.net/pdf?id=PBq8uOjGso",
    "comments": [
        {
            "summary": {
                "value": "This paper aims to reduce the annotation burden in LiDAR-based 3D object detection, the authors propose a Bidirectional Collaborative Semi-Supervised Active Learning framework (BC-SSAL). This framework combines Collaborative PseudoScene Pre-training (CPSP) to effectively utilize unlabeled data and Collaborative Active Learning (CAL) to enhance sampling, particularly for rare classes, in outdoor LiDAR scenes."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The task setting is practical, combining active learning (AL) and semi-supervised learning (SSL) to enhance 3D detection performance while minimizing annotation requirements.\n- Good exploration and analysis are conducted on various strategies for integrating SSL with existing AL frameworks."
            },
            "weaknesses": {
                "value": "- The proposed Collaborative PseudoScene Pre-training (CPSP) module shares similarities with the approach in [A], in which high-quality, high-certainty bounding boxes are stored in a memory bank, and point clouds from these boxes are integrated into scenes. Could you clarify and compare the conceptual and empirical differences between CPSP and [A]?\n\n- The Active Learning (AL) sampling strategy lacks novelty, as entropy is a widely used general AL method. Moreover, the box diversity metric shows minimal improvement, as demonstrated in Table 4.\n\n- Some typos: In lines 177 and 179, there should be a space before \"(TMU)\" and \"(USS).\" \n\n\n[A] Chen, Z., Luo, Y., Wang, Z., Baktashmotlagh, M., & Huang, Z. (2023). Revisiting domain-adaptive 3D object detection by reliable, diverse and class-balanced pseudo-labeling. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 3714-3726)."
            },
            "questions": {
                "value": "The impact of varying thresholds for confident object extraction has not been studied. Given that the model was initially pretrained on a limited dataset, its predictions may contain noise, suggesting that thresholds should be carefully tuned and selected. Could you explain the process for determining the optimal thresholds and demonstrate the impact of different threshold values?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a Bidirectional Collaborative Semi-Supervised Active Learning (BC-SSAL) framework for 3D object detection in LiDAR data, aiming to reduce the annotation burden. BC-SSAL integrates semi-supervised learning (SSL) with active learning (AL) to leverage unlabeled data effectively. Experiments on KITTI and Waymo datasets show BC-SSAL achieves state-of-the-art performance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This method combines active learning with semi-supervised learning, proposing a new scheme for efficient label learning. The idea is interesting. The proposed method achieves the best performance compared to multiple baseline methods on two datasets."
            },
            "weaknesses": {
                "value": "1. The Pre-train method proposed in this paper has limited novelty. The main content highly overlaps with SS3D[1]. Specifically, SS3D combines a pre-trained detector to mine potential instances in unlabeled scenes to generate an 'Instance Bank' and 'Broken Scene', and then uses gt-sampling to produce training data.\n2. The effectiveness of the active learning module is missing validation. One of the main contributions of this paper is active learning, so it is necessary to supplement a separate performance comparison with the state-of-the-art (SOTA) active learning methods [2][3].\n3. The method is called \"Bidirectional Collaborative Semi-Supervised Active Learning,\" but no clear design addresses this specific collaboration. It is recommended that the authors clarify the specific conflicts between the two strategies, provide experimental data to demonstrate the consequences of such conflicts, and explain how these conflicts are resolved.\n4. The semi-supervised scheme only employs HSSDA, lacking validation across different semi-supervised approaches. It is suggested that the authors validate the proposed bidirectional collaboration scheme across multiple representative semi-supervised methods. \n\n[1] SS3D: Sparsely-Supervised 3D Object Detection from Point Cloud. CVPR 2022\n[2] KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection. ICCV 2023\n[3] Exploringactive 3d object detection from a generalization perspective."
            },
            "questions": {
                "value": "What are the differences between the design of the CPSP module and the related model design in SS3D? Please also respond to the comments in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces BC-SSAL (Bidirectional Collaborative Semi-Supervised Active Learning) to enhance 3D object detection in LiDAR-based systems. The framework addresses the challenge of annotation burden by effectively leveraging unlabeled data through a combination of semi-supervised learning (SSL) and active learning (AL). Overall, this paper is technically detailed and the experiments are quite comprehensive. However, most of the designs in the paper are combinations of existing work, lacking novel designs, and the improvements in the experiments are not significant."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-structured, with a clear abstract, introduction, methodology, experiments, and conclusion sections that logically flow from one to the next.\n2. The paper provides extensive experimental results on the KITTI and WOD datasets and conducts a large number of ablation studies.\n3. The paper provides a multitude of figures that clearly demonstrate the design details of each module, facilitating the reader's understanding or reproduction of the methods described in the paper."
            },
            "weaknesses": {
                "value": "1. It is not clear why the method is named \u2018Bidirectional xx\u2019, I cannot see any module design that is \u2018bidirectional\u2019.\n2. I cannot see any special contributions from this paper. Most of the components are simple combinations of existing works. Such as the so-called CPSP is indeed a GT sampling data augmentation used in most of regular 3D object detectors.\n3. The improvement of this method does not seem to be very significant. On the KITTI dataset, the most convincing category is the car, as there are enough objects in this category to make the conclusions more reliable. However, this method is not even as good as 3DIoUMatch."
            },
            "questions": {
                "value": "1. Why is the paper titled 'Bidirectional xx'? Where is the bidirectional operation reflected?\n2. What are the core differences between CPSP and GT sampling?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes an active learning and semi-supervised learning collaborative label-efficient 3D object detection method. By mining useful information from unlabeled data to enhance the performance of 3D detectors. The proposed method is experimentally validated on two widely used datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper presents an ideal for 3D object detection that collaborates semi-supervised learning and active learning bidirectionally, which is novel and interesting.\n2. The design of the active learning scheme is reasonable, and the experiments have successfully validated the performance improvement brought by this module to the entire method."
            },
            "weaknesses": {
                "value": "1. The proposed method has limited innovation; the CPSP module is highly similar to the 'Reliable Background Mining Module' presented in the existing SS3D[1]. The Reliable Background Mining Module employs a pre-trained detector to process unlabeled scenes, extracting foreground instances to construct a bank, and then uses gt-sampling data augmentation to generate new training data. The CPSP module follows the same procedure without any difference.\n\n2. The motivation behind this paper is unclear, as there is no data proving the conflict between SSL and AL. It is suggested to provide experimental results of a naive combination of SSL  and AL  for 3D object detection, demonstrating that directly combining the two methods is unreliable. Additionally, the method does not offer a special design based on the proposed concept of 'bidirectional collaboration'.\n\n3. The figures in the paper are sketchy and not aesthetically pleasing. \n\n[1] Liu. et.al. SS3D: Sparsely-Supervised 3D Object Detection from Point Cloud. CVPR2022"
            },
            "questions": {
                "value": "see Weaknesses*."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}