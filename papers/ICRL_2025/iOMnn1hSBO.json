{
    "id": "iOMnn1hSBO",
    "title": "DECISION-FOCUSED UNCERTAINTY QUANTIFICATION",
    "abstract": "There is increasing interest in ``decision-focused\" machine learning methods which train models to account for how their predictions are used in downstream optimization problems. Doing so can often improve performance on subsequent decision problems. However, current methods for uncertainty quantification do not incorporate any information at all about downstream decisions. We develop a framework based on conformal prediction to produce prediction sets that account for a downstream decision loss function, making them more appropriate to inform high-stakes decision-making. Our approach harnesses the strengths of conformal methods\u2014modularity, model-agnosticism, and statistical coverage guarantees\u2014while incorporating downstream decisions and user-specified utility functions. We prove that our methods retain standard coverage guarantees.  Empirical evaluation across a range of datasets and utility metrics demonstrates that our methods achieve significantly lower decision loss compared to standard conformal methods. Additionally, we present a real-world use case in healthcare diagnosis, where our method effectively incorporates the hierarchical structure of dermatological diseases. It successfully generates sets with coherent diagnostic meaning, aiding the triage process during dermatology diagnosis and illustrating how our method can ground high-stakes decision-making on external domain knowledge.",
    "keywords": [
        "Decision-focused learning",
        "decision making",
        "uncertainty quantification",
        "healthcare"
    ],
    "primary_area": "alignment, fairness, safety, privacy, and societal considerations",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=iOMnn1hSBO",
    "pdf_link": "https://openreview.net/pdf?id=iOMnn1hSBO",
    "comments": [
        {
            "summary": {
                "value": "This paper presents a novel framework for decision-focused uncertainty quantification, integrating conformal prediction with downstream decision-making considerations. By introducing decision loss into the prediction process, the authors create a conformal method that offers both standard statistical coverage and improved utility for specific applications, such as healthcare diagnostics."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The setting of this paper is interesting that taking the decision loss in conformal prediction pipeline.\n2. This paper effectively bridges conformal prediction and downstream decision making by incorporating user-specified utility functions, providing both theoretical guarantees and practical applicability. The authors comprehensively address both separable and non-separable decision losses."
            },
            "weaknesses": {
                "value": "1. The motivation for the study and its illustrative example could be more clearly developed. The authors present the example of the Fitzpatrick dataset to explain their approach, but the rationale for selecting a loss function that reflects the hierarchical homogeneity of dermatologic pathologies remains somewhat unclear. It would benefit the reader if the authors further explained why this hierarchical approach yields a more interpretable clinical result. In addition, I suggest moving this example to the introduction or background section to establish the relevance of the study more clearly.\n\n2. The method relies on applications that require a decision loss function; however, the necessity and specific contexts for using a decision loss function should be more thoroughly explained. The authors claim that their method \"outperforms existing approaches\" in terms of decision loss; however, since the loss function is central to their conformal prediction adaptation, one would expect it to outperform basic conformal approaches that don't consider decision loss. An explanation of why certain applications requires such a loss function would clarify the broader applicability. For example, in Section 3.1, the authors present a medical example where penalties are associated with the cost and complexity of each test. However, the experimental datasets largely use homogeneity-focused loss functions, so it is unclear why this type of loss should apply to datasets such as CIFAR100. The authors might consider providing additional examples of potential applications and elaborating on appropriate loss functions for each."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a new framework that merges conformal prediction with decision-focused learning to create prediction sets that optimize decision-making while maintaining statistical coverage at various levels. The method addresses a gap in current techniques, which often ignore how predictions affect real-world decisions, especially in high-stakes areas like healthcare. The authors propose two algorithms: a penalty-based approach for separable losses and an optimization method for non-separable losses without hyperparameters. They provide theoretical and empirical evidence, including a healthcare case study, to show the effectiveness of their approach."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Originality: Novel integration of decision-focused loss into conformal prediction, addressing a key gap in uncertainty quantification for high-stakes applications.\n- Quality: Robust theoretical grounding and empirical results, demonstrating significant decision-loss reduction across multiple datasets.\n- Clarity: The paper is well-structured, with a logical flow from motivation to problem formulation, methodology, and results. Also explains previous related concepts well\n- Significance: Highly relevant for domains like healthcare, enhancing prediction sets to support actionable, utility-aligned decisions."
            },
            "weaknesses": {
                "value": "- Lacks comparisons with alternative uncertainty methods like Bayesian inference, limiting context on the framework\u2019s unique advantages.\n- Tuning for separable loss is computationally intensive; more efficient tuning methods would improve usability.\n- Focuses heavily on healthcare; additional applications in other high-stakes areas would demonstrate broader applicability.\n- Lacks comparisons with alternative uncertainty methods like Bayesian inference, limiting context on the framework\u2019s unique advantages."
            },
            "questions": {
                "value": "- For the penalty-based approach in separable losses, can you elaborate on the efficiency of grid-search tuning for large datasets? Are there faster alternatives?\n- Could you clarify how the fixed order of adding elements to prediction sets affects performance for complex utility structures? Would alternative scoring or ordering strategies improve flexibility for non-separable losses?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles a problem in AI decision-making and how to make AI predictions more useful for real-world decisions while maintaining reliability. Instead of just giving a set of possible predictions (like in conformal prediction methods), this work creates prediction sets that make practical sense for decision-makers. The paper suggests a solution that balances probability and cost using tunable parameters and another elegant solution that doesn't need to find this tunable parameter and automatically finds the best balance of likelihood and cost associated with the class."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- This is a strong and mathematically sound work that extends traditional conformal prediction work by generating sets of utility functions that capture the associated likelihoods and costs, which is crucial for decision-making."
            },
            "weaknesses": {
                "value": "- The results section is limited regarding insights provided and evaluated only on 4 common datasets. It would also be a nice insight to see the prediction sets for the experiments as a qualitative analysis. \n- It will be interesting to see how this approach works for more challenging datasets with complex hierarchical structures. \n- Limited ablation studies\n-There is no discussion on the loss functions choices and design beyond maximum distance and coverage"
            },
            "questions": {
                "value": "- The greedy approach overall seems to be doing worse than the approach that uses a learnable $\\lambda$ parameter. Could the authors please clarify the advantages of the greedy approach? \n- Can you provide theoretical bounds for the performance between greedy optimizer vs optimal solution for non-seperable losses ? \n- Is there a relationship between base model calibration and decision loss? \n- Did you consult medical experts about the clinical relevance of your prediction sets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper aims to generate prediction sets that maximize a utility function while having coverage guarantees. It extends standard approaches in conformal predictions with novel conformity scores that integrate the utility of the prediction set. Several utility functions are considered, and the approaches differ depending on whether they are separable or inseparable. The marginal coverage guarantees of conformal prediction can be preserved in both cases. Experiments on three classification datasets and diverse utility functions show that the methods achieve higher utility than the conformal prediction approach that uses the standard non-conformity score.\n\nMy evaluation of the paper is mixed. On the one hand, I find the notion of utility of prediction sets very interesting and novel (to my knowledge). On the other hand, I find the paper confusing in some parts, especially in its framing as a \"decision-focused\" approach, which refers to a stream of literature that provides structured predictions by integrating a constrained optimization problem."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The main novelty of the paper is providing prediction sets that maximize a user-specified utility function. If the utility function is the size of the set, we recover the traditional conformal prediction setting. However, the approach is more general. It can consider for instance the hierarchy / categories of the labels in the prediction set. The example in Figure 1 works quite well to illustrate the value of the obtained sets, which are more informative for users.\n\nFrom a methodological perspective, the algorithms and non-conformity score are quite simple (which is an advantage) and are shown to preserve the coverage guarantees of conformal predictions. The experiments also suggest that they provide good performance."
            },
            "weaknesses": {
                "value": "I have two main concerns.\n\nFirst, I find the framing of the paper as a decision-focused approach misleading and confusing. This is for two reasons. It hides the novelty of the paper, which is its focus on prediction sets with utility. It also makes it seems that the paper is focusing on decision-making in the same vein as the cited works of  Mandi et al., 2020; Elmachtoub & Grigas, 2022; Wang et al., 2021, etc. However, this is not the case because (a) the loss function is completely independent of the true label (hence, there is no notion of accuracy / task loss / decision loss / regret of the prediction set) and (b) the prediction sets are unconstrained since the coverage guarantee is achieved by the conformalization procedure. Decision-focused learning typically deals with the challenges of having to output a decision that is both heavily constrained (linear or combinatorial constraints) and provides good task loss thanks to end-to-end training.\n\nAn interesting direction to make the problem task-focused / end-to-end would be to consider Equation (1) as the task and train the ML classifier in an end-to-end fashion to minimize this task loss.\n\nI argue that the paper's main focus is conformal predictions with utility and does not have much to do with decision-focused learning. My second main concern is that the current analysis of the prediction sets is a bit light. The experiments do not show how large the prediction sets are (which is a common utility metric in conformal prediction) nor their achieved marginal and conditional coverage. There is likely to be a trade-off between these metrics (size vs. achieved coverage vs. user-specified utility) for having truly informative prediction sets. I would also expect to see benchmarks from the existing literature on conformal predictions, such as the adaptive approaches cited in the paper.\n\nI also have a few minor comments:\n- line 53 \"*the work to date on decision-focused learning has largely neglected uncertainty quantification, concentrating instead on constructing models to optimize point predictions for specific decision tasks*\". This is incorrect. Point forecasts are the focus when the task loss is linear in the predicted parameters. It is not always the case, see among others:\\\nQi et al. (2021). Integrated conditional estimation-optimization.\\\nChenreddy et al. (2022). Data-driven conditional robust optimization.\\\nKallu & Mao (2023). Stochastic optimization forests.\\\nSadana et al. (2024). A survey of contextual optimization methods for decision-making under uncertainty.\\\nas well as the following papers, who all use conformal predictions:\\\nChenreddy et al. (2024). End-to-end conditional robust optimization.\\\nPatel et al. (2024). Conformal contextual robust optimization.\\\nYeh et al. (2024). End-to-End Conformal Calibration for Optimization Under Uncertainty.\n- line 171. The first property states a conditional coverage guarantee (\u201c*for an instance*\u201d), whereas the objective is marginal coverage (what conformal predictions guarantee and what I believe is shown in Figure 2). It could help to formally introduce the problem using Equation (1), which includes a marginal coverage guarantee.\n- The short proofs of Proposition 3 and 4 should be moved to the paper body to clearly show that the coverage guarantee is achieved by the split procedure."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces new methods for uncertainty quantification in classification problems, focusing on conformal prediction techniques that optimize decision loss. Three methods are proposed to address different types of decision losses (separable and inseparable) and are with or without hyperparameters. These approaches retain the coverage guarantee of traditional conformal prediction while achieving significantly lower decision loss, as demonstrated through empirical evaluation on five datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper's goal is clear.\n- The simplicity of this method, along with the effort to propose a method without introducing a new hyperparameter, will favor its adoption in practical applications.\n- Empirical results show notable improvement over the standard conformal prediction method.\n- The methods are theoretically well-supported."
            },
            "weaknesses": {
                "value": "- The discussion of related work is insufficient, focusing exclusively on conformal prediction literature while neglecting other uncertainty quantification methods (quantile regression, Bayesian methods, ensemble methods...). As the goal of the paper is to \"Incorporate the decision loss into uncertainty quantification\", this omission makes it difficult to assess the significance of the paper beyond conformal prediction.\n\n- Building on the previous point, the paper lacks comparisons with existing methods, even though relevant approaches in conformal prediction appear to address the authors' objectives [1]. Other methods outside of conformal prediction also exist [2], and while they may not offer the same theoretical guarantees, comparing their empirical performance would help assess the impact of the proposed methods. Additionally, traditional conformal prediction could be directly applied to classifiers that focus on minimizing decision loss [3].\n\n- Some sections, such as Figure 2, require improved clarity for better readability.\n\n- The experimental details required to reproduce the results are missing. Specifically, classifiers trained on these datasets can be sensitive to variations in training hyperparameters.\n\n[1] (2022) Conformal Risk Control\n\n[2] (2024) Relaxed Quantile Regression: Prediction Intervals for Asymmetric Noise\n\n[3] (2022) Decision-Focused Learning without Differentiable Optimization: Learning Locally Optimized Decision Losses"
            },
            "questions": {
                "value": "- The authors modify the conformal score by incorporating an additional term to account for decision loss. Wouldn't this make the conformal score less informative and potentially increase the size of the conformal sets? In general, doesn't attempting to minimize decision loss tend to result in larger sets which carry less predictive value? Furthermore, for certain losses, is it possible that adding an extra element to the conformal set could directly reduce the decision loss? To address these concerns, I recommend that the authors report the average size of the conformal sets in their experiments.\n\n- The authors focus on split conformal prediction, but there are other conformal prediction methods available [1,2]. Can the proposed modifications be applied to these other methods, or are they specific to split conformal prediction?\n\n- Following the previous point, the lack of adaptiveness in split conformal prediction is a known issue [1]. How does the proposed method affect conditional coverage? Is the decision loss minimized uniformly across all subgroups, or are there significant discrepancies? Since the authors emphasize medical applications, it seems essential to assess the method's performance on specific subgroups in such contexts.\n\n[1] (2019) Conformalized Quantile Regression\n\n[2] (2022) A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}