{
    "id": "gStRS8L28g",
    "title": "Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation",
    "abstract": "Distribution shifts between training and testing datasets significantly impair the model performance on graph learning. A commonly-taken causal view in graph invariant learning suggests that stable features of graphs are causally associated with labels, whereas unstable environmental features lead to distribution shifts. In particular, covariate shifts caused by unseen environmental features in test graphs underscore the critical need for out-of-distribution (OOD) generalization. Existing graph augmentation methods designed to address the covariate shift often disentangle the stable and environmental features in the input space, and  selectively perturb or mixup the environmental features. However, such perturbation-based methods heavily rely on an accurate separation of stable and environmental features, and their exploration ability is confined to existing environmental features in the training distribution. To overcome these limitations, we introduce a novel approach using score-based graph generation strategies that synthesize unseen environmental features while preserving the validity and stable features of overall graph patterns. Our comprehensive empirical evaluations demonstrate the enhanced effectiveness of our method in improving graph OOD generalization.",
    "keywords": [
        "Graph Neural Network",
        "Graph Data Augmentation",
        "Distribution Shift"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "We propose an innovative score-based graph generation strategy to address covariate distribution shifts.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=gStRS8L28g",
    "pdf_link": "https://openreview.net/pdf?id=gStRS8L28g",
    "comments": [
        {
            "summary": {
                "value": "The paper proposes OODA, a score-based OOD augmentation framework for graph neural networks aimed at enhancing generalization under covariate shift conditions. It leverages a score-based generative model using diffusion processes to synthesize new graph environments, retaining stable predictive patterns while introducing controlled shifts. It generates OOD graphs that maintain graph validity and stable patterns without requiring explicit environmental separation. The authors conduct experiments across synthetic and real-world datasets, demonstrating OODA's advantages over traditional augmentation and invariant learning methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The research topic graph OOD is important. The idea of using OOD graphs with diffusion for simulating the environment is interesting.\n2. The experiments with synthetic and real-world datasets show effectiveness, which is good.\n3. The method is easy-to-understand overall."
            },
            "weaknesses": {
                "value": "1. One of the main concern is the motivation of the method, which I think is not well explained. I do not understand why the diffusion processes can synthesize OOD samples without enough and well-defined prior knowledge of the out-of-distribution.\n2. The methodology to adjust shifts via hyperparameters, such as \u03bb. However, it lacks a thorough discussion on selecting these parameters across different datasets, impacting reproducibility and usability.\n3. The discussions on graph OOD are very limited, especially the Invariant Graph Learning part. The authors might consider referring to the survey [1] or the other surveys for introducing more related works and comparing the differences.\n\n[1] Li, et al. Out-Of-Distribution Generalization on Graphs: A Survey. https://arxiv.org/pdf/2202.07987\n\nI am happy to increase my score if the concerns can be fully addressed."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work studies the data augmentation method for graph OOD generalization under covariate shifts. The authors argue that previous approaches in graph augmentation may generate inaccurate samples, as which heavily rely on an accurate separation of stable and environmental features. Therefore, they propose a new approach that adopts score-based graph generation strategies to synthesize unseen environmental features while preserving the validity and stable features of the overall graph patterns. They conduct extensive experiments on GOOD benchmark to verify the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(+) This work identifies a critical problem in generating valid graph examples for graph OOD generalization.\n\n(+) The idea of adopting a score-based strategy is new and interesting.\n\n(+) The experiments show the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "(-) It remains unclear to what extent the proposed score-based strategy could preserve the stable features.\n\n(-) The technical novelty is limited.\n\n(-) The ablation studies are limited."
            },
            "questions": {
                "value": "1. It remains unclear to what extent the proposed score-based strategy could preserve the stable features. It seems that the preservation of the stable graph features relies on the classifier $\\phi_t$. \n- However, it is unclear how the classifier is trained;\n- If there exists a classifier that can already reliably approximate $p_t(y_G|G_t)$, then, it seems the classifier itself can already be used for tackling covariate shifts;\n- In addition, it has been mentioned several times about the variable $y_ood$, but it has not been formally defined. Meanwhile, it is unclear why $y_ood$ could specify the amount of OOD exploration;\n\n2. The technical novelty is limited, as it is a simple modification of the diffusion models on graphs, and no additional theoretical results are provided;\n\n3. The ablation studies are limited:\n- It is unclear how the hyperparameters are selected and whether OODA is sensitive to the choice of hyperparameters;\n- It'd be great to give more examples of generated realistic graphs;\n\n4. Can we use the generated graphs to improve the performance of other graph OOD methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This study proposes a novel framework called Out-of-Distribution Diffusion Augmentation (OODA), which employs score-based graph generation to address covariate distribution shifts in graph data. The core idea is to expand the training distribution by generating new graph samples that capture previously unseen environmental features while preserving stable, predictive patterns, thus enhancing the model\u2019s OOD generalization capabilities."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-organized, clearly motivating the need for improved graph OOD generalization by highlighting the limitations of existing perturbation-based augmentations. \n\n2. Extending the score-based diffusion model to graph OOD generalization is novel, which aims to enable controlled augmentation that balances diversity with stability. \n\n3. Extensive experiments demonstrate the effectiveness of the proposed OODA framework. The experiments highlight the practical relevance of the method for real-world applications involving covariate shifts in graph data."
            },
            "weaknesses": {
                "value": "1. A primary concern is the diversity of the generated graphs, which remains somewhat unclear. While the authors report that the MMD distance increases as $\\lambda$ grows (Sec. 5.3), this metric alone does not sufficiently convey how diverse the generated subgraphs are for handling graph covariate shifts. The authors should conduct experiments to demonstrate the quality of the generated samples quantitatively (using some metric to quantify the degree of diversity), and better to provide a theoretical analysis as this is the key component of this work.\n\n2. The framework\u2019s effectiveness in addressing size shifts is unclear, as the generated subgraphs are constrained to match the original subgraphs in the total node count if I understand correctly. Despite this, the model performs well on the GOOD-HIV-size benchmark, can the authors explain how and why the method can generalize well for size shift on GOOD-HIV-size dataset but not so well on GOODMotif-size dataset? Second, OODA perform similarly to the SOTA method such AIA on synthetic datasets, e.g., GOOD-Motif. This may indicate that the samples generated by this method have limitations in terms of accuracy and diversity.\n\n3. Experimental comparisons may not be fair, as prior methods use GNN as backbones, whereas OODA relies on multiple graph transformers for estimating score functions and for predicting class labels. Furthermore, training multiple graph trasnsformers also introduce additional time and space complexity. Can the authors discuss the time and space complexity, and report the time and memory consumption, and compare with other methods?\n\n4. The choice to use a pretrained graph transformer for analyzing stable pattern preservation (line 435) lacks clarity, why not use the finally obtained invariant GNN for evaluation, but use the graph trasnformer,which is utilized for data augmentation.\n\n5. $\\lambda$ would affect the generated graphs\u2019 smoothness and the degree of diversity, yet the paper lacks a sensitivity analysis for this parameter. How different values of $\\lambda$ affect the graph diversity and model performance?\n\n6. OODA modify the differential equation to incorporate labels in Eqn. 5, however, it lacks a theoretical guarantee for the generated samples to preserve stable patterns and promote the diversity. It is better to provide some theoretical insights on this aspect."
            },
            "questions": {
                "value": "1. $\\lambda$ controls the extent of the exploration and the diversity of the generated sample, does it mean higher $\\lambda$ will lead to better OOD generalization performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a innovative OOD Augmentation (OODA) method to address the issue of covariate shifts in graph learning. Specifically, the authors propose a conditional score-based graph generation strategy that synthesizes unseen graphs. Extensive experiments show that OODA outperforms many baselines on synthetic and real-world datasets, including molecular and sentiment analysis tasks, under various covariate shift conditions."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is easy to follow with clear logic flow.\n2. Using diffusion models to generate OOD examples for OOD generalization is interesting.\n3. The experiments conducted are comprehensive with non-trivial improvements."
            },
            "weaknesses": {
                "value": "Although I find the diffusion-based OOD augmentation intriguing, there are several major weaknesses.\n\n1. The understanding of the OOD literature is not deep or accurate enough, which leads to misleading descriptions. For example, [1] is misused in the statement \u201cline 162: separating environmental components could be inherently unfeasible,\u201d while the original paper actually indicates that without explicit environmental information and **extra assumptions**, it is infeasible to achieve OOD generalization.\n2. While previous methods generally introduced clear assumptions and theoretical guarantees, this paper does not include any theoretical analysis. As a result, it is unclear why the proposed method would effectively solve the OOD generalization problem.\n3. The authors claim that covariate shifts are relatively neglected in graph learning, but they missed an important covariate shift-related baseline [2]. I believe including a comparison with this method would make the performance results more convincing. To be clear, I don\u2019t expect this method to outperform those that leverage environment labels. However, it is crucial to compare the performance under your assumptions and those of environment-available baselines. The performance of a good method under OOD assumptions can approach that of environment-available methods. *Essentially, with proper theoretical guarantees for optimization, comparing different OOD methods becomes a competition of assumptions.*\n\n[1] Chen, Yongqiang, Yatao Bian, Kaiwen Zhou, Binghui Xie, Bo Han, and James Cheng. \u201cDoes invariant graph learning via environment augmentation learn invariance?\u201d Advances in Neural Information Processing Systems 36 (2023).\n\n[2] Gui, Shurui, Meng Liu, Xiner Li, Youzhi Luo, and Shuiwang Ji. \u201cJoint learning of label and environment causal independence for graph out-of-distribution generalization.\u201d Advances in Neural Information Processing Systems 36 (2023)."
            },
            "questions": {
                "value": "1. Will this generation process eliminate important components of graphs?\n2. Is the OOD guidance targeting generating samples with low likelihood under the original distribution? Is it the only assumption used? Any other constraints?\n3. What do you mean more uniform relative to the original data distribution? (line 279)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}