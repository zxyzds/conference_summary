{
    "id": "7652tHbbVE",
    "title": "FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation",
    "abstract": "Lightweight, controllable, and physically plausible human motion synthesis is crucial for animation, virtual reality, robotics, and human-computer interaction applications. Existing methods often compromise between computational efficiency, physical realism, or spatial controllability. We propose FlexMotion, a novel framework that leverages a computationally lightweight diffusion model operating in the latent space, eliminating the need for physics simulators and enabling fast and efficient training. FlexMotion employs a multimodal pre-trained Transformer encoder-decoder, integrating joint locations, contact forces, joint actuations and muscle activations to ensure the physical plausibility of the generated motions. FlexMotion also introduces a plug-and-play module, which adds spatial controllability over a range of motion parameters (e.g., joint locations, joint actuations, contact forces, and muscle activations). Our framework achieves realistic motion generation with improved efficiency and control, setting a new benchmark for human motion synthesis. We evaluate FlexMotion on extended datasets and demonstrate its superior performance in terms of realism, physical plausibility, and controllability.",
    "keywords": [
        "3D human motion generation",
        "diffusion models",
        "conditional generation",
        "physics aware"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=7652tHbbVE",
    "pdf_link": "https://openreview.net/pdf?id=7652tHbbVE",
    "comments": [
        {
            "summary": {
                "value": "FlexMotion incorporates a multimodal Transformer encoder-decoder that integrates joint locations, muscle activations, contact forces, and joint actuations. This ensures the generated motion aligns with human biomechanics without needing external physics simulators. \nBy leveraging a diffusion model in latent space, the approach significantly reduces training and inference costs while maintaining performance.\n\nFlexMotion includes a plug-and-play spatial controllability module, allowing precise control over motion parameters, such as joint trajectories and muscle activations. The model outperforms existing methods in physical realism, efficiency, and adaptability across datasets like HumanML3D, KIT-ML, and FLAG3D."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "FlexMotion represents a significant advancement in the field of human motion generation. This innovative framework blends a lightweight diffusion model with a Transformer encoder-decoder, allowing for efficient and realistic motion synthesis. Unlike previous methods that either rely on physics simulators or lack physical constraints, FlexMotion integrates these constraints directly into its latent space. This unique approach enables the generation of highly realistic and physically accurate human motion while maintaining computational efficiency.\n\nThe model's architecture is meticulously designed to achieve optimal performance. It employs a multimodal pre-trained Transformer to capture complex human motion patterns. Additionally, physics-aware constraints are incorporated to ensure that the generated motions adhere to the laws of physics. This combination empowers users with fine-grained control over the synthesized motion, allowing them to specify desired spatial, muscle, and joint actuation parameters.\n\nTo evaluate FlexMotion's capabilities, the authors conducted extensive experiments on various datasets, including HumanML3D, KIT-ML, and FLAG3D. The model consistently outperformed state-of-the-art methods in terms of realism, accuracy, and efficiency. Ablation studies further validated the effectiveness of the different components of the model, highlighting the importance of physical constraints and the modular controllability approach.\n\nThe implications of FlexMotion extend beyond animation and virtual reality. Its potential applications include robotics, human-computer interaction, and other fields that require realistic and controllable human motion. By addressing the limitations of existing methods, FlexMotion opens up new possibilities for creating more immersive and interactive experiences."
            },
            "weaknesses": {
                "value": "FlexMotion is a novel framework that pushes the boundaries of human motion generation. By combining a lightweight diffusion model with a Transformer encoder-decoder, it achieves a balance between computational efficiency and physical accuracy. Unlike previous methods, FlexMotion directly embeds physical constraints into its latent space, resulting in more realistic and controllable motion synthesis.\n\nOne key limitation for FlexMotion is its adaptability to specific tasks or domains. and the model's dependency on pretrained weights. \nFurthermore, the paper could benefit from a more detailed analysis of the trade-offs between realism and physical accuracy. Exploring how adjustments to physical constraints impact the visual appeal of generated motions would provide valuable insights for users. \n\nFinally, addressing the lack of real-time testing and validation is crucial for practical applications. Demonstrating the model's performance in real-time scenarios would highlight its suitability for interactive applications like virtual reality and robotics. Additionally, providing more transparency in data augmentation and preprocessing methods would enhance reproducibility and facilitate further research."
            },
            "questions": {
                "value": "1. Could you elaborate on how the data augmentation process using OpenSim was conducted?   \n\n2. Which muscle activation, joint actuation, and contact force parameters were used, and how were these values calibrated for consistency across the different datasets?\n\n3. Did you observe any cases where the model generated physically implausible or biomechanically inaccurate motions, even with the physics-based loss integration? If so, how frequently did these issues arise, and what measures did you implement to minimize such artifacts?\n4. The paper describes the controllability module as a \u201cplug-and-play\u201d addition. How was the module trained or fine-tuned alongside the diffusion model, and what parameters or conditions proved most challenging for control?\n\n5. How does FlexMotion handle motions with varying complexity (e.g., simple walking vs. complex actions like acrobatics)? Did you find any performance discrepancies or limitations in generating more complex motions?\n\n6. Although the model is described as computationally efficient, were any real-time tests conducted to evaluate FlexMotion\u2019s responsiveness? For example, does FlexMotion achieve real-time performance on consumer-grade GPUs or only on high-end systems?\n\n7. Did you encounter any trade-offs between generating visually realistic (aesthetically pleasing) motions and maintaining physical plausibility? If so, how did you approach balancing these aspects, particularly in scenarios where users might prioritize one over the other?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper's goal is to build a physics-aware human motion model. The physics-aware multimodal autoencoder is a transformer-based autoencoder mapping the concatenation of pose features and physics quantities to a latent representation, and then back to the original features. This autoencoder is trained with an L2 reconstruction loss and a physics constraint with the Euler-Lagrange equation as in Zhang et al. 2024b. A latent diffusion model with a series of transformers is then used to generate motions in the latent space from the autoencoder. The spatial controllability is introduced to this latent diffusion model in the same way as Zhang et al. 2023c., which is similar to ControlNet but with a copy of transformer blocks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "Human motion understanding with physics awareness is an important problem.\n\nThe dataset with the OpenSim simulations can help follow-up research."
            },
            "weaknesses": {
                "value": "Please provide videos for submissions related to motions. Qualitative evaluations are extremely important to support and explain quantitative results.\n\nApplying OpenSim with muscle actuation to a large-scale kinematic motion dataset is not trivial. The authors provide no details on this. The appendix only has information about the OpenSim musculoskeletal model setup.\n\nThe formulation seems to have some flaws with missing details. Eq. 4 is missing the muscle activation term. It is not clear how the consistency between the OpenSim simulations and the Euler-Lagrange loss is guaranteed.\n\nThe technical novelty is questionable. Core components in this paper are straightforward applications of the previous methods, most notably Zhang et al. 2023b and 2023c but with the OpenSim data.\n\nThe authors do not discuss the sim2real problem at all. The actual dynamics in the kinematic motion captures of real people will have a significant gap from the simulations."
            },
            "questions": {
                "value": "See weaknesses. I would especially like to see videos of the results if the authors are allowed to share new results during the discussion phase."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents a flexible system for diffusion-based generation of human movements that allows conditioning information in terms of text and various physical constraints. The system is trained in three stages. A transformer-based autoencoder is trained to represent motion-related quantities,  such as kinematic measures, forces, and muscle activation, in a more compact form. A diffusion model for motion generation is then trained in the latent space of the autoencoder, which is finally augmented with inputs from a controllability module to allow for more explicit physical constraints. \n\nThe most important contribution of the paper is the physics-aware autoencoder and the fact that the diffusion model works in the latent space of the autoencoder. The controllability module is quite similar to models that have been used in many other contexts before."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "While previous approaches have tried to correct generated human movements to improve physical plausibility, often as a postprocessing step, the proposed system relies on the autoencoder\u2019s decoder to produce motion-related quantities that are physically consistent. Two loss functions grounded in the physics of the musculoskeletal system are introduced to facilitate this. The experimental evaluation shows that the autoencoder with associated loss functions considerably improves physical plausibility, even without additional conditioning information.\n\nThe fact that the system is trained in stages makes it more modular, and possibly easier to reproduce and modify. This is illustrated by the fact that only a single consumer-grade GPU was used for training.\n\nThe paper is well-written and very easy to read and understand, which includes the illustrations. The summary of the experimental results could be improved though by focusing more on the most important observations, rather than commenting on many other less relevant details.\n\nFrom the results, it appears that the proposed method is superior to all other tested methods in terms of both physical plausibility and speed. One should however keep in mind that not all other methods allow the same kind of conditioning information. However, even without conditioning information, the performance is competitive."
            },
            "weaknesses": {
                "value": "Unfortunately, the experimental part is not as clear as it could have been. The reader needs more help to interpret the results, preferably with a story that focuses on the most important lessons learned. Possibly to give a complete picture, the two last pages of the paper contain a large number of detailed results that could be better integrated into a limited number of clear conclusions. \n\nIn tables contain several experiments conducted with different conditions, but there ought to be a better explanation of these conditions. For example, does \u201c1 Muscle\u201d mean one muscle activation condition at one point in time or over the whole sequence? Given the results, both of these interpretations could be correct. Or is it for 20% of frames, since for \u201cAll Conditions\u201d only up to 20% of frames are used?\n\nThe last ablation results in the appendix seem fishy indeed. It should be statistically impossible to get the numbers 2.345, 4.567, 5.678, and 6.789. Strangely, the same combination of numbers 0.198 and 0.298 occurs in two different experiments. The authors ought to clarify this and possibly adjust or remove the results of the last ablation. This review was done assuming that what is in the main paper is correct, while the results in the appendix are not yet complete. \n\nMinor issues: $\\theta_{ctrl}$ in (13) should probably be $\\theta_{total}$. FLOGs on line 478, should be FLOPs."
            },
            "questions": {
                "value": "* How should the different conditions in the tables be interpreted?\n* How would the system work if the diffusion model has not worked in the latent space of the autoencoder? Are there any such results in the tables to point at? \n* Why is PhysDiff only tested on HumanML3D? Given that this method seems to be the only other method that permits physical constraints, it would have been good to see results from PhysDiff for the other datasets.\n* When do you get FID 0.298 on HumanML3D, when there is no conditional information, or when the Euler and muscle losses are dropped? Or the same number in both cases?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "There are no ethical issues."
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The framework, FlexMotion, leverages a computationally efficient diffusion model in the latent space, eliminating the need for physics simulators and enabling fast training. It employs a multimodal pre-trained Transformer encoder-decoder that integrates various motion parameters like joint locations, contact forces, joint actuations, and muscle activations to ensure the physical plausibility of the generated motions. FlexMotion also introduces a plug-and-play module for spatial control over motion parameters, enhancing its applicability across different domains."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.The use of a diffusion model in the latent space is a novel approach that significantly reduces computational costs compared to traditional methods that rely on physics engines.\n\n2.The integration of joint locations, contact forces, joint actuations, and muscle activations into a single framework is a comprehensive way to ensure physically plausible motion generation.\n\n3.The plug-and-play module for spatial control over a range of motion parameters adds versatility to the framework, making it suitable for various applications.\n\n4.The paper demonstrates superior performance in terms of realism, physical plausibility, and controllability over existing methods, as shown through evaluations on extended datasets.\n\n5.FlexMotion's lightweight design and efficient training process make it suitable for real-time applications, which is a significant advantage over computationally intensive methods"
            },
            "weaknesses": {
                "value": "1. This paper does not provide any videos to show their qualitative results, which are important to prove their contribution and progress in this research area.\n\n2. In this paper, the property of physics-aware motion is weak. Indeed, we need such properties on flat ground, but the physics-aware property also should work on some uneven terrains and human-human interactions.\n\n3. This paper ignores some baselines, for example, the TL-control in ECCV 2024.\n\n4. The physics-based results are still not as good as the simulation-based method, such as phydiff.\n\n5. Some citation issues, for example the ``Adding conditional control to text-to-image diffusion models'' has two different reference."
            },
            "questions": {
                "value": "1. The author should discuss more about how to obatin the physcis related inputs, for example torque.\n\n2. The author should give more examples to show their method significantly superpass other methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a human motion synthesis model that achieves realistic motion generation with high controllability. The model is trained using an augmented dataset, which utilizes OpenSim to enhance the biomechanical and physical fidelity of the original data. The training process involves three stages. In the first stage, an encoder and decoder are trained to map the motion into a latent space. In the second stage, a diffusion model is trained to generate latent variables from noise, allowing the decoder to reconstruct realistic motions. Lastly, a Spatial Controllability Module is trained to convert different user control inputs into motions. The proposed model outperforms various baselines on several evaluation metrics across different datasets."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The method appears solid and reliable.\n- Extensive baseline comparisons and ablation studies demonstrate the results.\n- The paper is well-structured and easy to follow"
            },
            "weaknesses": {
                "value": "- Different versions of the proposed methods need more elaboration. Adding this information to the appendix would help readers better understand the approach.\n- Some animation visualizations that compares original sources motion, augmented motion and generated motion would be helpful."
            },
            "questions": {
                "value": "- Are the source motions changed after data augmentation? I am curious about how the source data changes after augmentation compared to the original data."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}