{
    "id": "GTcEe5fayC",
    "title": "Mutual Effort for Efficiency: A Similarity-based Token Pruning for Vision Transformers in Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) offers a compelling solution to the challenge of extensive labeled data requirements in traditional supervised learning.\nWith the proven success of Vision Transformers (ViTs) in supervised tasks, there is increasing interest in adapting them for SSL frameworks. However, the high computational demands of SSL pose substantial challenges, particularly on resource-limited platforms like edge devices, despite its ability to achieve high accuracy without labeled data.\nRecent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However, SSL\u2019s dual-branch encoders make traditional single-branch pruning strategies less effective, as they fail to account for the critical cross-branch similarity information, leading to reduced accuracy in SSL.\nTo this end, we introduce SimPrune, a novel token pruning strategy designed for ViTs in SSL. SimPrune leverages cross-branch similarity information to efficiently prune tokens, retaining essential semantic information across dual branches. Additionally, we incorporate a difficulty-aware pruning strategy to further enhance SimPrune's effectiveness.\nExperimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically, our approach offers 24\\% savings in training costs compared to SSL baseline, without sacrificing accuracy.",
    "keywords": [
        "Efficient Self-Supervised Learning",
        "Vision Transformer",
        "Token Pruning"
    ],
    "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=GTcEe5fayC",
    "pdf_link": "https://openreview.net/pdf?id=GTcEe5fayC",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes Similarity-Based Pruning Method (SimPrune), a token pruning technique specifically designed for Vision Transformers in self-supervised learning (SSL). Unlike traditional pruning methods that rely on single-branch self-attention mechanisms, SimPrune uses cross-branch similarity to select tokens for pruning, preserving crucial cross-branch semantic consistency in SSL, thereby avoiding loss of important information due to improper pruning.\n\nExperiments show that SimPrune can reduce training costs by approximately 24% while maintaining accuracy."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. SimPrune is compatible and tailored for the dual-branch Siamese architecture used in SSL, where each branch processes different augmented versions of the same image. SimPrune ensures token consistency across branches, preventing unnecessary information loss, which is challenging to achieve with single-branch pruning. This makes it especially suitable for SSL.\n\n2. SimPrune introduces a \u201cdifficulty adjustment during training\u201d pruning strategy. In the early stages, it retains token pairs with high similarity, allowing the model to learn simpler patterns. As training progresses, it prunes increasingly similar tokens, enhancing the learning challenge. This design, inspired by the concept of \u201ccurriculum learning\u201d, helps improve the model\u2019s understanding of complex features."
            },
            "weaknesses": {
                "value": "I believe this paper has some interesting ideas on self-supervised token pruning.\nAs far as I know, the current SoTA is: Multi-criteria Token Fusion with One-step-ahead Attention for Efficient Vision Transformers, CVPR2024.\n\nHowever, the performance is still inferior to the supervised token pruning.\nAnd the proposed method requires many additional computation steps.\n\n1. In Section 3.2, \u201cApplying Existing Token Pruning Approach to SSL,\u201d the authors note that SSL accuracy drops significantly when traditional self-attention pruning methods are applied. The experiments reveal that SSL is highly sensitive to token pruning; even slight over-pruning leads to substantial accuracy loss compared to supervised learning (pp. 5-6).\n\nThis sensitivity arises because SSL relies more heavily on feature consistency than supervised learning, making it vulnerable to inappropriate pruning. To avoid compromising model performance, SimPrune requires precise tuning of hyperparameters like pruning ratios and retention rates.\n\n\n2. In Section 4.2, \u201cDifficulty-Aware Pruning Strategy,\u201d the authors propose a pruning approach that gradually increases in difficulty throughout training. Initially, token pairs with high similarity are retained, but as training progresses, more similar tokens are pruned (p. 6).\n\nSimPrune\u2019s design, which progressively raises training difficulty, challenges the model to handle increasingly complex features in later stages. If the model struggles to adapt to this increased difficulty, it may experience fluctuations or even declines in accuracy.\n\n\n3. In Section 4.1, \u201cLeveraging Cross-Branch Similarity for Token Pruning,\u201d the authors explain that SimPrune involves calculating cross-branch similarities by matching tokens using cosine similarity to establish token pairs across branches (pp. 5-6).\n\nSimPrune\u2019s requirement for cross-branch similarity calculations introduces additional cosine similarity computations. While this overhead is minor relative to the overall computational cost, it can increase total runtime in resource-constrained environments.\n\n\n4. In Section 4, \u201cSimPrune Design,\u201d the authors highlight that SimPrune includes key parameters, such as the \u201ctoken keep rate,\u201d which significantly affect final accuracy (p. 6).\n\nSimPrune\u2019s performance is highly sensitive to parameters like token retention rates and pruning stages, requiring careful adjustment based on the dataset and training setup. This need for customization adds complexity to implementation.\n\n\n5. In Section 3.2, the authors note that traditional pruning methods do not ensure semantic consistency across branches, potentially resulting in a loss of cross-branch semantic information (p. 5).\n\nWhile SimPrune seeks to maintain semantic consistency through cross-branch pruning, low precision in token matching may still cause semantic inconsistencies between branches, which can negatively impact model performance.\n\n\n6. In Section 5.3, \u201cCompatibility of SimPrune with Other Efficient SSL Methods,\u201d the authors observe that SimPrune demands high computational resources in the early stages due to extensive token matching and pruning operations needed to maintain semantic consistency (pp. 8-9).\n\nDuring initial training, SimPrune\u2019s intensive token matching and pruning calculations lead to high resource demands. While these requirements lessen in later stages, the early computational load may pose challenges for resource-limited devices or environments."
            },
            "questions": {
                "value": "Please see weakness comments and I would like to see the author's response if I have interpreted these correctly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper first conduct a preliminary study to analyze the effectiveness of conventional single-branch token pruning on dual-branch self-supervised learning (SSL) for vision transformers. Then, the authors propose SimPrune, which utilizes cross-branch similarity to guide token pruning and introduce a difficulty-aware pruning strategy to further enhance the approach. Experimental results demonstrate the effectiveness of the proposed SimPrune."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper is well-written. The insights, methodology and experimental results are introduced very clearly.\n2. The preliminary study of the effectiveness of conventional single-branch token pruning on dual-branch SSL can provide some valuable insights for researchers in this field.\n3. The proposed approach SimPrune seems to be somewhat novel.\n4. The experimental results demonstrate the effectiveness of SimPrune on image classification tasks."
            },
            "weaknesses": {
                "value": "1. The related work section is incomplete. There are other works, such as BeiT [1], MAE [2], and SimMIM [3], which also claim to be performing SSL for vision transformers. Although these are not dual-branch methods, the relationship between these methods and the proposed SimPrune should be clarified. For instance, it should be discussed whether dual-branch SSL approaches are better than MIM-based ones (e.g., on accuracy, speed or training costs), thereby highlighting the significance of this work's contribution.\n2. The experiment section is incomplete. This paper only evaluates the effectiveness of SimPrune on image classification tasks. However, in classification tasks, local features may not be critical, which is quite different from other dense tasks like object detection and image segmentation. The effectiveness of this token-pruning based approach should be further evaluated on those tasks (e.g., COCO, ADE20K, etc) to demonstrate the significance.\n3. The significance of this work is not very clear. It seems that saving such training costs of performing dual-branch SSL for these small models is not critical in this field, but the effectiveness on large models is not verified yet.\n\nI will pay more attention to the first two concerns since the third one is not actionable in a short time.\n\n[1] Bao, Hangbo, Li Dong, Songhao Piao, and Furu Wei. \"BEiT: BERT Pre-Training of Image Transformers,\u201d In\u00a0ICLR, 2022. \\\n[2] He, Kaiming, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \"Masked autoencoders are scalable vision learners.\" In\u00a0CVPR, 2022. \\\n[3] Xie, Zhenda, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, and Han Hu. \"Simmim: A simple framework for masked image modeling.\" In\u00a0CVPR, 2022."
            },
            "questions": {
                "value": "1. The proposed similarity-based token pair pruning approach seems to be a little complicated due to many-to-one issue. Have you tried some other methods like bipartite matching?\n2. Is \u201c24% savings in training costs\u201d significant enough? It seems that the other pruning based methods mentioned in this paper can save about 30%-40% costs."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper first analyzes the effectiveness of conventional single-branch token pruning frameworks on SSL and reveals these methods fail to efficiently prune tokens for SSL approaches. To alleviate this issue, this paper proposes to guide token pruning based on cross-branch similarity. Besides, a difficulty-aware pruning strategy is introduced to control the difficulty of the training process. Experiments are conducted to verify the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The motivation is clear. The finding that existing token pruning strategies fail to enhance SSL efficiencies is interesting. It is reasonable to prune the pair tokens from two branches based on the cross-branch similarities in the SSL paradigm. \n\n2. The conducted experiments and visualizations are extensive and well-organized.\n\n3. The paper is well-written and easy to understand."
            },
            "weaknesses": {
                "value": "1. Some important references about token pruning are missing: \n[1] Not all images are worth 16x16 words: Dynamic transformers for efficient image recognition, NeurIPS 2021.\n[2] Patch slimming for efficient vision transformers, CVPR 2022. \n[3] Self-slimmed vision transformer, ECCV 2022.\n\n2. The downstream tasks, such as object detection and semantic segmentation, are widely adopted to verify the effectiveness of SSL methods (e.g., MAE and ViTDet). Could you present some finetuning results on downstream tasks?\n\n3. Given that some layers of the ViT only observe a subset of tokens during SSL training due to token pruning, a potential discrepancy arises: downstream tasks typically utilize all tokens. Does this inconsistency decrease the downstream performance of SSL-trained models?\n\n4. What's the sliding window size in your experiments?\n\n5. This paper utilizes a dynamic pruning strategy. The visualizations shown in Figure 4 are static. Could you provide additional visualizations, statistics, or other observations illustrating how the pruning patterns change over time?"
            },
            "questions": {
                "value": "Please see the Weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors introduce SimPrune, a novel token pruning strategy designed for ViTs in SSL. SimPrune leverages cross-branch similarity information to efficiently prune tokens, retaining essential semantic information across dual branches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The method is easy to understand."
            },
            "weaknesses": {
                "value": "1. Why are the results in the article so different from the official results? In the Table1, the authors use DeiT-Small as the encoder and\nuse ImageNet dataset to do the self-supervised training. The performance of DINO is 57.16 without pruning. But according to the [official DINO paper](https://arxiv.org/pdf/2104.14294v2), it achieves 77.0 with a ViT-S backbone. The fact that the results in this paper are so different from those in other articles makes it difficult to compare the methods in this paper to other work, so I'm curious as to what differences in setups lead to such differences.\n2. Many SSL methods outperform the DINO used in this paper, such as DINOv2/MIM-Refiner/Unicom, and there are already many methods that can boost up the vision transformer without training, such as [Expediting ViT](https://openreview.net/pdf?id=9ND8fMUzOAr). So the question is, if the task is boosting up the self-supervised training process, a better framework(DINOv2/MIM-Refiner/Unicom) with a smaller backbone may be a better choice; if the task is getting a faster model, choosing a better framework then apply the prune method without finetuning, or just use a smaller network may be the better solutions. Unless the method of this paper can be shown to be effective and better than methods such as Expediting ViT on the latest self-supervised frameworks, it is difficult for me to think of where the superiority of the method of this paper lies."
            },
            "questions": {
                "value": "1. Why the performance gap exists?\n2. Does the proposed method works on the latest SSL framework and achieves the competitive results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}