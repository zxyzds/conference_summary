{
    "id": "t8hMqAn8ZG",
    "title": "Decentralized Federated Learning Over Noisy Labels: A Majority Voting Method",
    "abstract": "Contrary to centralized federated learning (CFL), decentralized federated learning (DFL) allows clients to cooperate in training their local models without relying on a central parameter server. As different clients have varying annotation skills and preferences, noisy labels are inevitable in decentralized data ownership. In centralized learning (CL) and CFL settings, learning from noisy labels has been extensively explored; however, such methods cannot be directly applied in DFL settings due to limited computational resources or privacy requirements. This paper introduces DFLMV \\textit{(majority voting based decentralized federated learning)}, a general DFL framework for learning from noisy data without relying on any assumptions about local client noise models while maintaining data privacy for all clients. Specifically, (1) Clients first use traditional DFL to train their local models until they become stable. (2) Clients use each of their neighbors' models to make a prediction of every data point in their training datasets, then correct the labels based on majority voting. (3) Clients further fine-tune their models based on their updated training dataset. A theoretical analysis of DFLMV is also provided. Extensive experiments conducted on MNIST, Fashion-MNIST, CIFA-10, CIFAR-10N, CIFAR-100N, Clothing1M, and ANIMAL-10N validate the effectiveness of our proposed approach at various noise levels and different data settings in mitigating the adverse effects of noisy labels.",
    "keywords": [
        "decentralized federated learning",
        "distributed learning",
        "federated learning",
        "majority voting",
        "label-noise learning"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "We propose a majority voting method across different clients to deal with noisy labels in a decentralized federated learning.",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=t8hMqAn8ZG",
    "pdf_link": "https://openreview.net/pdf?id=t8hMqAn8ZG",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a decentralized federated learning algorithms to handle noisy training labels. The federated networks first perform decentralized training. Then each client makes predictions based on the majority voting from the models from its neighbours. The submissions tries to give some theoretical justifications of the proposed approach. Experiments show that the proposed algorithm improves model accuracy across various datasets, under non-IID settings and various noise conditions."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Handling noisy training data and understanding the generalization of robust learning algorithms (with distribution shifts) is an important problem.\n\nThe proposed method is relatively lightweight, communication efficient, and easy to implement.\n\nExperiments consider various noisy ratios and settings."
            },
            "weaknesses": {
                "value": "It is not clear what implications Theorem 1 (the generalization result) have. In addition, it is modeling the gap between the population error under two distributions, not involving empirical error over the noisy dataset, making it not applicable to practical settings where we only have access to a finite set of samples. Consequently, Theorem 2 has similar issues.\n\nClients train on non-IID data, and it is not clear why assuming vote distributions are identical reasonable.\n\nThe proof of Theorem 3 is confusing. theta_1 (and theta_2) are the differences between the two probability distributions, but `difference\u2019 is not defined. How does the submission mean by theta_1 is larger than theta_2?\n\nExperiments use simple and similar datasets (despite including a set of image benchmarks). The non-IID dataset partition among clients is not natural partitions, and doesn\u2019t fully reflect the real-world non-IIDness. \n\n\nExperiments don\u2019t compare with algorithms that target at label noise, for instance, simple baselines such as applying state-of-the-art robust learning algorithms (against noisy labels) locally on each client during decentralized training."
            },
            "questions": {
                "value": "Please see 'weaknesses'."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces DFLMV, a decentralized federated learning (DFL) algorithm for training under noisy labels. DFLMV has in total three stages: (1) initial model training with traditional DFL, (2) label correction using a majority voting mechanism with peer models, and (3) fine-tuning models on the corrected data. This approach tackles the label noise issue without a centralized server and without the need for additional clean datasets. The authors provided theoretical guarantees on generalization error and error rate bounds for the majority voting mechanism. In addition, the authors conducted extensive experiments to demonstrate the accuracy improvements of DFLMV across several benchmark datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The idea of using peer model majority voting in the DFL setting for handling label noise is novel. \n- The paper provided clear explanations of the stages in DFLMV with the detailed theoretical analysis for each component of the algorithm.\n- The evaluation of DFLMV is extensive where the authors considered different data distribution and label noise distribution. The results all demonstrated that the proposed method is effective."
            },
            "weaknesses": {
                "value": "Some details and ablation studies about the dataset partition are missing: how many clients are there for each dataset? For each client, how are the neighbors defined? How does the number of neighbors affect the utility of this approach? How many data points are needed for the initial staging to provide a reasonable model for relabeling?"
            },
            "questions": {
                "value": "- How robust is this approach considering malicious clients who might intentionally send manipulated model parameters to mess up the majority voting process?\n- Have you considered other voting methods, e.g. weighted majority vote based on peer distance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Noisy labels exist in widely used datasets, which can adversely affect model training. Existing methods aiming for learning with noisy labels mostly focus on centralized learning (CL) and centralized parameter server-based FL (CFL) settings, which cannot be efficiently employed in the decentralized federated learning (DFL) setting.\nThis paper then proposes a framework for learning with noisy labels in the DFL setting. The proposed framework is made up of three stages: typical DFL training, label correction which is based on majority voting, and extra fine-tuning.\nThe authors also provide a theoretical upper bound on the generalization error of any DFL algorithm using cross-entropy loss under arbitrary label noise, and an upper bound on the error rate of majority voting.\nExperimental results further show the effectiveness of the proposed framework against noisy labels."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The motivation is clear, and the paper is well-written.\n- The proposed framework is simple yet effective, and it includes a theoretical analysis of performance bounds.\n- Extensive experiments across various IID and non-IID data/noise settings demonstrate the effectiveness of the proposed framework."
            },
            "weaknesses": {
                "value": "- The assumption that the distributions of the votes are identical seems too strong, particularly under non-IID settings which mostly cannot stand.\n- It is still not clear about the extra overhead. Regarding the claim \"DFLMV does not introduce any extra communication overhead\", stage 2 involves communication among clients, which would introduce extra communication overhead. Besides, stages 2 and 3 can be considered as the extra steps as stage 1 can be viewed as a whole typical DFL training (until it reaches a stable point), aside from the dimension of model parameters, then the extra overhead would be related to the number of iterations and local epochs in the later 2 stages."
            },
            "questions": {
                "value": "- Regarding stage 2, can the authors please explain why not consider the aggregated model for label correction? Also, in this way, existing methods could be adopted in DFL as well, and the computational cost may vary.\n- Can the authors please provide specific extra computational costs, at least for one setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the challenge of training machine learning models in decentralized environments with noisy label data. To address this, the paper proposes a majority voting-based algorithm called DFLMV (Decentralized Federated Learning Majority Voting), designed to enhance model quality in the presence of label noise without the need for a central server. DFLMV consists of three key stages:\n\n**Initial Training Stage:** Each client performs traditional decentralized learning on its local dataset (an merging periodically with their neighbors) to train an initial model. After training for several epochs, each client reaches a \u00ab\u00a0stable loss\u00a0\u00bb value, at which point it moves to the label correction phase.\n\n**Label Correction Stage:** Clients share model parameters with their neighbors, who then use these models to predict labels on their data. For each data point, the client assigns a new label based on majority voting among the predictions from its neighbors, thus correcting potentially noisy labels.\n\n**Retraining Stage:** With updated labels, clients further fine-tune their local models on this improved dataset to enhance model accuracy and robustness.\n\nThe paper provides some theoretical analysis simplified results on the performance of DFLMV. It also compares DFLMV to PENS, another noisy label decentralized learning approach, by evaluating both methods across multiple datasets (e.g., MNIST, Fashion-MNIST, and CIFAR-10) under various levels of label noise and data heterogeneity."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper addresses a meaningful topic, and further exploration in this direction holds strong potential to benefit the research community. The core idea is clear and straightforward, which is an advantage. Furthermore, provided the results withstand scrutiny, it offers a practical and effective approach to improving the robustness of machine learning algorithms against label noise."
            },
            "weaknesses": {
                "value": "I found the paper challenging to follow, as aspects such as the organization, technical writing, clarity of results, and integration of related work could significantly benefit from improvements. Strengthening these areas would greatly enhance the paper\u2019s overall clarity and impact. To be more precise I provide a specific list of concerns below.\n\n## Quality of Technical Writing\nIn my view, the level of technical writing in this paper currently falls short of the standards expected for a top-tier conference like ICLR. Here are some specific points that I believe limit its clarity:\n\n**Problem Presentation**: The problem setup presents an optimization problem in Equation (1) before defining the relevant notations. Generally, it would improve readability to first introduce the notations, clearly defining spaces and terms, and then present the optimization problem. \n\n**Unexplained Concepts and Notation**: Several concepts and notations are introduced without sufficient explanation. For example, symbols like $d_x$ and $d_y$ first appear in line 182 without clarification, similarly $f_k$ in line 193, and the term \"non-colluding neighbors\" in line 299. Although these may appear minor, they contribute to a challenging reading experience, especially in the preliminaries.\n\n**Inconsistencies in Notations**: There are several inconsistencies in the notations, which make the paper harder to follow. Here is a non-exhaustive list:\n\n   - The loss function is first introduced as $\\mathcal{L}$ in Equation (1), then $\\mathcal{L}_k$ in Equation (3), and switches back to $\\mathcal{L}$ in Equation (4) before reverting to $\\mathcal{L}_k$ in Equation (8).\n\n   - The output space and corresponding vectors vary between $\\mathbb{R}^{d_y}$ and {$1, \\dots, C$}, leading to errors such as computing the one-hot encoding of a vector from $\\mathbb{R}^{d_y}$ in line 191. This inconsistency also makes Theorem 1 difficult to interpret, as the left-hand side assumes vectors in $\\mathbb{R}^{d_y}$ while the right-hand side assumes $Y$ is discrete.\n\n   - Datasets are defined as sets of lowercase samples in Section 3, then as sets of uppercase random variables in Section 4.\n\n   - Both $B$ and $n_{\\text{peers}}$ appear to serve the same role, but they are used interchangeably throughout the paper.\n\n## Presentation of the algorithms\n\nThe algorithm\u2019s presentation lacks clarity and structure in the main paper. The analysis is intertwined with the algorithm's steps, making it difficult to follow. I would suggest dedicating one section solely to the algorithm's presentation and a separate section for the analysis to improve readability.\n\n## Clarity and soundness of the results\n\nDue to the clarity issues mentioned earlier, the presented results exhibit similar concerns on clarity. While I have reservations about their overall soundness, I believe that at least Theorem 1, as it currently stands, is factually incorrect. It appears that the paper attempts to adapt results from (Ke et al., 2023), but it overlooks key assumptions from the original work, particularly Assumption 5 and Assumption 6. As a result, the conclusions drawn in this paper cannot be valid, and consequently, the proof that follows the steps of (Ke et al., 2023) is also flawed. \n\n## Related work and comparison with existing solutions\n\nThe analysis of related work could be strengthened significantly. For instance, in line 125, the claim that decentralized (federated) learning was introduced by Lalitha et al. (2018) is misleading. The research on decentralized algorithms actually has a rich history (see e.g.,https://arxiv.org/pdf/2006.13838).\n\nAdditionally, I found the reference to (Yagli et al., 2020) regarding the definition of generalization somewhat confusing. After reviewing that reference, it does not appear to directly address the concept of noisy labels, and I was unable to locate a definition comparable to Equation (10). Could you provide a more appropriate reference for your definition of generalization error, or explain how you derive your definition from Yagli et al. (2020) if it is indeed relevant?\n\nI also believe that the paper would benefit from a comparison with solutions that address stronger forms of corruption, such as Byzantine attacks in decentralized learning (see e.g., https://proceedings.mlr.press/v202/farhadkhani23a/farhadkhani23a.pdf). While I understand that your paper does not focus on these stronger attacks, exploring whether existing defenses in the literature could also apply to the seemingly simpler problem of noisy labels would be valuable. It\u2019s possible that these methods may be less effective in terms of accuracy, but gaining insight on this would be beneficial before developing alternative approaches.\n\nFinally, I would like to note that it appears the current paper is heavily inspired by (Ke et al., 2023), including similarities in notation and results. Given this, it seems somewhat unexpected that (Ke et al., 2023) is cited only once and solely in the appendix. A more thorough engagement with this source, discussing more explicitly how the submission builds upon or differs from Ke et al. (2023) (highlighting both similarities and key differences) could enhance the paper's depth and contextualization."
            },
            "questions": {
                "value": "Please comment on the above concerns"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}