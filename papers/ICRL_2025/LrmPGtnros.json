{
    "id": "LrmPGtnros",
    "title": "Three-in-One: Fast and Accurate Transducer for Hybrid-Autoregressive Speech Recognition",
    "abstract": "We present Hybrid-Autoregressive Inference Transducers (HAI-T), a novel architecture for speech recognition that extends the Token-and-Duration Transducer (TDT) model. Trained with randomly masked predictor network outputs, HAI-T supports both autoregressive inference with all network components and non-autoregressive inference without the predictor. Additionally, we propose a novel semi-autoregressive inference paradigm that first generates an initial hypothesis using non-autoregressive inference, followed by refinement steps where each token prediction is regenerated using parallelized autoregression on the initial hypothesis. Experiments on multiple datasets across different languages demonstrate that HAI-T achieves efficiency parity with CTC in non-autoregressive mode and with TDT in autoregressive mode. In terms of accuracy, autoregressive HAI-T outperforms TDT and RNN-T, while non-autoregressive HAI-T significantly outperforms CTC. Semi-autoregressive inference further enhances the model's accuracy with minimal computational overhead, and even outperforms TDT results in some cases. These results highlight HAI-T's flexibility in balancing accuracy and speed, positioning it as a strong candidate for real-world speech recognition applications.",
    "keywords": [
        "speech recognition",
        "sequence modeling",
        "non-autoregressive models",
        "RNN-T",
        "Transducers"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We introduce a novel speech recognition model that supports different levels of autoregression, achieving better speed-accuracy tradeoff than alternative methods.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=LrmPGtnros",
    "pdf_link": "https://openreview.net/pdf?id=LrmPGtnros",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a training method to improve the performance of Token-and-Duration Transducer (TDT, Xu et al., 2023), which enables TDT to perform decoding in several different modes that improve efficiency without sacrificing performance much.\n\nThe main contributions are as follows\n1. Introduce \u201ctranscript masking\u201d as a regularization method for TDT training, which improves the regular auto-regressive decoding performance\n2. Decode with \u201cempty transcript\u201d (ie feed entirely masked transcript to the predictor module) to greatly reduce the runtime for AR decoding. (This is referred to as non-autoregressive (NAR) decoding in the paper, but I do not agree it should be called NAR. See details in later sections)\n3. A hybrid decoding approach to improve the hypothesis proposed by empty transcript decoding. In particular, it uses that hypothesis as input the predictor module, gets predictor embeddings for each text position \u201cin parallel\u201d, and the take the argmax from each position in parallel."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Masking target is an effective approach verified in several other models (TDS for CTC, MaskPredict for NAR translation), which can serve as a method of regularization or a way to build non-autoregressive model. Applying to TDT is a clever idea which serves both purposes.\n2. Empirical results on large scale study are convincing in terms of the effectiveness of improving NAR and the more efficient decoding methods (NAR, SAR) proposed in the paper based on TDT\n3. The paper also presents a good set of ablation studies (stateless / no zero duration / duration range / duration distribution analysis / argmax token analysis) to provide readers more insights on why it works and how the model behaves."
            },
            "weaknesses": {
                "value": "1. Technically it is not correct to call the method non-autoregressive. Despite that the predictor does not take the predicted token as input, it still depends on the duration predicted from the previous step to determine what enc[t] to compute argmax on (line 7 of Xu et al. (2023)). Hence, they cannot be fully parallel and should be still considered autoregressive. I acknowledge that runtime wise it is almost identical to NAR because argmax can be precomputed for all (t, u), but this is still wrong in terms of the nomenclature.\n2. Missing discussion of limitations. For example, the refinement step cannot fix the error if the NAR hypothesis is shorter or longer than the ground truth. \n3. Missing comparison with similar or related methods. For example, how does it compare with generating top-K hypothesis with HAI-T NAR or CTC, and then rescore by an AR model\n4. The argument of HAI-T being superior than RNN-T and TDT is too strong. On individual datasets it loses in quite a few cases (e22, giga, clean, other, spgi, vox). The authors should just claim on-par."
            },
            "questions": {
                "value": "* (Line 254) How important is it to initialize HAI-T with TDT? Are the baseline models\u2019 encoder initialized from a PT model? What\u2019s the performance drop for HAI-T if it is not initialized from TDT?\n* Is the stateless predictor merely an embedding table?\n* Has the authors compared NAR with NAR-Viterbi? How are the duration posterior and token posterior combined (ie is a weight introduce to rebalance token and duration posterior)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces the Hybrid-Autoregressive Inference Transducer (HAI-T), an extension of the Token-and-Duration Transducer (TDT) designed to support autoregressive (AR), non-autoregressive (NAR), and semi-autoregressive (SAR) inference within a single framework. The key innovation is the use of stochastic predictor masking during training, enabling seamless switching between inference modes.\n\nAR inference follows the TDT process, while NAR inference simplifies processing by using a zeroed tensor in place of predictor outputs for single-pass decoding. SAR inference combines the strengths of both approaches, generating an initial hypothesis with NAR and refining it with AR-like processing using shifted representations. The paper also proposes a Viterbi-based decoding method to enhance results. Experimental evaluations across English and German datasets show that HAI-T outperforms CTC in NAR mode and matches or exceeds TDT and RNN-T in AR mode, with further improvements observed using Viterbi decoding."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "**Originality**: The paper introduces a simple but effective technique: masking the predictor output 50% of the time during training, which allows the joiner to handle non-autoregressive (NAR) inference. This enables the model to support multiple inference strategies\u2014AR, NAR, and SAR. The carefully crafted NAR and SAR inference strategies leverage the TDT architecture well and show improved performance across multiple datasets.\n\n**Quality**: The paper provides thorough experimental evaluations across various datasets in both English and German, and includes comparisons with standard models like CTC, TDT, and RNN-T. The consistent improvements in performance across these benchmarks demonstrate the robustness of the proposed approach.\n\n**Clarity**: The authors do a great job explaining how the AR, NAR, and SAR inference modes work, making it easier for readers to follow how HAI-T switches between different inference strategies. The inclusion of a code snippet to show how the masking is implemented during training is a nice touch that makes the paper accessible to researchers at various levels of ASR expertise.\n\n**Significance**: The introduction of NAR inference with TDT, which outperforms CTC, and the development of SAR inference, which balances the speed of NAR with the accuracy of AR, are important contributions for real-world ASR applications where both efficiency and accuracy are needed. HAI-T effectively addresses some of the limitations of existing transducer models and sets a new standard for flexible and adaptable ASR models. This work is likely to encourage more research in hybrid inference strategies within the ASR field."
            },
            "weaknesses": {
                "value": "1. **Incremental Architectural Innovation**: While HAI-T's hybrid approach to inference is creative, it builds on the existing Token-and-Duration Transducer (TDT) model. The primary novelty lies in its training strategy and inference flexibility rather than any fundamental architectural innovations. This could make the contribution seem incremental.\n\n2. **Lack of Detailed Training/Inference Specifications**: The paper omits crucial details about the training setup, such as the type and number of GPUs used, learning rates, schedules, and batch sizes. Additionally, the reported inference times lack confidence intervals and clarity on whether they were computed using a CPU or GPU. These omissions limit reproducibility and make it difficult to gauge the true computational demands of the model.\n\n3. **Dependency on Pretrained Models**: The reliance on pretrained models for initializing the encoder, which are already robust and highly optimized, raises questions about the origin of the reported performance gains. This reliance could make it challenging to separate the contribution of HAI-T's unique elements from the advantages conferred by the pretrained encoder. Furthermore, the use of an English checkpoint for initializing the German model might influence the results, yet the paper does not address this potential impact.\n\n4. **Clarity on Limitations**: The paper would benefit from a clearer discussion of the potential limitations of HAI-T. For instance, it does not explore how the model performs under challenging conditions, such as noisy or highly varied audio inputs, or whether it would require significant adjustments to maintain performance in such scenarios."
            },
            "questions": {
                "value": "1. Why was the Viterbi-based decoding added as an after-thought rather than in the main experiment? By how much does it increase the inference times?\n\n1. Could you provide more details on the training setup? The link to hyperparameters in footnote 3 gives a 404-not found error.\n\n2. How were the inference times computed, and provide the confidence intervals?\n\n3. Did you try training the HAI-T from scratch? Especially since you have access to a large English dataset, training from scratch should be feasible.\n\n4. What are the potential impacts of initializing the German model with an English encoder checkpoint? \n\n5. When applied to data with high variability or noise, how does the model handle such conditions compared to existing approaches? \n\n6. Table 1 and 3 exceeds the margin, please ensure it fits within the margins.\n\n7. The algorithms could use some refinement to avoid ambiguity in mathematical operations and naming conventions. For example `shifted_hyp` instead of `shifted-hyp`"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a simple yet effective method for training a Token-and-Duration Transducer (TDT) model by stochastically masking out the predictor. It also introduces a novel semi-autoregressive (SAR) inference mode, which first uses non-autoregressive (NAR) decoding to generate initial hypotheses and then applies autoregression to iteratively refine these hypotheses in parallel. Evaluation on multiple datasets demonstrates that the proposed method, HAI-T, achieves substantial performance gains compared to vanilla CTC in non-autoregressive mode. Furthermore, the proposed semi-autoregressive mode provides greater flexibility in balancing accuracy and speed."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "* The paper introduces a straightforward approach that requires only a single-line change to the existing joint computation code in the Token-and-Duration (TDT) implementation and performs effectively in practice.\n* Evaluations are conducted on multiple ASR corpora, including the AMI test, Earnings22, Gigaspeech test, Librispeech test-clean and test-other, Spgispeech test, Tedlium test, and VoxPopuli test."
            },
            "weaknesses": {
                "value": "Although the method is simple, the proposed HAI-T appears to be an incremental improvement over TDT."
            },
            "questions": {
                "value": "* In line 259, the authors should clarify what is meant by [1-8].\n* The proposed semi-autoregressive inference mode generates an initial hypothesis through NAR inference and then refines the hypothesis using the predictor. How is the proposed semi-autoregressive mode different from CTC/RNN-T-based joint decoding? Could the authors expand the discussion in the related work section?\n* Please provide results for the HAI-T model without duration settings in Table 2 for a better understanding across different language settings.\n* Include decoding time results using Viterbi decoding in Table 3 for completeness.\n* Add x and y labels in Figure 2.\n* For deeper understanding, the authors could include results on RTF and emission delays for both the proposed and baseline methods.\n* A realistic comparison would include the proposed semi-autoregressive inference mode against CTC/RNN-T results in joint decoding modes.\n* The results appear promising. However, a detailed breakdown of the Word Error Rate (WER) improvements with semi-autoregressive mode would be beneficial. For instance, are there notable changes in substitutions, deletions, or insertions? Which error type shows the most improvement, or are they all enhanced to a similar degree? This information could provide clearer insights into the impact of semi-autoregressive decoding.\n* It is difficult to understand how the HAI-T training procedure dramatically reduces the occurrence of 0-duration predictions, given that it is trained by stochastically masking out the predictor. Could the authors expand on this phenomenon in the discussion?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a model called HAI-T, an extension of the Token-and-Duration Transducer (TDT). TDT itself is an extension of RNN-T, where token prediction and duration prediction are decoupled. The authors propose randomly dropping the predictor network of TDT so that the model can operate in both auto-regressive (AR) and non-autoregressive (NAR) modes. They also investigate a semi-AR mode, where the NAR decoding result is refined through AR decoding."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper presents a novel idea of randomly dropping the predictor network to enable the TDT model to function in both AR and NAR modes. Especially, as far as I am aware, this is the first work to evaluate the NAR version of the TDT model."
            },
            "weaknesses": {
                "value": "- Insufficient Contributions\n  - The idea of randomly dropping the decoder network is quite simple, making this more of an investigation paper rather than a presentation of a highly novel idea. In this context, rigorous experimental validation is crucial, but the evaluation provided is not sufficient to substantiate their claims (see the next section).\n  - The combination of NAR and AR modes -- or more generally, the combination of a faster, less accurate model with a slower, more accurate model -- has been explored extensively. The method proposed in this paper is relatively straightforward and lacks theoretical novelty. I have listed a few papers as examples, but there are many more relevant works. I suggest explicitly discussing these prior works and highlighting specific differences in methodology or performance.\n    - NAR + AR:\n      - H. Inaguma, et al., \u201cNon-autoregressive end-to-end speech translation with parallel autoregressive rescoring,\u201d 2021.\n      - S. Arora, et al., \u201cSemi-Autoregressive Streaming ASR with Label Context,\u201d ICASSP 2024.\n    - Fast + Slow:\n      - J. Mahadeokar, \u201cStreaming parallel transducer beam search with fast-slow cascaded encoders,\u201d Interspeech, 2022.\n\n- Insufficient Evaluation\n  - The authors claim that the proposed method outperforms RNN-T and TDT in AR mode, but their experimental evidence is not convincing. In the first 7 rows of Table 1, the AR mode results for RNN-T, TDT, and HAI-T (the proposed model) average 7.15%, 7.13%, and 7.10%, respectively. The difference from 7.13% to 7.10% is too minor to definitively demonstrate HAI-T's superiority. Moreover, when examining individual test sets like \u201cami\u201d and \u201ce22,\u201d the proposed model often underperforms compared to RNN-T and TDT. It is likely that there is no statistically significant difference between TDT and HAI-T in AR mode, and the observed difference may be due to random fluctuation (e.g., the trend could easily reverse with additional testing data). More extensive experiments with statistical significance tests over multiple evaluation sets are suggested.\n  -  Additionally, while the authors show that the HAI-T model performs better with a \u201cstateless\u201d decoder or when excluding 0-duration configurations in the remaining 8 results of Table 1, the same configurations should have been applied to the baseline models for a fair comparison.\n  - The authors claim that their proposed method outperforms CTC in NAR mode, but this is not convincingly demonstrated. In the NAR setting, the HAI-T model slightly outperforms CTC (7.38% vs. 7.19%) but with a slight increase in computational overhead (41 vs. 39 in time). While the increase in time is minor, the improvement in WER is also small, raising concerns that the improvement may simply be due to increased parameters. \n  - Additionally, the paper does not define the term \u201ctime,\u201d which presents another issue. Please explicitly define how \"time\" is measured (e.g., wall clock time, CPU time, number of operations) and under what conditions (e.g., hardware specifications, batch size) instead of merely mentioning Huggingface ASR leaderboard.\n  - It would be beneficial to include the \u201ctime\u201d metric in Table 3.\n\n- Description Issues\n  - The descriptions of their \u201ccode (page 4)\u201d and \u201calgorithm (page 5)\u201d are inadequately defined.\n    - The code on page 4 seems unnecessary. The algorithm is simple enough that additional explanation is not required.\n    - The algorithm on page 5 relies on hidden assumptions known only to the authors. For example, (1) it is unclear what the output of the \u201cjoint\u201d function is, and why the second output is omitted, and (2) the application of \u201cdim=-1\u201d in argmax assumes a specific shape of \u201ctoken-probs,\u201d which remains undefined. Please make the algorithm self-contained by appropriately defining each notion.\n  - The decoding strategy used for NAR-mode is unclear.\n    - From the explanation in Section 4.1, it appears that the authors still applied a decoding algorithm used for TDT even when the model is used in NAR mode. I have several questions:\n      - I assume that the decoding algorithm is still left-to-right. If this is the case, can it still be called \"NAR\"? Please explicitly define the notion of NAR in the paper.\n      - Is there any notion of a 'beam' in the decoding algorithm for HAI-T? This is a clarification question, and I guess the answer is no. However, if beam search decoding was used, the configuration needs to be specified. In addition, if all experiments were conducted without beam search, it is still highly recommended to evaluate each method using the beam search configuration, as it is the most widely used.\n      - What decoding algorithm is used for CTC (best path, prefix search)? Can the author provide the impact of decoding algorithms (not only for CTC, but also for RNN-T with beam size) to understand the impact of it?\n    - In Section 6.2, the authors suddenly introduce Viterbi-based decoding in the experimental section. They should have described the details of the decoding strategies (both the one in the main experiment and Viterbi decoding) in the proposed method section to clearly show the differences between them. It would have been better to explicitly describe Algorithm 2 of Xu et al. (2023) instead of merely referencing it, as the algorithm is not widely known within the community. Including the memory footprint is also highly recommended, as Viterbi decoding may require significantly more memory during inference, especially for long input durations.\n  - The discussion in Section 6.3 is unclear to me. The authors claimed that \"the ability to skip more frames enables the model to learn better representations\" by presenting Table 4 with different max-duration settings, where the shorter max-duration setting provided worse results. However, isn't it just showing that the shorter max-duration is not able to capture the real duration distribution? I think that the only conclusion we could draw from Table 4 is \"the max duration needs to be sufficiently large to represent the real distribution,\" and their claim that \"the ability to skip more frames enables the model to learn better representations\" cannot be drawn."
            },
            "questions": {
                "value": "Please address the concerns and questions raised in the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}