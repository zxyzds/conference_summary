{
    "id": "QZuZmfLLRG",
    "title": "LW2G: Learning Whether to Grow for Prompt-based Continual Learning",
    "abstract": "Continual Learning (CL) aims to learn in non-stationary scenarios, progressively acquiring and maintaining knowledge from sequential tasks. Recent Prompt-based Continual Learning (PCL) has achieved remarkable performance with Pre-Trained Models (PTMs). These approaches grow a prompt sets pool by adding a new set of prompts when learning each new task (prompt learning) and adopt a matching mechanism to select the correct set for each testing sample (prompt retrieval). Previous studies focus on the latter stage by improving the matching mechanism to enhance Prompt Retrieval Accuracy (PRA). To promote cross-task knowledge facilitation and form an effective and efficient prompt sets pool, we propose a plug-in module in the former stage to Learn Whether to Grow (LW2G) based on the disparities between tasks. Specifically, a shared set of prompts is utilized when several tasks share certain commonalities, and a new set is added when there are significant differences between the new task and previous tasks. Inspired by Gradient Projection Continual Learning, our LW2G develops a metric called Hinder Forward Capability (HFC) to measure the hindrance imposed on learning new tasks by surgically modifying the original gradient onto the orthogonal complement of the old feature space. With HFC, an automated scheme Dynamic Growing Approach adaptively learns whether to grow with a dynamic threshold. Furthermore, we design a gradient-based constraint to ensure the consistency between the updating prompts and pre-trained knowledge, and a prompts weights reusing strategy to enhance forward transfer. Extensive experiments show the effectiveness of our method.",
    "keywords": [
        "Continual Learning",
        "Gradient Orthogonal",
        "Pre-Trained Model",
        "Prompt Learning"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "LW2G employs a novel approach (HFC) to dynamically determine whether to add a new set of prompts or reuse existing ones based on the relationships between tasks.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=QZuZmfLLRG",
    "pdf_link": "https://openreview.net/pdf?id=QZuZmfLLRG",
    "comments": [
        {
            "summary": {
                "value": "This work proposes a strategy for determining the dynamic expansion of the prompt pool over time for prompt-based Continual Learning methods, based on techniques inspired by Gradient Projection Memory for Continual Learning."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The motivation of the proposed method is clear. There are theoretical supports. The experimental superiority over baselines can be seen."
            },
            "weaknesses": {
                "value": "1. It seems to me that this paper is the application of the technique in [1] to the existing methods with the criteria to expand the prompt pool. However, this technique is quite similar to those in [2], [3]. The authors should highlight the novelty and innovative contribution of this work. \n\n2. It is not clear how the performance on CUB of HiDE is has minimal change, while those on CIFAR100 and ImageNet-R is decrease significantly. If the codebase of HiDE has some problem, why didn't the authors consider other codebases of other baselines?\n\n3. The authors claim their method can promote positive knowledge transfer, however relevant experimental results seem to be lacking.\n\n4. The method saves the number of parameters to learn, but storing the basis vectors of the subspaces is also expensive.\n\n5. This work is close to [1], thus, it is essential to have the comparisons between them.\n\n[1] Prompt Gradient Projection for Continual Learning, ICLR 2024.\n\n[2] Beyond Not-Forgetting: Continual Learning with Backward Knowledge Transfer, NeurIPS 2022.\n\n[3] TRGP: Trust Region Gradient Projection for Continual Learning, ICLR 2022."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a new method called LW2G (Learning Whether to Grow) for prompt-based continual learning.\nLW2G decides whether to grow the prompt pool or reuse existing prompts when learning a new task, based on measuring the hindrance of learning the new task on old prompts compared to an ideal hindrance-free scenario. I think the idea of Hinder Forward Capability (HFC) is inspiring, that measures the difference between new and old tasks as well as the hindrance imposed on learning new tasks under a strict orthogonality constraint to old task feature spaces.\nExtensive experiments demonstrating the effectiveness of adding LW2G to existing prompt-based continual learning methods across multiple datasets and settings."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- LW2G is an approach that actively decides whether to grow new prompts or reuse existing ones for each new task. This aspect distinguishes LW2G from previous methods.\n\n- Introduces a new Hinder Forward Capability (HFC) metric to quantify the hindrance of learning a new task on old prompts under orthogonality constraints. \n\n- The three main components of LW2G - DGA, CPK, and FFT - provide a complete implementation for reusing existing prompts in continual learning tasks. However, to some extent, the approach is quite redundant, as it requires repeatedly training all the prompts to determine the optimal reuse strategy.\n\n- The authors have shared their code and implementation, which, although I haven't personally tested it, lends some credibility to the soundness of their method. At least, from the README.md file, it appears they have provided a full implementation of the Hide-Prompt version.\n\n- Overall, the proposed method is sound as there are so comprehensive experiments."
            },
            "weaknesses": {
                "value": "- One important aspect missing from the experiments in this paper is the average results from multiple runs. This is particularly evident in the paper, as the experimental results in Tables 1, 2, and 3 show that the proposed method has only a slight difference compared to the baselines. It's quite possible that running the baselines multiple times could yield a better result. I'm not claiming that this paper has done so. But providing the mean and standard deviation would better demonstrate statistical robustness.\n\n- LW2G  needs for significant manual intervention and careful hyperparameter selection to ensure the prompt resule/increase strategy works appropriately. For example, HFC thresholds, CPK's soft constraint coefficient and FFT's top-N selection."
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a plug-in module within existing Prompt-based Continual Learning (PCL), \ncalled Learning Whether To Grow (LW2G). LW2G enables PCL to dynamically learn to whether to add a new set of prompts for each task (to grow) or to utilize an existing set of prompts (not to grow) based on the relationships between tasks. LW2G consists of three components: Dynamic Growing Approach (DGA), Consistency with Pre-trained Knowledge (CPK), and Facilitation for Forward Transfer (FFT). Its superiority across multiple benchmarks and various CL settings is also verified."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(1)By learning whether to grow or not to grow set of prompts, this work forms an effective and efficient prompt sets pool where each single set contains knowledge from multiple tasks, thus facilitating cross-task promotion. \n(2)LW2G is a plug-in and effective module within existing PCL."
            },
            "weaknesses": {
                "value": "I have two main concerns: \n(1)The proposed LW2G is mainly designed for prompt-based CL methods, and further improves their performances. However, the improvements with respect to the mainstream CL metrics, FAA and FMM, as shown in Table 1, are not significant. In particular, for some stronger baselines, S-prompt++, the performance with LW2G makes no obvious performance. \n(2)It seems that the performance reported on the Hide-prompt paper is better than that in this work, in which Hide-prompt even performs better than S-prompt++.\n(3) FFA or FAA? It is a little confused."
            },
            "questions": {
                "value": "(1)Does LW2G still work in the context of various pre-trained models?\n(2)Is it still effective in more prompt-based CL methods, such as coda-prompt?\n(3)As more recent studies show, lora-based CL methods are more effective than prompt-based in CIL tasks. So, does the proposed strategy have more advantages?\n(4)When does the Theorem 1 hold? Any assumptions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In this paper, the authors propose a method namely Learn Whether to Grow (LW2G), wherein a shared set of prompts is utilized when several tasks share certain commonalities, and a new set is added when there are significant differences between the new task and previous tasks. The proposed  LW2G develops a metric named Hinder Forward Capability (HFC) to measure the hindrance. With HFC, an automated scheme Dynamic Growing Approach adaptively learns whether to grow with a dynamic threshold. Furthermore, a gradient-based constraint is introduced to ensure consistency between the updating prompts and pre-trained knowledge. Extensive experiments are provided."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The experiments and analysis are very thorough and well-written, and the proposed method has some novelty"
            },
            "weaknesses": {
                "value": "Weakness\uff1a\n\n1: I agree that Prompt Retrieval Accuracy (PRA) has a certain impact on performance and is an urgent problem to be solved before 2023. However, some of the lasted prompt-based methods ([1], [2], etc) and some of the lasted Adapter-Based methods ([3], [4], [5], etc.) do not need to consider PRA issues and surpass the classical methods using the matching mechanism. I have doubts whether the PRA problem should be the main motivation for building continuous learning solutions using pre-trained models.\n\n2: There are also some methods for optimizing the prompt selection (matching) mechanism. For example, [6], [7], [8] all try to improve the matching mechanism. Compared with the above methods, the improvement of the projection method seems to be relatively limited. it may not prove that your method is superior to them.\n\n3: The comparison is not sufficient, lacking performance comparison of some of the latest methods (as above) and the display of plug-in effects in the latest methods, etc. \n\n4: Gradient projection and whether to choose growth are not novel in the field of CL, but they are somewhat novel in the PTM-based CIL task.\n\n[1]: CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning\n[2]: Generating Instance-level Prompts for Rehearsal-free Continual Learning\n[3]: InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning\n[4]: Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA\n[5]: Revisiting class-incremental learning with pre-trained models: Generalizability and adaptivity are all you need\n[6]: Consistent Prompting for Rehearsal-Free Continual Learning\n[7]: One-stage Prompt-based Continual Learning\n[8]: Evolving Parameterized Prompt Memory for Continual Learning"
            },
            "questions": {
                "value": "see the weakness.\n\nI'd like to raise my score if all my concerns are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Learning Whether to Grow (LW2G), a plug-in module for Prompt-based Continual Learning (PCL). LW2G determines whether to expand the prompt pool by adding new prompts or reusing existing ones based on the similarity between tasks, aiming to improve efficiency and knowledge transfer. Inspired by Gradient Projection Continual Learning (GPCL), the method leverages orthogonal projections to measure task interference using a new metric called Hinder Forward Capability (HFC). LW2G also introduces strategies for gradient-based prompt consistency and prompt weight reuse to further optimize learning. Experimental results show that LW2G improved the performances of three baseline PCL models."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Dynamically growing the prompt pool for PCL methods aligns well with the continual learning paradigm.\n\n2. Using a gradient-projection-based metric to assess task similarity looks reasonable."
            },
            "weaknesses": {
                "value": "While the idea of leveraging orthogonal conditions to mitigate forgetting is reasonable, the paper does not sufficiently formulate this method within the context of PCL. Section 3 introduces the formulation for layer $l$, but it lacks clarity on how this formulation applies specifically for PCL, where prompts serve as the primary trainable parameters. A detailed and precise formulation is essential to fully understand the proposed method.\n\nThe reported performance of baseline models appears lower than those reported in prior work. For instance, HiDe-Prompt, when initialized with ImageNet-21K pre-trained weights, achieves FAA scores of 92.61 on CIFAR-100, 75.06 on ImageNet-R, and 86.56 on CUB, which are much higher than the ones presented in Table 1 under the same task settings. These discrepancies raise concerns about the reliability of the reported results and warrant further explanation.\n\nThe differences between the proposed LW2G and other orthogonal continual learning methods are not sufficiently highlighted. A more explicit comparison would help better position LW2G and clarify its unique contributions.\n\n\nSome terminologies require clearer definitions. For example, the term \u201cmatrix with suitable dimensions\u201d is vague. A more precise description is needed to avoid confusion.\n\nSome minors. 1) There seem to be some messy codes in line 082. 2) Use \u201cViT\u201d instead of \u201cVIT\u201d to align with established conventions. 3) The notion $l$ is slightly reused for the layer index and the number of bases for space $\\mathcal{S}_1$."
            },
            "questions": {
                "value": "1. Does the proposed method require computing the representation matrix for every layer after learning each task? Additionally, what specific samples are used to calculate the representation matrix?\n\n2. What does the variable $N$ in line 165 refer to? \n\n3. How is $\\mathbf{B}_t^l$ obtained? While it appears to be introduced in the supplementary material, it is recommended to briefly explain this process in the main paper as it is essential for understanding the overall method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}