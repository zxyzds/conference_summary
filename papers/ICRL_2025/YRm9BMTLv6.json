{
    "id": "YRm9BMTLv6",
    "title": "Source-Free Target Domain Confidence Calibration",
    "abstract": "In this study, we consider the setup of source-free domain adaptation and address the challenge of calibrating the confidence of a model adapted to the target domain using only unlabeled data. The primary challenge in addressing uncertainty calibration is the absence of labeled data which prevents computing the accuracy of the adapted network on the target domain. We address this by leveraging pseudo-labels generated from the source model\u2019s predictions to estimate the true, unobserved accuracy. We demonstrate that, although the pseudo-labels are noisy, the network accuracy calculated using these pseudo-labels is similar to the accuracy obtained with the correct labels. We validate the effectiveness of our calibration approach by applying it to standard domain adaptation datasets and show that it achieves results comparable to, or even better than, previous calibration methods that relied on the availability of labeled source data.",
    "keywords": [
        "confidence calibration",
        "domain adaptation",
        "source-free"
    ],
    "primary_area": "transfer learning, meta learning, and lifelong learning",
    "TLDR": "We present a confidence calibration method for a source-free domain adaptation setup",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=YRm9BMTLv6",
    "pdf_link": "https://openreview.net/pdf?id=YRm9BMTLv6",
    "comments": [
        {
            "summary": {
                "value": "This paper addresses the calibration of model confidence in source-free domain adaptation (SFDA) scenarios, where only unlabeled target data is accessible. The authors introduce **Source-Free Confidence Calibration (SFCC)**, a method that combines a pre-trained feature extractor with a deep clustering approach to improve pseudo-label accuracy and uses temperature scaling to achieve calibration in SFDA. Experiments on benchmarks like VisDA, DomainNet, and Office-Home suggest that SFCC performs comparably to, or better than, some existing methods that rely on source data."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper is structured clearly, with step-by-step explanations that make it easy to follow. For example, the authors use experimental observations to explain why temperature scaling is suitable for SFDA problems even without clean target labels.\n    \n- The study focuses on a real-world challenge in SFDA where source data may be inaccessible due to privacy or storage issues, and the calibration is particularly relevant.\n    \n- Extensive testing across different datasets and adaptation methods validate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "- **Limited Novelty**. The novelty of this work is marginal. Calibration approaches for SFDA, particularly temperature scaling, are already covered in previous research [1]. A more extensive literature review and in-depth comparisons with related methods are needed to clarify the contribution and differentiate this work.\n    \n- **External Feature Extractor**. The use of an external feature extractor for pseudo-labeling in SFDA is not particularly innovative, as similar approaches are seen in prior work [2,3]. Additional discussion on the practicality and computational efficiency of this technique would strengthen the paper.\n    \n- Experimental Results. The experimental analysis could be more comprehensive and further discussed. Please refer to the Questions.\n    \n- (Minor) Theoretical Insight. The use of noisy pseudo-labels to estimate bin-wise accuracies is based on empirical results without theoretical insight, which limits the rigor of the approach.\n    \n\n[1] Dapeng Hu, Jian Liang, Xinchao Wang, Chuan-Sheng Foo: PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation.\n\n[2] Idit Diamant, Idan Achituve, Arnon Netzer: De-Confusing Pseudo-Labels in Source-Free Domain Adaptation. 2024 ICCV.\n\n[3] Wenyu Zhang, Li Shen, Chuan-Sheng Foo: Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation. 2023 ICCV."
            },
            "questions": {
                "value": "Most of my concerns are centered around the experiments and methodology:\n\n- Will the proposed enhanced pseudo-labelling (EPL) method also benefit the SFDA performance, compared to the baseline methods, SHOT and DCPL?\n    \n- For calibration, how was the bin number decided? Would variations in bin number affect the calibration outcomes?\n    \n- In Figures 1 and 2, are the shown results recorded at the end of the adaptation process? How do these indicators evolve during adaptation, and what accuracy levels are associated with the displayed calibration levels?\n    \n- For temperature scaling, is the optimal temperature calculated on the entire dataset or per mini-batch?\n    \n- Clarifications Needed:\n    \n    - In lines 504-510, the argument about classifying difficulty lacks clarity\u2014how does this paragraph validate that claim?\n        \n    - Does Figure 4b account for outliers, and could they impact the interpretability of the results?\n        \n    - Figure 3b appears to support Equation (6), but the connection of Eq. (6) to Figure 4b is unclear for me.Please correct me if I've misunderstood anything."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies the model calibration problem in the context of source-free domain adaptation (SFDA). The authors claim to propose the first source-free model calibration approach by using only pseudo labels of target-domain data. Specifically, a method called Source Free Confidence Calibration (SFCC) is designed as the solution. SFCC consists of two steps: first using the clustering-based strategy to refine the pseudo labels and then applying temperature scaling with the refined pseudo label-ed target data. Experiments on three SFDA datasets demonstrate that SFCC outperforms existing calibration approaches."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(+) Both the source-free domain adaptation and the model calibration are significant for improving the robustness and generalization of models in real-world scenarios with complex data distributions. Therefore, it is meaningful to study the problem of source-free model calibration.\n\n(+) The background presentation is comprehensive enough to introduce the investigated problem.\n\n(+) It is good to see that code implementation is provided, which is helpful."
            },
            "weaknesses": {
                "value": "(-) The technical novelty is not clear. The GEPL method in Algorithm 1 has been widely used in source-free domain adaptation (SFDA) since the pioneering SFDA work SHOT [1] used the iterative version of GEPL to improve the pseudo-label quality. In addition, Algorithm 2 only applies the widely used model calibration method Temperature Scaling [2] to pseudo-labeled target-domain data. Therefore, it seems the technical novelty of this paper is very limited due to the use of many existing techniques without proposing a new one.\n\n(-) The presentation is hard to understand, especially the methodology introduced in Lines 191-208. It is confusing and weak to claim that two versions of A_{i, 1} are equal by definition. By which definition? Presentation from Line198 to Line215 is only based on assumptions without any theoretical or generalized empirical guarantee as the support. This is also for the proposed SFCC method, although experimental results are impressive, it is unknown why SFCC can do well and how it can generalize.\n\n(-) More experiments and ablations are required. First, only three SFDA methods are not enough. Since the claim of this submission is a calibration method for SFDA, only if the authors believe that the selected three SFDA methods (SHOT, AaD, and DCPL) can fully represent existing SFDA approaches, however, is it a fact? Second, it is required to do ablations on GEPL with other techniques of improving pseudo labels such as the common thresholding-based method. Third, other calibration error metrics mentioned in TransCal [3] excluding ECE should be reported because ECE could be misleading sometimes. In addition, what is the accuracy of all SFDA models? \n\nReferences\n\n[1] Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation ICML 2020\n\n[2] On calibration of modern neural networks ICML 2017\n\n[3] Transferable calibration with lower bias and variance in domain adaptation NeurIPS 2020"
            },
            "questions": {
                "value": "Please refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The author proposed a Temperature scaling-based calibration method for the SFDA by leveraging the Pesudo labels."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea of calibrating the confidence of a model in interesting."
            },
            "weaknesses": {
                "value": "1. Why you think the noisy label would have the same effect of the correct label in calibration? Is there any empirical observation or theoretical guarantee? I doubt this motivation. \n2. In Eq.4, what is the difference between the Pseudo label and the predicted label? \n3. Using $\\hat{A}$ to $A$ is not suitable as they would exist a big gap (you do not even know how reliable the pseudo labels are). $\\hat{A}_{i}$ would not be equal to $A_{i}$ in this case. Also, the approach from the left to right in Eq.6 should not be held. \n4. The reason in Fig.4b may be the fact that you are using a strong pre-trained network, which should not be concluded as a common empirical observation.\n5. Are the bins are divided manually with a fixed number?"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The author considers the source-free calibration problem. Since the absence of labeled data, we cannot use the traditional calibration methods. In this way, the author addresses it by leveraging pseudo labels generated from the source model\u2019s predictions to estimate the true, unobserved accuracy. Finally, the author verify the effectiveness on various datasets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) The calibration problem is important.\n2) The proposed method is effective."
            },
            "weaknesses": {
                "value": "1) The paper is hard to read. The author should split the chapters to make them easier to read, for example, the third section should be split appropriately.\n2) I am a little confused about this setting, i.e., calibration via the unlabelled data from the target domain. In what scenarios would this setting be used? TransCal [a] realizes calibration via the labeled source domain data. The author may discuss the differences and applications between the two settings. \n3) The pseudo label has been explored thoroughly in semi-supervised learning. Simply transferring it to the calibration lacks novelty.\n4) The author optimizes the temperature $T$ via the adaECE loss. For a fair comparison, the author should report other evaluation metrics such as SCE. \n5) line 309. \"we followed the evaluation protocol described in the TransCal Paper,  which involves splitting each target domain into 80% for training and 20% for validation\". It seems that TransCal split the training set and validation set on the source domain. \n\nminor:\nI think the author should draw a main figure to describe the basic setting of the calibration.\n\n[a] Transferable Calibration with Lower Bias and Variance in Domain Adaptation"
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}