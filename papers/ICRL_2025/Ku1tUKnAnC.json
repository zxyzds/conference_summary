{
    "id": "Ku1tUKnAnC",
    "title": "Measuring the Reliability of Causal Probing Methods: Tradeoffs, Limitations, and the Plight of Nullifying Interventions",
    "abstract": "Causal probing aims to analyze large language models (or other foundation models) by examining how modifying their representation of various latent properties using interventions derived from probing classifiers impacts their outputs. Recent works have cast doubt on the theoretical basis of several leading causal probing intervention methods, but it has been unclear how to systematically evaluate the effectiveness of probing interventions in practice. To address this, we formally define and quantify two key causal probing desiderata: completeness (how thoroughly the representation of the target property has been transformed) and selectivity (how little other properties have been impacted). We introduce an empirical analysis framework to measure and evaluate completeness and selectivity, allowing us to make the first direct comparisons of the reliability of different families of causal probing methods (e.g., linear vs. nonlinear or counterfactual vs. nullifying interventions). Our experimental analysis shows that: (1) there is an inherent tradeoff between completeness and selectivity, (2) no leading probing method is able to consistently satisfy both criteria at once, and (3) across the board, nullifying interventions are far less complete than counterfactual interventions, which suggests that nullifying methods may not be an effective approach to causal probing.",
    "keywords": [
        "interpretability",
        "probing",
        "causal probing",
        "interventions",
        "mechanistic interpretability",
        "language models"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "We introduce an empirical analysis framework to evaluate the reliability of causal probing interventions for interpreting foundation models.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Ku1tUKnAnC",
    "pdf_link": "https://openreview.net/pdf?id=Ku1tUKnAnC",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a method to evaluate interventions in a model\u2019s representation to enforce specific properties. The authors propose to evaluate these interventions by training a model evaluator (approximated oracle probe) that can assess whether the targeted property has been set or removed, as well as the degree to which the intervention affects other properties. The evaluation is conducted on a single-task case study where the target property has two possible values."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper is well-written and organized, making the proposed method easy to follow."
            },
            "weaknesses": {
                "value": "The primary concern with this work lies in the overlap between the evaluator (approximated oracle probe) and the intervention generator (underlying structural probe used, for example, in the counterfactual approach). Both aim to predict the latent variable \\( Z \\) from the representation, meaning the evaluator and the intervention generator essentially encode the same information. This overlap likely explains why the counterfactual intervention seems to perform best, as assuming they both perform well (also, the authors use the same architecture for these models), it is almost like directly leveraging the evaluator in generating the intervention and assessing using the evaluator afterwards.\n\nThe simplicity of the experimental setup also limits the work's scope. It would be more compelling if the authors tested their method on cases with more than binary causal variables. Additionally, introducing interventions that could potentially not impact task accuracy would provide a clearer understanding of whether performance loss is due to the intervention\u2019s effectiveness or simply the disruption caused by perturbing the representation. \n\nAnother suggestion would be to evaluate a scenario where \\( Z_c \\) and \\( Z_e \\) are independent, \\( Z_c \\) only impact label. This setup could test if intervening on \\( Z_e \\) affects task accuracy while maintaining good selectivity or completeness."
            },
            "questions": {
                "value": "- The rationale behind equating nullified representations to a uniform distribution isn\u2019t entirely clear (I have already read your detailed description in Appendix B). Why not add a distinct category representing \"neither\" of the options, rather than assuming a uniform distribution?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces an empirical framework to evaluate causal probing methodologies in language models, particularly focusing on completeness and selectivity. The study highlights a trade-off between these two criteria, showing that counterfactual interventions are generally more effective in altering targeted representations without impacting unrelated properties, unlike nullifying interventions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. **Novel Evaluation Framework**: I appreciated the proposed structured framework for measuring the reliability of causal probing interventions. Such a standardized idea can be used to evaluate and compare various methods.\n\n2. **Detailed Experimental Analysis**: The experiments are conducted with detailed analysis across multiple intervention methods and settings, offering a comprehensive evaluation of the methods' performance under varied conditions."
            },
            "weaknesses": {
                "value": "1. **Limited Model Scope**: The major concern is insufficient experimental verification. As the authors also claim in the paper, this evaluation is conducted only on a simple model and task (line 672), which might limit the generalizability of the findings to more complex language models and tasks. Since some ideas seem challenging to achieve in practice (line 145), it would be beneficial to see verification or discussion on how the proposed framework could adapt to more general and complex scenarios.\n\n2. **Redundant Descriptions**: Some sections, like Sections 4 and 5, provide extensive details that could be condensed, with some specifics better suited for an appendix. Simplifying these sections (maybe at the same time introducing more settings and results) could enhance readability without compromising clarity."
            },
            "questions": {
                "value": "Can the authors provide any guidance or verification on applying the proposed idea to a more general setting? Although the framework appears novel, its current verification relies on several strict assumptions (e.g., full determinism, binary variables, etc.). I\u2019m curious about how this framework could be implemented in a more universally applicable manner."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "How do you evaluate a causal probe when you can't even be sure it has representation for the right concept (instead of some correlated concept)? This paper seeks to answer this popular question by training \"oracle probes\" for both the target and off-target concepts, thereby increasing confidence that an intervention to the representation space is *actually* the one that was intended.\n\nWith these oracle probes in hand, the authors then propose evaluating causal probing methods according to two desiderata which they formally define: completeness and selectivity (corresponding to whether the representation captures *all* of the concept, and whether it *does affect anything else*, intuitively). \n\nThese are then used to experimentally evaluate different types of causal probing methods, thereby retrodicting the observation that nullifying interventions are less complete than counterfactual interventions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The proposed method of training \"oracle probes\" is simple yet versatile: it seems applicable to any attribute with a supervised dataset.\nTo my knowledge, such an approach is novel, as probes are often used as a source of explanation, rather than as a means to assess the effect of an intervention. The contribution of \"oracle probes\" thus seems analogous to the development of synthetic controls for causal inference: use a machine learning model to close the causal inference loop, under some suitable assumptions (which here are missing, see weaknesses).\n\nThis paper emphasizes that completeness and selectivity empirically induce a trade-off, and so aptly propose the harmonic mean as a way to aggregate these appropriately."
            },
            "weaknesses": {
                "value": "1. This approach requires enumerating all off-target concepts in order to construct the oracle probe for Z_e. However, this is a common assumption in the causal-inference-in-text literature, so not surprising.\n2. A crux of this paper is the development of *good* oracle probes. However, there is very little analysis of how to evaluate the oracle probes (which are then used to evaluate causal probing methods).\n3. Currently, this paper only considers binary concepts. This is a common assumption, so not very limiting."
            },
            "questions": {
                "value": "1. Could you elaborate on the implicit assumptions on the oracle probes? For instance, in the experiments section, you mention the assumption that they are trained in a such a way that they have no spurious correlation in their training data. Are there other theoretical assumptions on the oracle probes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose metrics to measure the completeness and selectivity of causal probing techniques, and conduct an empirical study with diverse causal probing techniques; including recently proposed counterfactual intervention techniques. The motivation behind the empirical study is to formally understand the challenges with causal probing, and establish trends to understand the relative advantages/disadvantages of the different causal probing techniques; counterfactual vs nullifying intervention techniques, and linear vs non-linear counterfactual intervention techniques. The authors report results with BERT on the LGD subject-verb agreement dataset, and find that counterfactual probing methods are better than nullifying probing methods in terms of completeness, and also linear counterfactual techniques fare better than non-linear counterfactual techniques in terms of reliability."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The proposed evaluation framework is novel to the best of my knowledge, and the analysis of recently proposed counterfactual intervention techniques has not been done in prior works. However, I am not very familiar with the literature in causal probing, hence I am not the best judge for this.\n\n- The experiment results are present clearly and there is a good discussion around them, which makes it easy to follow the main claims. The explanations given in the paper behind observed trends are good and justified.\n\n- The observation of counterfactual interventions better than nullifying interventions for causal probing maybe of significance to the community, and help in development of better causal probing techniques. \n\n- The experiment setup is comprehensive enough as it covers a variety of causal probing techniques, and considers widely used benchmark for causal probing."
            },
            "weaknesses": {
                "value": "- There should be more details provided regarding the performance of (trained) oracle probe. While the authors just report that the oracle obtains high accuracy for predicting the causal variables, more details are needed regarding the distribution learnt by the oracle probe. For example, the completeness metric for nullifying interventions (e.q. 2)  is designed under the assumption that the oracle probe has a uniform  distribution after the null intervention. Is this true for the oracle probe trained by the authors in their empirical study? If this is not the case and the distribution learnt by oracle probe is not uniform, that might bias the completeness metric for nullifying interventions, leading to the question whether we can trust the observed trend that nullifying interventions are worse than counterfactual interventions for completeness. Hence, the authors should verify the oracle distribution in the case of nullifying interventions and check how similar it is to the uniform distribution. \n \n- Table 1 should report standard error/deviation as well over the different examples in the test set. Same comment for figures, but if the error bars are not too significant then they can be dropped, but they must be explicitly mentioned in the appendix. Also, it is not clear how many random seed were used for conducting the empirical study. Are the findings based on a single random seed? If that is the case then I advise the authors to conduct experiments with multiple random seeds to have robust trends.\n\n- Overall, I have some concerns with the writing of the paper in terms of details regarding notations and metrics. For example, for the metrics (e.q. 1, 2, 3), why do the authors remove the dependence on $z_{i'}$ from $P^\\star$ and $\\hat P$, as they are a function of the value set after intervention. Similarly, the derivation behind the metric are not clearly stated in some cases. For example, equation 3, what is the min and max of the distributions $P^\\star$ and $\\hat P$? Over what argument are we taking the min/max over? More justification should be provided for the derivation of the selectivity metric. I have expanded more on this point about notations etc. in the questions section ahead."
            },
            "questions": {
                "value": "- Regarding the discussion on linear vs non-linear counterfactual probing methods, can the authors conduct a small experiment where the intervention happened on not the last layer? This will help to understand whether the improvement in completeness with linear counterfactual probing is due to intervention happening on the last layer, or there are some other reasons behind it. Also, can you provide an example where non-linear counterfactual probing is better than linear counterfactual probing?\n\n- The training objective of the oracle probe is not clear to me, please provide more details on it.\n\n- The notation of $\\hat h^{l}$ and $h^{l^{\\star}}$ should be more clearly defined in the text. Also, why are authors using $h^{l^{\\star}}$ and not $h^{\\star^l}$, was there some specific reason? Currently its a bit confusing as the notation for layers is not consistent, $l$ versus $l^{\\star}$ in $\\hat P$ and $P^{\\star}$.\n\n\nMinor comments\n\n- It might be good to have a figure denoting the overall design of the evaluation framework.\n\n- The contributions in the introduction can be stated more clearly; either in terms of bullet points and some of the content about the limitation of causal probing can be brought in the introduction.\n\n- There is a typo on linear 172; it should be $c(\\hat h^{l, k})$ instead of $c(\\hat h^{l, i} )$.\n\n- Line 64, it would be good to provide a clear reference to prior works that criticize the nullifying interventions; instead of referring to Section 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}