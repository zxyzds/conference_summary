{
    "id": "AfZH9EEuRR",
    "title": "EgoQR: Efficient QR Code Reading in Egocentric Settings",
    "abstract": "QR codes have become ubiquitous in daily life, enabling rapid information exchange. With the increasing adoption of smart wearable devices, there is a need for efficient, and friction-less QR code reading capabilities from Egocentric point-of-views. However, adapting existing phone-based QR code readers to egocentric images poses significant challenges.\nCode reading from egocentric images bring unique challenges such as wide field-of-view, code distortion and lack of visual feedback as compared to phones where users can adjust the position and framing. Furthermore, wearable devices impose constraints on resources like compute, power and memory.\nTo address these challenges, we present EgoQR, a novel system for reading QR codes from egocentric images, and is well suited for deployment on wearable devices. Our approach consists of two primary components: detection and decoding, designed to operate on high-resolution images on the device with minimal power consumption and added latency. The detection component efficiently locates potential QR codes within the image, while our enhanced decoding component extracts and interprets the encoded information. We incorporate innovative techniques to handle the specific challenges of egocentric imagery, such as varying perspectives, wider field of view, and motion blur.\nWe evaluate our approach on a dataset of egocentric images, demonstrating 34% improvement in reading the code compared to an existing state of the art QR code readers.",
    "keywords": [
        "QR Code Reading",
        "Egocentric vision",
        "Smart Wearable Devices",
        "Resource-Constrained Computing",
        "QR Code Detection",
        "QR Code Decoding",
        "Super Resolution"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "This work presents a novel QR code reader for smart wearable devices, addressing unique challenges posed by egocentric vision and resource-constrained devices.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=AfZH9EEuRR",
    "pdf_link": "https://openreview.net/pdf?id=AfZH9EEuRR",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a QR code reader for wearable devices. The Implementation of this system incorporates existing modules such as Faster-RCNN and ZXing. In addition, a series of image processing algorithms are used for enhancing decoding rate. Overall, the practical significance of this paper is greater than its algorithmic innovation, and it is not suitable for submission to conferences such as ICLR, which emphasize theoretical innovation or exploration. We recommend that the authors submit this paper to a conference in the field of embodied intelligence."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1.complex system implementation\n2.great practical significance\n3.experimental results in real-world environments"
            },
            "weaknesses": {
                "value": "1.The method lacks novelty\n2.The method is a simple combination of existing modules"
            },
            "questions": {
                "value": "1.\tThe core modules of existing QR reader are locating and alignment, how to solve these two problems in this paper? The authors use faster-rcnn to detect QR codes, however faster-rcnn can only predict horizontal bounding box, thus the output roi suffer perspective deformation.\n2.\tFaster-rcnn is a two-stage model, which may be time-consuming in edge-ai device, why not use yolo? The newest version yolo has support well for small object detection.\n3.\tFor question#1, why not use keypoint detection to replace the object detection? If you can determine the vertices of qr code, the perspective deformation can be removed by compute homograph matrix, which can play a role of alignment.\n4.\tPlease explain the implementation environments.\n5.\tTable 2 doesn\u2019t show running time, which is important for edge-ai."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a QR code processing system that consists of QR code detection, an image enhancement module, and QR code decoding. The paper claims two challenges in QR code reading: 1) Stylistic QR code and 2) Small QR code. The proposed method resolves the issue by utilizing image enhancement modules, such as color inversion, multi-scale processing, contrast enhancement, morphological operation, and super-resolution. As a result, the method achieved a higher success rate compared to previous off-the-shelf QR scan methods. However, the main weakness of the paper is novelty. The paper is a naive systematic paper that combines existing methods to resolve the QR code problem. It isn't sufficient enough for ICLR's novelty standard."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "S1. The proposed method resolves stylistic QR code and small QR code problems by utilizing image enhancement modules, such as color inversion, multi-scale processing, contrast enhancement morphological operation, and super-resolution."
            },
            "weaknesses": {
                "value": "W1. Novelty. \n* The paper proposes a simple pipeline that combines a QR code detection module, an image enhancement module, and a QR code decoding module. It is difficult to find any new idea, novelty, or new perspective for each component. ICLR requires new and brilliant ideas, perspectives, and contributions to various research fields. However, the paper's contribution is not enough to meet ICLR standards. \n\nW2. Presentation\n* The paper presentation needs to be clarified. For instance, Table 2 doesn't properly reference each method.\nAlso, Fig 8 is mentioned earlier than Fig 1. The figure and table should be mentioned in their order.\n\nW3. Experiments\n* The effect of each image enhancement method is unclear. For instance, the stylistic QR code problem is resolved by introducing a number of enhancement tools, such as color inversion, multi-scale processing, contrast enhancement, and morphological operation. Are they all necessary? How do they affect the performance of stylistic QR code reading?"
            },
            "questions": {
                "value": "Please see weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work introduces a system for reading QR codes from first-person perspectives on wearable devices. It tackles challenges like wide field-of-view and code distortion using a detection and decoding approach that includes a tailored Faster R-CNN model and image enhancement techniques. The system has a 34% improvement in QR code reading over existing methods on a novel egocentric dataset. Future work will focus on improving the detection and decoding of small QR codes and integrating the system with other AI models for more context-aware applications."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-  The proposed EgoQR system demonstrated a significant 34% improvement in QR code reading success over existing state-of-the-art readers. \n- By incorporating image enhancement techniques like super-resolution and adaptive histogram equalization, the system improves decoding success rates even in challenging conditions such as motion blur and varying lighting."
            },
            "weaknesses": {
                "value": "- Lack of novelty: The paper builds upon well-established techniques such as Faster R-CNN for detection and common image enhancement methods for decoding.\n- Concern about efficiency: The proposed system employs high-resolution image processing and machine learning models which could be computationally intensive. It would be beneficial to see a more detailed analysis of the trade-offs between performance and resource consumption."
            },
            "questions": {
                "value": "It would be helpful if the authors provide explanations on the novelty of this system. Also, I hope the authors provide experiments to compare the efficiency of the proposed system against existing approaches."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes EgoQR, a system designed to enhance QR code reading on smart wearable devices from an egocentric perspective. EgoQR addresses challenges like code distortion, varying perspectives, and resource constraints through efficient detection and decoding components tailored for egocentric images. Evaluations on a self-collected dataset show a 34% improvement over existing QR code readers."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper identifies a practical problem: the growing need for efficient and frictionless QR code reading capabilities from egocentric viewpoints, particularly with the rising adoption of smart wearable devices with limited computational resources.\n\n2. The paper introduces a solution to tackle issues like code distortion and resource constraints. Experimental results on a self-collected dataset demonstrate its superior performance compared to other commercial applications."
            },
            "weaknesses": {
                "value": "1. The novelty of the paper is limited, resembling more of a technical report addressing an engineering problem than a formal academic paper. The core modules of the proposed pipeline are nearly all previous methods.\n\n2. The experimental section is insufficient, as it only reports the accuracy of different methods without providing in-depth analysis or conducting an ablation study on various components.\n \n3. The paper lacks a comparison of the public dataset."
            },
            "questions": {
                "value": "No."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents a system for QR code detection and recognition in egocentric settings. The authors combine existing tools and techniques, including Faster R-CNN for detection and various image enhancement techniques for decoding, along with a disambiguation method for multiple QR codes. While the paper addresses an interesting practical problem, it has several significant limitations that make it unsuitable for publication at ICLR."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The paper addresses a practical and relevant problem, as QR code reading in egocentric/wearable settings is becoming increasingly important with the rise of AR/VR devices."
            },
            "weaknesses": {
                "value": "**Note that this paper is over-paged (It should be desk rejected?)**\n\n1. Limited Technical Novelty:\n- The paper primarily integrates existing methods (Faster R-CNN, traditional image processing techniques, LRSRN for super-resolution) without introducing significant algorithmic innovations\n- The image enhancement pipeline is a straightforward combination of standard techniques (color inversion, multi-scale processing, CLAHE, morphological operations)\n- The disambiguation approach relies on existing ROI detection from another system (Lumos)\n\n2. Questionable Experimental Setup:\n- The dataset collection methodology lacks rigor and proper controls\n- No clear description of what constitutes an \"egocentric\" image in their data collection\n- No comparison with actual egocentric devices or properly collected egocentric datasets\n- The baseline comparisons (zxing, pyzbar, etc.) are with general-purpose QR code readers rather than systems specifically designed for egocentric settings\n\n3. Insufficient Validation:\n- The paper claims to address egocentric-specific challenges but doesn't provide quantitative analysis of how their system handles these specific issues\n- No ablation studies to justify the choice and order of enhancement techniques\n- Limited analysis of computational efficiency and power consumption, despite claiming suitability for wearable devices\n- The claimed 34% improvement lacks context as it's compared against general-purpose QR readers rather than egocentric-specific solutions\n\n4. Methodological Issues:\n- The dataset size (528 images) seems inadequate for comprehensive evaluation\n- No clear distinction between training and test sets\n- Lack of detailed analysis of failure cases and their relationship to egocentric challenges\n- No discussion of statistical significance in the reported improvements\n\n5. Incomplete Resource Analysis:\n- Despite targeting wearable devices, there's limited discussion of memory usage and power consumption\n- No concrete benchmarks on actual wearable hardware\n\nWhile the problem is interesting and practically relevant, the paper's limitations in technical novelty and experimental validation make it unsuitable for ICLR. The work would be more appropriate for an applied computer vision or system-focused venue after addressing the identified issues."
            },
            "questions": {
                "value": "- Could you clarify what specific devices were used for data collection? Was this data collected using actual AR/VR headsets or wearable cameras?\n- What was your protocol for ensuring the collected data truly represents egocentric viewpoints and challenges?\n- Would you share details about the train/test split and validation methodology?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}