{
    "id": "w2HL7yuWE2",
    "title": "Uncertainty-aware Guided Diffusion for Missing Data in Sequential Recommendation",
    "abstract": "Denoising diffusion models (DDMs) have shown significant potential in generating oracle items that best match user preference with guidance from user historical interaction sequences. However, the quality of guidance is often compromised by the unpredictable missing data in the observed sequence, leading to suboptimal item generation. To tackle this challenge, we propose a novel uncertainty-aware guided diffusion model (DreamMiss) to alleviate the influence of missing data. The core of DreamMiss is the utilization of a dual-side Thompson sampling (DTS) strategy, which simulates the stochastical mechanism of missing data without disrupting preference evolution. Specifically, we first define dual-side probability models to capture user preference evolution, taking into account both local item continuity and global sequence stability. We then strategically remove items based on these two models with DTS, creating uncertainty-aware guidance for DDMs to generate oracle items. This can achieve DDMs\u2019 consistency regularization, enabling them to resile against uncertain missing data. Additionally, to accelerate sampling in the reverse process, DreamMiss is implemented under the framework of denoising diffusion implicit models (DDIM). Extensive experimental results show that DreamMiss significantly outperforms baselines in sequential recommendation.",
    "keywords": [
        "Diffusion Models",
        "Recommender Systems",
        "Missing Data"
    ],
    "primary_area": "generative models",
    "TLDR": "We introduce a dual-side Thompson sampling strategy to create uncertainty-aware guidance for DDMs in sequential recommendation.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=w2HL7yuWE2",
    "pdf_link": "https://openreview.net/pdf?id=w2HL7yuWE2",
    "comments": [
        {
            "summary": {
                "value": "The proposed method aims to tackle overlooking the missing data within the guidance for diffusion models. Specifically, they first detect the missing data by constructing local and global models and checking the continuity and stability. Based on the detected missing data, the authors then train diffusion models with uncertainty-aware guidance. Extensive results are provided to support the effectiveness."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper is well-structured and easy to follow.\n- The proposed method is well-motivated and novel. \n- The details of the experiments are revealed, and the code is released, which will ease the reproducibility of this paper."
            },
            "weaknesses": {
                "value": "- Some typos exist. For example, the first character in line 72 should be capitalized.\n- This paper is not well-motivated. Why is Thompson sampling the best choice to derive the guide signal for a diffusion-based recommendation? Besides, no related experiments can verify the best of the Thompson sampling strategy compared to other sampling strategies.\n- I noticed that the scale of datasets used in the experiments is relatively small, with interaction counts of fewer than one million. I recommend that the authors conduct experiments on larger datasets to further demonstrate the effectiveness of the proposed method, or the method's efficiency may be questioned."
            },
            "questions": {
                "value": "All my questions have been included in the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes DreamMiss, a novel approach to handle missing data in sequential recommendation systems using denoising diffusion models (DDMs). The key innovation is a dual-side Thompson sampling (DTS) strategy that simulates missing data stochastically while preserving user preference patterns. The approach uses two probability models: 1) A local model that captures continuity between adjacent items A global model that evaluates sequence stability. 2) DreamMiss is implemented using denoising diffusion implicit models (DDIM) for faster sampling and achieves consistency regularization through uncertainty-aware guidance."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The paper is generally well-written.\nThe problem of missing data is crucial for developing sequential recommenders."
            },
            "weaknesses": {
                "value": "W1. Conceptual Clarity and Methodology Concerns.\nThe paper lacks clear theoretical justification for how generating additional missing data helps address the original missing data problem.\nThe approach of simulating missing data from already incomplete sequences raises questions about potential error propagation.\nThe methodology appears counterintuitive compared to traditional approaches that aim to recover or compensate for missing data.\nThe paper would benefit from a more rigorous theoretical analysis of why this approach is superior to data completion methods.\n\nW2. Limited Validation of Dual-side Thompson Sampling (DTS).\nThe paper does not sufficiently justify why DTS is specifically effective for diffusion-based sequential recommenders.\nThere is inadequate theoretical analysis or empirical validation of the reliability of the continuity and stability metrics.\nThe generalizability of DTS to other recommendation architectures needs more thorough investigation.\nThe robustness of the probability models used in DTS requires more comprehensive validation.\n\nW3. Incomplete Baseline Comparisons.\nNotable omissions of important state-of-the-art baselines, particularly:\n[1] Lin, Y.; Wang, C.; Chen, Z.; Ren, Z.; Xin, X.; Yan, Q.; de Rijke, M.; Cheng, X.; and Ren, P. A Self-Correcting Sequential Recommender. In TheWebConf 2023.\n[2] Zhang, C.; Han, Q.; Chen, R.; Zhao, X.; Tang, P.; and Song, H. SSDRec: Self-Augmented Sequence Denoising\nfor Sequential Recommendation. In ICDE 2024.\nThese omissions make it difficult to fully assess the comparative advantages of the proposed method.\nThe evaluation would be more convincing with a more comprehensive comparison against recent approaches.\n\nW4. Scalability Limitations.\nThe computational complexity of the proposed method may limit its practical applications.\nInsufficient discussion of performance on large-scale recommendation systems.\nLimited analysis of computational resource requirements for real-world deployment.\nNeed for more detailed discussion of potential optimization strategies for larger datasets.\n\nW5. Dataset Limitations.\nThe evaluation relies on relatively small-scale datasets.\nQuestions about generalizability to larger, more complex real-world recommendation scenarios.\nNeed for validation on more diverse and larger-scale datasets.\nLimited demonstration of effectiveness across different domains and data distributions."
            },
            "questions": {
                "value": "Please refer to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "Sorry, I am not familiar with this research area so I can't give a valuable score. Please overlook my score."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "Sorry, I am not familiar with this research area so I can't give a valuable score. Please overlook my score."
            },
            "weaknesses": {
                "value": "Sorry, I am not familiar with this research area so I can't give a valuable score. Please overlook my score."
            },
            "questions": {
                "value": "Sorry, I am not familiar with this research area so I can't give a valuable score. Please overlook my score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 10
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a dual-side Thompson sampling (DTS) strategy to simulate the stochastical mechanism of missing data, and integrates it into denoising diffusion models for sequential recommendation. Extensive experimental results show that DreamMiss significantly outperforms baselines."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The experimental results are sound.\n2. The paper is overall well written."
            },
            "weaknesses": {
                "value": "1. The missing data issue is not well discussed. Thompson sampling can not tackle all the missing data issues. How the proposed model can address which kind of missing data should be discussed in the paper.\n2. The rationale of accelerated sampling is not well explained.\n2. The hypothesis of stability scores is not reasonable. In recommendation model training, data are often shuffled to remove the dependency among samples. However, the stability scores seems the opposite way; it used the batch information for sampling. It contradicts with the traditional way."
            },
            "questions": {
                "value": "1. The line 7 of Algorithm 1 seems a bit different than other DDPM models. There's no square root above the $(1 - \\alpha_{\\tau_s})$. Is it a typo?\n2. Can the authors explain why accelerated sampling works? It seems to reduce thousands of iterations to less than 100 rounds, which is a huge improvement.\n3. Based on the performance of Dreasmiss, can we say the DreamRec has a overfitting problem? With much more rounds of iteration DreamRec has inferior performance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}