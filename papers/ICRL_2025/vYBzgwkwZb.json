{
    "id": "vYBzgwkwZb",
    "title": "BiQAP: Neural Bi-level Optimization-based Framework for Solving Quadratic Assignment Problems",
    "abstract": "Quadratic Assignment Problem (QAP) has attracted lasting attention for its wide applications and computational challenge. Despite the rich literature in machine learning for QAP, most works often address the problem in the setting of image matching, whereby deep networks could play a vital role in extracting useful features for the subsequent matching. While its power on pure numerical QAP instances is limited in node embedding, often with a vanilla graph neural network. This paper tries to tap the potential of deep nets for QAP, specifically by modifying the input instance which is orthogonal to previous efforts. Specifically, we develop a bi-level  unsupervised framework, where the inner optimization involves trying to solve the modified instance with entropic regularization that can be solved iteratively using the Sinkhorn algorithm without affecting backpropagation by truncating gradients during training. The outer minimization deals with the quadratic objective function of the original QAP. In particular, seeing the intractable scale of the most general form i.e. Lawler's QAP and the practical utility of the more efficient Koopmans-Beckmann QAP (KBQAP) form for solving other graph and combinatorial problems like TSP and graph edit distance, we embody our network on the KBQAP, and show its strong performance on various benchmarks in our experiments. Source code will be made publicly available.",
    "keywords": [
        "Quadratic Assignment Problems",
        "Entropic Regularization",
        "Differential Gromov-Wasserstein Solver",
        "Unsupervised Learning"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vYBzgwkwZb",
    "pdf_link": "https://openreview.net/pdf?id=vYBzgwkwZb",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes an unsupervised learning framework, BiQAP, based on a bilevel optimization model, to solve the Koopmans-Beckmann Quadratic Assignment Problem (KBQAP). In this framework, the outer level objective corresponds to the original QAP objective, while the inner level is a differentiable Gromov-Sinkhorn QAP solver applied to new QAP instances generated by a neural network, FormulaNet. FormulaNet is trained by minimizing the original QAP objective. Extensive experiments across five tasks demonstrate its effectiveness and efficiency compared to both non-learning and learning-based methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The bilevel optimization formulation used to design an unsupervised learning framework for solving KBQAP is novel, contributing to a clearer understanding of the proposed framework's methodology.\n\n2. The comprehensive experimental results highlight the notable effectiveness and efficiency of BiQAP in comparison to existing methods."
            },
            "weaknesses": {
                "value": "1. The core concept behind the proposed BiQAP framework appears counterintuitive. If understood correctly, the primary idea is to train a neural network that takes the original QAP instance as input and outputs a modified QAP instance. This network is trained so that, when the Gromov-Sinkhorn algorithm is applied to the generated QAP instance, the resulting solution yields a lower objective value for the original QAP. However, it is unclear why solving a modified QAP instance should yield better results than directly solving the original QAP. No discussion, theoretical analysis, or explanation is provided to justify why this approach would be effective for solving the KBQAP.\n\n2. Although the proposed BiQAP framework is based on a bilevel optimization model, the paper lacks a review of relevant literature on bilevel optimization, as well as a discussion on why the bilevel optimization model in Eq. 3 is preferable to directly solving the original QAP.\n\n3. This work presents a practical method but lacks theoretical analysis or discussion. For example, it does not clarify the relationship between the bilevel optimization model in Eq. 3 and the original QAP, nor does it discuss whether the solution to Eq. 3 can approximate or recover a solution to the original QAP. Additionally, the paper does not establish any properties or guarantees regarding the quality of outputs generated by the proposed BiQAP framework."
            },
            "questions": {
                "value": "1. In the numerical experiments, are the numbers of outer and inner iterations different for training and testing? If so, how crucial is this for the performance of the BiQAP?\n\n2. Numerous existing studies focus on algorithms for solving bilevel optimization models. How does the proposed BiQAP framework relate to these studies, and could insights from this literature potentially enhance the BiQAP framework?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes BiQAP, a procedure for solving Koopmans-Beckmann Quadratic Assignment Problems. The method formulates a bi-level optimization procedure, where the inner problem solves an entropy-regularized QAP. The problem data of the inner problem is predicted from the original problem data using a sequence to sequence neural network that is invariant to the size of the involved matrices. This neural network can be trained in an unsupervised manner, which removes the need for access to expensive gold solutions. The inner problem is solved with a differentiable approximate Gromov-Wasserstein Sinkhorn solver.\nThe method is tested on a wide set of experimental setups, including synthetically generated graph matching instances and more realistic graph edit distance (formulated as QAP) and QAP instances. Throughout the extensive evaluation, BiQAP produces strong results both in terms of achieved objective values of the computed solution as well as the required computation time, outperforming all of the other compared methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "- The paper has a thorough experimental evaluation with strong results, and substantially advances the state of the art in multiple experimental setups.\n- The experimental setup and evaluation are well-described and easy to follow.\n- The approach taken (bi-level problem with entropy-regularized inner problem on predicted parameters) seems more widely applicable and could serve as a new paradigm in solving difficult non-convex and combinatorial problems."
            },
            "weaknesses": {
                "value": "- The paper lacks theoretical analysis of the bi-level optimization problem formulation (3).\n- In the first part of the paper, I found the language used often imprecise and a bit confusing. Especially figure 1 seems misleading, because using QAP for visual keypoint matching is not what is done in this work, instead machine learning is used to improve the QAP solving itself. The presentation could be improved here.\n- The ablation study on the number of samples in Fig 3 shows that in this setting the results are not very sensitive to this hyperparameter. This hyperparameter will be important for a practitioner so this ablation study should be repeated on a different experiment where it potentially makes a difference, e.g. on the GED experiment.\n- The regularization strength $\\epsilon$ of the inner problem is most likely an important hyperparameter (affecting the inner solution and its differentiation), it should be discussed and experimentally tested. What happens when it is set to very large or very small values?\n- No ablation for different architectures of the FormulaNet is included. It would be important to see how the SSM compares to GNN or Transformer-based architectures."
            },
            "questions": {
                "value": "- What is the theoretical justification for using Gumbel noise to sample the initial $X^{(0)}$?\n- I assume the time measurements in the tables and plots are given in seconds? Unless I missed it, this information should be added in."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents an unsupervised learning approach to solve QAPs. The proposed method includes two main components: a \"FormulaNet\" that generates a new QAP and a differentiable solver utilizing the Sinkhorn algorithm to solve this generated QAP. Experimental results show certain advantages over the baseline methods."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written, with a logical flow.\n2. Unlike existing graph-matching methods, which use optimal transportation as the implicit optimization problem, the proposed approach aims to solve a new QAP. This is novel.\n3. Extensive experiments are conducted, covering different types of QAPs and various exsting baseline methods."
            },
            "weaknesses": {
                "value": "I don't see any major weaknesses, but a few improvements could enhance this paper:\n\n1. The implicit optimization problem appears crucial, as described by the author in lines 280-285. Including a baseline where FormulaNet produces an optimal transportation problem could provide a more robust validation and enhance readers' understanding.\n2. The author should clarify the choice of randomly generated datasets over publicly available ones, as the latter might be more convincing."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}