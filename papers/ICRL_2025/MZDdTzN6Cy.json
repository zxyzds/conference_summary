{
    "id": "MZDdTzN6Cy",
    "title": "TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation",
    "abstract": "With the recent development and advancement of Transformer and MLP architectures, significant strides have been made in time series analysis. Conversely, the performance of Convolutional Neural Networks (CNNs) in time series analysis has fallen short of expectations, diminishing their potential for future applications. Our research aims to enhance the representational capacity of Convolutional Neural Networks (CNNs) in time series analysis by introducing novel perspectives and design innovations. To be specific, We introduce a novel time series reshaping technique that considers the inter-patch, intra-patch, and cross-variable dimensions. Consequently, we propose TVNet, a dynamic convolutional network leveraging a 3D perspective to employ time series analysis. TVNet retains the computational efficiency of CNNs and achieves state-of-the-art results in five key time series analysis tasks, offering a superior balance of efficiency and performance over the state-of-the-art Transformer-based and MLP-based models. Additionally, our findings suggest that TVNet exhibits enhanced transferability and robustness. Therefore, it provides a new perspective for applying CNN in advanced time series analysis tasks.",
    "keywords": [
        "Time series Analysis",
        "Dynamic convolution",
        "Deep Learning"
    ],
    "primary_area": "learning on time series and dynamical systems",
    "TLDR": "New time series modeling perspective based 3D-variation and new analysis framework based dynamic convolution",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=MZDdTzN6Cy",
    "pdf_link": "https://openreview.net/pdf?id=MZDdTzN6Cy",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces TVNet, a novel time series analysis method that addresses the limitations of CNNs in capturing complex temporal dynamics by converting 1D time series data into 3D tensors and applying dynamic convolution. This approach achieves state-of-the-art performance across various time series tasks while maintaining efficiency."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper introduces TVNet, a novel method for time series analysis that leverages dynamic convolution and 3D transformation, offering a fresh perspective in the field by converting 1D time series data into 3D tensors through a 3D-Embedding technique.\n2. The paper demonstrates the capacity of the model across five critical time series analysis tasks, including long-term and short-term forecasting, imputation, classification, and anomaly detection, showcasing the model's generalization capabilities.\n3. The paper is well-organized, with a logical flow , making it easy to follow and understand."
            },
            "weaknesses": {
                "value": "1. Although the paper mentions the efficiency of the model, it does not discuss in detail the consumption of computational resources when running on datasets of different scales. Additionally, different methods have different training strategies, making the training time a poor reflection of the true time consumption of the model. It is recommended to present the inference time and computational load of the model under the same settings.\n2. The experimental results show long-term forecasting, but it seems that the prediction lengths = {24, 36, 48, 60} do not reflect the setting of 'long-term.' It is suggested to follow the same settings as the original dataset, such as: {96, 192, 336, 720}.\n3. In Table 1, it is a very serious error that the values for weather and traffic are identical.\n4. The article's claim of \"achieves top-tier performance across five pivotal analytical tasks\" is overclaimed because the results on long sequences show that the method did not achieve state-of-the-art (SOTA) on multiple datasets, and the improvement in results that did achieve SOTA is very limited (approximately 0.85% to 2.36% on MSE).\n5. Although the paper proposes a powerful model, more explanation may be needed to justify its complexity, especially in the experimental analysis, where more demonstration of its performance in terms of inter-patch, intra-patch, and cross-variable interpretability is needed."
            },
            "questions": {
                "value": "1. It is recommended to present the inference time and computational load of the model under the same settings.\n2. To effectively demonstrate the capability of long-term forecasting, it is recommended to follow the same settings as the original dataset, for instance: {96, 192, 336, 720}.\n3. More explanation may be needed to justify its complexity, especially in the experimental analysis, where more demonstration of its performance in terms of inter-patch, intra-patch, and cross-variable interpretability is needed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The manuscript introduces TVNet, a dynamic convolutional network for time series analysis, employing 3D embedding and convolution mechanisms to handle inter-patch, intra-patch, and cross-variable dependencies. TVNet aims to improve CNN performance in time series tasks and demonstrates its utility across multiple tasks, including long-term and short-term forecasting, classification, anomaly detection, and data imputation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The modular design of TVNet is scalable and easily extensible\n- Maintains computational efficiency comparable to CNNs while achieving superior results.\n- Comprehensive experiments covering many tasks, baselines and analysis"
            },
            "weaknesses": {
                "value": "- **Lack of Strong Motivation**: The paper's motivation could be strengthened. While it aims to \u201cenhance the representational capacity of CNNs for time series analysis,\u201d it does not adequately explain **why** this enhancement is necessary, given the strong performance of RNNs and Transformers for such tasks. It is well understood that different network architectures are suited for different input modalities, based on the inductive biases they introduce [1]. Therefore, further justification is needed to clarify the specific gaps that CNNs can fill in time series analysis.\n- **Insufficient Emphasis on Novelty**: Although the introduction of **3D-embedding** is a core idea, the rationale for choosing the specific three embeddings (inter-patch, intra-patch, and cross-variable) is not adequately explained. A deeper discussion is necessary to understand why these dimensions were prioritized and how they contribute to improved performance. This would help highlight the **novelty** and distinctiveness of the proposed method.\n\n[1] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Michael C. Mozer, Yoram Singer: Identity Crisis: Memorization and Generalization Under Extreme Overparameterization. ICLR 2020"
            },
            "questions": {
                "value": "- **Motivation**:\n    - Can the authors elaborate on the specific limitations of RNNs and Transformers in time series analysis that CNNs aim to address? Given the well-known success of Transformers and RNNs, what makes CNNs uniquely suitable for time series tasks?\n- **Rationale Behind 3D-Embedding**:\n    - Why were the inter-patch, intra-patch, and cross-variable embeddings selected? Are there theoretical or empirical justifications for these choices? Could alternative embeddings have been explored, and how would the performance be affected by such variations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents TVNet, a dynamic convolutional network for time series analysis, utilizing a 3D-Embedding technique and dynamic convolution to capture intra-patch, inter-patch, and cross-variable dependencies. TVNet is evaluated on five tasks and shows state-of-the-art performance, better efficiency than some models, and good transferability and robustness."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed 3D-Embedding technique and the consideration of different types of dependencies (intra-patch, inter-patch, cross-variable) are novel and well-motivated.\n2. The experimental evaluation is comprehensive, covering multiple tasks and comparing with a wide range of state-of-the-art models. The consistent top performance across these tasks is a significant strength."
            },
            "weaknesses": {
                "value": "1. Some parts of the method description could be made clearer. For example, the generation function for the time-varying weight could be explained in more detail.\n2. The paper does not compare with some of the latest models such as TimeMixer[1] and recent models combined with large language models (e.g., S2 IP-LLM[2], TimeLLM[3]). This omission may lead to an incomplete understanding of the relative performance and novelty of TVNet in the context of the most recent research trends.\n\n[1]Wang S, Wu H, Shi X, et al. Timemixer: Decomposable multiscale mixing for time series forecasting[J]. arXiv preprint arXiv:2405.14616, 2024.\n[2]Pan Z, Jiang Y, Garg S, et al. $ S^ 2$ IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting[C]//Forty-first International Conference on Machine Learning. 2024.\n[3]Jin M, Wang S, Ma L, et al. Time-llm: Time series forecasting by reprogramming large language models[J]. arXiv preprint arXiv:2310.01728, 2023."
            },
            "questions": {
                "value": "1. Can the authors provide more details about the choice of hyperparameters and their impact on performance? \n2. Why was there no comparison with some of the latest models such as TimeMixer and models combined with large language models (e.g., S2 IP-LLM, TimeLLM)? What could be the potential implications of such comparisons for the evaluation of TVNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper propose a method called TVNet. TVNet can capture intra-patch,inter-patch and cross-variables features by converting 1D time series data into 3D shape tensor."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "To sum up, this is a good paper. They proposed TVNet.\nTVNet captures intra-patch,inter-patch and cross-variables features by converting 1D time series data into 3D shape tensor.\nTVNet implements consistent state-of-the-art performance time series analysis tasks across multiple mainstreams, demonstrating excellent task generalization."
            },
            "weaknesses": {
                "value": "1. 3D-EMBEDDING\nThis is your innovation, but you did not tell it  clearly. For example: \n\"stride S to divide into N patches($X_{emb} \u2208 R^{N\u00d7P \u00d7C_m}$)\" \nIt is hard for me to know how do you achieve this. Almost the whole process in this part is confused. You should give explanations."
            },
            "questions": {
                "value": "The same to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}