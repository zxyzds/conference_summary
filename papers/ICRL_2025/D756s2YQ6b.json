{
    "id": "D756s2YQ6b",
    "title": "Diffusing to the Top: Boost Graph Neural Networks with Minimal Hyperparameter Tuning",
    "abstract": "Graph Neural Networks (GNNs) are proficient in graph representation learning and achieve promising performance on versatile tasks such as node classification and link prediction.\nUsually, a comprehensive hyperparameter tuning is essential for fully unlocking GNN's top performance, especially for complicated tasks such as node classification on large graphs and long-range graphs. This is usually associated with high computational and time costs and careful design of appropriate search spaces. \nThis work introduces a graph-conditioned latent diffusion framework (GNN-Diff) to generate high-performing GNNs based on the model checkpoints of sub-optimal hyperparameters selected by a light-tuning coarse search. We validate our method through 166 experiments across four graph tasks: node classification on small, large, and long-range graphs, as well as link prediction. Our experiments involve 10 classic and state-of-the-art target models and 20 publicly available datasets. The results consistently demonstrate that GNN-Diff: (1) boosts the performance of GNNs with efficient hyperparameter tuning; and (2) presents high stability and generalizability on unseen data across multiple generation runs. The code is available at https://anonymous.4open.science/r/GNN-Diff-1AD3.",
    "keywords": [
        "graph neural networks",
        "generative diffusion models",
        "network generation",
        "hyperparameter tuning",
        "node classification",
        "link prediction"
    ],
    "primary_area": "learning on graphs and other geometries & topologies",
    "TLDR": "",
    "creation_date": "2024-09-25",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=D756s2YQ6b",
    "pdf_link": "https://openreview.net/pdf?id=D756s2YQ6b",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces GNN-Diff, a latent diffusion model designed to enhance GNN training while minimizing the need for hyperparameter tuning. The author claim that this approach not only improves GNN performance but also demonstrates significant stability across various tasks."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tThe overall motivation is clear: improving hyperparameter search strategies can save time and enhance performance. This is an area that has not been explored too much in GNN training so far.\n\n2.\tThe presentation is clear, with well-organized results and analysis provided for better interpretability."
            },
            "weaknesses": {
                "value": "1.\tThe reported performance is a significant concern, as many results are noticeably lower than expected. For instance, nearly all results in Table 2 fall substantially short of those reported in existing literature and on the OGBN leaderboard: for example, I believe that GCN on OGBN-Arxiv can achieve 71.6% (as opposed to the reported 69.2%), APPNP can reache 71.8% (versus the reported 55.05%), and GraphSAGE can easily achieve around 79% on OGBN-Products, compared to the reported 75.6%. This discrepancy raises questions about whether the authors adhered to standard settings, whether the reported accuracy is reliable, and, if not, how the experimental setup was configured. Clearer details on these aspects would help clarify the validity of the reported results.\n\n2.\tThe motivation for certain components is unclear. For instance, why do the authors choose to incorporate GAE in the training process?\n\n3.\tAn ablation study illustrating the impact of the proposed techniques would strengthen the findings.\n\n4.\tThe authors use classical GNNs for downstream tasks, but employing SOTA GNNs are necessary. For example, RevGAT[1], SAGN[2] and LazyGNN[3]. Many advanced architectures perform well without extensive parameter tuning, and using these models could better showcase the contributions of this work.\n\n5.\tFigure 7 reports only running time, without any indication of memory cost. Additionally, if three different models are trained in this work, I am wondering how the runtime remains lower than that of a random search? A comparison with coarse search would also be useful.\n\n6.\tCan the proposed techniques be applied to graph classification?\n\n[1] Training Graph Neural Networks with 1000 Layers\n\n[2] Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced training\n\n[3] LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation"
            },
            "questions": {
                "value": "1. Could you explain the reason of the claim that concatenating different receptive fields in message passing can handle both homophilic and heterophilic graphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "In summary\uff0c this paper proposes a strategy for tuning hyper-parameters of GNNs to maximize their potential. It is achieved by collecting a set of model parameters, encoding graphs, and then learning to generate parameters for GNNs. Extensive methods have been conducted in this paper to verify the designed method."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper is well-organized.\n- Extensive experiments are conducted in this paper."
            },
            "weaknesses": {
                "value": "1. The technical contribution is limited given the related works.\nIt seems that GNN-diff is a combination of LDM and graph techniques. The sample collection method described in Section 4.1 is trivial, and the designed encoder is also widely used in existing methods. It would be better to highlight the technical contributions in comparison with the different methods mentioned in the related work section.\n\n2. The experiments seem somewhat unrigorous and fail to adequately highlight the efficiency and effectiveness of GNN-diff. \n- Baseline selection: While numerous target GNNs and datasets are utilized, the paper employs only a few comparable baselines. It appears that methods from \"Advanced Methods for Hyperparameter Tuning\" should be incorporated to validate the designed parameter tuning strategy more effectively. \n-  Evaluations of the effectiveness of Coarse search: In Tables 1-4, the \"Coarse\" variant struggles to outperform the \"Random\" and \"Grid\" baselines. With these results, justifying the effectiveness of the coarse search approach is challenging.\n\n3. The transferability of GNN-Diff is limited due to its hyper-parameter tuning being tailored for a specific dataset, relying on parameter collection and the GAE model."
            },
            "questions": {
                "value": "The upper bound of the proposed method remains unclear. It is uncertain how a well fine-tuned GCN compares to lightly fine-tuned, more expressive models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This article introduces an interesting hyperparameter search architecture that learns graph embedding information for specific graph tasks through a designed GNN architecture. This information is then integrated into conditional latent denoising diffusion probabilistic models, using a parameter encoding module to flexibly convert the input and output dimensions of the parameters."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The overall expression of the article is clear and easy to understand.\n2. The experiments are comprehensive, and the performance of the algorithm is impressive.\n3. It connects model parameter tuning with the data itself."
            },
            "weaknesses": {
                "value": "Simply using GNNs for embedding learning on graph-structured data and adding it to the G-LDM module does not analyze why this part of the graph embedding works for the method."
            },
            "questions": {
                "value": "1. There is a spelling error at line 126 of the article, \"P-Eecoder()\".\n2. Why use such a GNN architecture? Would using classical graph embedding frameworks like GAT or GCN be effective?\n3. Clearly, graph data structures are diverse, and using just one type of GNN makes it difficult to effectively embed all types of graph data. When GNNs become ineffective, or when increasing the number of GNN layers causes the graph embeddings to become too smooth, what impact will that have on the method? Since this paper proposes a parameter tuning method, which can be considered a fundamental approach, we need to focus more on when it will fail or the lower limits of the method\u2019s capabilities."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes GNN-Diff, a graph-conditioned latent diffusion model designed to enhance Graph Neural Networks (GNNs) by generating effective parameters with minimal hyperparameter tuning. This is achieved by utilizing a coarse search strategy that identifies a subset of viable hyperparameters, which then guides the model\u2019s parameter generation. GNN-Diff claims to reduce tuning time and computational cost by creating high-performance GNN parameters through diffusion in a latent space conditioned on graph data. The authors validate GNN-Diff through extensive experiments on various tasks including node classification and link prediction with numerous model backbones, showing improved efficiency and stability."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The idea of using the diffusion framework to help with hyperparameter tuning seems novel and reasonable.\n- The experiments are thorough, spanning a diverse set of tasks and backbone models, with results that are both convincing and reproducible.\n- The proposed method effectively enhances both speed and performance across most cases, showcasing its practical value."
            },
            "weaknesses": {
                "value": "- The heterophily datasets used in this paper have faced criticism for extensive duplicate nodes as noted in [1]. It would be beneficial for the authors to consider experimenting with the datasets proposed in [1] for a more robust evaluation of heterophilic cases.\n\n- Table 5 shows that, compared to p-Diff, the improvements with GNN-Diff are relatively marginal and often inconsistent, with many results falling within one standard deviation. This brings into question the effectiveness of the GNN-Encoder design (Eq. 2).\n\n- There is a lack of theoretical analysis. \n\n\n[1] A critical look at the evaluation of GNNs under heterophily: Are we really making progress?"
            },
            "questions": {
                "value": "Have the authors tried other forms of G-Encoders other than Eq. (2) and conducted ablation studies about it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}