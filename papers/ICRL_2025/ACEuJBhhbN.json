{
    "id": "ACEuJBhhbN",
    "title": "PoGDiff: Product-of-Gaussians Diffusion Models for Imbalanced Text-to-Image Generation",
    "abstract": "Diffusion models have made significant advancements in recent years. However, their performance often deteriorates when trained or fine-tuned on imbalanced datasets. This degradation is largely due to the disproportionate representation of majority and minority data in image-text pairs. In this paper, we propose a general fine-tuning approach, dubbed PoGDiff, to address this challenge. Rather than directly minimizing the KL divergence between the predicted and ground-truth distributions, PoGDiff replaces the ground-truth distribution with a Product of Gaussians (PoG), which is constructed by combining the original ground-truth targets with the predicted distribution conditioned on a neighboring text embedding. Experiments on real-world datasets demonstrate that our method effectively addresses the imbalance problem in diffusion models, improving both generation accuracy and quality.",
    "keywords": [
        "Diffusion Model",
        "Probabilistic Methods"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "We propose a general fine-tuning approach to address the performance drops on the imbalanced text-to-image generation tasks.",
    "creation_date": "2024-09-21",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=ACEuJBhhbN",
    "pdf_link": "https://openreview.net/pdf?id=ACEuJBhhbN",
    "comments": [
        {
            "summary": {
                "value": "This paper argues that current Diffusion models are trained on imbalanced datasets.\nTo solve this problem, they propose a fine-tuning framework, PoGDiff.\nPoGDiff replaces the ground-truth distribution with a Product of Gaussians (PoG), which is constructed by combining the original ground-truth targets with the predicted distribution conditioned on a neighboring text embedding.\nExperiments show that PoGDiff effectively addresses the imbalance problem in diffusion models, improving both generations' accuracy and quality."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper addresses the issue of imbalanced training data in diffusion models and proposes a novel fine-tuning method. The core idea is to modify the ground-truth image supervision signal during training by incorporating neighboring text embeddings. \n1) The issue addressed in this paper is valuable and important. \n2) The proposed solution appears to be reasonable. \n3) The writing and analytical approach of the paper are clear. \n4) The experiments also demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "Although the approach of PoGDiff is reasonable and effective, and I understand that the addition of text embeddings can increase the diversity of the supervision signal, I still have the following concerns: 1) From the results shown in Figure 1, some of the images generated by PoGDiff exhibit noticeable deviations in color and other aspects from the ground truth (GT). Does this modification align with the expected outcomes? 2) There are already several custom techniques that can achieve diversity with just a single or a few new style images, and in some cases, without any training. The fine-tuning method proposed by the authors might degrade the performance of the original model. How should we evaluate this? 3) The proposed method essentially resembles data re-weighting, yet the experiments lack comparisons and detailed analyses with similar methods."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "use face images"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper presents Product-of-Gaussians Diffusion Models, a approach to fine-tuning diffusion models for imbalanced text-to-image generation. PoGDiff addresses the challenges of generating minority class images by using a product of Gaussians (PoG) to combine original target distributions with nearby text embeddings. Experimental results show that PoGDiff outperforms traditional methods like Stable Diffusion and Class Balancing Diffusion Model (CBDM) across various datasets, particularly enhancing generation for minority classes."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. PoGDiff introduces the use of Gaussian products for fine-tuning in imbalanced datasets, an original approach that improves minority class image generation.\n\n2. The paper provides theoretical analysis, showing that PoGDiff retains diffusion model properties while better representing minority classes."
            },
            "weaknesses": {
                "value": "1. Experiments are primarily conducted on AgeDB-IT2I and DigiFace-IT2I, which may not fully represent real-world, large-scale imbalanced datasets. Additional testing on broader datasets is necessary.\n\n2. PoGDiff relies on neighboring samples for minority class improvement, which may be less effective in sparse data settings. There is a lack of discussion on how the model handles extremely sparse data."
            },
            "questions": {
                "value": "see weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper aims to enhance the performance of diffusion models when trained or fine-tuned on imbalanced datasets. Instead of relying on a single prompt, the authors align one image with multiple group prompts sampled from the training data. To achieve this, they employ a Product of Gaussians technique. The authors conduct various experiments to demonstrate that their method is effective."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The authors introduce the Product of Gaussians technique to sample mixed prompts, which alleviates the need for numerous small image-text pairs in the training dataset. This technique allows one image to interact with more prompts, thereby increasing generative potential.\n   \n2. The approach of using multiple texts to represent a single image is a reasonable consideration.\n\n3. The authors provide theoretical support for their proposed method, which is intriguing.\n\n4. Extensive experiments are conducted to support this idea.\n\n5. The paper presents valuable insights into the proposed methodology."
            },
            "weaknesses": {
                "value": "1. The authors consider the use of non-target prompts for the current image, which may introduce noise and misalignment. This could result in generated images that do not align well with the prompts, potentially leading to lower CLIP scores, a metric that is not reported in the paper. Thus, there may be issues with text-image alignment.\n\n2. The baseline comparisons are limited, focusing only on SD and CBDM, which may not be sufficient to fully validate the proposed idea.\n\n3. As shown in Table 1, the proposed method does not demonstrate a significant advantage compared to the baselines, leaving me unconvinced about its effectiveness.\n\n4. The visualizations do not clearly support the proposed method. For instance, Figure 5 reveals a lack of diversity in the generated outputs."
            },
            "questions": {
                "value": "see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a novel method PoGDiff to address the long-tailed data distributions cause by the imbalanced datasets. This paper proposes a general fine-tuning approach, replacing the ground-truth distribution with a Product of Gaussians conditioned on a neighboring text embedding. Experiments are conducted on AgeDB-IT2I and DigiFace-IT2I using FID, DINO, Human Score and GPT-4o Evaluation evaluation metrics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tSelecting neighboring embeddings from other samples is an interesting approach, as it can help get a new density.\n2.\tFigure 3 is interesting, but it would benefit from a more detailed explanation."
            },
            "weaknesses": {
                "value": "1.\t\u201cEncouraging the model to generate the same image given similar text prompts\u201d may result in a loss of diversity in the generated images. How can this drawback be overcome?\n2.\tThe paper mentions that in diffusion models, a data point is affected only by its text embedding. However, even with the same text embedding, different latent codes can produce images of varying quality. Additionally, classifier-free guidance and negative prompts also influence image generation. \n3.\tWhy is directly smoothing the text embedding not feasible?\n4.\tWhat is the basis for hypothetically defining $\\sigma_{y'}^2 = \\frac{\\sigma_{t}^2}{\\psi[(x,y), (x',y')]}$ ?\n5.\tWhat does \u2018Cat\u2019 refer to in line 249? It doesn\u2019t seem to be explained in the paper.  The author should define or explain this term when it's first introduced\n6.\tWhat does the superscript of s in Equation 9 represent? The previous definition of s did not include a superscript (e.g., Equation 8)."
            },
            "questions": {
                "value": "1.\tArtifacts from PoGDiff appear to be present in the images generated at low density (e.g., Figure 1, lower left corner, J. Willard Marriott), but not in those generated at high density. Is this a result of the model's limitations?\n2.\tThe paper mentions that when training a diffusion model on an imbalanced dataset, existing models often struggle to generate accurate images for less frequent individuals. Personalized methods (e.g., CustomDiffusion, PhotoMaker) can use 3 to 5 images to learn an identity and generate accurate images for these less frequent individuals. What is the difference between PoGDiff and personalized methods that learn a specific identity?\nCustomDiffusion: Multi-Concept Customization of Text-to-Image Diffusion\nPhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding\n3.\tHow to obtain the ground-truth distribution $q(x_{t-1}|x_t, x_0,y)$, when given $x_t$, $x_0$, and $y$ ?\n4.\tThe $y^{'}$ in line 167 and the $y^{'}$in line 169 should be the same symbol.\n5.\tFig. 3 is interesting, but the type and amount of data used in Fig. 3 is quite confusing to me.\n6.\tEquation 7 neglects $y^{'}$.\n7.\tDoes the distance between the current text embedding $y$ and the sampled $y^{'}$ significantly affect the final generated results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}