{
    "id": "qZz7PKt4bE",
    "title": "AutoTune for Time Series Transformers using Low Rank Adaptation and Limited Discrepancy Search",
    "abstract": "Transformer models have achieved remarkable results in the field of Natural Language Processing (NLP) with the introduction of breakthrough large language models like GPT and LLaMA recently. Motivated by their ability to capture long-range dependencies, researchers have successfully adapted these models to the task of time series forecasting. However, despite their potential, effectiveness of applying these pre-trained time series transformer models in the target domain is limited due to the need for hyper-parameter optimisation to match the characteristics of the target domain. This paper presents a novel algorithm that uses parameter efficient fine-tuning such as Low Rank Adaptation (LoRA) coupled with Limited Discrepancy Search (LDS) to efficiently auto fine-tune pre-trained time series transformers for a given target domain. Our approach helps in making informed design choices involving LoRA tunable hyper-parameters with strong performance-cost trade-offs that are highly transferable across different target domains. Our experiments demonstrate that autotune efficiently identifies the optimal configuration of LoRA hyper-parameters, achieving an average MASE\nimprovement of 5.21% across all datasets and 4.76% for out-of-domain datasets compared to zero shot pre-trained models, with improvements as high as 20.59% for one of the out-of-domain datasets.",
    "keywords": [
        "Time Series Transformers",
        "LoRA",
        "Time Series Forecasting"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=qZz7PKt4bE",
    "pdf_link": "https://openreview.net/pdf?id=qZz7PKt4bE",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a novel method for automatic tuning of time series Transformer models, combining Low Rank Adaptation (LoRA) and Limited Discrepancy Search (LDS). The method aims to efficiently fine-tune pre-trained models, addressing the computational complexity associated with full parameter fine-tuning. LDS is used to optimize the hyperparameters of LoRA to enhance the model's adaptability to target domain tasks. Experimental results demonstrate that the proposed automatic tuning method outperforms both zero-shot and full fine-tuning approaches on most datasets, particularly in unseen target domains."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper presents an efficient parameter tuning scheme for Transformer models in time series forecasting by combining Low Rank Adaptation (LoRA) with Limited Discrepancy Search (LDS).\n\n- The effectiveness of Autotune is demonstrated through experiments on multiple datasets."
            },
            "weaknesses": {
                "value": "1. **Experimental Design Limitations**:\n   - (1) The main experiments lack performance reports of Autotune on different sizes of the Chronos models. Although the authors stated that only the smallest model size was used to validate the proposed method's applicability, they also compared the performance of all sizes of Chronos T5 models under a zero-shot setting. Therefore, reporting the Autotune results for all model sizes would make the findings more convincing.\n   - (2) The evaluation metric is singular. Although MASE reflects the overall performance improvement, it fails to capture other characteristics such as overfitting risks, error distribution, and extreme value prediction capabilities. The original Chronos-T5[1] also used WQL, and the work [2] employed additional metrics such as MSE and DTW.\n   - (3) Missing ablation study. The authors used the LDS search algorithm to find the optimal LoRA hyperparameter settings, but there is no ablation study on the LDS algorithm itself. Including a comparison with the best hyperparameters selected after n random trials would help demonstrate the significance and necessity of the LDS algorithm.\n\n2. **Limited Novelty**:\n   - Although the authors claim that this is the first work to explore parameter-efficient fine-tuning in time series forecasting (Line 56), there are earlier studies that have explored this area (e.g., Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting). Furthermore, the effectiveness of the LDS search algorithm has not been sufficiently validated through ablation studies.\n\n3. **Writing Issues**:\n   - The citation format throughout the paper results in unclear and difficult-to-understand statements, such as those in Lines 38-42."
            },
            "questions": {
                "value": "1. Why was only one evaluation metric chosen? Are there any specific reasons related to the task setup for this decision?\n\n2. Why were ablation studies and parameter analysis experiments not provided? Most of the figures in the experimental section only report the MASE scores compared to the baseline across different datasets, adequately demonstrating the effectiveness of the proposed method. However, would including ablation studies on the LDS search algorithm make the findings more persuasive?\n\n3. How efficient is Autotune? After fine-tuning multiple hyperparameters and selecting the best-performing model on the validation set, is there a significant improvement compared to randomly selecting a set of hyperparameters (e.g., from Table 2) for a single LoRA fine-tuning?\n\n4. Can the necessity of the LDS algorithm be demonstrated? The authors could provide a performance comparison by randomly selecting parameters from Table 2, training the model, and selecting the best-performing model on the validation set after n iterations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a new method for autotune time series transformers, combining Low Rank Adaptation (LoRA) and Limited Discrepancy Search (LDS) to efficiently perform parameter optimization on pre-trained time series models. In this paper, LoRA is used for efficient parameter tuning, and LDS is combined to explore the optimal hyperparameter configuration to make the model perform better in the target domain. Experimental results show that compared with the zero-shot pre-trained model and the traditional full-parameter fine-tuning, the proposed method achieves better performance on multiple datasets."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. This paper proposes an innovative automatic tuning method that combines the efficient parameter fine-tuning of LoRA and the search strategy of LDS to solve the problem of adaptability of large-scale models in time series.\n2. Experimental results show that the proposed method has significant performance improvement on multiple datasets, especially on some target domain datasets, which has significant advantages over zero-shot models.\n3. In the process of LoRA fine-tuning, only a small number of parameters need to be adjusted, which significantly reduces the requirements of computing resources compared with full-parameter fine-tuning, thus greatly saving the computing cost.\n4. This paper shows that the method has achieved good results on a variety of target domain datasets, showing the versatility and adaptability of the method."
            },
            "weaknesses": {
                "value": "1. Although LoRA is suitable for efficient parameter fine-tuning, its application is mainly concentrated in the case of large differences between the target domain and the source domain, and the effect improvement in some specific fields is limited.\n2. Although LDS optimizes the search space to a certain extent, its essence is still a depth-first search based on limited differences, and the search efficiency may be limited in the face of a larger hyperparameter space.\n3. The use of LDS for hyperparameter searching in LoRA is a key innovation presented in this paper; however, the article does not provide a detailed experimental analysis of this method. It remains unclear whether LDS leads to a reduction in search iterations or an improvement in search efficiency compared with other hyperparameter search methods.\n4. This paper employs LoRA as a fine-tuning method for time series forecasting models, demonstrating competitive results compared to zero-shot and full fine-tuning methods. However, as LoRA is already established as a general parameter-efficient fine-tuning approach, such results are widely evidenced in the literature\uff0cwhich, consequently, diminishes the contribution of this paper.\n5. Although the paper compares the zero-shot model and the full-parameter fine-tuning, it does not make an in-depth comparison of other advanced fine-tuning methods, such as Adapter or other AutoML strategies, which limits the comprehensiveness of the comparison results."
            },
            "questions": {
                "value": "I have some doubts about the specific implementation details of the combination of LDS and LoRA in the paper. For example, the selection criteria for LDS and how to effectively handle the size of the hyperparameter space, and whether tuning on different datasets will be affected by specific hyperparameters. In addition, there is a clear definition of the \"optimal\" hyperparameters in the experimental setup, which may affect the interpretation of the results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper covers the application of Limited Discrepancy Search (LDS) to optimize LoRA finetuning for transformer-based time-series forecasting models (Chronos in this case). The core idea is to optimize the LoRA training hyperparameters to automate the finetuning of time-series forecasting models for downstream tasks. The authors present results on several different datasets from different domains. They fix the hyper-parameter search space so that each parameter has a finite set of values. They then compare their results versus the zero-shot chronos model, the fully finetuned version and the autotuned version. They show that on average their method increases performance relative to the other versions."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1.\tAuto-tuning of time-series models is relatively understudied\n2.\tThey perform their tests on several datasets from a wide range of domains\n3.\tThey choose a model architecture which comes in a range of sizes which makes the results more interesting"
            },
            "weaknesses": {
                "value": "1.\tThe novelty is lacking. This research takes a pretrained model and applies LoRA finetuning to it with a new method of hyperparameter tuning. Most of these concepts are not new for time-series analysis\n2.\tThe paper claims to increase performance but often this strategy does not improve the quality of the forecasting. Given that you are finetuning the model for a downstream task how is it that the performance is getting worse in some cases (Table 3 and 4)?\n3.\tYou claim the autotuned model method is improving the performance but what if you simply finetune the models with LoRA and a standard set of hyperparameters would the performance be the same as your method? This is a question you need to answer clearly.\n4.\tWhy do you need figure 5 and table 4? Its looks like it is showing the same thing, it looks like you were trying to fill the space. Figure 4 also looks unnecessarily large and is a generally convoluted way of showing the results.\n5.\tWhy would you not apply this method to each model size, why is it only applied once?\n6.\tThe tuning strategy only seems to be applied to the mini model, a key advantage of LoRA is that you can train a larger model with less compute. Which is the opposite of what was chosen here.\n7.\tWhy are there standard deviations in table 3 but not in table 4.\n8.\tFigure 2 is not centered\n9.\tSome references should be in parathesis (for example line 38).\n10.\tAll of these models tested are relatively small and could be trained on somewhat accessible hardware even for academia. Why apply LoRA in this case?"
            },
            "questions": {
                "value": "In general ,I think this paper is too low impact for this conference. Their strategy lacks novelty and the results are not rigorous enough. Particularly in the validation of their method. I do have some questions pertaining to the weaknesses mentioned above:\n1. Why did you not compare to a model finetuned using LoRA with default hyperparameters?\n2. Can you show how this works with other models? There are many other pretrained time-series forecasting models you could do this with.\n3. How does this method improve the accuracy over other existing hyperparameter searching methods?\n4. Finetuning a model for time-series analysis with LoRA is not novel, performing a hyperparameter search for the LoRA hyperparameters is not novel, how do we know that the performance increases are due to the use of the LDS algorithm with LoRA?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}