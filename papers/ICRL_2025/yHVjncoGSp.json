{
    "id": "yHVjncoGSp",
    "title": "Deep Learning Aided Broadcast Codes With Feedback",
    "abstract": "Deep learning aided codes have been shown to improve code performance in feedback codes in high noise regimes due to the ability to leverage non-linearity in code design. In the additive white Gaussian broadcast channel (AWGN-BC), the addition of feedback may allow the capacity region to extend far beyond the capacity region of the channel without feedback, enabling higher data rates. On the other hand, there are limited deep-learning aided implementations of broadcast codes. In this work, we extend two classes of deep-learning assisted feedback codes to the AWGN-BC channel; the first being an RNN-based architecture and the second being a lightweight MLP-based architecture. Both codes are trained using a global model, and then they are trained using a more realistic vertical federated learning based framework. We first show that in most cases, using an AWGN-BC code outperforms a linear-based concatenated scheme. Second, we show in some regimes, the lightweight architecture far exceeds the RNN-based code, but in especially unreliable conditions, the RNN-based code dominates.  The results show the promise of deep-learning aided broadcast codes in unreliable channels, and future research directions are discussed.",
    "keywords": [
        "Deep Learning",
        "Wireless Communication",
        "Feedback Coding",
        "Error Control Coding",
        "Federated Learning"
    ],
    "primary_area": "other topics in machine learning (i.e., none of the above)",
    "TLDR": "Deep Learning is applied to broadcast channel codes to leverage the performance of non-linear codes. A global and federated model are trained and results are shown for an RNN-based scheme and lighter-weight scheme.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=yHVjncoGSp",
    "pdf_link": "https://openreview.net/pdf?id=yHVjncoGSp",
    "comments": [
        {
            "summary": {
                "value": "This manuscript proposes two classes of deep-learning assisted encoder and decoders for a broadcast channel. The first is an extension of the RNN-based architecture, and the second is a lighter MLP-based architecture. The authors compare them with conventional concatenated codes in various settings, indicating that the proposed architectures outperform conventional codes. In addition, they consider the federated learning scheme for the models and examine the performance when the gradient of trainable weights is transmitted over noisy channels."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "* The proposed models are the first fully-learnable architectures for an AWGN-broadcast channel (AWGN-BC). They show excellent performance compared with a conventional concatenated linear code. \n* The authors investigate a federated learning strategy for training weights in the models. In particular, they examine the effect of noise in transmitting gradients in the training process.\n* These issues are of importance in terms of future wireless communications."
            },
            "weaknesses": {
                "value": "Although the reviewer agrees with the importance of the issues, there are several flaws in this manuscript.\n1. **Poor technical contributions** \n\nThe contributions of this manuscript are twofold: the proposal of deep-learning architectures for AWGN-BC and the proposal of federated learning for these models. However, the proposed architectures are simple extensions of existing models for single-user cases. In short, the modifications are only learning multiple decoders and changing the loss function. As for federated learning, the concept is familiar and the modifications of the learning process are straightforward. Including not providing any theoretical analyses, the reviewer cannot avoid judging that the contributions of this manuscript are poor. \n\n2. **Lack of comparison between proposed models**\n\nThe authors proposed two models for AWGN-BC. It is claimed that LightBC is lighter than RPC-BC, but the authors do not explicitly compare the number of trainable weights and/or training costs of these models. This will be important because the comparison of model size is a performance metric other than an error rate. In addition, it will be related to the analysis of the numerical results, e.g., Fig. 3.\n\n3. **Lack of comparison with other models**\n\nAnother issue is that the numerical results do not contain those of other learning-based AWGN-BC codes such as [Li et al. 2022] in the manuscript. Even if Li's model is not fully learnable, as stated in Sec. 1.1, there is no reason to omit the model from comparison in this manuscript. \n\n4. **Possibly insufficient numerical experiments on federated learning**\n\nThe authors state, \"We choose to explore the uncoded downlink versus a quantized method as it has been shown that there is better convergence behavior in federated learning with noisy downlinks Amiri et al. (2021).\" in Line 126-129. However, Fig. 3 only contains the results of uncoded transmission (Line 490). The manuscript seems to be flawed.\n\n5. **No theoretical analysis nor interpretation of numerical results**\n\nThe manuscript contains no theoretical analysis of the proposed models or federated learning process. At the very least, I believe that the interpretation of the numerical results should be described in the manuscript. However, the manuscript only describes the facts from numerical results. See the \"Question\" section for more details."
            },
            "questions": {
                "value": "Questions:\n1. In some numerical results, RPC-BC shows an error floor in the high SNR region but LightBC does not, which is described by \"LightBC behaves somewhat like a linear feedback code\" (Line448). The reviewer wonders the reason of the fact because RPC-BC must be more flexible than LightBC. A possible reason is the hardness of learning RPC-BC. Is there any explanation of the fact? \nAnother question: why LightBC can behaves like linear codes? Does learned LightBC really have some linearlity like a linear code? How to examine it? \n\n2. Is there any possible reason that LightBC outperforms RPC-BC in some settings? Is it related to the hardness of learning models? \n\n3. In Fig.3, why LightBC by federated learning performs close to LightBC by global learning? \n\n4. What is the benefit of fully-learnanable AWGN-BC code? \n\n5. Are the training parameters in Tab. 1 optimized for AWGN-BC? The reviewer is concerned that the use of parameters \"consistent with the training parameters proposed in the single user versions\" (Line 408) may be unsuitable for the AWGN-BC case, resulting in poor performance of RPC-BC.\n\nSuggestions:\n1. The size of trainable parameters should be described. It will be helpful to show how much LightBC is lighter than RPC-BC. \n2. In Line 232, $\\mathbb{R}^{N_s,2}$ should be $\\mathbb{R}^{N_{s,2}}$. \n3. In Line 394, \"The decoder sends the length $|W_\\ell|$\u2212length vector...\" is somewhat confusing.\n4. In Fig. 2(a), the term \"SU\" is confusing because it is denoted by \"TDD\" in the main text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper considers a broadcast channel with feedback and considers a two-user symmetrical AWGN case. Feedback is known to improve the capacity region of this channel, and the authors consider a machine learning-based approach to construct good codes for this setup. The authors consider both noiseless and noisy feedback.\n\nThe proposed training methods are based on the extension of previous works devoted to a single-user channel:\n - Robust Power-Constrained Deep Learning Algorithm (RPC)\n - LightCode\n\nThe authors consider a simulation setup with small block length equal to 9 or 18 channel uses. The authors consider three different scenarios:\n- noiseless feedback,\n- noisy feedback and comparison with an orthogonal (TDD) scheme,\n- noisy feedback and comparison between different coding rates."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The authors consider the case of a multiuser broadcast channel with feedback. Feedback is known to improve the capacity region of the multiuser channel without feedback. Moreover, the behavior of this setup in the finite blocklength regime is not addressed in the literature. Thus, the application of machine learning in designing codes for broadcast channels with feedback seems quite reasonable and interesting."
            },
            "weaknesses": {
                "value": "The paper lacks some discussion related to the broadcast channel with feedback. The authors just say that \u00abthe use of feedback in the AWGN-BC channel can far exceed the capacity of the AWGN-BC channel without feedback\u00bb. I think that more discussion on this topic may significantly improve the understanding of the problem and numerical results analysis. The questions that I suggest to address may be as follows:\n- What are existing theoretical results on capacity region?\n- How exactly the capacity region can be improved and in which setups? \n- What about successive interference cancellation that is widely used in communications? Is it applicable to feedback channels? \n- What about finite block length regime? Were there any attempts to address it?\n\nNext, in the final section, the authors mention that \"... numerical studies indicated that there appears to be not much advantage over using the simple extension of LightBC in the broadcast setting versus utilizing TDD with the single user LightCode in the high rate, noisy regime\", which seems a bit confusing. It seems that the improvement can be achieved exactly when a non-orthogonal transmission scheme is used.\n\nThe authors consider numerical results by addressing a finite (N = 18 channel uses) block length, which is too far from any coding scheme used in practice. I suggest adding some discussion on how the block length can be increased and which results one should expect in this case.\n\nThe main numerical results are presented in Fig. 1 (noiseless feedback), and this figure lacks a comparison with any known theoretical bounds (like orthogonal TDM mentioned later when considering noisy feedback channels or a finite block length random coding bound for multiple access channels without feedback) and practical schemes. More references will also improve the understanding of the provided results."
            },
            "questions": {
                "value": "1. Can the scheme be applied to a block transmission with feedback? I think this scenario is of high importance because cellular systems operate in this regime (hybrid ARQ).\n2. Please provide a more detailed comparison with orthogonal (TDM) schemes when considering noiseless feedback channel. Comparing results of the  LightCode paper (arXiv 2403.10751) and Fig. 5 (rate K=3/N=9, and BLER=1e-9 at approximately -1 dB SNR), and results presented in Fig 1. (BLER 1e-6 at the same SNR for K=3/uers and N=18 channel uses).\n3. Please address the problem of error-floor appearing in Figure 1. (RPC, K=3/N=18)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper studies error correction coding over a broadcast channel in the presence of feedback. The goal of the transmitter is to convey independent messages to different receivers using the same channel resources. Assuming that the transmitter can see the channel outputs received by the receivers perfectly or with some noise, its goal is to transmit signals in an iterative fashion to gradually improve the decoding reliability of the receivers of their own messages. The author review the literature in this domain, and emphasize the lack of prior work on deep learning aided code design for this problem, although some works have appeared for the single-user channel with feedback.\n\nThe authors extend two approaches recently proposed for the single-user problem to the broadcast channel setting. They also propose a federated learning based training approach for the code."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The main strength of the paper is to study a communication scenario that has not received much attention, particularly in terms of the application of recently developed neural network based code designs."
            },
            "weaknesses": {
                "value": "- The novelty of the paper is very limited. The authors mainly take two existing designs and train these models by considering multiple receivers. This is rather trivial, and as such the paper does not introduce any new concept, architecture or tool. \n\n- The federated learning (FL) approach is not well motivated or explained. Why would a vertical FL approach make sense here? As long as the channel model is available, what prevents the encoder from training all the decoders centrally? Is it a complexity issue? The proposed uncoded transmission of gradients, as also observed by the authors, is limiting, and not well motivated. \n\n- Presentation can be improved. Especially in the numerical results part, there are some confusing sentences. \n\n- Comparison is limited to a single relatively weak code from Li et al. It seems that the state of the art for point-to-point channels with feedback (GBAF codes) is not considered in this scenario. Although complexity is argued against these codes, there is no presentation of complexity for the presented schemes."
            },
            "questions": {
                "value": "- Can you please better motivate the FL approach? Is the scenario a distributed communication setting with unknown channels? I believe estimating the channels before training the code would be a better approach in general (as is done in practice). Can you please better motivate the underlying scenario? \n\n- RPC-BC seems to do worse than time-division transmission of point-to-point RPC codes. Then, what is the point of considering these codes? LightBC seems to improve compared to time-division, does that hold for longer codes as well? I expect the training will get harder quickly with the code length, and the gains with respect to TD may quickly diminish. Can you please provide additional simulation for longer code lengths? \n\n- Why consider the code rate of 2/3 in Fig. 1 given that the error probabilities are quite high? \n\n- Can you please provide a comparison of these schemes with the linear coding approaches proposed in the literature? Even though you argue that non-linear coding can help, you do not provide any evidence for that. \n\n- How practical these codes in practice? If I understand correctly, a different neural network decoder is trained for each receiver. In a practical setting, where users roam from cell to cell, does it mean that each user has to have all the decoders as they can be assigned as any user i. Similarly, it seems that a separate encoder/decoder are trained for each SNR, which further increases the memory requirement."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a new feedback coding scheme for AWGN broadcast channels (AWGN-BC) by extending two of the exising feedback coding schemes for feedback channels, a RNN based scheme and a lightweight-MLP scheme. Further, a new vertical fedearted learning based training scheme is proposed, which reflects a real world scenario more closely. Finally the authors peroform an emoirial study to demonstrate the benefits of each coding scheme under different channel conditions."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Relatively unexplored problem space. While deep learning based feedback schemes are well studied for single user AWGN channels, utility of the same for broadcast channels is not well studied and open for improvements. \n2. The paper is well written overall and easy to follow for someone familiar with the problem space. \n3. The concept of federated training of encoder and decoders is novel and interesting and relevant to practical settings. \n4. Performance gains over existing linear schemes is non-trivial and compelling. \n5. The takeway on LightBC being a better choice in low-noise scenarios and RPC-BC being better in high-noise scenarios is sn interesting observation."
            },
            "weaknesses": {
                "value": "1. Limited novelty from an architecture and training perspective, as both RPC and LightCode schemes are being reused directly from existing works. \n2.  No system model included in the main body of the paper, making the problem setup hard to grasp.\n3. Throughout the paper, there was the mention of LightCode being simpler than RPC. But there is not study on the complaexity, memory, and run-time comparison between the schemes makaing it harder to understand the difference between the schemes in terms of resource overhead. \n4. Authors mention in introduction that the capacity of AWGN-BC channel increases in presence of feedback. In the experiemnts section, it would be interesting to see some discussion on this and how the feedback is impacting the performance. Specifically, a reference line indicating the capacity of the channel would make it easier to comprehened the efficiency of the proposed scheme compared to the theoretical limits. \n5. Captions to the figures are rather short and very informative. I suggest updating all the captions to reflect the key takeaway. \n6. Experimental section is written poorly. It's not immediately apparent what authors mean by \"Lin.\" in the plots. More discussion should go into explaining the figures well.\n7. Lack of proper baselines. Since the authors propose modifying two schemes that were originally proposed for single user case, there should be atleast one more learning-based baseline that was designed for 2-user case. The reference Li. et al. \"Deep learning-aided coding for the fading broadcast channel with feedback\" would be a good baseline (despite the BPSK modulation).\n\nMisc.\nMinor typos and grammatical errors should be corrected throughout the paper. ex. in line 147 - \"receives\""
            },
            "questions": {
                "value": "Included everything in the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}