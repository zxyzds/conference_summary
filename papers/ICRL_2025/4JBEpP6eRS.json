{
    "id": "4JBEpP6eRS",
    "title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment",
    "abstract": "Selecting high-quality, aligned fine-tuning data is crucial for improving the downstream performance of language models (LMs). Automatic data selection in these scenarios is challenging and often inefficient due to previous approaches relying on neural embeddings or limited n-gram representations to identify aligned datasets. In addition, traditional data selection methods often focus on increasing the size of the training data, making them computationally expensive to use and data inefficient. In this work, we introduce ZIP-FIT, an embedding-free, data-efficient selection framework that leverages gzip compression to measure the alignment between training data and target domains. We show that ZIP-FIT significantly outperforms two leading baselines, DSIR and D4, in selecting high-quality data for ProofNet, a formal mathematical dataset, and HumanEval, a benchmark for code generation tasks. Specifically, ZIP-FIT demonstrates a computational speed advantage, performing data selection up to  65.8\\% faster than DSIR and achieving its lowest cross-entropy loss up to 85.1\\% faster. Our findings suggest that ZIP-FIT offers a scalable and adaptable approach for data selection, enabling more precise fine-tuning for code generation domains. By demonstrating that embedding-free data selection can outperform established methods like DSIR and D4, our research opens new avenues for optimizing model training, thereby enhancing the effectiveness and efficiency of machine learning workflows.",
    "keywords": [
        "data centric machine learning",
        "autoformalization",
        "large language models",
        "reasoning"
    ],
    "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)",
    "TLDR": "use gzip to select optimal data for code and autoformalization",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=4JBEpP6eRS",
    "pdf_link": "https://openreview.net/pdf?id=4JBEpP6eRS",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces a new data selection mechanism based on text\ncompression distances. The concept of using compression methods for\ndeep learning follows several modern practical results and theoretical\nmotivations that language modeling is fundamentally based in text\ncompression. The method's conceptual simplicity combined with strong\nempirical results make it stand out as a modern way for filtering for\naligned data."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "The paper is concise, sound, well written, and the experimental section shows promise for the method, especially with regard to other embedding-free methods.\n\nThe conceptual simplicity combined with the empirical results of the method is an especially strong point of the work."
            },
            "weaknesses": {
                "value": "Ideally, it would be shown how the size of $n$ (i.e., number of\nsamples from the target domain $p$) influences the performance of the\nmethod. If it is possible to pick $n$ just sufficiently large enough,\nit would greatly improve the computational efficiency of the method\nfor large target datasets.\n\nExperiments in other domains would be really nice to better\ndemonstrate the generalization capabilities of the method. Possibly\nthere is data that is not well-suited to compression and accordingly\nZIP-FIT, or where the data's compression factor varies too much\nbetween samples?"
            },
            "questions": {
                "value": "### Minor comments\n\nFigure 3, page 5:  \nThe color bar is labeled \"Gzip Alignment\" instead of\n\"ZIP-FIT-Alignment\" from Algorithm\u00a01; it may be confusing to readers.\n\nFigure 3, page 5, line 231:  \nPlease mention also in the figure caption that the test loss is\ncalculated on ProofNet data."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces ZIP-FIT, an embedding-free data selection method leveraging gzip compression to measure the alignment between training and target domains. Unlike existing approaches that rely on neural embeddings, ZIP-FIT uses a computationally efficient compression-based alignment metric, enabling faster data selection while maintaining high relevance to the target task. Empirical evaluations demonstrate ZIP-FIT\u2019s superiority over baselines DSIR and D4 in AutoFormalization and code generation tasks, achieving significantly faster convergence and lower cross-entropy loss with reduced computational costs. ZIP-FIT\u2019s promise lies in its scalability and effectiveness, particularly in low-resource settings, where traditional embedding-based methods may be impractical."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. ZIP-FIT\u2019s embedding-free approach is a refreshing deviation from common embedding-based methods, offering a novel solution by leveraging gzip compression. The concept of using normalized compression distance (NCD) as an alignment metric is insightful and could inspire future research in embedding-free methodologies for various data selection tasks.\n2. The empirical results support the claims, showing that ZIP-FIT achieves faster convergence and better performance than established methods. The experiments were conducted on both AutoFormalization and code generation tasks, demonstrating ZIP-FIT's versatility across different domains.\n3. The paper is well-structured, with a clear exposition of the algorithm, experimental setup, and results. The figures effectively illustrate the performance benefits of ZIP-FIT.\n4. ZIP-FIT could represent a significant advancement in data selection for machine learning, particularly in computationally constrained environments. Its potential to optimize model fine-tuning with minimal resource requirements makes it highly applicable for real-world use cases, especially in domain-specific and low-resource applications."
            },
            "weaknesses": {
                "value": "1. While ZIP-FIT achieves excellent results on the tasks tested, its reliance on gzip compression may limit its effectiveness in complex semantic domains where relationships are nuanced and less compressible. Embedding-free approaches, while efficient, may not be ideal for tasks that require deep semantic understanding or complex syntactic relationships."
            },
            "questions": {
                "value": "1. Could you provide further insights into how ZIP-FIT might perform with data that have higher variability and diverse syntactic structures, such as conversational datasets?\n2. Can you clarify the theoretical basis for using gzip compression over other compression methods that might exploit redundancy differently? Would alternative compression algorithms affect the performance of ZIP-FIT?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes ZIP-FIT, an efficient, embedding-free method for selecting high-quality, domain-specific fine-tuning data for language models (LMs). Prior methods often rely on computationally expensive neural embeddings or classifiers to filter aligned datasets, while those based on N-gram similarity may lack the structural depth needed for complex tasks like code generation. In contrast, ZIP-FIT leverages gzip compression to evaluate data alignment with target domains, based on the idea that compression algorithms encode information in a way similar to neural networks. The ZIP-FIT approach eliminates the need for LM forward passes to obtain embeddings, making it efficient and particularly suitable for low-resource environments. Experimental results show that ZIP-FIT outperforms prior data selection methods, such as DSIR and D4, as measured by test loss."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This paper is well-presented and well-motivated.\n- Studying computation-efficient methods for data selection in LLM instruction fine-tuning is a promising research direction.\n- The proposed ZIP-FIT is intuitive and easy to follow.\n- The proposed approach bypasses the need for LLM forward computation to obtain embeddings, making it computationally efficient.\n- The presented experimental results seem promising."
            },
            "weaknesses": {
                "value": "- [Major] The proposed method seems very simple and straightforward; using a gzip-style method to embed data appears to be a relatively standard approach.\n- [Major] All experimental results are based on test loss, which may not be very reliable. It would be essential to conduct evaluations on some standard benchmarks, such as HumanEval and MBPP for code evaluation, to demonstrate the scores the model can achieve.\n- It is unclear how the proposed ZIP-FIT compares to prior, more complex data selection methods in terms of both running speed and final model quality (e.g., [1]), aside from deduplication approaches like D4.\n- [Minor] The paper seems to be written somewhat in rush, the figure quality of Figure 2 does not seem to be very high.\n\n[1] https://arxiv.org/abs/2405.00705"
            },
            "questions": {
                "value": "As specified in the \"Weaknesses\" section:\n- What is the score of the fine-tuned LLM using ZIP-FIT on benchmarks like HumanEval and PubMedQA compare to LLMs fine-tuned without using ZIP-FIT?\n- How does ZIP-FIT compare to prior method like https://arxiv.org/abs/2405.00705 in terms of both running time and final model score?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces an innovative, embedding-free data selection method for efficient fine-tuning of large language models. Drawing inspiration from gzip compression techniques, the authors propose utilizing Normalized Compression Distance as a metric to filter and prune fine-tuning datasets. The authors conduct a comparative analysis with prior embedding-free methods, originally designed for filtering pre-training datasets, on Autoformalization and Python coding tasks."
            },
            "soundness": {
                "value": 1
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "(1) Problem Significance: The author tackles a crucial problem in low-resource settings, addressing the challenge of fine-tune data selection without relying on GPU-intensive and embedding-based methods. This is a highly relevant and impactful research direction.\n\n(2) Innovative Filtering Criterion: The authors' inspiration from gzip compression methods has led to the proposal of a novel and intriguing selection criterion. This approach is not only interesting but also demonstrates out-of-the-box thinking, making it a notable contribution to the field."
            },
            "weaknesses": {
                "value": "(1) **Inadequate Baselines**: The authors propose a data selection method for model alignment, but only compare it with prior works such as DSIR and D4, which were primarily designed for data selection during the pre-training phase. A more comprehensive literature review on data pruning methods for model alignment is lacking, including embedding-based methods [1], LLM model response metrics [2], Gradient-based metrics [3],Quality metrics judged by LLMs [4], inference loss on evaluation sets [5].\n\n(2) **Evaluation Metrics**: The authors primarily use test data cross-entropy loss as the evaluation metric, results are thus not surprising given that the data selection method uses the test data to anchor the selection criteria. However, the authors do not compare their results with widely accepted metrics in the research community for the studied downstream tasks, such as:\n\n(a). Autoformalization: proof success rates on miniF2F [6,7]\n\n(b). Python coding: functionality pass rates (pass@k on HumanEval) based on unit-tests [8,9]\n\n\n(3) **Clarifications on Motivation**: In Section 2.3, the authors argue that n-grams fail to capture syntactic or structural relationships within the data, while hypothesizing that gzip does. However, this hypothesis is not supported by theoretical or empirical evidence, weakening the motivation for the proposed approach. It is also not compared on if the proposed approach is better or worse than high-resource methods, such as embedding-based methods.\n\nReferences: \n\n[1] DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection\n\n[2] From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning\n\n[3] LESS: Selecting Influential Data for Targeted Instruction Tuning\n\n[4] Alpagasus: Training a better alpaca with fewer data\n\n[5] Instruction Mining: Instruction Data Selection for Tuning Large Language Models\n\n[6] Autoformalization with Large Language Models\n\n[7] LEGO-Prover: Neural Theorem Proving with Growing Libraries\n\n[8] Evaluating Large Language Models Trained on Code\n\n[9] Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation"
            },
            "questions": {
                "value": "(1) Could the authors provide additional evidence to support the claim that gzip is effective in capturing syntactic and structural relationships in textual sequences?\n\n(2) Would the authors be able to demonstrate the effectiveness of their approach using evaluation metrics beyond cross-entropy test loss, and compare it to relevant baselines, such as those mentioned earlier?\n\n(3) Could you provide more insight into why D4 was excluded from the code generation experiments, and specifically how it affected model performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}