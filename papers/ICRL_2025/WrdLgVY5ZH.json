{
    "id": "WrdLgVY5ZH",
    "title": "Statistical Test on Diffusion Model-based Anomaly Detection by Selective Inference",
    "abstract": "Advancements in AI image generation, particularly diffusion models, have progressed rapidly. However, the absence of an established framework for quantifying the reliability of AI-generated images hinders their use in critical decision-making tasks, such as medical image diagnosis. In this study, we address the task of detecting anomalous regions in medical images using diffusion models and propose a statistical method to quantify the reliability of the detected anomalies. The core concept of our method involves a selective inference framework, wherein statistical tests are conducted under the condition that the images are produced by a diffusion model. With our approach, the statistical significance of anomaly detection results can be quantified in the form of a $p$-value, enabling decision-making with controlled error rates, as is standard in medical practice. We demonstrate the theoretical soundness and practical effectiveness of our statistical test through numerical experiments on both synthetic and brain image datasets.",
    "keywords": [
        "diffusion models",
        "anomaly detection",
        "statistical test",
        "selective inference"
    ],
    "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",
    "TLDR": "A new statistical test for anomaly detection using diffusion model is proposed based on selective inference framework.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=WrdLgVY5ZH",
    "pdf_link": "https://openreview.net/pdf?id=WrdLgVY5ZH",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a statistical significance test to reconstruction-based anomaly detection, enhancing the reliability of decision-making with synthetic images generated by AI. In the context of anomaly detection, the proposed DMAD-test method quantifies the statistical significance of anomalous regions using p-values, which helps reduce the false alarm rate. In the experimental section, DMAD-test and its variant, DMAD-test-oc, are evaluated on a synthetic dataset and a brain anomaly detection dataset."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper motivation is well presented. The problem the paper tackles is very important, as generative models may lead to deteriorate performance due to the quality of its output.\n\n2. The introduction of a statistical significance test to refine identified anomaly regions is quite novel, offering a new approach to anomaly localization."
            },
            "weaknesses": {
                "value": "1. The statistical test relies solely on the mean value of the identified anomalous region, without accounting for structural differences. In medical image anomaly detection, anomalous regions may have mean values similar to those of normal regions; however, the spatial structure of tissues and anatomical patterns often show significant differences. Without considering the structure difference in the statistical test, the obtained results may still suffer from large false detection.\n\n2. It is not clear how to generate the reference image for calculating the statistics.\n\n3. Although the paper includes visualization examples for brain image anomaly detection, it lacks quantitative results. Without a thorough quantitative comparison to prior methods, it is difficult to assess the significance and effectiveness of the proposed approach."
            },
            "questions": {
                "value": "Please refer to the weakness section for my questions and comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 1
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method for detecting and quantify the reliability of anomalous regions in images. In particular, the authors focus on images generated by diffusion model and use selective inference framework. The authors test the present method using numerical experiments and on a brain image dataset. The output of the proposed model is a p-value that can determine the significance of the detected anomaly."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) The authors address a highly relevant problem by proposing a method for anomaly detection. A method that identifies the significance of anomalies and enable automated anomaly detection in a hospital setting would be extremely useful and important.\n2) The authors test their proposed DMAD-test through numerical experiments and on a brain imaging dataset, which provides a good way of evaluating the method's effectiveness in different contexts."
            },
            "weaknesses": {
                "value": "3) The section on diffusion models feels somewhat out of place, as it mainly covers basic concepts without providing specifics about the model actually used. It may be more effective to reference the foundational paper on diffusion models and focus on describing details relevant to this study, such as was the same architecture of the diffusion model used for the real data and the experimental data? Could the authors provide more information on the model architecture, input image sizes, and preprocessing steps?\n4) Expanding on the previous point, the quality of reconstructed images is essential for the accuracy of the resulting p-values. Reporting image quality metrics like MMD (Maximum Mean Discrepancy), SSIM, or MS-SSIM would help assess the reconstruction quality. Specifically, calculating MMD/MS-SSIM between reconstructions and real healthy images would be informative, and it could also be insightful to compare these values between reconstructions of healthy images and those containing anomalies. For reference, Table 1 of https://arxiv.org/pdf/2307.15208 provides a similar evaluation. Including these metrics would significantly strengthen the paper\u2019s conclusions, especially considering that only 329 images were used to train the diffusion model on real data.\n5) Additional details on the images used would help readers better understand the study\u2019s setup when using the brain images. Are the images 2D or 3D brain images, and how were they pre-processed before analysis?"
            },
            "questions": {
                "value": "6) The submission used the ICRL 2024 template. Could the authors update the submission to use the ICRL 2025 template?\n7) Could the authors elaborate on what is the reference image? How is the reference image different than the reconstructed?\n8) Could the authors discuss their choice to focus on diffusion models rather than exploring alternative models like transformers? Why were diffusion models selected over transformers, could the authors compare the advantages and disadvantages of diffusion models versus transformers for this particular anomaly detection task? Could the authors discuss any prior work that has used transformers for similar tasks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a statistical framework for anomaly detection in medical images using diffusion models, emphasizing reliable decision-making through selective inference. The authors propose a Diffusion Model-based Anomalous Region Detection test, which quantifies the statistical reliability of detected anomalies by computing selective p-values. This approach allows for controlled error rates, supporting clinical applications where rigorous reliability is essential. They implement selective inference with a piecewise-linear reconstruction error function, leveraging polyhedral geometry, and validate their method through numerical experiments and brain imaging tests. The work aims to bridge the gap between generative AI and statistical rigor in medical diagnostics."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This approach leverages the unique combination of polyhedral and piecewise-linear functions in constructing a selective p-value, which allows the method to yield statistically sound inferences in an area where conventional anomaly detection techniques might lack formal reliability measures. The use of selective inference in the context of diffusion-based image generation is particularly novel, as the approach traditionally applies to feature selection in simpler models.\n\nThe authors provide a thorough theoretical foundation for their test. Their experiments demonstrate both the effectiveness and robustness of the method, detailing performance under various types of noise distributions and comparing it against other statistical tests like Bonferroni correction and permutation testing. Additionally, the stepwise construction and conditioning processes for selective inference are well-documented, highlighting the method\u2019s robustness and adaptability in different testing scenarios.\n\nThe paper is well-structured, with a logical progression from the theoretical underpinnings to the experimental validation. The core concepts, including the their test, selective p-value, and the role of selective inference, are clearly defined. Figures illustrating the architecture and reconstruction process enhance reader comprehension. The piecewise-linear and polyhedral properties are described in a way that allows technically proficient readers to understand the model\u2019s behavior and interpretability.\n\nThis work has some potential for impact. By providing statistical reliability measures via selective inference, the authors address a key limitation in deploying AI for clinical diagnostics: the need for transparent and error-controlled anomaly detection. The methodology\u2019s ability to maintain controlled false-positive rates aligns with clinical requirements, supporting better trust and broader adoption of generative AI in medical applications. This is a meaningful contribution."
            },
            "weaknesses": {
                "value": "The statement \"the diffusion model detects anomalies\" (p.4) is somewhat misleading, as the detection is more accurately based on comparing input and reconstructed images to highlight discrepancies. This phrasing implies the model actively detects anomalies, while in practice, it passively reconstructs images, with anomalies inferred from reconstruction errors. A more accurate description could clarify the diffusion model's role and prevent misinterpretation of the model's capabilities.\n\nMany plots, notably Figures 2, 3, and 5, lack essential elements like axis labels and legends, limiting their interpretability. For complex analyses like these, well-labeled figures are critical for readers to follow and validate the findings. \n\nGiven the complexity of the statistical testing framework, a visual illustration of the DMAD-test would be beneficial. Many statistical papers can be challenging to interpret without sufficient diagrams, and a schematic representation of the test could improve comprehension, particularly for readers unfamiliar with selective inference. This could be placed early on to guide readers through the methodology.\n\nWhile computational resources are mentioned, there is no discussion of computational time, which is critical for assessing the method\u2019s feasibility in practical applications. Adding specific timing metrics, ideally with a breakdown by test stage, would help readers gauge whether this approach could realistically be applied to clinical workflows.\n\nThe experiments focus on brain images with tumors, limiting the generalizability of the findings. Testing on a broader dataset, such as DeepLesion (https://nihcc.app.box.com/v/DeepLesion), or including non-tumor regions within volumes could provide a more comprehensive evaluation. Additionally, validating on datasets with a mix of normal and abnormal slices would assess the model's robustness and applicability to varied clinical scenarios.\n\nThe supplementary material mentions code, but it is unclear if this is executable code or pseudocode. Given the complexity of the statistical framework, accessible and runnable code would support reproducibility and encourage other researchers to build on this work. \n\nWhile the theoretical equations appear solid, some expressions, especially those in the SI framework, are intricate. Although no clear mistakes are present, a supplementary derivation or walkthrough of the core equations would support readers who may struggle with verifying them. This could be presented as an appendix to guide readers through critical steps and foster better understanding."
            },
            "questions": {
                "value": "- Could you clarify the reasoning behind describing the diffusion model as \u201cdetecting\u201d anomalies?\n- Could you provide details on the computational time required for the DMAD-test on a standard dataset? \n- Could you clarify whether the supplementary code provided is fully executable, and, if so, whether it includes detailed instructions for setup and testing?\n- Have you considered testing on broader datasets, such as DeepLesion or other modalities?\n- Given the computational complexity and reliance on high-level statistical inference, do you foresee any specific challenges in deploying this method in real-time clinical settings?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}