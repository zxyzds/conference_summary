{
    "id": "Nx4PMtJ1ER",
    "title": "Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes",
    "abstract": "Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via `which variables enter the differential of which other variables'. In this paper, we develop conditional independence (CI) constraints on coordinate processes over selected intervals that are Markov with respect to the acyclic dependence graph (allowing self-loops) induced by a general SDE model. We then provide a sound and complete causal discovery algorithm, capable of handling both fully and partially observed data, and uniquely recovering the underlying or induced ancestral graph by exploiting time directionality assuming a CI oracle. Finally, to make our algorithm practically usable, we also propose a flexible, consistent signature kernel-based CI test to infer these constraints from data. We extensively benchmark the CI test in isolation and as part of our causal discovery algorithms, outperforming existing approaches in SDE models and beyond.",
    "keywords": [
        "causality",
        "dynamical systems",
        "stochastic processes",
        "causal discovery",
        "signature kernel"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "We develop a kernel-based conditional independence test on \u2018path-space\u2019 and constraint-based causal discovery algorithms for SDE solutions that make use of the test for robust causal discovery.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Nx4PMtJ1ER",
    "pdf_link": "https://openreview.net/pdf?id=Nx4PMtJ1ER",
    "comments": [
        {
            "title": {
                "value": "Rebuttal by Authors (part 2)"
            },
            "comment": {
                "value": "## Questions\n\nIndeed, our key focus lies on inter-variable dependencies instead of on self-loops. We believe that in most practical settings, where one aims for causal discovery, (a) the key focus lies on inter-variable relationships, and (b) one may assume that self-loops always exist for essentially all variables. Assumption (b), that processes always feed into themselves is a reasonable assumption in physical systems and broadly applied, e.g., by PCMCI or as a blanket assumption in $\\delta$-separation in [1].\nThe power analysis in Figure 3 indicates that for our (or any) test to have non-zero power in finding inter-variable relations, we require a certain \u201csignal-to-noise\u201d ratio (in our case the ratio of inter-variable strength to self-loop strength). Hence, as the reviewer stated, we chose the values for self-loops and inter-variable strengths accordingly.\nOne issue arising in evaluating self-loops as part of causal discovery is that particularly in graphs with sparse inter-variable dependencies, there may be more self-loops than inter-variable edges. Hence, the normalized SHD (where normalization by the overall number of possible edges is important for meaningful comparisons across graphs with different numbers of vertices) would be heavily \u201cdiluted\u201d by the self-loops. Therefore, in our experiments we perform SHD for the inter-variable edges only. For example, in bivariate experiments we primarily aim at inferring $X \\to Y$ (instead of the other direction or no edge at all), but self-loops would have twice the effect on the overall score than the edge of interest.\n\n[1] Didelez, Vanessa. \"Asymmetric Separation for Local Independence Graphs.\" arXiv preprint arXiv:1206.6841 (2008)."
            }
        },
        {
            "title": {
                "value": "Rebuttal by Authors"
            },
            "comment": {
                "value": "We thank the reviewer for their time and detailed constructive feedback. We address all mentioned concerns and questions one by one.\n\n## Weaknesses\n\n1. We apologize, this is on us. In the more detailed description of the SDE model in Appendix A.2 in the revised version and Appendix A.1 in the old version (Intuition and details for the SDE model), we state in line 966 of the revised paper (line 920 in the old version) that we assume the diffusion coefficient to be block-diagonal. This critical assumption \u2013 as rightfully pointed out by the reviewer \u2013 has disappeared from the main text (likely during our \u201cshortening\u201d process to satisfy the tight space constraints) and should have been clearly mentioned right in the \u201cData generating process\u201d paragraph in line 50. We have added it back to where it belongs in the revised version (see also Appendix A.2 lines 967-971 in the revised version for the overall SDE structure).\\\nThe mentioned counterexample in [1] does not satisfy this assumption. With the block-diagonal diffusion structure (i.e., orthogonal diffusions) processes do have different distributions when given the same initial values (see also Theorem 4.1 and Assumption 2 (\u201corthogonal diffusion processes\u201d) in [2] for this statement). \n\n[1] Niels Hansen and Alexander Sokol, \u201cCausal interpretation of stochastic differential equations\u201d \\\n[2] Benjie Wang, Joel Jenning and Wenbo Gong, \u201cNeural Structure Learning with Stochastic Differential Equations\u201d\n\n2. We agree. The space constraints made it difficult to prioritize what to provide intuition for while keeping the main text self-contained. We have extended Appendix A.4 (Signature Kernel Details) in the revised version (Appendix A.3 in the old version) to include more intuition about signatures and the signature kernel:\\\nThe signature transform of a (potentially multidimensional) continuous path (or time series) is a sequence of iterated integrals, static features, which form an expressive representation of the path. An analogy is often drawn to monomials in (multiple) indeterminants, with which one can express continuous functions. Another useful analogy is the Fourier transform. While Fourier transforms (or wavelet transforms) capture the frequency content of different modes (over different times), the signature captures information about order, area, and so forth (due to the \\emph{iterated} integrals). For example, the depth 1 (or order 1) iterated integral describes the changes of each variable throughout the time interval; depth 2 describes the signed area that is swept by the curve (an illustration of depth 1 and 2 of a path can be found in [1]); higher depths capture properties of the volume, and so on, but those can be hard to grasp visually. We refer the reader to [2,3] as introductory texts on the signature (kernel) method that contain more visualizations and examples for building intuitions about these mathematical objects.\n\n[1] Morrill, James, Adeline Fermanian, Patrick Kidger, and Terry Lyons. \"A Generalised Signature Method for Multivariate Time Series Feature Extraction.\" arXiv preprint arXiv:2006.00873 (2020).\\\n[2] Chevyrev, Ilya, and Andrey Kormilitzin. \"A primer on the signature method in machine learning.\" arXiv preprint arXiv:1603.03788 (2016).\\\n[3] Lee, Darrick, and Harald Oberhauser. \"The Signature Kernel.\" arXiv preprint arXiv:2305.04625 (2023).\n\n3. We thank the reviewer for this helpful suggestion. We have added a new section A.1 in the Appendix including a table with mathematical notations."
            }
        },
        {
            "title": {
                "value": "Rebuttal by Authors"
            },
            "comment": {
                "value": "We thank the reviewer for their time, helpful feedback, and positive evaluation. We reply to the raised points one by one:\n\n## Weaknesses\n\n**Real-world examples:** We thank the reviewer for these excellent suggestions. \nWe have worked hard to benchmark our method on the proposed example from Gamella et al. 2024, which they curated in the notebook to also allow for comparison with an independent application of PCMCI+ (theirs). These experiments are currently running/work in progress and we are happy to provide results as soon as they come in.\n\n## Questions\n\nThanks for all these great catches, we have fixed/clarified all of these in the revised version."
            }
        },
        {
            "title": {
                "value": "Rebuttal by Authors"
            },
            "comment": {
                "value": "We thank the reviewer for their time, helpful feedback, and positive evaluation. We reply to the questions one by one:\n\n* \u201cwhat if the oracle is wrong?\u201d: While the oracle is never wrong (by definition), any practical CI test will sometimes make mistakes on finite data (type I and II errors). All constraint-based causal discovery methods (including PC, FCI, and all variants of PCMCI in the time series setting) perform adaptive (C)I tests, where subsequent tests depend on the outcomes of previous tests. While this is a widely acknowledged challenge faced by all constraint-based methods, how the final graph depends on type I and II errors remains an important open problem in the field. Spirtes and Meek already discussed it in 1995 [1]. They added a (from today\u2019s viewpoint somewhat limited) simulation study showing how sensitive different methods are to the different types of errors without a clear-cut conclusion (different benefits and drawbacks at different sample sizes for \u201cadjacency\u201d detection and \u201carrowhead\u201d detection, respectively). Instead, [2] provides theoretical results showing that the PC algorithm is uniformly consistent for high-dimensional settings under a mild sparsity assumption on the DAGs, where the number of nodes can grow quickly with the sample size. However, they critically rely on the restrictive assumption that the observational distribution is a multi-variate Gaussian for their finite sample results, where a strong theory for testing CI with partial correlations is available. \\\nIn summary, the reviewer puts their finger on an important open problem in constraint-based causal structure learning, highlighting the need for empirical simulation studies to evaluate the performance of any concrete method (as provided in our paper). We added this discussion with the two references as a novel Appendix section A.12 and linked it to the importance of having a consistent CI test (Appendix A.14 in the revised version and Appendix A.11 in the old version).\n* \u201cwhat if there are cycles?\u201d As we show in Example A.1 (Appendix A.3 in the revised version and Appendix A.2 in the old version), in the presence of cycles, it becomes impossible to infer the entire graph (even if there is no unobserved confounding). On cyclic graphs, our Algorithm 1 will output a supergraph of the true graph (in the oracle setting), i.e., if an edge is in the true graph, it is also in the algorithm's output, guaranteeing edges will not falsely be removed. The output may include additional edges that are not in the true graph.\\\nIn such situations where the unique true graph is impossible to obtain, one would typically attempt to characterize the entire set of graphs compatible with the testable conditional independencies (Markov equivalence class) in a parsimonious fashion (similar to the CPDAG for Markov equivalence classes of DAGs). A comprehensive characterization of the equivalence class of graphs (entailing the same set of separations) in the cyclic setting is an exciting direction for future work, which we touch upon in Section 5.\n* \u201csubsamples\u201d: We are not 100% sure we understand what is meant, but assume this question aims at the algorithm's sensitivity to fewer and fewer observed time points in the individual paths? Appendix B.3 (Figure 7) provides an analysis of how the CI test power (the critical component here) changes with the level of \u201cdata missingness,\u201d i.e., when dropping more and more observation points in the paths. Test power remains surprisingly strong, even for high levels of data missingness. (The influence of the number of paths, i.e., the sample size, is assessed in Figure 3 and varied throughout many of the other experiments.)\n\n\n[1] Spirtes, Peter, and Christopher Meek. \"Learning Bayesian networks with discrete variables from data.\" KDD. Vol. 1. 1995.\\\n[2] Kalisch, Markus, and Peter B\u00fchlman. \"Estimating high-dimensional directed acyclic graphs with the PC-algorithm.\" Journal of Machine Learning Research 8.3 (2007)."
            }
        },
        {
            "summary": {
                "value": "This paper introduces an innovative approach to uncovering causal relationships in stochastic processes, using conditional independence (CI) tests based on signature kernels to detect causal links within stochastic differential equation (SDE) models. It presents a comprehensive algorithm to reconstruct causal graphs, even with partially observed data and irregular sampling patterns. Benchmark tests show this method outperforms existing causal discovery techniques (in small graphs) in continuous-time settings, showing particular strength in cases with incomplete data and path-dependence (without need for hyper parameter tuning)"
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 4
            },
            "strengths": {
                "value": "- Provides a solid framework for causal inference in continuous-time SDEs, going beyond the limitations of traditional discrete-time models.\n- Introduces a practical CI test using signature kernels, suited for handling path-dependent random variables.\n- Shows strong performance with incomplete data and irregularly sampled time series.\n- Empirical tests and real-world examples, like pairs trading, demonstrate the algorithm\u2019s practical effectiveness and accuracy.\n- Method is not heavily dependent on hyper parameters."
            },
            "weaknesses": {
                "value": "- The paper assumes stationarity and acyclicity, which may restrict its use in scenarios where causal relationships change over time.\n- Limited discussion on performance of the algorithm if the IC Oracle is wrong.\n- While I appreciate the rigor in the paper, the length of the paper, considering the appendix is more than $2 /3$ of the page limit. Might be more suitable for a journal setting."
            },
            "questions": {
                "value": "- The  Oracle used for this algorithm, how likely it is to be wrong? How much it would affect the performance?\n- What happens if the underlying causal graph has a cycle? How does the algorithm handle this situation?\n- How does the algorithm handles the case where the observation in time is limited (subsampled) ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a sound and complete causal discovery algorithm for stochastic processes, incorporating a consistent signature kernel conditional independence test. The stochastic process is modeled using a stochastic differential equation (SDE), and the entire process is segmented into intervals that exhibit the Markov property with respect to an acyclic dependence graph."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The effect working on the 'continuous-time' path sequence is impressive.\n\n2. The signature kernel conditional independence test is a novel CI test for path sequences.\n\n3. The paper is well written, and the framework of the paper is straightforward.\n\n4. The proposed algorithm has been applied to a series of simulations and one real-world dataset."
            },
            "weaknesses": {
                "value": "1. There seems to be no assumption sections. The acyclic assumption seems like a common assumption used in many causal discovery methods; however, it is more restricted in this paper as a cycle could be easily created if the causal relations exist for both $X^i_{0,s}$ to $X^j_{s,s+h}$ and $X^j_{s+h,s+2h}$ to $X^i_{s+2h,s+3h}$. Such pairs of causal relations are allowed in many causal discovery methods for time series, such as PCMCI. Therefore, though the authors claim that the proposed algorithm will not rely on the 'discrete-time' assumption, they did not discuss the impact of not assuming a time lag based on the 'discrete-time' assumption and the additional limitations from the acyclic assumption in this paper, compared to many previous causal discovery algorithms. Hence, the limitation discussion and comparison is not comprehensive. The acyclic assumption in this context is not very practical.\n\n2. Does the proposed CI test only work in the specific setting of this paper? Could it be utilized outside of this setting, for more general time series?\n\n3. In the limitations and requirements section, it is stated that the proposed algorithm far exceeds other existing causal discovery methods for time series data, which may not be the best way to frame the discussion. For instance, in part (b), it is mentioned that the proposed algorithm can handle confounders; however, there are already many algorithms that allow for confounders in time series, such as LPCMCI [1] and tsFCI [2]. Additionally, there are algorithms for non-stationary time series, such as CD-NOD [3], and those with special periodic patterns, such as PCMCI$_{\\Omega}$ [4]. Therefore, it is difficult to conclude that the proposed algorithm far exceeds other related work, given different settings and assumptions.\n\n4. The number of baselines in the experiment results is limited for both causal discovery and the CI test. Please refer to the questions section for more details.\n\n5. Please correct me if I am mistaken, but it seems there is no computational complexity analysis or running time results provided.\n\n6. I may have misunderstood, but does the first selected interval of $[0, s], [s, h]$ have to start at the beginning? Based on line 233, there are two copies of vertex $V$. Does this imply $h = T$? If not, how many intervals are possible? If multiple intervals are allowed, can the acyclic assumption be relaxed since different time-ordered intervals resemble the concept of \"time lag\" in a 'discrete-time' setting?\n\n7. By intuition, is having $V_0$ and $V_1$ essentially a sub-sampling technique, where samples in $[0,s]$ and samples in $[s,h]$ are considered? The full causal graph that the algorithm aims to discover is restricted to this $V_0$ and $V_1$, and the estimated causal graph will be influenced by the intervals selected. Again, the full causal graph discussed here is different from the one in many causal discovery algorithms, referred to as the full time causal graph, which does not require sub-sampling and is more comprehensive. Therefore, this discussion needs to be handled with care.\n\n[1]Gerhardus, Andreas, and Jakob Runge. \"High-recall causal discovery for autocorrelated time series with latent confounders.\" Advances in Neural Information Processing Systems 33 (2020): 12615-12625.\n\n[2]Entner, Doris, and Patrik O. Hoyer. \"On causal discovery from time series data using FCI.\" Probabilistic graphical models 16 (2010).\n\n[3]Huang, Biwei, et al. \"Causal discovery from heterogeneous/nonstationary data.\" Journal of Machine Learning Research 21.89 (2020): 1-53.\n\n[4]Gao, Shanyun, et al. \"Causal discovery in semi-stationary time series.\" Advances in Neural Information Processing Systems 36 (2024)."
            },
            "questions": {
                "value": "1. Could you briefly explain how to incorporate or partially incorporate PC and FCI into the proposed algorithm, given that both assume IID samples? Is any adjustment needed for non-IID samples?\n\n2. Do KCIPT and SDCIT require IID samples as well? If so, a similar question arises as in item 1.\n\n3. Are the simulated datasets used in the experiments 'continuous-time'? If so, how do you choose the discretization interval for PCMCI and other baselines that assume 'discrete-time'? Does using different discretization intervals influence their performance? How do you compare the output of PCMCI and the proposed algorithm, given that PCMCI includes time lags and may cause 'cycles' according to the definitions in this context?\n\n4. Are you considering using more baselines designed for time series, particularly non-stationary time series? The number of baselines included is limited. Is there a specific reason for not using metrics such as F1 score, precision, and recall but just SHD?\n\n5. Is there a power analysis for the conditional test, and how does it perform with different conditioning sets?\n\n6. Could you explain how to obtain bi-directed edges as shown in Figure 4?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper makes contributions to causal discovery in stochastic dynamical systems. In particular, it introduces a novel framework of conditional independence constraints in SDE processes, which are then leveraged to provide a causal discovery (CD) algorithm. The authors also provide a conditional independence (CI) test to evaluate these constraints from data. The authors evaluate the CD algorithm on synthetic data and compare it to other state-of-the-art baselines. They also evaluate their CI test on synthetic data and in a small case study on stock trading pairs."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is well-written and a pleasure to read. All theoretical claims are backed by careful proofs, and care is taken to ensure reproducibility of their experimental results. The authors openly address the limitations of their methodology,  and additional interesting results and discussions are provided in a well-organized and comprehensive appendix.\n\nI believe the paper earns its place in the suite of tools for causal inference with time-series data from dynamical systems. In my opinion, this is a high-quality paper that deserves acceptance."
            },
            "weaknesses": {
                "value": "The only major weakness is the lack of real-world experiments for the causal discovery algorithm, which I understand to be the main contribution of the paper. Only the CI test has a real-world data experiment on a downstream task, which I found creative and is well-documented in the appendix.\n\nNaturally, because we are in causal inference, real-world data with a ground truth can be difficult to find. However, I would like to point the authors to two recent papers that provide real-world data with a causal ground truth and whose settings appear to be a good fit for the method in this paper:\n\n**\u201c[Causal discovery in a complex industrial system: A time series benchmark](https://arxiv.org/abs/2310.18654)\u201d by Mogensen et al. (2023).**\n\nThe paper presents a real-world dataset from a dynamical system with partially observed data. The authors provide a ground-truth causal graph (section 2.4). The paper comes with a website (https://soerenwengel.github.io/essdata) with links to the dataset and preprocessing code.\n\n**\u201c[The Causal Chambers: Real Physical Systems as a Testbed for AI Methodology](https://arxiv.org/abs/2404.11341)\u201d by Gamella et al. (2024)**\n\nThe authors build two physical devices, one of which (wind tunnel) produces real-world, time-series data from a dynamical system. There is a causal ground-truth graph for this system (Figure 3), which the authors use to benchmark the PCMCI+ algorithm (Figure 6a). I believe this is an extension of one of your baselines (PCMCI), which makes me suspect your method is also applicable. The authors provide a well-documented [notebook ](https://github.com/juangamella/causal-chamber-paper/blob/main/case_studies/causal_discovery_time.ipynb) to download the dataset and reproduce the PCMCI+ experiment. Using your method may be plug-and-play in this case.\n\nThere may be other suitable real-world datasets, but I found none after this search. A real-world experiment for the main contribution of the paper (the causal discovery algorithm) would further elevate the value of the paper, and I would be happy to raise my score as a result. This is only a suggestion, and my decision to accept is independent of whether the authors do this or not."
            },
            "questions": {
                "value": "Some minor typos and unclear sentences:\n\n- Line 421: \u201ceven in the settings it was tailored to\u201d -> what was tailored to these settings, SigKer or the state of the art?\n- For figure 2, maybe explicitly say which graph is the lifted graph (right) and which is G (left)\n- Line 157: \u201cis inapplicable\u201d -> \u201cit is inapplicable\u201d?\n- Some pedantic styling comments:\n- Line 105: you have double parenthesis with the citation to Laumaann et al.\n- Lines 170,200,420:  you appear to be using hyphens (-) instead of em dashes (---) for interjections. See the JMLR formatting guide (under dashes): https://www.jmlr.org/format/format.html"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel approach for causal discovery in stochastic processes modeled by stochastic differential equations (SDEs). The authors propose a conditional independence (CI) test based on signature kernels, which enables the identification of causal relationships in continuous-time dynamical systems, even under irregular or partially observed data. Key contributions include a causal discovery algorithm that leverages the directionality of time, as well as an efficient signature kernel-based CI test."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper is well-motivated, presenting a clear need for improved causal discovery methods within the context of stochastic processes.\n2. Extensive experimental evaluations support the effectiveness of the proposed approach. The method demonstrates consistent superiority over several baseline models, underscoring its potential contributions to the field."
            },
            "weaknesses": {
                "value": "1.\tThe paper\u2019s claims regarding diffusion-dependence cases may be somewhat overstated. In particular, for SDE models involving \"driving noise\" (i.e., cases where the diffusion coefficient depends on $X_t$), certain **causal graphs may not be identifiable from observational data**. See example 5.5 in https://projecteuclid.org/journals/electronic-journal-of-probability/volume-19/issue-none/Causal-interpretation-of-stochastic-differential-equations/10.1214/EJP.v19-2891.full. In such cases, identifying the generator of the SDE model\u2014so as to identify the post-interventional distribution\u2014may be a more reasonable goal, as explored inhttps://proceedings.neurips.cc/paper_files/paper/2023/file/ca642f8e1174012d67c05c1c9f969644-Paper-Conference.pdf for linear SDEs. This may also provide some insight into the **diffusion-dependence** results presented in Table 1, where the proposed method shows comparatively lower performance.\n2.\tThe section on signature kernels in Section 2 is mathematically dense and may be challenging for readers unfamiliar with the topic. Including more intuitive explanations would enhance accessibility.\n3.\tGiven the extensive use of mathematical notations, a summary table listing the key notations could be helpful for readers in following the manuscript\u2019s developments."
            },
            "questions": {
                "value": "The experimental setup involves setting small parameters for self-loops (e.g.,  $a_{ii} \\sim  U([-0.5, 0.5])$), while the parameters influencing causal effects between different variables are set higher (e.g., $a_{ij} \\sim U([-2,-1] \\cup [1, 2])$). While I understand this may help to emphasize inter-variable causal relationships, practical applications may not always exhibit this distinction so clearly. Additionally, could the authors clarify whether errors related to self-loops are reported in the Structural Hamming Distance (SHD) results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}