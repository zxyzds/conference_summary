{
    "id": "XFYUwIyTxQ",
    "title": "EmbodiedSAM: Online Segment Any 3D Thing in Real Time",
    "abstract": "Embodied tasks require the agent to fully understand 3D scenes simultaneously with its exploration, so an online, real-time, fine-grained and highly-generalized 3D perception model is desperately needed. Since high-quality 3D data is limited, directly training such a model in 3D is infeasible. Meanwhile, vision foundation models (VFM) has revolutionized the field of 2D computer vision with superior performance, which makes the use of VFM to assist embodied 3D perception a promising direction. However, most existing VFM-assisted 3D perception methods are either offline or too slow that cannot be applied in practical embodied tasks. In this paper, we aim to leverage Segment Anything Model (SAM) for real-time 3D instance segmentation in an online setting. This is a challenging problem since future frames are not available in the input streaming RGB-D video, and an instance may be observed in several frames so efficient object matching between frames is required. To address these challenges, we first propose a geometric-aware query lifting module to represent the 2D masks generated by SAM by 3D-aware queries, which is then iteratively refined by a dual-level query decoder. In this way, the 2D masks are transferred to fine-grained shapes on 3D point clouds. Benefit from the query representation for 3D masks, we can compute the similarity matrix between the 3D masks from different views by efficient matrix operation, which enables real-time inference. Experiments on ScanNet, ScanNet200, SceneNN and 3RScan show our method achieves state-of-the-art performance among online 3D perception models, even outperforming offline VFM-assisted 3D instance segmentation methods by a large margin. Our method also demonstrates great generalization ability in several zero-shot dataset transferring experiments and show great potential in data-efficient setting. Code and demo will be released.",
    "keywords": [
        "3d instance segmentation; online 3d scene segmentation"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We presented EmbodiedSAM, an efficient framework that leverages vision foundation models for online, real-time, fine-grained and generalized 3D instance segmentation.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=XFYUwIyTxQ",
    "pdf_link": "https://openreview.net/pdf?id=XFYUwIyTxQ",
    "comments": [
        {
            "summary": {
                "value": "This paper leverages SAM for 3D instance segmentation, incorporating a geometry-aware query lifting module that transforms 2D masks into fine-grained 3D shapes on point clouds. Using 3D queries, it efficiently merges 3D masks across frames through simple matrix operations. This design enables online, real-time 3D instance segmentation."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "Unlike approaches that apply SAM on individual images and project 2D masks onto 3D point clouds, this paper introduces a geometry-aware module that lifts 2D masks to 3D queries. This enables the prediction of temporally and geometrically consistent 3D masks using iterative query refinement.\n\nThis work eliminates the need for handcrafted merging strategies by instead identifying similarities between newly predicted and previously generated 3D masks, resulting in improved performance.\n\nAchieving real-time inference, and outperforming not only online methods but also offline methods."
            },
            "weaknesses": {
                "value": "The abstract and introduction quickly dive into the implementation without providing sufficient motivation to explain why this approach is taken. For instance, it lacks clarity on how 3D-aware is achieved, the role of queries, the need for iterative refinement, and the insight of the dual-level query decoder. Although the comparison with prior work is clear, the explanation of the proposed method lacks an overview, leaving out insights behind the approach."
            },
            "questions": {
                "value": "Lack of discussion with respect to :\nGaussian Grouping: Segment and Edit Anything in 3D Scenes\nLangSplat: 3D Language Gaussian Splatting\nSegment Any 3D Gaussians"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a real-time, online 3D instance segmentation method for embodied tasks, leveraging the Segment Anything Model (SAM) to address the lack of high-quality 3D data for direct training. Unlike existing methods, which are often too slow for practical use, this approach translates SAM\u2019s 2D masks into fine-grained 3D shapes via a geometric-aware query lifting module and a dual-level query decoder. This enables efficient object matching across frames, achieving state-of-the-art results on benchmarks like ScanNet and demonstrating strong generalization in zero-shot and data-efficient scenarios."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The writing is clear and easy to follow.\n2. The method is technically sound.\n3. The performance results are strong."
            },
            "weaknesses": {
                "value": "1. The camera's intrinsic and extrinsic parameters are crucial for this task. In embodied environments, it is very important to obtain accurate and stable intrinsic and extrinsic parameters. How can you acquire them in embodied environments? Whether the unstable and incorrect  intrinsic and extrinsic parameters affect the final results? Additionally, in lines 139-140, the point clouds are generated by projecting the depth image into 3D space using pose parameters. So, how are two point clouds aligned and merged? In real-world scenarios, point cloud alignment is also a significant issue.\n\n2. There is a lack of visualization for the point-wise weights predicted in Geometric-aware Pooling. Providing this visualization would clarify how the model weights features across different geometric regions.\n\n3. Regarding the class-agnostic 3D instance segmentation results compared in Table 1, the fairness of the comparison could be questioned. Since Open3DIS does not use semantic and instance labels for supervision, it may not be entirely fair to compare it with fully-supervised methods. I think a comparison with fully-supervised online 3D instance segmentation methods, as done in Table 3, would be more appropriate."
            },
            "questions": {
                "value": "See weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a geometry-aware query lifting module that represents 2D masks generated by SAM as 3D-aware queries. These queries are then iteratively refined using a similarity matrix between 3D masks from various viewpoints through a dual-level query decoder. EMBODIEDSAM partially addresses the offline and slow-processing issues present in most existing VFM-assisted 3D perception methods, making it more suitable for real-world embodied tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Using InsQuery instead of traditional handcrafted strategies achieves faster and geometrically consistent multi-frame mask merging, ultimately enabling real-time inference speed.\n2. The paper is well-structured and clearly written.\n3. The supplementary video demo effectively highlights the online, real-time, fine-grained, and highly generalized capabilities of EmbodiedSAM."
            },
            "weaknesses": {
                "value": "1. How is recognition achieved for any 3D object category? Why are the results in Table 1 for class-agnostic 3D instance segmentation\uff1f\n2. In Figure 4, it would be helpful to match the colors of predicted and ground truth instances for easier comparison.\n3. Provide additional comparisons with more recent offline methods, such as OpenMask3D[1] and OpenIns3D[2].\n\nReference:\n\n[1] Takmaz, Ay\u00e7a, et al. \"Openmask3d: Open-vocabulary 3d instance segmentation.\" arXiv preprint arXiv:2306.13631 (2023).\n\n[2] Huang, Zhening, et al. \"Openins3d: Snap and lookup for 3d open-vocabulary instance segmentation.\" arXiv preprint arXiv:2309.00616 (2023)."
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a method for online 3D instance segmentation. Given a sequence of posed RGB-D images, they first use SAM to acquire 2D masks, and unproject them to 3D superpoints using the depth maps. Then they propose a novel framework to aggregate geometric features of superpoints, followed by a dual-level query decoder to predict 3D masks. They additionally propose to leverage bounding boxes IOU and semantics to assist the similarity computation, and use feature contrasting to further improve the performance."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. Motivation: The paper proposes a novel framework for online, efficient 3D instance segmentation from RGB-D sequences, which is of high potential for embodied tasks.\n2. Contribution: The proposed framework is efficient in mask generation and query merging, and the use of the IOU and semantic are reasonable and effective.\n3. Performance: The performance greatly surpasses the baselines."
            },
            "weaknesses": {
                "value": "I'm not very familiar with the task of this paper and did not find obvious weaknesses in this paper. Please see the questions below."
            },
            "questions": {
                "value": "1. According to Table 5 and 6, the performance gains mainly come from the merging strategies. An ablation of the geometric-aware query lifting and dual-level query decoder would better evaluate the necessity of the proposed framework.\n2. According to Table 6, the computation of the similarity matrix in Eq.(7) plays a vital role, and it would be beneficial if can provide an ablation study on the weights of the different terms in Eq.(7). Besides, is directly adding them better than multiplying them?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a 3D instance segmentation method that is online, real-time, fine-trained and generalizable. Specifically it lifts the 2D segmentation masks generated by SAM to 3D using depth and uses the instance indices to group points into superpoints. It proposes a dula-level query decoder to use both points and superpoints for efficiently generating fine-grained masks. As an online method, it proposes a efficient way to merge masks at current timestamp to previous masks, which considers geometric similarity, contrastive similarity and semantic similarity. Because each superpoint has a feature vector, the similarities can be compuated as matrix operation for quick inference. Experiments were conducted on four baseline datasets and the proposed method outperforms both previous online methods and offline methods, and it also shows generalizability on zero-shot cases."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The paper proposes a novel way to lift 2D segmentation masks to 3D that is geometry aware. It also proposes an algorithm to better, efficiently merge 3D masks from different timestamps.\n2. The method can achieve better results on four datasets, most notably in a real-time way (can achieve 10 fps with FastSAM as backbone). This is very important for its application in real-world scenarios. \n3. The paper is well-organized and easy to follow."
            },
            "weaknesses": {
                "value": "1. All qualitative results are on ScanNet200. Wondering if the proposed method also has clear visual improvements on other datasets used in the paper.\n2. Since the method is targeted to be used in real-world embodied tasks and is supposed to generalize to unseen scenes, it would be more convincing if results on some real-world captures are included.\n3. For generating superpoint features in equation (3), why the $z^{global}$ is added instead of concatenated to the pooled point features? Also why using the original point features instead of $z^{local}$"
            },
            "questions": {
                "value": "1. Typo: L280: position pair-> positive pair\n2. All results included in the paper are class-agnostic. I am curious if the proposed method has advantages over all object categories equally or it works better on certain categories."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents EmbodiedSAM, a framework designed for online 3D instance segmentation, leveraging the Segment Anything Model (SAM). This method integrates SAM with a novel merging strategy that fuses geometric, contrastive, and semantic information to deliver high-efficiency segmentation of 3D objects in dynamic environments. By enabling real-time segmentation, EmbodiedSAM is positioned to enhance 3D perception tasks where immediate processing is critical. The framework is evaluated on several datasets, demonstrating its potential to perform effectively in real-world applications where timely response is essential."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to follow.\n2. The experiment part of this paper is sufficient.\n3. This paper provides a nice summary of existing works."
            },
            "weaknesses": {
                "value": "This paper is very interesting, I think it has reached the standard for acceptance at the conference, I only have a few simple questions.\n\n1. The Geo-aware Pooling module \bis a common technology. So, I think it should not be one of the main contributions of this paper, the whole pipeline is the most important design.\n2. As an online segmentation network, the author should report the time cost of each module, such as super point building, query refinement, and merging.\n3. The results presented in Table 6 should include more detailed explanations regarding the performance impact of removing each of the three auxiliary tasks (geometric, contrastive, and semantic similarities) in the merging strategy. This clarification is necessary to understand the individual contribution of each auxiliary task.\n4. The ablation study is conducted across different datasets, making it difficult to directly compare the results. It would be more effective to perform the entire ablation study on a single dataset to ensure clearer and more consistent analysis."
            },
            "questions": {
                "value": "See the \"weakness\" part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}