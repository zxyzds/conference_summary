{
    "id": "FZa1UCC9SC",
    "title": "Exact risk curves of signSGD in High-Dimensions: quantifying preconditioning and noise-compression effects",
    "abstract": "In recent years, SignSGD has garnered interest as both a practical optimizer as well as a simple model to understand adaptive optimizers like Adam. Though there is a general consensus that SignSGD acts to precondition optimization and reshapes noise,  quantitatively understanding these effects in theoretically solvable settings remains difficult. We present an analysis of SignSGD in a high dimensional limit, and derive a limiting SDE and ODE to describe the risk. Using this framework we quantify four effects of SignSGD: effective learning rate, noise compression, diagonal preconditioning, and gradient noise reshaping. Our analysis is consistent with experimental observations but moves beyond that by quantifying the dependence of these effects on the data and noise distributions. We conclude with a conjecture on how these results might be extended to Adam.",
    "keywords": [
        "signSGD",
        "stochastic optimization",
        "Deep learning theory",
        "high-dimensional probability",
        "stochastic differential equation"
    ],
    "primary_area": "optimization",
    "TLDR": "SDEs and ODEs for SignSGD in high-dimensions: identifying scheduling, preconditioning, noise compression effects.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=FZa1UCC9SC",
    "pdf_link": "https://openreview.net/pdf?id=FZa1UCC9SC",
    "comments": [
        {
            "title": {
                "value": "Weak approximation vs High-dimensional limit (pt2)"
            },
            "comment": {
                "value": "* The SDEs are substantially different, and this stems from a fundamental difference between Weak-approximation and high-dimensional limit theory.  In Weak-approximation, the formal comparison is:\n$$ \n\\max_{k=0, \\ldots,\\left\\lfloor T / \\eta^2\\right\\rfloor}\n\\left|\\mathbb{E} g\\left(x_k\\right)-\\mathbb{E} g\\left(X_{k \\eta^2}\\right)\\right| \\leq C \\eta^2 \n$$ \nThe constant $C$ depends on $g,T,$ and _crucially_ the dimension $d$. Hence, weak-approximation unfortunately says nothing about sequences of problems of growing dimension.  In our setup, we look at problems of growing dimension and obtain a dimension-independent bound on the approximation error (Theorem 1).\n* High-dimensionality has multiple consequences.  One is that the loss-curves _become deterministic_ as dimension grows.  Hence we can describe them by a deterministic system of ODEs (Theorem 2), which are influenced by all the sources of noise (label-noise and gradient-noise).  One of the criticisms made was:\n> **Currently, insights are derived primarily about the SDEs rather than the optimizers themselves but are framed as insights on the optimizers.**\n\nThe main goal of high-dimensional analysis is to understand the behavior of the optimizers themselves _through_ the SDEs. The self-averaging seen in high-dimensions makes this possible; this is what makes the\ntrue risk trajectory comparable to the SDE risk trajectory (and, indeed, the averaged SDE risk described by our ODEs). This is the key content in Theorem 1 of our paper.\n\n* Another consequence of high-dimensionality is that our SDE is easier to interpret: from the Malladi et al SDE, we cannot see the $\\psi$ factor or the $K_\\sigma$, whose properties we develop from (Eqn 16) on in the paper.  High-dimensionality is a _key_ ingredient to this; we are putting additional restrictions on the problem setup in order to gain more information about the behavior of the optimizer.  We do not believe the type of conclusions we draw about the high-dimensional SDE and ODE (especially Theorems 3 and 4) can be derived from the Malladi et al SDE, because the key high-dimensional simplifications are not built-into that framework.\n\n* Once the problem instance has been specified (data covariance, noise structure, learning rate), we can solve the high-dimensional SDEs and corresponding ODEs for the risk and other quantities. This makes our\nhigh-dimensional approach a good tool for understanding how different aspects of the problem interact with the optimizer to generate learning dynamics. In contrast, Malladi et al. do not consider an optimization problem, and instead consider a `noisy gradient model;' a major contribution of our paper is characterizing the optimization consequences of properties of SignSGD through its ODEs (esp. Theorems 3 and 4). Nonetheless, we propose to include the detailed comparison to Malladi et al in the Appendix of the paper and include a shorter comparison in the main text.\n\n* You also mention that a major limitation of Theorem 1 was the restriction to risk:\n> While your paper provides guarantees for the risk (as per Theorem 1), extending these guarantees to other critical aspects\u2014such as the gradient norm and the norm of the iterates (as defined in Definition 2 of Li et al.)\u2014would strengthen the validity of your models.\n\nWe agree. In fact, the main theorem in the Appendix (Lemma 3) does compare other statistics, including the very-important distance to optimality and norm of the iterates. The gradient norm, in our setup is actually given by the $\\mathcal{P}$, which is already covered by Theorem 1. We will clarify this point in the main text, and add some additional discussion around other optimizer statistics.\n\n* There were additional concerns about experimental validations:\n>Incorporating experimental validation of your results and insights would greatly enhance the manuscript. Validating the theoretical findings empirically will demonstrate the practical applicability of your SDE models and confirm that they are informative.\n\nWe note that Figure 1 in the original submission already shows correspondence between the raw signSGD simulation and our derived SDE and ODE. The SDE well-captures the distribution (80% CI plotted in figure 1, raw\nsignSGD in purple, SDE in yellow), and the ODE representing the average well describes both the average of the raw signSGD, but also the typical trajectory as well (given that the 80% CI envelope has the same shape as the ODE).\nThe simulations in the original paper were done at fixed dimension $d = 500$; we are preparing additional simulations which show that increasing $d$ improves the convergence of the process to the SDE as our\ntheorem suggests.\n\nWe look forward to discussing further with you in the rebuttal period, and we reiterate that we will include a full response soon.\n\nThe authors."
            }
        },
        {
            "title": {
                "value": "Weak--approximation vs high-dimensional limit"
            },
            "comment": {
                "value": "Dear Reviewer QUHk,\n\nFirst, thank you for the exceptionally thorough review that you have performed of our paper. Regardless of the outcome of the review process,\nyour feedback has already helped us improve the paper.\n\nMuch of your review discusses the Weak-Approximation framework. We agree that a comparison between our work and the Weak-Approximation framework will improve our paper. The Weak-Approximation approach is quantitatively and qualitatively different from our approach, and we would like to explain the details here.\nWe will make a more detailed, itemized response to your points later, but we wanted to begin discussion of this substantial point of your critique first.\n\nThe Weak--approximation SDE is the following:\n\n(Malladi et al. -- Adam SDE, Def 4.4).  Let $c_1 \\triangleq\\left(1-\\beta_1\\right) / \\eta^2, c_2 \\triangleq\\left(1-\\beta_2\\right) / \\eta^2$. Let $\\gamma_1(t) \\triangleq 1-\\exp \\left(-c_1 t\\right)$ and $\\gamma_2(t) \\triangleq 1-\\exp \\left(-c_2 t\\right)$. Define the state of the SDE as $\\boldsymbol{X}_t=\\left(\\boldsymbol{\\theta}_t, \\boldsymbol{m}_t, \\boldsymbol{u}_t\\right)$ and the dynamics as\n\n$$\n\\mathrm{d} \\boldsymbol{\\theta}_t=-\\frac{\\sqrt{\\gamma_2(t)}}{\\gamma_1(t)} \\boldsymbol{P}_t^{-1} \\boldsymbol{m}_t \\mathrm{d} t,\n$$\n$$\\mathrm{d} \\boldsymbol{m}_t =c_1\\left(\\nabla f\\left(\\boldsymbol{\\theta}_t\\right)-\\boldsymbol{m}_t\\right) \\mathrm{d} t+\\sigma_0 c_1 \\boldsymbol{\\Sigma}^{1 / 2}\\left(\\boldsymbol{\\theta}_t\\right) \\mathrm{d} \\boldsymbol{B}_t\n$$\n$$\n\\mathrm{d} \\boldsymbol{u}_t  =c_2\\left(\\operatorname{diag}\\left(\\boldsymbol{\\Sigma}\\left(\\boldsymbol{\\theta}_t\\right)\\right)-\\boldsymbol{u}_t\\right) \\mathrm{d} t\n$$\n$$\n\\boldsymbol{P}_t:=\\sigma_0 \\operatorname{diag}\\left(\\boldsymbol{u}_t\\right)^{1 / 2}+\\epsilon_0 \\sqrt{\\gamma_2(t)} \\boldsymbol{I}\n$$\nwhere, $\\boldsymbol{B}_t$ is $d$-dimensional Brownian motion.  \n\nTo recover SignSGD from ADAM, we would take $\\beta_2=0$ and $\\beta_1=0$.  The noisy gradient model which most closely reproduces our setup has  $\\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}_t) = \\boldsymbol{K}{2\\mathcal{P}(\\theta_t)}$ with $2\\mathcal{P}(\\theta_t)$ as in (Eqn 2) of our paper.  (Note Malladi et al also has RMS-Prop, with a slightly simpler SDE.  But even recovering the RMS-Prop SDE from the ADAM SDE requires taking a nontrivial limit $c_1 \\to \\infty$.  We will add an appendix to the paper in which we take these limits; even after doing so, however, the resulting SDE is substantially different from ours).\n\nIn comparison, our SDE is given by (Eqn 7):\n$$\\mathrm{d} \\Theta_t=-\\eta_t \\frac{\\varphi\\left(\\mathcal{R}\\left(\\Theta_t\\right)\\right)}{\\sqrt{2\\mathcal{R}\\left(\\Theta_t\\right)}}\\overline{\\mathbf{K}}\\left(\\Theta_t-\\theta_*\\right)\\mathrm{d} t+\\eta_t \\sqrt{\\frac{\\mathbf{K}_\\sigma}{\\pi d}} \\mathrm{d}\\mathbf{B}_t$$\n\nThe SDEs are different in many ways.  In the comment below, we discuss in detail some of these details."
            }
        },
        {
            "summary": {
                "value": "This paper studies SignSGD to have better qualitative understanding of this algorithm, especially in the high-dimensional limit. The authors derive SDE and ODE for the limiting equation as continuous approximation of SignSGD. Using this framework they quantify four effects of SignSGD: effective learning rate, noise compression, diagonal preconditioning, and gradient noise reshaping. They finally conjectured how this might be extended to ADAM."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) The presentation is very clear;\n\n(2) The results present a good quantitative understanding of SignSGD;\n\n(3) A comparison with vanilla SGD is provided;"
            },
            "weaknesses": {
                "value": "Overall, the paper looks good."
            },
            "questions": {
                "value": "Using continuous approximation may explain features of SignSGD but only at the qualitative level. At the quantitative level, long-time behavior of SignSGD and its continuous approximation may be very different. Can the authors explain more about this situation? This may include:\n\n(1) Discuss any theoretical or empirical evidence the authors have for how well the continuous approximation matches discrete SignSGD over long time horizons.\n\n(2) Clarify if there are specific regimes or conditions where the authors expect the approximation to break down for long-time behavior.\n\n(3) Consider adding a discussion of the limitations of the continuous approximation approach, particularly for long-time dynamics, to their paper.\n\nA suggested reference paper: Kushner, H. J. (1982). A cautionary note on the use of singular perturbation methods for \u201csmall\nnoise\u201d models. Stochastics: An International Journal of Probability and Stochastic Processes, 6(2):117\u2013120."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The objective of this paper is to study SignSGD under the lens of SDEs in high dimensions. They try to use this continuous-time model to unveil some aspects of the dynamics of SignSGD such as i) Its effective learning rate; ii) Noise compression; iii) Preconditioning iv) Gradient noise reshaping. They provide some limited experimental evidence supporting their claims and close by highlighting that they expect these findings to be extended to Adam as well."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- **Originality:** The authors attempt to contribute by deriving an SDE for SignSGD in a simple high-dimensional setup, which appears to be a new direction in modeling this optimizer.\n\n- **Quality:** The derivation of an ODE that models the risk function for linear regression based on this SDE provides an interesting theoretical perspective which is also partially corroborated empirically.\n\n- **Significance:** The use of this model to predict the asymptotic expected risk level under Gaussian label noise offers some potential insights into SignSGD\u2019s behavior in specific scenarios, though its practical relevance remains limited to the assumptions made.\n\n- **Clarity:** The paper presents the theoretical results in a generally understandable manner."
            },
            "weaknesses": {
                "value": "**Weak Points**\n\nSince there is no dedicated space to provide one, I will write my \"Overall Comment\" here. I relegate a \"Detailed Feedback\" to the Questions, where I corroborate more on the points below.\n\n**Overall Comment:** The paper addresses interesting questions and demonstrates potential through its mathematically sound approach. To enhance the quality and impact of the manuscript, I recommend focusing on several key areas for improvement, which are detailed below. Given the current status of the paper, I recommend **rejection**: Addressing these points could significantly strengthen the work which certainly deserves it.\n\n1. **Inclusion of Related Works:** To strengthen the manuscript, it would be beneficial to discuss existing literature on continuous-time modeling of optimizers, particularly the Weak-Approximation (WA) Framework introduced by Li et al. (2019). Including this framework and comparing it with your approach could provide valuable context and demonstrate how your work contributes to the field. Additionally, since the SDE of Adam has been derived by Malladi et al. (2022), and given that SignSGD is a special case of Adam, incorporating a comparison with these results would enhance the depth of the analysis. Including relevant references when stating key facts will also improve the manuscript's credibility (See below for details).\n\n2. **Assumption Justification and Validation:** Clarifying and justifying the assumptions upon which your analysis is based would strengthen the paper. Providing theoretical or experimental validation for these assumptions will help readers understand their appropriateness and relevance. It would also be valuable to explain any advantages your setup may have over the Weak-Approximation framework. For instance, elaborating on the necessity of the high-dimensional setup in your SDE derivations, especially when such a requirement is not present in weak approximations, could clarify the benefits of your approach.\n\n3. **Addressing Conceptual Missteps:** It's important to ensure that the continuous-time models derived in your work faithfully represent the behavior of the optimizers they are intended to model. While your paper provides guarantees for the risk (as per Theorem 1), extending these guarantees to other critical aspects\u2014such as the gradient norm and the norm of the iterates (as defined in Definition 2 of Li et al.)\u2014would strengthen the validity of your models. **Currently, insights are derived primarily about the SDEs rather than the optimizers themselves but are framed as insights on the optimizers.** To effectively carry these insights over to the optimizers, it would be beneficial to provide guarantees that the SDEs closely track the behavior of their respective optimizers or to include experimental verifications demonstrating this correspondence.\n\n4. **Inclusion of Experimental Validation:** Incorporating experimental validation of your results and insights would greatly enhance the manuscript. Validating the theoretical findings empirically will demonstrate the practical applicability of your SDE models and confirm that they are informative. For instance, if you derive a bound on the risk using an SDE, empirically verifying this bound for the respective optimizer would provide strong support for your theoretical claims.\n\n5. **Improving Structure and Clarity:** Enhancing the organization and clarity of the manuscript would significantly improve its readability and impact. Formalizing key results as Lemmas, Propositions, or Theorems, rather than discussing them in free text, would make the arguments more rigorous and easier to follow. Clearly defining all symbols and terms, such as \"Vanilla ODE,\" will help avoid confusion. Additionally, ensuring that figures are accessible to all readers, including those who are colorblind, by choosing appropriate color schemes and providing clear labels, will enhance the overall quality of the presentation.\n\nI have provided detailed feedback on these points in the **Questions** section below, where I elaborate further on how the manuscript can be improved.\n\n**References:**\n\n- Li et al. (2019) *\"Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations\"*.\n- Malladi et al. (2022) *\"On the SDEs and Scaling Rules for Adaptive Gradient Algorithms\"*."
            },
            "questions": {
                "value": "**Detailed Feedback:**\n\nIn the following, I provide detailed feedback. These points are generally marked in the same order as they appear in the paper and are not arranged by relevance.\n\n1. **Literature Review:** It would be beneficial to include a review of the literature surrounding continuous-time models for optimizers. In particular, discussing weak approximations (Li et al. 2019) could enhance the context of your work, as they have been successful in deriving SDEs and ensuring their accuracy. Additionally, since not all readers may be familiar with SDEs and the concept of continuous-time models, providing visual aids\u2014such as plotting a trajectory of the optimizer alongside that of the SDE\u2014could make these ideas more accessible.\n\n2. **Discussion of Limitations:** Including a section dedicated to the limitations of your approach would be appreciated. A subsection comparing your method with existing literature could provide readers with a clearer understanding of the advantages and potential drawbacks of your work.\n\n3. **High-Dimensional Setting Clarification:** It would be helpful to clarify why your derivations require the high-dimensional setting, especially since the Weak Approximation framework does not have this requirement and has been effectively used to derive SDEs for various methods like SGD (Li et al.), Adam and RMSprop (Malladi et al.), and SAM (Compagnoni et al.). Explaining could enhance readers' understanding of your approach.\n\n4. **Focus on Linear Regression Model:** It might be beneficial to explain why your analysis focuses on the linear regression model, particularly when the Weak Approximation framework allows for SDE derivations with relatively general loss functions. Highlighting any specific advantages your setting offers would strengthen your argument.\n\n5. **Relation to Existing SDEs:** Considering that the SDE of Adam/RMSprop has been derived by Malladi et al. (2022), and since SignSGD is a special case of these algorithms, it would be helpful if you could explain how their SDE relates to yours. Demonstrating this connection could enhance the comprehensiveness of your work.\n\n6. **Definition Clarity:** Regarding **Definition 1**, it appears that the risk definitions do not depend on the labels. It might improve clarity to list Assumption 1 first and then define the risks, enhancing the logical flow of your presentation.\n\n7. **Assumption 1 Concerns:** In deep learning, we often encounter overparameterized regimes where there are more parameters than data points, leading to potentially infinite solutions for the regression task. This could make the SDE ill-posed because you define it in terms of a specific $\\theta_*$, but the dynamics might converge to a different solution. This could result in the risk in the denominator approaching zero while the numerator does not. Therefore, it seems that the SDE may have **non-Lipschitz coefficients, which could hinder the existence and uniqueness of the solution**: Could you comment on this aspect?\n\n8. **Conceptual Mistake (Line 86):** In **Line 86**, the statement that \"an important characterizing feature of SignSGD is its effect on the covariance matrix K\" seems conceptually wrong. The matrix K is fixed and exists independently; it is not influenced by the choice of optimizer. Perhaps it would be more accurate to say that K influences SignSGD.\n\n9. **Universality Reference (Line 96):** In **Line 96**, you mention *universality* as if it's a commonly known concept. Providing a reference for this phenomenon and considering whether this is the best place to introduce it in your manuscript would be helpful.\n\n10. **Assumption 3 Organization and Discussion:** Regarding **Assumption 3**, presenting assumptions on the matrices immediately after their definitions, rather than after Assumption 3, could avoid confusion. Additionally:\n\n    - **i)** You mention that the upper bound is standard; including a reference would be helpful. Regarding the lower bound, does it hold in practice? High-dimensional data often have a lot of structure, and their generating covariance might be degenerate.\n    - **ii)** There is no discussion of the second assumption; adding this would enhance understanding.\n    - **iii)** The discussion around the third assumption is somewhat informal. Clarifying what you mean by \"typical\" and providing references or experimental validation would strengthen this section, as real-world covariance matrices are not random and possess rich structures.\n\n11. **Assumption 4 Clarification:** Concerning **Assumption 4**, this assumption appears cumbersome, especially since the Weak Approximation setting does not require such special rescaling. Does this imply that SignSGD needs to be run with a learning rate that scales with $1/d$? Clarifying this point would be beneficial.\n\n12. **(Assumption 5):** Regarding **Assumption 5**, Equation (4) guarantees an upper bound on the resolvent. However, in Equation (6), you divide by it. How do you ensure that you are not dividing by zero?\n\n13. **Conceptual Misunderstanding (Line 149):** In **Line 149**, there may be a conceptual misunderstanding. Compression does not change the landscape; the landscape exists independently, and the optimizer moves through it without altering it. Are you suggesting that there is some implicit regularization of the landscape (Li. et al. & Compagnoni et al.)?\n\n14. **Naming Convention (Line 153 and Definition 2):** In **Line 153 and Definition 2**, you refer to the method as \"Homogenized.\" It might be clearer to call it what it is: the SDE of SignSGD. Additionally, as mentioned earlier, the SDE appears to be ill-defined in overparameterized settings.\n\n15. **Recovery of ODE from SDE (Definition 2):** Regarding **Definition 2**, explaining how we can recover the ODE of SignGD when there is no noise would be helpful. If this is not possible, it raises questions about the explanatory power of the method. Experimenting with your provided Python code did not clarify this for me. Additionally, relating and comparing this SDE with that of Adam in Malladi et al. (2022), if possible, would enhance the comprehensiveness of your analysis. If not possible, providing an explanation would be helpful.\n\n16. **Figure 1 Clarity:** Concerning **Figure 1**, it's crucial for figures to be clearly readable and well-described. The labels in the legend are unclear; terms like \"Vanilla ODE\" are not defined in the text, and I had to refer to your code to understand them. Similarly for \"ODE.\" Additionally, the color scheme is not color-blind-friendly. I recommend using different markers for the lines and avoiding overlapping colors, as it was challenging to distinguish them. Regarding the caption:\n\n    - **i)** Are you representing the dynamics of Sign(H)SGD, or is it the dynamics of the risk under the dynamics of Sign(H)SGD?\n    - **ii)** When you mention the \"usefulness of the ODE,\" do you mean its faithfulness or accuracy in describing the optimizer's behavior?\n    - **iii)** The phrase \"and the significant estimation of key quantities\" is unclear. Could you clarify what you mean?\n\n17. **Extended Plotting (Figure 1):** While the initial part of the dynamics is well captured in **Figure 1**, the central purpose of SDEs is to model the stochastic nature of the optimizer, which is often most evident near convergence. Could you extend the plots to include more epochs (e.g., 100 or 1000) to illustrate this aspect?\n\n18. **Terminology Clarification (Remark 1):** In **Remark 1**, it might be confusing to refer to this as interpolation. You can have label noise and still achieve interpolation; indeed, it's possible to fit random inputs x to random outputs y. Clarifying your terminology here would be helpful.\n\n19. **Theorem 1 Commentary:** **Theorem 1** is a key result and could benefit from further commentary:\n\n    - **i)** Do you have any insights into how strong the exponential explosion is?\n    - **ii)** What role do the moments play in this statement?\n    - **iii)** It might be clearer to denote the two constants currently marked with $C$ using different letters to avoid confusion.\n    - **iv)** It seems that under your framework, you're only able to derive the curves for the loss, whereas the Weak Approximation method provides guarantees for each sufficiently regular test function (Def. 2 of Li et al.). This might limit your framework. Is it possible to generalize your result to other functions, such as the norm of the gradient or the norm of the iterates? Would each quantity require a separate theorem, or is there a way to cover a class of interesting test functions under a broader theorem, similar to the WA setup?\n\n20. **Formalizing ODE Results:** It might enhance your manuscript to formalize the ODE for the Risk as a Proposition or Theorem, rather than just describing it in the text. Additionally, providing a similar result for SGD would allow for a better comparison between the methods.\n\n21. **Equation Clarification (Eq 10):** Regarding Equation (10), is this a definition or an equality?\n\n22. **Theorem 2 Statement Clarity:** **Theorem 2** is another key result, and similar observations as those for Theorem 1 apply here. Also, $R_t$ is given by Equation (10), but its dynamics are described by Equations (11.a) and (11.b). It might be helpful to rephrase the statement to make this clearer.\n\n23. **SDE Derivation for SGD (Eq 13):** Regarding Equation (13), the SDE of SGD does not seem to be derived in the paper, and I couldn't locate it in the given reference. Could you provide more details on this? Additionally, the SDE of SGD has been extensively studied and derived without requiring high-dimensional settings (see Li et al.). Why is the high-dimensional setting needed here? How can we see that in a noiseless setup, this SDE becomes the ODE of Gradient Descent?\n\n24. **Scheduler Boundedness (Eq 14):** Concerning Equation (14), is this scheduler actually bounded? As you approach a stationary point, it seems to diverge. Additionally, this scheduler resembles the normalization used to define Normalized SGD. Could you elaborate on this point?\n\n25. **Highlighting SignSGD's Advantage (Lines 276-277):** In Lines 276-277, you mention that SignSGD is favored when the noise has unbounded variance. This point hasn't been mentioned earlier. It might be helpful to highlight this earlier in the manuscript, provide a reference, or offer an argument or example to support this claim.\n\n26. \"Training with signSGD\": To my understanding, you are not training anything here. It seems like you are comparing the dynamics of the SDE models for SGD and signSGD: It is important to remember that you are not comparing the behavior of the real optimizers but that of their SDE models. To confirm your insights from the models, you need to run experiments on the real optimizers.\n\n27. **Definition of Variables (Eq 15.b):** In Equation (15.b), the variable $\\psi$ is not defined at this point. It might be clearer to include a remark or lemma where you define all the variables used in the equation before proceeding with the analysis.\n\n28. **Preservation of Optimizer Properties (Line 315):** In Line 315, if I understand correctly, you suggest that SignSGD does not converge properly when the risk is small, and to address this, you propose multiplying the increments of SignSGD by the square root of the risk. However, this could negate the optimizer's resistance to noises with unbounded variance. Could you explain why you would want to remove such a significant advantage of the optimizer?\n\n29. **Relevance of Comment (Lines 316-318):** Lines 316-318 contain a comment that seems somewhat disconnected from the surrounding discussion and lacks sufficient motivation. You might consider elaborating further to clarify its relevance or consider removing it.\n\n30. **Empirical Validation (Theorem 3):** **Theorem 3** presents an interesting result, and I strongly encourage you to provide empirical validation for this limit. Including a corresponding result for SGD would greatly enhance the ability to compare the methods. Additionally, is it possible to extend this result to scenarios with unbounded variance?\n\n31. **Section 4.2 Clarification:** Section 4.2 may need further clarification. If the noise variance approaches infinity, wouldn't the risk also tend to infinity? In that case, $\\psi$ might not actually diverge to infinity. Modeling unbounded variance is highly relevant because it's precisely the situation where SignSGD would be most beneficial. Addressing this point could strengthen your analysis.\n\n32. **Framing and Definitions (Lines 370-377):** In Lines 370-377:\n\n    - **i)** It might be beneficial to formalize this discussion as a Proposition. Additionally, kurtosis is not defined for all degrees of freedom of the Student's t-distribution, and it quickly becomes unbounded in cases of interest like unbounded variance. Could you clarify why you use this term in such contexts?\n    - **ii)** Is Equation (19) straightforward? Is it possible for the risk to be nearly zero while the noise has an increasingly large (possibly unbounded) variance?\n\n33. **Collecting Equations into Results:** It might strengthen the flow of the paper if you combined Equations (19), (20), and (21) into a clearly stated result, and present the equivalent findings for SGD for comparison. Including experimental validation would further support your theoretical claims.\n\n34. **Scheduling SignSGD Concerns:** Regarding **Scheduling SignSGD**, this appears to be a puzzling point. In Equation (24), you suggest using a scheduler that increases or decreases with the risk. This could effectively undo the normalization that contributes to SignSGD's effectiveness: For instance, if the noise variance is unbounded, this scheduler could diverge, which may not be desirable. It might be counterproductive to undo the adaptive gradient rescaling. Could you provide further insight into this?\n\n35. **Relation to Existing SDEs (Line 432):** In Line 432, it seems that this analysis could be performed by considering the SDE of Adam as derived in Malladi et al. Could you elaborate on this point? In your appendix, I noticed only an informal SDE for the iterates of Adam, but not the differential equations for $m_t$ and $v_t$.\n\n36. **Merging Results (Theorem 4):** Regarding **Theorem 4**, is it possible to merge this result with Theorem 3, or am I misunderstanding something? Including experimental validation and comparisons with SGD would be valuable additions to your manuscript.\n\n37. **Elaboration Needed (Line 465):** In Line 465, you mention \"when the covariance\u2014the Hessian of the risk.\" Could you elaborate on this point? Providing a reference or a brief explanation would help clarify this statement.\n\n38. **Practical Implications (Section 4.3):** A general comment on Section 4.3: In practical terms, could you provide guidance on when it is better to use one method over the other? This would help readers understand the practical implications of your findings.\n\n39. **Quantitative Characterization (Section 4.4):** In Section 4.4, the discussion is mostly qualitative and intuitive. It would be helpful to include a quantitative characterization of the differences in noise structure to provide a clearer understanding of your analysis.\n\n---\n\n**Minor Points:**\n\n1. **Rewriting for Clarity (Lines 87-93):** It might improve the readability to rephrase this section into a cohesive paragraph rather than a list of facts and observations. Regarding Equation (4), elaborating further and possibly providing a brief proof for the derivation of $K_\\sigma$ would enhance the clarity.\n\n2. **Lines 94 to 96:** Please rephrase and make correct use of words and commas. Suggestion: \"Although our theory is framed in the setting of Gaussian data, as we will see, the results are still a good description for real-world, a priori non-Gaussian settings.\"\n\n3. **Punctuation (Line 248):** Please add a comma before the word \"respectively\".\n\n4. **Consistent Notation:** It would be helpful to maintain consistent notation throughout the manuscript. For example, choose either $P_t$ or $P(t)$ for processes and use it consistently.\n\n5. **Formal Language (Line 267):** The phrase \"apples-to-apples\" is informal. Consider using more formal language appropriate for a scientific paper.\n\n6. **Terminology Correction (Figure 3):** The correct term is \"Student's t,\" not \"Student-t.\" Please make this correction.\n\n---\n\n**Appendix:**\n\nWhile I won't go into detailed comments about the appendix, I noticed that it's quite technical and could benefit from better organization. Presenting technical lemmas upfront and breaking down major results into smaller components could streamline the proofs. Several missing preliminaries and notation definitions affect readability. Here are some examples that came to mind:\n\n1. **Equation Justification (Line 738):** It would be preferable to first prove, in a technical lemma, what is necessary to justify Equation (44) before using it. Since you seem to drop this term and mention that you will justify it later, it's important to handle such a key step carefully to ensure clarity and rigor.\n\n2. **Assumption Clarity (Line 739):** It appears that you're working under the assumption of bounded risk, which may not be realistic in practical scenarios. **This is a significant assumption that should be explicitly stated in the main paper.**\n\n3. **Accessibility of Concepts:** Concepts like nets, stopped processes, and martingales may not be familiar to all readers. Including a section that compiles all the notation, technical lemmas, and theoretical preliminaries would help make the appendix more accessible and provide a more self-contained experience for readers. I attempted to follow the proofs **but found it challenging to verify all the steps in a reasonable amount of time.**\n\n4. **Lemma Placement (Line 836):** **Lemma 8** is referred to here but is stated much later in the appendix. Reorganizing the content so that lemmas are introduced before they are used would improve the flow and readability.\n\n5. **Undefined Notation (Line 915):** The notation $\\mathcal{E}_j^i$ is used but not defined at this point. Defining all notation when first introduced would help prevent confusion.\n\n6. **Conceptual Clarification (Line 1007):** There seems to be a conceptual misunderstanding here. It is the dynamics of the SDE that converge to those of the optimizer, not the other way around.\n\n7. **Variable Definition (Line 1025):** The notation $\\sigma_{k+1}$ is used but not defined. Providing a definition would improve clarity.\n\n8. **Term Introduction (Line 1049):** The term \"HSGD\" is mentioned, but it hasn't been introduced earlier in the paper.\n\n9. **Notation Clarification (Line 1630):** The notation $v_i$ is used without prior definition.\n\nCompagnoni et al. \"An SDE for Modeling SAM: Theory and Insights\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors motivated by the signed gradient interpretation of the stochastic gradient algorithm, develop and apply an SDE/ODE framework to analyze the dynamics of the stochastic gradient algorithm using signed gradients. With this framework they study quantities like the effective learning rate of the algorithm, preconditioning and gradient noise. In addition, they draw up a conjecture to explain Adaptive moment estimation using their framework."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "I think the biggest strength of the paper is its clarity of presentation."
            },
            "weaknesses": {
                "value": "The weakness of the paper lies in the technical side, most especially relatively recent work that attempt to connect diagonal preconditioning and sign gradients to Adam.\n\n1. For the generic reader, the authors fail to explicitly define what SDE and ODE mean.\n\n2. In line 458, the authors can better reframe the content of the line to be more technically sound.  \nThe use of the phrase: \"... optimal deterministic convex opt algorithm such as Heavy ball momentum and conjugate gradient...\" is not accurate with respect to stochastic gradient algorithms. The wording passes the two algorithms as two different algorithms, whereas, you have the same stochastic gradient algorithm, only with a different learning rate setting and a lowpass filter (momentum parameter) setting.\nA better phrase could be: \"... the stochastic gradient algorithm with smooth gradients (momentum) and optimal convex optimization settings such as Polyak's Heavy Ball and the Conjugate Gradient ...\".\nNote that the stochastic gradient algorithm itself does not care whether we use a minibatch gradient or not.\n\n3. The extra conjecture adds nothing essentially to the paper. \nAdam is simply a learning rate setting for the stochastic gradient algorithm. It is when you decompose the learning rate that you get a normalized gradient in expectation. It is the normalized gradient that has a connection with the sign function. \nAgain, these things are not new. A careful study of classic literature, especially Tsypkin's classic 1971 work on Adaptation and learning in automatic systems will make this much clearer.\nAlso, diagonal preconditioning is only true, if the hessian of the objective function is diagonal. In the case of the learning rate called Adam, we are only implementing it by dividing the gradient with its estimated variance (or moment), which gives a normalized gradient in expectation. \nThe diagonal preconditioning is also in expectation because, in a sense, the eigenvalues of the hessian can be interpretated as variances of the gradient."
            },
            "questions": {
                "value": "None."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}