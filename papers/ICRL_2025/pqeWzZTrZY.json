{
    "id": "pqeWzZTrZY",
    "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping",
    "abstract": "Recent works have attacked person detectors using adversarial patches or static-3D-model-based texture modifications. However, these methods suffer from low attack success rates when faced with significant human movements. The primary challenge stems from the highly non-rigid nature of the human body and clothing. Current attacks fail to model these 3D non-rigid deformations caused by varied actions.\nFortunately, recent research has shown significant progress in using NeRF for dynamic human modeling. \nIn this paper, we introduce \\texttt{UV-Attack}, a novel physical adversarial attack achieving high attack success rates in scenarios involving extensive and unseen actions. We address the challenges above by leveraging dynamic-NeRF-based UV mapping. Our method can generate human images across diverse actions and viewpoints and even create novel unseen actions by sampling from the SMPL parameter space. While dynamic NeRF models are capable of modeling human bodies, modifying their clothing textures is challenging due to the texture being embedded within neural network parameters.\nTo overcome this, \\texttt{UV-Attack} generates UV maps instead of RGB images and modifies the texture stacks. This approach enables real-time texture edits and makes attacks more practical. Finally, we propose a novel Expectation over Pose Transformation loss (EoPT) to improve the evasion success rate on unseen poses and views.\nOur experiments show that \\texttt{UV-Attack} achieves a 92.75\\% attack success rate against the FastRCNN model across varied poses in dynamic video settings, significantly outperforming the state-of-the-art AdvCaT attack, which only had a 28.50\\% ASR. Moreover, we achieve 49.5\\% ASR on the latest YOLOv8 detector in black-box settings.",
    "keywords": [
        "Adversarial Attack; Person Detection; NeRF; UV-Mapping"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "We propose UV-Attack, the first physical adversarial attack that has high attack success rate on person detection in large-action scenarios.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=pqeWzZTrZY",
    "pdf_link": "https://openreview.net/pdf?id=pqeWzZTrZY",
    "comments": [
        {
            "summary": {
                "value": "The paper presents UV-Attack, a novel physical-world adversarial attack for person detection systems. The core idea is leveraging dynamic Neural Radiance Fields (NeRF) for UV mapping to generate adversarial images across varying human actions and viewpoints. The attack modifies clothing textures through UV maps rather than traditional RGB images, allowing real-time, practical texture edits. A new Expectation over Pose Transformation (EoPT) loss is introduced to improve the attack's success rate for unseen human poses. The paper highlights the potential of using dynamic NeRF and UV mapping for adversarial attacks on non-rigid objects like human bodies."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The use of dynamic NeRF-based UV mapping for adversarial attacks is an innovative approach, addressing the challenge of human movement.\n\n2. The approach can generate adversarial textures in real-time, making it feasible for real-world attacks\n\n3. The proposed method outperforms previous adversarial attacks, achieving a high ASR across varied poses and detectors, particularly in free-pose settings.\n\n4. The method\u2019s ability to handle diverse human poses through EoPT and UV mapping may enhance its robustness"
            },
            "weaknesses": {
                "value": "1. The method heavily depends on pretrained stable diffusion models for generating adversarial patches, which might limit its generalizability to other model architectures.\n\n2. The attack pipeline involves multiple steps, including dynamic NeRF, UV mapping, and diffusion models, which increases the complexity and may pose practical limitations in some applications.\n\n3. While the paper claims success in physical-world attacks, the physical-world experiments are limited to a few environments and detection models. \n\n4. The paper shows good results on some detectors but does not fully address how transferable the attack is to other models not tested in the experiments. The impact of domain shift (e.g., different datasets) is also not well explored."
            },
            "questions": {
                "value": "In addition to the weaknesses, please refer to the following:\n\n1. How sensitive is the attack to the specific poses, say sampled from the Gaussian Mixture Model (GMM)? Would other pose distributions significantly affect the results? There is limited statistical insight in the paper.\n\n2.  Does the complexity of clothing textures (e.g., different patterns or colors) impact the effectiveness of the attack? \n\n3. How well does UV-Attack generalize to detection models not tested in the paper, particularly beyond YOLO and FastRCNN variants? Could there be a model-specific bias in the attack\u2019s success rate? This needs to be addressed in detail.\n\n4. There is limited discussion on potential defenses against UV-Attack, which is crucial for the broader adversarial machine learning community. A discussion or experiment on how robust the attack is to adversarial training or other defenses would make the paper more impactful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces a novel adversarial attack pipeline for person detection, termed UV-Attack. First, it innovatively incorporates a NeRF-based UV mapping method into the person detection adversarial attack pipeline, enabling the generation of diverse human UV maps and textures with varying poses and camera perspectives. Second, it leverages a diffusion model to generate adversarial patches, which are then interpolated with textures produced by 3D human models to render adversarial human images. Finally, comprehensive experiments are conducted across various mainstream detectors and scenarios, benchmarking the proposed method against existing approaches."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "This paper presents a novel approach to generating adversarial samples for human detection. Firstly, it cleverly utilizes the UV map and texture of the human model to introduce adversarial patches, enabling efficient rendering onto RGB images of the human figure for multi-view attacks. Secondly, it leverages the robust generative priors of diffusion models to perform interpolation at the texture level. Finally, this method achieves significant accuracy improvements in dynamic and multi-pose scenarios by sampling various human poses and perspectives, further validating the effectiveness of the proposed approach."
            },
            "weaknesses": {
                "value": "This paper has shortcomings in the presentation of experimental details and data, which may lead to confusion regarding the reproducibility and generalizability of the findings."
            },
            "questions": {
                "value": "1. In your training for a specific detector, you mentioned that you collected 100 different backgrounds from both indoor and outdoor scenarios. Could you provide more details about this data and its sources? In other words, how significantly does this data impact the effectiveness of the adversarial sample generation?\n2. Your pipeline requires sampling SMPL pose parameters from a Gaussian Mixture Model (GMM). When modeling the GMM, you need to input the target video and the human pose dataset. What is the purpose of including the target video?\n3. When validating the ASR, you average class labels except for \"person\" in the COCO dataset. During training, is the diffusion model condition kept consistent throughout?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose a novel method to attack person detectors for various human poses in the physical world. They incorporate dynamic NeRF-based UV mapping and the Gaussian Mixture Model to sample and generate unseen human poses with editable textures. The texture is generated by a latent diffusion model. They then combine PSO and Adam optimizer to find the optimal diffusion latent variable for the adversarial texture. The adversarial texture outperforms multiple baselines in both the digital and the physical world."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 4
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1.\tThe writing is clear and easy to understand.\n2.\tThe goal of this paper is important to this area, and the solution is technically sound.\n3.\tThe experiments are comprehensive. The authors evaluate the adversarial effectiveness of the adversarial patterns under various parameters, including poses, viewing angles, and IoU thresholds. White box and transfer study are both included."
            },
            "weaknesses": {
                "value": "1.\tThe digital test setting seems a little problematic. The test poses are generated by GMM, which could be unreal. This raises the training-test contamination issue since a GMM-based model is also included in the model comparison. I suggested using videos from a different source.\n2.\tIt lacks a null model for comparison: a non-adversarial pattern, such as an everyday clothes pattern, or a generated pattern from a random initial point.\n3.\tThe training detail section is confusing; please see the questions."
            },
            "questions": {
                "value": "1.\tWhat is the training dataset? Does it include the videos recorded by the authors? If so, the authors should make a split on the training and test dataset that consists of different subjects and backgrounds.\n2.\tAre the training datasets for digital and physical evaluation different? If so, why? What is the physical adversarial effectiveness of the digitally optimized patterns?\n3.\tIs the SMPL modeling for each subject the same? What's the transferability to unseen subjects? Does this mean that this method requires training a UV-volume model and optimizing for each person who is going to wear the adversarial clothes? If so, this method seems to have a great limitation; how to address this?\n\nI'm happy to raise the score if these concerns are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces UV-Attack, a novel adversarial approach using dynamic-NeRF-based UV mapping to achieve high ASRs on person detectors across diverse human actions and viewpoints. By generating UV maps rather than static RGB images, UV-Attack enables real-time texture modifications, making it practical and adaptable to unseen poses. Experiments show a 92.75% ASR against FastRCNN and 49.5% on YOLOv8, significantly surpassing prior methods and showcasing the potential of dynamic NeRF for effective adversarial attacks on moving human targets."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The idea of expanding the perturbation space by removing classifier-free guidance is interesting and brings a fresh perspective for boosting the transferability in the physical world.\n2. The experiments are comprehensive, covering both digital and physical environments for thorough validation.\n3. The paper is well-organized, with a clear and logical flow."
            },
            "weaknesses": {
                "value": "1. I\u2019m a bit unclear on the Expectation over Pose Transformation (EoPT) loss. How does it differ from the standard Expectation over Transformation (EoT)? From Equation (5), it seems that the transformations traditionally applied at the image level have been shifted to include pose, camera, and lighting changes.\n2.  Why do you choose YOLOv3 and Faster R-CNN as the target models rather than other, potentially more recent models?  Is there an underlying reason for this choice?\n3. In line 431, the paper mentions that structural differences between models like SSD and the target model lead to limited transferability. Why not try a model ensemble approach to boost transferability, which is often used in physical attacks?\n4. Could you clarify how the target model is set up? Is it just a pretrained model, or is it fine-tuned on a specific dataset? Additionally, how do each of the models perform on clean samples? This would serve as an important comparison, especially for physical-world testing. Since factors like distance, angle, and setting can greatly impact a detector\u2019s performance in the physical world, poor performance on clean samples would reduce the significance of the attack itself.\n5. For the physical experiments: (1) there is no mention of how many frames were captured in the video used to calculate ASR; if the frame count is too low, the results may lack credibility; (2) the physical-world attack examples are limited in the current draft\u2014please provide a more complete set."
            },
            "questions": {
                "value": "Please refer to the weakness. If my questions are addressed, I will raise the score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents UV-Attack, a method designed to generate effective physical adversarial attacks targeting person detection systems by leveraging dynamic Neural Radiance Fields (NeRF) and UV mapping. This approach allows adversarial textures on clothing to adapt seamlessly to various human poses, addressing the challenges posed by non-rigid human movement. UV-Attack introduces two key components: a custom Expectation over Pose Transformation (EoPT) loss function to enhance attack success across diverse poses and viewpoints, and adjustments to the diffusion model to improve the transferability of adversarial examples to different detection systems."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- The paper introduces a novel application of dynamic NeRF and UV mapping, addressing the challenge of generating adaptable adversarial textures for non-rigid objects like human bodies. \n- The authors propose an Expectation over Pose Transformation (EoPT) loss, which improves the patch\u2019s robustness by ensuring its effectiveness across a wide range of poses.\n- Extensive experiments across multiple person detection models and in various settings, including both white-box and black-box scenarios.\n- The physical testing on printed clothing showcases UV-Attack\u2019s applicability in real-world scenarios.\n- The writing and presentation are clear and easy to follow."
            },
            "weaknesses": {
                "value": "- The paper focuses heavily on maximizing attack success rates against person detection models but does not address visual inconspicuousness or stealth. For a physical adversarial attack to be practical in real-world scenarios, it should evade not only machine detection but also appear natural and undetectable to human observers. UV-Attack\u2019s textures might draw attention due to potentially unnatural patterns, especially in public settings where they could be easily noticed.\n\n=> Action: I recommend introducing constraints that limit the patch\u2019s appearance to more natural or common textures, to balance adversarial effectiveness with visual stealth. This could improve the applicability of UV-Attack in sensitive contexts, such as surveillance evasion, where inconspicuousness is essential.\n\n- The authors report success rates for state-of-the-art attacks that differ significantly from those in the original publications. This inconsistency complicates direct comparisons and may impact the perceived credibility of UV-Attack\u2019s comparative performance. Additionally, some state-of-the-art techniques apply constraints on patch appearance to ensure inconspicuousness, making comparisons with unconstrained approaches potentially unfair.\n\n=> Action: To improve clarity and credibility, the authors should explicitly document the reasons behind any benchmarking deviations and, where possible, apply similar constraints to UV-Attack\u2019s patches for fair comparison. Aligning evaluation protocols with prior works or noting significant differences in approach would enhance the validity of the comparison.\n\nLess Important:\n\n- The paper overlooks relevant related work, particularly \u201cDAP: A Dynamic Adversarial Patch for Evading Person Detectors,\u201d which similarly aims to create patches that are robust to non-rigid transformations. Including this work in the literature review would help contextualize UV-Attack\u2019s contributions within the existing research.\n\n=> Action: Discussing DAP and other similar methods would provide readers with a clearer understanding of UV-Attack\u2019s novelty and advancements, especially in handling non-rigid transformations.\n\n- The use of dynamic NeRF in UV-Attack is computationally intensive, which could limit applicability in scenarios requiring frequent re-designs of the patch for different targets or environments. While this is less relevant for single, offline generation, the computational demand could become a significant limitation if applications required ongoing adaptations."
            },
            "questions": {
                "value": "Check weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}