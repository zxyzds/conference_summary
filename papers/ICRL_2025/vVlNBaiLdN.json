{
    "id": "vVlNBaiLdN",
    "title": "ESMGain: Effective and Efficient Prediction of Mutation\u2019s functional Effect via ESM2 Transfer Learning and robust Benchmarks",
    "abstract": "Mutations are complex biological phenomena with extensive impact on health and disease. With precision medicine\u2019s growing demand for mutation testing and the cost of wetlab experiments, ESM2 and a modified AlphaFold2 architecture have been used to predict a binary measurement of mutation \u201cpathogenicity\u201d. But many applications require a differentiated, functional effect measurement: does the mutation lead to a loss- or gain-of-function or neutral impact on the protein? First, we hypothesize and demonstrate that fine-tuning ESM2 with a custom regression head incorporating inductive biases enables the application of learned protein semantics to functional effect prediction. Notably, our model, dubbed ESMGain, outperforms state-of-the-art competitor PreMode on deep mutational scans (DMSs) from three different enzymes with a mean Spearman\u2019s rho of 0.74 vs. 0.68, although PreMode is pre-trained on 4.7M labeled mutations and uses protein structure, multiple sequence alignments and ESM2 embeddings. Second, these results lead us to hypothesize that the signal provided by protein structure, MSAs, and embeddings is largely redundant. PreMode's ablation studies show minimal performance drop when any of these modalities is excluded, suggesting that they capture overlapping information for functional effect prediction. This explains ESMGain\u2019s superior performance: its fine-tuned embeddings are task-specific and avoid the redundancy present in PreMode\u2019s features. Third, we introduce the first benchmarking framework for functional effect prediction: instead of only using a test split of the same protein DMS as the training data, we advocate testing the predictor on a different protein\u2018s DMS of the same protein family to test generalization. Because most mutations have a neutral effect and loss-/gain-of-function mechanisms are complex, the Spearman rho is inflated because of many accurate neutral predictions and rare, probably inaccurate loss-/gain-of-function predictions. Thus we introduce the harmonic Spearman as a fine-grained, realistic metric equally weighting performance for each effect.",
    "keywords": [
        "protein",
        "language model",
        "deep learning",
        "biology",
        "gain of function",
        "enzyme"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "ESMGain leverages ESM2 fine-tuning to predict functional effects of mutations, outperforming competitors by task-specific optimization, and introduces a benchmarking framework with harmonic Spearman as an accurate metric across effect types.",
    "creation_date": "2024-09-28",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=vVlNBaiLdN",
    "pdf_link": "https://openreview.net/pdf?id=vVlNBaiLdN",
    "comments": [
        {
            "summary": {
                "value": "This paper introduces a method for fine-tuning protein language models, specifically ESM2, using deep mutational scanning (DMS) data. The fine-tuning process involves generating both local and global representations of the reference and mutant protein sequences by utilizing separate, mostly frozen ESM models for the two sequences. These representations are combined and passed through a two-layer linear neural network to predict quantitative measurements from a DMS assay.\n\nFurther, the authors propose two modifications to the evaluation of fine-tuned models. First, they recommend fine-tuning models on one protein and testing them on a different protein within the same family, rather than using held-out positions from the original protein. Second, they suggest calculating correlation metrics separately for LoF, neutral, and GoF mutations. These separate correlation scores are then combined using a harmonic mean to produce a single protein-level metric."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The authors introduce important ideas for better evaluating fine-tuned models: (a) evaluating models on completely held out proteins and (b) developing a metric that prioritizes performance on LoF and GoF variants over neutral variants.\n2. Their fine-tuning approach demonstrates superior performance compared to existing methods, such as PreMode and augmented versions of unsupervised models.\n3. Through ablation studies, the authors establish that using larger versions of ESM2 does not significantly improve performance and that employing separate models for reference and mutant sequences provides some benefits."
            },
            "weaknesses": {
                "value": "1. Limited dataset evaluation: The authors do not evaluate their method on the large compendium of DMS datasets that are available in ProteinGym (217 datasets covering 2.5 million mutations), instead focusing on only 5 datasets (Figure 2). To convincingly prove that their fine-tuning approach outperforms existing methods, they should expand their analysis to more datasets.\n\n2. Insufficient comparison to existing fine-tuning approaches: PreMode and augmented unsupervised models are not the only approaches that have been proposed to fine-tune protein language models on DMS datasets. See https://www.nature.com/articles/s41467-024-51844-2 and https://arxiv.org/pdf/2405.06729. These papers explore strategies such as parameter-efficient fine-tuning and fine-tuning jointly on multiple DMS assays that this paper does not consider. In particular, the approach proposed in the second paper listed above shows improved performance on entirely held out proteins, which is in stark contrast to the poor generalization to new proteins exhibited by ESMGain in Fig. 4. \n\n3. While the idea to compute separate correlation metrics for LoF, neutral, and GoF variants is clever, the method of dividing variants into these categories by splitting the ground-truth scores into thirds is arbitrary. A more robust method, such as a Gaussian mixture model with three components, could provide a more principled assignment of variants to these classes."
            },
            "questions": {
                "value": "1. The poor generalization performance in Fig 4 to new proteins seems to indicate that ESMGain is overfitting. Can you more heavily regularize your model to avoid this?\n2. Do you find that performance depends on what fraction of ESM2 is frozen? What happens if it is entirely frozen and you only train a 2-layer NN on top of the reference/mutant representations?\n3. Does the harmonic Spearman correlation provide a more meaningful ranking than say AUROC at distinguishing the bottom third from the top third of variants?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This work proposed a method called ESMGain to use fine-tuning ESM2 with a custom regression head incorporating inductive biases and enable the application of learned protein semantics to functional effect prediction. This method outperforms state-of-the-art competitor PreMode on deep mutational scans from three different enzymes."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The proposed method performs the best for functional effect prediction in the dataset.\n2. The methodology of ESMGain can predict functional effects without the limitation of feature redundancy and task specificity."
            },
            "weaknesses": {
                "value": "1. The organization needs improvement. Some terms like \"PTEN\" didn't have full names. The size of font in those figures is too small to read and is not consistent. The section 7 should be in the section of the experiential setup.\n2. In Fig4, \"LoF, Neutral and GoF\" in captions should be the same as the text in x axis of figure. How about the performance in all other baselines like competitor PreMode in Fig4?\n3. Have you conducted multiple train-test split seeds in ablation study of ESMGain? Why the result of the original ESMGain in the ablation study is different from the one in Fig2? Do they use different datasets or strategies to train and test?"
            },
            "questions": {
                "value": "see above. The questions are about the description of the result and additional result in other baselines."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes a novel model method  ESMGain for predicting the functional impact of protein mutations, expanding addressing limitations in existing binary pathogenicity predictors. By fine-tuning ESM2 embeddings with a custom regression head, ESMGain aims to accurately classify mutations as loss-of-function, neutral, or gain-of-function. Through evaluations  in catalytic activity prediction tasks, ESMGain outperforms the state-of-the-art baselines by leveraging only ESM2 embeddings. Besides, the authors propose a new benchmarking framework for functional effect prediction, emphasizing cross-protein generalization tests within the same protein family. A Harmonic Spearman metric is also introduced to balance performance evaluation across mutation effect categories."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1) The paper is well-structured and clearly written.\n\n2) The proposed method achieves state-of-the-art performance on selected datasets in functional effect prediction.\n\n3) By employing two independent ESM2 models to embed wildtype and mutant sequences separately, the paper addresses potential information loss in mutation representation, enhancing the model\u2019s ability to capture subtle differences. Ablation studies demonstrate that only using ESM2 embeddings effectively captures most of the relevant information on DMS datasets,  effectively reducing the reliance on additional data modalities.\n\n4) The paper proposes a novel benchmarking framework for functional effect prediction incorporates a cross-protein generalization test within the same protein family."
            },
            "weaknesses": {
                "value": "1) The novelty of this paper is limited. The use of dual ESM2 embeddings to separately represent wildtype and mutant sequences, along with the introduction of the Harmonic Spearman metric to address label imbalance, appears more incremental than groundbreaking.\n\n2) It seems that the motivation of the proposed benchmarking framework is underdeveloped. While focusing on cross-protein generalization within the same family is technically interesting, it lacks a clear connection to real-world situations where this type of evaluation would be essential.\n\n3) While ESMGain performs well on the tested DMS data, its generalization to other samples within the same protein family is weak (cross-family tests). The model may be overfitting in the specific training proteins."
            },
            "questions": {
                "value": "1) The paper includes relatively few citations and offers limited analysis of related work. Could the authors clarify if this indicates that the approach is less informed by recent research developments?\n\n2) Additional questions are noted in the \"Weaknesses\" section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a method for mutation effect prediction. The method relies on two ESM2 heads for generating protein sequence embeddings, one used with wildtype sequences and the other one for the mutated sequences. On top of the embeddings a custom regression head is trained. The technical novelty of the method is their design of the regression head and the fact that the two ESM2 models have different weights one fine-tuned for wildtype sequences and the other for the mutated sequences. Other contributions claimed by the paper are towards better bencharking (i) testing generalization of the models fine-tuned on one protein by testing them on a different protein from the same family and (ii) introduction of \u201cHarmonic Spearman\u201d as a new metric."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The generalization test is of interest. In Figure 3, authors show the different distribution of labels for two different proteins from the same family and convincingly show why generalization between proteins (even in the same family) is not easy."
            },
            "weaknesses": {
                "value": "1. Paper is poorly structured, making it very hard to read:\n\n\t- Introduction contains contents which would better fit to related work or background (\u201cNotably, PreMode was pre-trained to predict the binary measurement of \u201cpathogenicity\u201d for 4.7 million mutations and uses AlphaFold2\u00a0predicted protein structure, Multiple Sequence Alignments (MSAs) and pre-trained ESM2 650M embeddings as features (John Jumper, 2021).\u201d) And it also presents some results and their discussion (\u201cThat leads us to hypothesize that the signal provided by protein structure, MSAs, and embeddings is largely redundant for the task of effect prediction. PreMode\u2019s ablation studies show minimal performance drop when any of these modalities is ex- cluded, suggesting that they capture overlapping information for functional effect prediction. This explains ESMGain\u2019s superior performance in turn: its fine-tuned embeddings are task-specific and the single modality avoids the redundancy.\u201d). I suggest honoring the usual structure of the paper and using introduction just for motivation and a very brief (not so detailed) teaser for the contributions of the paper.\n\n    - Chapter 4, which should be describing the technical novelty and the method does not provide that many details, for example Figure 1 illustrating the method is never referenced in the text. I suggest to use a figure and equations to better describe the regression head, instead of the textual description at the end of section 4.2.\n\n    - No table summarizing results. The reported numbers are scattered across text and some figures, making it very hard to get a glimpse of the results. I suggest a more transparent summarization of the results, such as by using a table.\n\n2. Poor formatting of the paper.\n\n    - Authors are not economical with the space by being sometimes too verbose, repetitive in repeating their contributions or for example by wasting the whole first page just on abstract. Being more economical would enable the authors to make bigger figures which have too small fonts and are hard to read. I suggest making figure large enough so the fonts can be legible. \n\n    - References are poorly formated. Some references starting with \u201c\u2026\u201d. AlphaFold referenced as \u201c(John Jumper, 2021)\u201d - note that AlphaFold was a collective effort. I suggest proper citing and formatting of references.\n\n3. Insufficient literature survey. Authors only have 13 references. I suspect authors were trying to fit into the page limit of 10 pages including references - this is not necessary references dont count in the page limit. I suggest making proper literature survey and crediting relevant work. For example, I miss the reference to ProteinGym, arguably one of the most influential benchmarks in this area.\n\n4. Insufficient benchmarking. Authors only focus on the comparison to PreMode (which was still not peer reviewed) and only compare on 5 proteins. I suggest to compare for example to AlphaMissense as well.\n\n5. The key contribution of having separate ESM2 heads for wildtype and for the mutated sequence is questionable. Authors claim this to give them the key improvement by the underlying inductive bias. To me it is not clear how to decide what is wildtype and what is mutation. What if the mutation is adopted by evolution and becomes the \u201cnew wildtype\u201d and then gets mutated again? There is no fundamental reason to distinguish between the sequences. So I believe that using the distinction between the sequences based on the dataset definition and then adapting the two heads to this definition only leads to overfitting to the dataset, potentially explaining any benefit gained from these separate heads. I dont have a concrete suggestion how to prove authors point, because I think the point is wrong. If authors stand by their point they should present convincing evidence supporting that their \u201cinductive bias\u201d is not just overfitting to the dataset definition of what is wildtype and what is mutation.\n\n6. The model seems to improve over PreMod on just 2-3 out of 5 proteins (Figure 2), this does not seem very convincing. My suggestion would be to get other datasets (maybe something relevant could be found in ProteinGym) and show improvement on other dataset as well.\n\n7. The Harmonic Spearman is just introduced at the end of the paper and not motivated well enough. Could authors explain the choice of using harmonic average? Could authors clearly compare harmonic spearman to normal spearman? How does it change the evaluation of all the benchmarked models? A table summarizing the results (as suggested in Weak point 1) would help.\n\n\nI suggest to reject this paper for the following reasons. (i) The paper is not is well placed in literature, comparison to AlphaMissense is missing and the survey of the related work is not sufficient. (ii) The key contribution of using two separate ESM2 models for the wildtype and the mutated sequence is questionable and the claim of bringing a useful inductive bias is not supported by strong evidence, the improvement coming from this choice might be due to overfitting to the dataset definition of what is mutant and what is original sequence. (iii) The results dont seem as strong, only showing improvement for 2-3 out of 5 proteins. More convincing evaluation using other dataset would be necessary. (iv) The technical novelty of separate fine-tuning of two ESM models with a custom regression head is limited. (v) The writing is poor, making it hard for the reader to asses the contributions, the results of the method and its placement in the literature."
            },
            "questions": {
                "value": "Most of my questions and suggestions for the authors are listed alongside the weaknesses in the above section. \n\nTo sum up: \n\n- I suggest to find more datasets of other proteins from ProteinGym and use them to compare ESMGain at least with PreMode and AlphaMissense.\n\n- Present clearly the results in a table using both the Spearman correlation and the proposed Harmonic Spearman at one place.\n\n- Authors should provide evidence for bringing a new useful inductive bias by taking the two separately fine-tuned ESM2 heads. Other evidence than the improved performance (for some proteins), which might just hint at overfitting to the dataset definition.\n\n- The paper should be rewritten focusing on clear presentation of the method and results, clear structure of the paper and proper formatting of figures and references. The method (in particular the new regression head) is not clearly presented, the structure is chaotic with discussion of results and related work appearing already in introduction. The figures have tiny fonts making them hard to read and the references are wrongly formatted."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}