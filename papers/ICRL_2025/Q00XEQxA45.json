{
    "id": "Q00XEQxA45",
    "title": "TRAIN THE LATENT, NOT THE IMAGE: JOINT IMAGE COMPRESSION AND STEGANOGRAPHY",
    "abstract": "Image steganography is the process of hiding secret information in an image through imperceptible changes. Most of recent works achieve message in the image by modifying the pixels of image itself. However, those images with hidden messages are not robust to compression such as JPEG, which is used almost everywhere. In order to achieve the ability to compress the image while still having the ability to carry the message, we propose an innovative optimization method which leverages a semi-amortized approach to directly manipulate latent space data for the joint optimization of image compression and steganography. In the compression module, we investigate two of the most popular models in learned image compression with  different pre-trained quality: the hyperprior model and the ELIC model. For the steganography module, our method employs the pre-trained fixed neural network steganography (FNNS) model. We compare our method with two state-of-the-art methods such as FNNS-JPEG and LISO-JPEG, achieving significant image compression while maintaining high fidelity and ensuring the accuracy of content upon decoding. The results demonstrate the effectiveness and superiority of our approach.",
    "keywords": [
        "steganography",
        "image compression",
        "semi-amotorize",
        "adversatial learning"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=Q00XEQxA45",
    "pdf_link": "https://openreview.net/pdf?id=Q00XEQxA45",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes a novel method for robust image steganography that withstands JPEG compression. Instead of directly modifying image pixels, the approach uses a semi-amortized optimization technique in the latent space to jointly optimize image compression and steganography. By combining popular learned compression models (hyperprior and ELIC) with a pre-trained steganography model (FNNS), the method achieves superior compression, high fidelity, and accurate decoding, outperforming existing methods like FNNS-JPEG and LISO-JPEG."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This article is written clearly.\n\n- This paper first proposes a joint optimization of compression and steganography, which solves the problem that steganographic images are degraded.\n\n- The experimental results demonstrate attractive performance."
            },
            "weaknesses": {
                "value": "Could the authors provide an example of a neural network-based steganography method being practically applied? My research area is not in this field, but it seems to me that this field offers little practical value beyond papers and some handcraft metrics."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper provides an interesting approach to combining image compression and steganography in the latent space, yet there are several areas where it falls short in terms of innovation, clarity, and practical value. Here are my detailed comments and suggestions:"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "This paper proposes a model for joint optimization of image compression and steganography by operating in the latent space instead of directly on the image. By utilizing semi-amortized inference and latent optimization, the model aims to improve robustness against compression, specifically targeting JPEG degradation. It integrates a GAN-based discriminator to enhance the visual quality of compressed images and leverages pre-trained ELIC and Hyperprior models for image compression. The approach is tested on several datasets and compared with other steganography methods (e.g., FNNS and LISO) in terms of compression rate, PSNR, and robustness."
            },
            "weaknesses": {
                "value": "1. Weak Motivation: The paper\u2019s focus on JPEG compression as the main adversarial scenario for steganography is narrow. JPEG is not the sole or the most challenging attack vector in steganography, limiting the practical significance of this work.\n2. The claim of \"joint optimization of image compression and steganography\" is not convincingly supported, as the paper mainly demonstrates standard compression techniques applied to a latent code without introducing novel optimization strategies. Integrating a GAN-based discriminator to improve image quality is not a new concept and has been widely used in image steganography. This reduces the paper's innovative contribution. \n3. Confusing Experimental Comparisons: The experiments are difficult to follow, with unclear captions and a lack of structure in presenting results.\n4. Lack of Diverse Baseline and Attack Comparisons: The evaluation would be more robust with additional baseline methods and attack scenarios beyond JPEG compression. Including comparisons with a broader range of steganography techniques and different attack types (e.g., scaling, noise addition) would provide a better understanding of the model\u2019s resilience and comparative performance.\n5. Parameter Choices and Absence of Ablation Study: The model\u2019s reliance on multiple parameters (\u03bb1 to \u03bb5) without any ablation study to show their individual effects. A detailed ablation study would strengthen the paper by showing the impact of each parameter and justifying their choices.\n6. The security claims would be stronger with evaluations using neural network-based steganalysis tools, as these are increasingly relevant in steganography. Including such tests would provide a more robust validation of the method's security."
            },
            "questions": {
                "value": "The approach is highly dependent on existing pre-trained models (ELIC and Hyperprior), which raises questions about generalizability and scalability. The paper lacks an exploration of how the method would perform with different compression models, limiting the flexibility and applicability of the approach.\nRelying on specific models makes the method harder to adapt or extend to other compression or steganography frameworks. This reduces the scope of the method to limited model architectures, constraining its adoption."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes to jointly optimize the steganography and compression through code editing, so that the encrypted images can be more robust to compression. However, the presentation of experimental results is unclear, and the experiments are insufficient to demonstrate its effectiveness. Additionally, to me, the approach of joint optimization and code editing may lack the novelty expected for an ICLR submission."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper explores a joint optimization approach to enhance steganography performance under image compression.\n2. The method employs instance-wise latent optimization to achieve effective joint optimization."
            },
            "weaknesses": {
                "value": "1. Presentation of results. The experimental results are presented with too many separate metrics (BPP, PSNR, Acc., RSBPP, FID), making it challenging to interpret the proposed method's advantages. In the field of compression, performance is commonly illustrated through rate-distortion curves. Reorganizing the results into consolidated curves (e.g., BPP-PSNR and BPP-RSBPP) would offer a clearer demonstration.\n2. Insufficient experiments. The compression performance of ELIC is competitive with VTM and significantly outperforms JPEG. To clearly demonstrate that the performance gain is due to the proposed joint optimization rather than simply the strength of the coding baseline, a comparison with direct cascades of Hyper/ELIC and FNNS/LISO, without joint optimization, should be included.\n3. Poor visual quality. Figure 2 shows poor visual quality, especially in comparison to LISO-JPG. Notably, ELICbase_6 introduces visible green artifacts in the zebra image.\n4. In my view, the joint optimization of compression and steganography lacks novelty, as does instance-wise latent optimization (termed code editing here), which is already widely applied for rate-distortion optimization in compression. I encourage the authors to introduce additional innovations that address more practical issues within joint optimization, such as improving visual quality or enhancing overall performance."
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 5
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This manuscript proposes a new neural image steganography method that directly manipulates latent space and joint optimization \nwith an image compression module."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "The idea of incorporating image compression into the training process of a steganography model sounds interesting."
            },
            "weaknesses": {
                "value": "The primary weakness of this manuscript lies in the presentation, it appears to have been put together in a rush. Some instances that I find confusing include:\n\n- Section 3 (the proposed method part) heavily incorporates components of prior works (e.g., ELIC, Hyper and HIFIC). Although the authors claimed that \"Our approach relies entirely on pre-trained models\", it is important to emphasize the original contributions made in this work.\n- Figure 1 seems to be missing legends for key components. For example, the details of \"Q\", \"AE\", \"AD\" and \"SCCTX\" are not provided.\n- The experimental settings are not clear. For example, what are the differences among the settings from \"hyperbase\\_3\" to \"hyperbase\\_8\" in Table 1-3? It should be highlighted and discussed more clearly.\n- In the steganalysis part (Section 4.4), the authors discuss several DL-based steganalysis models like YeNet, but they do not present the corresponding results in Table 4.\n- The limitations of the presented approach should be appropriately discussed."
            },
            "questions": {
                "value": "The authors referenced \"Semi-amortized Variational Inference\" in Sections 1 and 2. However, it is unclear how this concept has been incorporated into the proposed method discussed in Section 3, and this term does not even appear in the subsequent sections. Could the authors clarify how \"Semi-amortized Variational Inference\" is applied in the proposed approach?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}