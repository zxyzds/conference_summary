{
    "id": "BV84FICIAM",
    "title": "Energy-Based Conceptual Diffusion Model",
    "abstract": "Diffusion models have shown impressive sample generation capabilities across various domains. However, current methods are still lacking in human-understandable explanations and interpretable control: (1) they do not provide a probabilistic framework for systematic interpretation. For example, when tasked with generating an image of a \"Nighthawk\", they cannot quantify the probability of specific concepts (e.g., \"black bill\" and \"brown crown\" usually seen in Nighthawks) or verify whether the generated concepts align with the instruction. This limits explanations of the generative process; (2) they do not naturally support control mechanisms based on concept probabilities, such as correcting errors (e.g., correcting \"black crown\" to \"brown crown\" in a generated \"Nighthawk\" image) or performing imputations using these concepts, therefore falling short in interpretable editing capabilities. To address these limitations, we propose Energy-based Conceptual Diffusion Models (ECDMs). ECDMs integrate diffusion models and Concept Bottleneck Models (CBMs) within the framework of Energy-Based Models to provide unified interpretations. Unlike conventional CBMs, which are typically discriminative, our approach extends CBMs to the generative process. ECDMs use a set of energy networks and pretrained diffusion models to define the joint energy estimation of the input instructions, concept vectors, and generated images. This unified framework enables concept-based generation, interpretation, debugging, intervention, and imputation through conditional probabilities derived from energy estimates. Our experiments on various real-world datasets demonstrate that ECDMs offer both strong generative performance and rich concept-based interpretability.",
    "keywords": [
        "Interpretability",
        "Concepts",
        "Diffusion Model",
        "Energy-Based Model",
        "Generative Model"
    ],
    "primary_area": "interpretability and explainable AI",
    "TLDR": "We propose Energy-Based Conceptual Diffusion Models (ECDMs), a framework that unifies the concept-based generation, conditional interpretation, concept debugging, intervention, and imputation under the joint energy-based formulation.",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=BV84FICIAM",
    "pdf_link": "https://openreview.net/pdf?id=BV84FICIAM",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces concept bottleneck model into the diffusion generation process."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to read.\n\n2. The paper introduces concept bottleneck model into the generative diffusion model. Now the model has probilistic interpretation about the generated images."
            },
            "weaknesses": {
                "value": "1.  Although I appreciate the idea of using concept sets to explain the generation, the proposed formulation does not make sense to me. The paper transforms a text embedding into a probility vector that represents the concepts. The point is that it is a deterministic mapping. For instance, \"polar bear\" outputs a determinsitic vector that represents the \"paws\", \"furry\" and \"big\".  In many situations, we would expect a polar bear could be of different size, so \"big\" dim should vary from [0,1] in different polar bear images. In other words, I am expecting that the concept probability vector changes with generated image (not only the input tex prompt).  \n\n2. Given a binary concept labes set, I am wondering the optimal output of the concept energy model with input y?  It seems that a binary output is also expected from y to minimize the loss? If yes, can we just use a logic mapping, i.e., \"polar bear\"-> paws=1, big=1. (So, we do not have to learn the first energy model).  If not, can you provide any explanation why it would not learn a binary vector given the target is binary?\n\nIf these two concerns are addressed, I am happy to raise my score."
            },
            "questions": {
                "value": "as above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces Energy-based Conceptual Diffusion Models (ECDMs), which integrate diffusion models and Concept Bottleneck Models within an energy-based framework. The key contribution is providing a unified approach for concept-based generation, interpretation, debugging, intervention, and imputation. The method enables both high-quality image generation and human-interpretable control through concepts. The authors demonstrate effectiveness on three datasets (CUB, AWA2, CelebA-HQ) through quantitative and qualitative evaluations."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Novel integration of concept bottleneck models with diffusion models through an energy-based framework\n\n2. Comprehensive theoretical framework with detailed proofs\n\n3. Multiple practical applications (generation, interpretation, debugging, intervention)\n\n4. Strong empirical results across different datasets\n\n5. Clear improvement over baseline methods in both generation quality and concept accuracy"
            },
            "weaknesses": {
                "value": "The paper fails to acknowledge pioneering work on energy-based diffusion models, particularly \"Diffusion Recovery Likelihood\" and \"Cooperative Diffusion Recovery Likelihood\" and also fail to include a wide range of works using EBM as compositions such as \"a theory of generative convnet\", \"Implicit Generation and Generalization in Energy-Based Models\" etc."
            },
            "questions": {
                "value": "1. How does the method scale with increasing number of concepts?\n\n2. What is the computational overhead compared to standard diffusion models?\n\n3. Could the framework be extended to handle continuous concept values rather than binary?\n\n4. How robust is the concept interpretation when handling out-of-distribution samples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a framework that integrates diffusion models and Concept Bottleneck Models in an energy based model structure. ECDM aims to address interpretable control in current diffusion models. It allows concept-based generation, interpretation, debugging, intervention, and imputation. ECDM unifies tasks through energy networks, which enables modifications in the generated images based on probabilistic estimates. The model is evaluated on datasets like AWA2, CUB, and CelebA-HQ in concept accuracy, class accuracy, and FID scores with existing diffusion models."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. ECDM combines diffusion models with concept bottlenecks in a way that supports both generative and interpretive tasks.\n2. The model allows users to modify generated images based on specific concept-level controls, which is a practical tool.\n3. The experiments on multiple datasets shows quantitative improvements in image quality and concept alignment."
            },
            "weaknesses": {
                "value": "1. The paper lacks comparisons with some related methods like COMET or CBGM, which are relevant energy-based interpretive frameworks for diffusion models.\n2. While FID, class, and concept accuracy are used, other metrics like diversity or user-study-based interpretability scores could further validate the model's effectiveness.\n3. Code for reproducibility is not provided.\n4. The experiments rely on a fixed pretrained stable diffusion model, while other models are not explored.\n5. Limitations: The method struggles with precise regional control over concept-based edits. Also, the energy-based approach is computationally intensive, especially during joint optimization steps."
            },
            "questions": {
                "value": "1. Concepts like \"pivotal inversion\" and \"energy matching inference\" could be better explained for clarity."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper proposes a concept-based diffusion model that enables conditional generation, concept interpretation and debugging, as well as image operations like intervention and imputation."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is clearly written and well-organized, making complex concepts more accessible.\n2. The authors conduct thorough experiments across various datasets and tasks, providing clear comparisons to existing benchmarks.\n3. The concept-based framework is versatile and seems applicable to any conditional data generation task.\n4. The framework enhances the interpretability of the elements and features in the generated images."
            },
            "weaknesses": {
                "value": "1.  I have to mention that I have not previously conducted research about concept-based generation, but the significance of this work within the broader field of generative models is unclear for me. It appears to be a straightforward combination of concept bottleneck models and standard conditional diffusion models.\n2. The concept-based generation method described in (11)-(13) resembles a Gibbs sampling or coordinate-wise algorithm, but equation (11) focuses on maximizing mapping energy $ E^{map} $ rather than the entire joint energy $E^{joint}$. This raises questions about the rationale behind this approach, as $ E^{joint}=E^{map} +E^{concept}  $ incorporates dependencies on the concept $c $ in both terms. Additionally, maximizing  $ E^{map} $ with respect to the binary vector $c$ suggests an integer programming problem, which the paper does not sufficiently address regarding efficiency."
            },
            "questions": {
                "value": "1. Is the code for the model available now?\n2. How is the number of concepts  $K$ in the concept vector $ c \\in \\set{0,1}^K $ determined? Is $ K $ fixed?\n3. How is the concept embedding $v_k $ modeled?\n4. What distinguishes the generation process described in equations (12) and (13) from that of a standard conditional diffusion model? It seems the only change is replacing the conditioning input $ y $ with the processed conditioning input $ c $ obtained from $y$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}