{
    "id": "aGBA8wz9qA",
    "title": "Debiased Contrastive Learning with multi-resolution Kolmogorov-Arnold Network for Gravitational Wave Glitch Detection",
    "abstract": "Time-series gravitational wave glitch detection presents significant challenges for machine learning due to the complexity of the data, limited labeled examples, and data imbalance. To address these issues, we introduce Debiased Contrastive Learning with Multi-Resolution Kolmogorov-Arnold Network(dcMltR-KAN), a novel self-supervised learning (SSL) approach that enhances glitch detection, robustness, explainability, and generalization. dcMltR-KAN consists of three key novel components: Wasserstein Debiased Contrastive Learning (wDCL), a CNN-based encoder, and a Multi-Resolution KAN (MltR-KAN). The wDCL improves the model\u2019s sensitivity to data imbalance and geometric structure. The CNN-based encoder eliminates false negatives during training, refines feature representations through similarity-based weighting (SBW), and reduces data complexity within the embedding. Additionally, MltR-KAN enhances explainability, generalization, and efficiency by adaptively learning parameters. Our model outperforms widely-used fully supervised baselines on the O1, O2, and O3 data from LIGO/Virgo observations, demonstrating its effectiveness. We also extend dcMltR-KAN to benchmark audio data, further showcasing its novelty and efficiency. To our knowledge, this is the first model of its kind for this application and will inspire future research in this field and SSL.",
    "keywords": [
        "self-supervised learning",
        "Debiased Contrastive Learning",
        "Gravitational Wave",
        "Glitch detection",
        "deep learning"
    ],
    "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)",
    "TLDR": "Debiased Contrastive Learning with Kolmogorov-Arnold Network for Gravitational Wave Glitch Detection",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=aGBA8wz9qA",
    "pdf_link": "https://openreview.net/pdf?id=aGBA8wz9qA",
    "comments": [
        {
            "summary": {
                "value": "The paper presents a new KAN-based model to solve time-series gravitational wave glitch detection problem. It is characterized by its multi-resolution KAN architecture and debiased contrastive learning loss that improves the CNN-based encoder. The paper presents experimental results on the benchmark datasets (also including an audio dataset), showcasing performance improvement over common supervised-learning methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper provides rigorous mathematical definitions of their methods. Easy to follow and understand the proposed concept. \n- Although the reviewer is not an expert in that particular domain area, the proposed method seems to have improved over the reasonable supervised-learning models. \n- The paper did ablation tests to prove that each of the newly proposed methods is meaningful."
            },
            "weaknesses": {
                "value": "- It is not clear why Wasserstein distance needs to be used. The explanation implies the imbalanced data could be an issue by comparing the distributions, instead of Euclidean distance. But wouldn't the same argument be made via KL-divergence?\n\n- It could be based on my lack of experience with the dataset, but the way the dataset was divided into training and testing folds, while the information on validation is missing, is not too informative. More detail is needed, as to how the model was trained. \n\n- The construction of the similarity matrix seems to be very computationally demanding. Meanwhile, it also means that the features can be based on the original similarity defined in the CNN's output. The additional contrastive learning part does introduce some performance improvement, but it is a little difficult to wrap my head around how these two different approaches interact with each other."
            },
            "questions": {
                "value": "- In eq (2), what's the meaning of x(\\alpha)? I understand what \\alpha actually means, but x as a function of \\alpha doesn't make sense to me. \n\n- Is there any better way to construct the positive pair for contrastive learning? Curious if adding Gaussian noise generalizes well enough to unseen examples. For example, in text processing, positive word pairs can be constructed by using context windows. Is there any way to do something like this in this dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper applies debiased contrastive learning (DCL) on wave gravitational data for the task of wave glitch detection. The authors add an auxiliary Wassterstein DCL loss to address data imbalance. Additionnally, they refine the feature representations by weighting using the similarity embedding matrix. Finally, they introduce Multi-Resolution Kolmogorov-Arnold Network (KAN) layers on top of a CNN encoder to capture multi-scale patterns."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The paper is clearly written and easy to follow. \n\n2. The application of contrastive learning for wave glitch detection is interesting, and is promising for extending to large unlabelled dataset.\n\n3. The use of False Negative Elimination (FNE) at multiple levels with the multi-resolution KAN is an interesting idea.\n\n4. The ablation studies effectively demonstrate the importance of different model components."
            },
            "weaknesses": {
                "value": "1. Unsupported claims\n\n\n1.1. The authors make strong claims about KAN layers enhancing explainability, efficiency, and generalization without providing supporting evidence. The KAN layers, in fact, introduce additional complexity, and the paper does not demonstrate the claimed explainability.\n\n1.2. Propositions and theorems are stated without proof or detailed explanation. These could have been included in an appendix for clarity and rigor.\n\n2. Insufficient Literature Review\n\n2.1. The literature review lacks coverage of class imbalance approaches, especially relevant methods in self-supervised contrastive learning.\n\n2.2. Comparisons are limited to the authors' own baselines; there is no evaluation against established methods from the literature ( including on the EmoDB audio dataset).\n\n3. The proposed approach is complex and appears unsuitable for scaling to large datasets, potentially limiting its practical applicability for large-scale learning on unlabeled data."
            },
            "questions": {
                "value": "In Section 3.1, please define L_wass for clarity. Figure 1 is very small; consider increasing its size to enhance readability. The legends in Figure 2 are very small and too difficult to read.\n\n1. For L_wdcl (Eq. 2), why not use a single hyperparameter to balance the two losses, allowing one to scale relative to the other instead of using two hyperparameters?\n\n2. I don't see the point of comparing two losses computed on different examples in Proposition 1, can you clarify its purpose? (also true for Theorem 3, and probably Theorem 2 too). Additionally, could you define the Rademacher complexity to improve clarity for readers unfamiliar with this concept?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors present dcMltR-KAN, consisting of three components. Wasserstein Debiased Contrastive Learning (wDCL), a CNN-based encoder and multi-resolution KAN (MltR-KAN) layers. wDCL replaces the Euclidian distance with the Wasserstein distance to enhance the sensitivity to the geometric structure of the data. MltR-KAN can capture patterns at different scales. The model outperforms fully supervised baselines in classifying glitches in gravitational glitches and in speaker emotion classification."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. Application of recent KAN architecture in suitable application fields and novel combination with debiased contrastive learning. Ablation studies show the importance of both contributions to a base CNN.\n2. Significant improvements compared to current state of the art on gravitational wave dataset and speaker emotion detection dataset."
            },
            "weaknesses": {
                "value": "1. The presented experiments are done in somewhat niches and therefore give limited insides of the significance of the work for the ML community. More experiments could be provided, e.g. on the task of environmental sound classification (ESC50 dataset).\n2. The KAN architecture is a essential part of your model and could also be motivated in the introduction."
            },
            "questions": {
                "value": "1. What are meaningful features?\n2. Is the explainability still given if the CNN first encodes the input data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper introduces a new architecture and self-supervised learning method dedicated to gravitational wave glich detection. Three modules are introduced as the novel components of the proposed method: wDCL, CNN-based encoder, and Multi-Resolution KAN. The author conducted one experiment to show its superiority to existing SOTA methods and another for ablation study. The method is also tested in emotional speech recognition. The results show the proposed method performs the best among the presented baselines"
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The structure of the paper is easy to follow. Motivation of using each method is clearly written at the top of each section \n- Three methods proposed for the glich detection task, when used all together, perform SOTA in objective metrics"
            },
            "weaknesses": {
                "value": "- Tables are not clear: 1) Results of the baseline model w/o two methods (wDCL, mltR-KAN) should be listed in Table 2 to make readers easy to find the difference. 2) Difficult to know if the numerical differences between methods in Table 2 are statistically significant\n- Task selection is not clear: EMODB dataset is for speech emotion recognition and not suited for event detections. If the author wishes to claim the effectiveness of the proposed method in the audio domain, I recommend including an experiment with a sound event detection dataset like DESED, MAESTRO, most of which you could find at the official IEEE DCASE challenge website\n- Presentation of figures: Figure 1 and 2 are too small. Figure 2 is not even cited in the paper. I suspect Figure 1 is mistakenly cited instead of Figure 2. Still one of them is not cited"
            },
            "questions": {
                "value": "Why the SOTA comparison in the audio experiments are not included in Table 3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}