{
    "id": "1ou5noWgHM",
    "title": "Source Attribution for Large Language Model-Generated Data",
    "abstract": "The impressive performances of Large Language Models (LLMs) and their immense potential for commercialization have given rise to serious concerns over the Intellectual Property (IP) of their training data. In particular, the synthetic texts generated by LLMs may infringe the IP of the data being used to train the LLMs. To this end, it is imperative to be able to perform source attribution by identifying the data provider who contributed to the generation of a synthetic text by an LLM. In this paper, we show that this problem can be tackled by watermarking, i.e., by enabling an LLM to generate synthetic texts with embedded watermarks that contain information about their source(s). We identify the key properties of such watermarking frameworks (e.g., source attribution accuracy, robustness against adversaries), and propose a source attribution framework that satisfies these key properties due to our algorithmic designs. Our framework enables an LLM to learn an accurate mapping from the generated texts to data providers, which sets the foundation for effective source attribution. Extensive empirical evaluations show that our framework achieves effective source attribution.",
    "keywords": [
        "Large Language Model",
        "Source Attirbution"
    ],
    "primary_area": "foundation or frontier models, including LLMs",
    "TLDR": "This paper proposes a WASA framework, which is the first framework capable of producing LLMs whose generated texts allow for effective source attribution.",
    "creation_date": "2024-09-26",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=1ou5noWgHM",
    "pdf_link": "https://openreview.net/pdf?id=1ou5noWgHM",
    "comments": [
        {
            "summary": {
                "value": "The authors introduce a framework named WASA (Watermarking for Source Attribution) that embeds unique, imperceptible watermarks into the data used for training LLMs. This approach enables the identification of specific data providers when synthetic texts are generated, thus providing a solution for source attribution. The paper discusses the key properties of an effective source attribution system, including accuracy, robustness against attacks, scalability, and performance preservation. WASA is demonstrated to achieve high source attribution accuracy while maintaining the generation quality of the LLMs. It utilizes unique Unicode characters as watermarks and is shown to be effective in empirical evaluations, even under adversarial conditions such as text modification. This work positions itself as a pioneering solution for source attribution in LLM-generated outputs, offering significant implications for data protection and IP verification in AI-generated content."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Provide convincing real-world application for readers.\n- Clear definition of the source attribution problem.\n-  Large amount of main experiments and ablation studies to show the aspects of a good source attribution algorithm the author claims."
            },
            "weaknesses": {
                "value": "- Not clear difference from text watermark for copyright protection\n- Not enough evidence for avoiding pertubation attack on word tokens.\n- Data distribution problems of different data providers.\n- Implementation details: embedding settings. \n- Lack of experiments on recently proposed LLMs."
            },
            "questions": {
                "value": "1. The authors claim that source attribution is a new task proposed by them. I need more explanation of the differences between source attribution and text watermarks for copyright protection.\n\n2. The authors claim that through the design of splitting the linear layer, the WASA-LLM can avoid pertubations. However, as far as I'm concerned, as described in Figure 3, all hidden states(including hidden embeddings of word tokens) will be in the forward pass of  We\u2032[V + 1 : V + V \u2032], and will influence the outputs(generated watermark tokens). So, pertubations on input words have effects on the output watermarks. \n\n3. There may be some challenges in proving the authors' claim. The authors utilize a one-hot vector for data from a single provider. However, data from the same provider may be very different in distribution, and data from different providers may be similar. For instance, data from Arxiv and DBLP may have similar distributions, as they all contain scientific papers. And, data from a social media may be very different in topics and ideas. How can the author prove that with this problem, their proposed method can also work well? Extra experiments needed.\n\n4. I also want to know the implementation details. As we all know, the way of adding tokens to the vocabulary is important for the final results. How do you initialize your embeddings of the watermark Unicode tokens? And, do you update the embedding parameters during training? This design may be important for results.\n\n4. The author use GPT-2(maybe not an LLM) and llama-2 for experiment results. However, open-source LLMs with better capability have been proposed after them. LLaMA-3-8B[1] and other LLMs may be good choices. You can do supplementary experiments on LLaMA-3-8B to show me the performances.\n\n\n[1] Dubey, Abhimanyu, et al. \"The llama 3 herd of models.\" arXiv preprint arXiv:2407.21783 (2024)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors study how to generate source attribution\u2014identifying data sources that influence specific outputs\u2014for LLMs. The authors discusses a list of effective source attribution desiderata: 1) accuracy, 2) robustness, 3) performance preservation, 4) scalability, 5) transferability, 6) adaptability. The authors propose WASA which embeds invisible characters into the sentences that are most representative of a data provider. WASA-LLM can fit in during or after the pre-training stage. The framework learns to insert watermark randomly in the desired sentence, by a modified transformer structure, where there is a separation of text and watermark token predictions. This benefits WASA-LLM in generating watermark for clean sentences."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The authors propose a novel method that tackles source attribution, an important and difficult problem.\n- The authors lay out clear desiderata for source attribution and demonstrate that the proposed method has promise in satisfying the desiderata.\n- The writing and presentation of the paper is clear and easy to follow. Experiments are well set up and detailed for each desiderata."
            },
            "weaknesses": {
                "value": "1. The proposed source attribution method requires pre-training and performs worse with growing number of data providers. See Q1, Q2, Q3.\n2. Other related work: \nhttps://arxiv.org/pdf/2302.14035 \nhttps://arxiv.org/pdf/2403.03187\nhttps://arxiv.org/pdf/2311.12233\n3. Main experimental comparison is against BM25, though BM25 has limitations related to changed word order, and less semantic relationship captured. Experiments would be stronger compared with other retrieval methods."
            },
            "questions": {
                "value": "Q1: The method is a pre-training source attribution method. How would this method integrate into pipelines of continuous training, where the number of data providers may also be growing? \n\nQ2: The authors discuss the performance drop as data provider number grows. How would this method scale to thousands or millions of data providers? \n\nQ3: Can you motivate the argument for source attribution via training rather than search more? Results in the paper show for 500 data providers, WASA is better than BM25. But practically, data providers may be in the number of millions rather than hundreds."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The article addresses the challenge of attributing sources for synthetic text generated by large language models (LLMs). It presents a framework called \"Watermark for Source Attribution\" (WASA), which embeds watermarks in the generated text to identify the data sources used during LLM training. This framework aims to ensure accurate source attribution, considering factors such as robustness to attacks, scalability, performance retention, transferability, and adaptability."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- This is a popular topic that explores the attribution of sources for text generated by LLMs, a crucial issue for effective data regulation in the age of large language models.\n- The proposed WASA framework is well-defined, considering key attributes for practical application such as accuracy, robustness, and scalability."
            },
            "weaknesses": {
                "value": "Despite this, the method's practical applicability remains weak and raises concerns:\n\n- Unlike recent watermarking efforts that focus on injecting watermarks during the model generation process, this approach targets pre-training data for various providers. Therefore, a potential attack could involve provider B using provider A's data and repeatedly injecting watermarks to attribute the content to provider B. In a more common scenario under AI-assisted writing, if provider A uses provider B's WASA-LLM for text refinement, even for simple grammar checks, provider B's content might inadvertently receive provider A's watermark, leading to intellectual property conflicts.\n- The consideration for attacks is insufficient; stronger paraphrasing is necessary beyond simple changes to prepositions, tenses, and syntax. This means semantically equivalent rewriting, as demonstrated by the DIPPER paraphraser [1]'s effectiveness against watermarks.\n- The technique relies on classic text steganography. Effective defenses include: 1. Scanning and cleaning all Unicode characters; 2. Injecting numerous Unicode characters for perturbation. This raises questions about the effectiveness of WASA-LLM.\n\n- Additionally, if the method cannot attribute output to multiple data sources, it cannot truly identify specific sources influencing a particular output, as claimed. This is similar to data provenance, offering only binary determination. Techniques like those by Kirchenbauer et al. [2] can assign keys to each provider to achieve this identification, which diminishes the distinct contribution of this paper compared to other watermarking work.\n\nOverall, while the motivation is novel, the method seems insufficiently comprehensive. If the authors address these weaknesses convincingly, I am open to revising my evaluation.\n\n[1] Krishna, K., Song, Y., Karpinska, M., Wieting, J., & Iyyer, M. (2024). Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense. Advances in Neural Information Processing Systems, 36.\n[2] Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., & Goldstein, T. (2023, July). A watermark for large language models. In International Conference on Machine Learning (pp. 17061-17084). PMLR."
            },
            "questions": {
                "value": "- Can this framework be applied to code data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tackles the challenge of source attribution for texts generated by LLMs, aiming to protect intellectual property. It introduces a framework called WASA, which embeds watermarks in generated texts to trace back the data providers involved in training the LLM. WASA is designed to ensure accurate attribution while maintaining robustness against adversarial attacks, preserving performance, and scaling to accommodate a large number of data providers. Additionally, it is transferable and adaptable across different LLMs. Extensive empirical experiments demonstrate the framework\u2019s effectiveness in source attribution."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "+ This paper introduces a new task that is more challenging than traditional data provenance, as it requires more detailed information about the data source. It successfully tackles this challenge by using watermarking techniques, which enable precise identification and tracking of the original data sources.\n+ This paper identifies six key properties essential for successful source attribution. To address these, the authors develop a framework designed to meet multiple critical requirements, ensuring that the system is both versatile and functional.\n+ Through extensive empirical evaluations, including ablation studies and comparisons with alternative methods, the paper demonstrates the effectiveness, robustness, scalability, performance preservation, and adaptability of the WASA framework."
            },
            "weaknesses": {
                "value": "1. The writing style is unclear, making the paper's motivation less apparent. It claims that source attribution addresses IP concerns related to synthetic texts generated by LLMs. However, it fails to clearly explain why allowing a data provider to verify the use of their data in training an honest LLM is a more effective solution for these IP issues.\n2. This paper highlights robustness as a key feature and demonstrates it against multiple attacks. However, it overlooks a simple method for watermark removal. Specifically, the watermark could be removed using basic standard formatting methods.\n3. Embedding and regenerating watermarks may increase computational overhead, particularly in large-scale applications. Yet, the paper does not offer a detailed analysis of how this affects performance and resource usage."
            },
            "questions": {
                "value": "1. Why is it more effective to allow a data provider to verify if their data was used to train an honest LLM when addressing IP issues?\n2. In the effectiveness experiments, the comparative baselines for source attribution seem limited. They rely solely on the simple probabilistic model BM25. More advanced methods, such as machine learning approaches, exist for estimating the relevance of generated texts to data providers. How does the proposed WASA method perform compared to these machine learning techniques?\n3. What is the specific impact of the watermarking process on the computational resources and performance of the LLM, especially in large-scale applications?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper tries to attribute the source of the generated text by LLM using invisible unicode characters included during training. The approach is evaluated with 20 sources to show that the source could be correctly identified. The proposed approach is compared with BM25 and shown to outperform it by 17-29% margin."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "- S1: The proposed approach is simple and generally applicable many existing LLM architecture and training scheme.\n- S2: The evaluation shows that the proposed approach outperform the baseline by a large margin.\n- S3: The approach is generally well presented.\n- S4: The paper presents the negative result where the normal performance of the LLM can degrade with this defense, setting the expectation when this approach is adopted."
            },
            "weaknesses": {
                "value": "- W1: The approach is evaluated with only 20 sources, limiting the understanding of its real world impact. Thus, it is unclear if the watermark will survive with a lot more sources (e.g., thousands to millions) that would be closer to the real world.\n- W2: The baseline approach can be a little bit better. The first and simplistic approach would be training BERT to classify the generated text to sources (similarly to Matching Pairs, Foley et al., 2023 @ ACL) given the number of sources is only 20. For a large number of sources, a Siamese model or 1/k-shot classification can be used. BM25 is not a conventional baseline for a classification task.\n- W3: The accuracy evaluation uses the samples directly from the data providers, which is not realistic in a modern LLM usage since there will be more information, context, structure, or other utterances will be present. This trivialize the problem to a typical classification task such as topic classification, etc."
            },
            "questions": {
                "value": "- Q1: What's the impact of the random insertion of the watermark during training and inference? Can it rather be fixed?\n- Q2: How is this approach different from training the model to generate the citation like \"Sentence [arxiv:math]\"? If the citation can be reconstructed anyway, we don't need to be limited by the invisible unicode characters.\n- Q3: How do we control the model to memorize the watermark/citation? Or how are we sure about it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}