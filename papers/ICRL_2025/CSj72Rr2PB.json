{
    "id": "CSj72Rr2PB",
    "title": "Bias Mitigation in Graph Diffusion Models",
    "abstract": "Most existing graph generative diffusion models suffer from significant exposure bias during graph sampling. We observe that the forward diffusion\u2019s maximum perturbation distribution in most models deviates from the standard normal distribution, while reverse sampling consistently starts from a standard normal distribution. This mismatch results in a reverse starting bias, which, together with the exposure bias, degrades generation quality. The exposure bias typically accumulates and propagates throughout the sampling process. In this paper, we effectively address both biases. To mitigate reverse starting bias, we employ a newly designed Langevin sampling algorithm to align with the forward maximum perturbation distribution, establishing a new reverse starting point. To address the exposure bias, we introduce a fraction correction mechanism based on a newly defined score difference. Our approach, which requires no network modifications, is validated across multiple models, datasets, and tasks, achieving state-of-the-art results.",
    "keywords": [
        "Diffusion models",
        "Graph learning",
        "Bias analysis"
    ],
    "primary_area": "generative models",
    "TLDR": "",
    "creation_date": "2024-09-17",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=CSj72Rr2PB",
    "pdf_link": "https://openreview.net/pdf?id=CSj72Rr2PB",
    "comments": [
        {
            "summary": {
                "value": "In view that the existing graph diffusion models can not reach the standard Gaussian distribution if following their defined transition distribution, this paper proposes a Langevin sampling algorithm to align with the forward maximum perturbation distribution. Extensive experiments have verified the effectiveness of the proposed method in generating better graphs."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "(1) The observed misalignment between the maximum perturbation distribution and the actual starting distribution in the generation phase is very important and novel.\n\n(2) The proposed technique for correcting the misalignment bias is technically sound. Furthermore, Figure 1 has demonstrated its effectiveness.\n\n(3) Extensive experiments have been conducted to verify the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "(1) Some of the motivations are not so clear based on the experiments. See question in (3)."
            },
            "questions": {
                "value": "(1) In line 87, the author mentions that the proposed bias correction method can be integrated into existing methods (e.g., spatial, spectral, and hyperbolic domains). I wonder if it also includes discrete graph diffusion, such as DiGress, since that one proves to be more effective in generating discrete graph structure.\n\n(2) In line 205, how do we get the score function $s_{\\bar{\\theta}, t}(\\cdot)$? Is it $s_{\\phi, t}(\\cdot)$ based on the Appendix B?\n\n(3) I do not fully understand the insights drawn between line 232 and line 236. Why do these experiments provide these two directions for addressing the reverse sampling bias?\n\n(4) How is the continuous diffusion model equipped with the proposed strategy here compared with the discrete diffusion model such as GDSS?\n\n(5) In Figure 2(c), why the perturbation at the very early stage does not lead to any tweaking impact in $s_{\\theta, t}(\\cdot)$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper improves GDSS  from a unified perspective and solves a significant problem of exposure bias during graph sampling.\nTheir approach requires no network modifications, which is validated across multiple models, datasets, and tasks compared with SOTA methods."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "1. The proposed method effectively mitigates reverse starting bias by employing a newly designed Langevin sampling algorithm.  \n\n2. It introduces a fraction correction mechanism based on a newly defined score difference to address exposure bias.  \n\n3. The approach requires no network modifications and demonstrates state-of-the-art performance across multiple models, datasets, and tasks."
            },
            "weaknesses": {
                "value": "For me, I understand the problems the author wants to solve, and they are indeed meaningful (if solved). But I think the biggest problem is that the paper's presentation is not satisfactory, so I cannot give it a higher score. Perhaps, in the rebuttal process, reasonable explanations can alleviate my bias."
            },
            "questions": {
                "value": "1. Can the proposed model generate attributes?\n\n2. The authors repeatedly emphasize that \"Their approach requires no network modification.\" My confusion is that the noise or bias will not be the same for different networks. Suppose the proposed approach is robust to the network and does not require modifications in different scenarios. How can it ensure that the new reverse starting point is robust and correct across different noises in different networks?\n\n3. The authors claim that they can achieve good performance across multiple tasks and have strong reusability. However, since the code is not open-sourced, I am unable to evaluate it.\n\n4. The abstract is very intriguing, but the introduction is somewhat difficult to read. For example, some symbol definitions and descriptions are not explained, and the authors assume that this knowledge is already known to readers. Additionally, I did not fully understand how the authors addressed the existing problems in Q1 and Q2, as this was not clearly explained."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors focused on two problems in the Diffusion models for graph data. The first problem is the reverse starting point bias, in which the maximally perturbed data distribution is far from the standard normal distribution from which the reverse process starts during the inference. The second problem is the exposure bias, in which  diffusion model generates data with errors that accumulate across every step of the reverse process, leading to a large gap between the generated data and the true data distribution. The paper proposed solutions to the two problems respectively, and the empirical results are provided to verify the effectiveness of the methods."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "The paper is well motivated and explained the intuitive and mathematical explanations of the proposed solutions to the problems. In particular, the solution based on the Langevin sampling to the first problem sounds well and is novel."
            },
            "weaknesses": {
                "value": "**Main arguments**:\n\n- *A1*: Two solutions are proposed in the paper, which are not synergetic and not specific to graph diffusion models (e.g., they can be applied to other types of data). While this is a another strength, given its generic nature, the paper needs to position itself in the existing literature, in particular in context of the second problem (exposure bias). For example, some solutions to the exposure bias exists [1,2] for image generation, and they can be replaced with the proposed solution to the exposure bias. How effective is the proposed solution compared to the existing ones is not clear in the paper, questioning the significance of the solution.\n  1. Li, Mingxiao, et al. \"Alleviating exposure bias in diffusion models through sampling with shifted time steps.\" arXiv preprint arXiv:2305.15583 (2023).\n  2. Ning, Mang, et al. \"Elucidating the exposure bias in diffusion models.\" arXiv preprint arXiv:2308.15321 (2023).\n\n- *A2*: The solution to the exposure bias has a key parameter, $\\lambda$, that controls the degree of correction during inference. In the experiment, the authors used specific value of $\\lambda$. However, it is not clear how did they choose and whether the method is sensitive to the choice of $\\lambda$. If  $\\lambda$ is a highly sensitive parameter, the practical value of the method is limited.\n\nGiven the above arguments, I believe that the paper is not strong enough to be accepted at ICLR 2025 at its current form."
            },
            "questions": {
                "value": "1. What is the key features and novelty of the proposed exposure bias correction in light of the existing methods?\n2. How was the $\\lambda$ selected in the experiment? Why do they differ across different experiments? How sensitive the results are to the choice of $\\lambda$ values?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "To solve the exposure bias and the reverse starting bias at the same time, the authors propose to adopt Langevin sampling to obtain samples aligned with the forward maximum perturbation distribution. A fraction correction mechanism is presented. It is based on score difference to solve the exposure bias of the fraction network. The approach is free of network modification and introduction of new components. Empirical experiments demonstrate that the proposed method can achieve state-of-the-art performance on multiple datasets and multiple tasks."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 3
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Contribution: This paper aims at mitigating the reverse starting bias and the exposure bias at the same time, which is obviously an important topic that yet to be solved.\n\nSolid and sound method: The proposed fraction correction mechanism is elaborated clearly. Multiple medias are employed to help with understanding the methods.\n\nAmple empirical analysis: The proposed method is compared with multiple modern baselines on several datasets. The experiment results are presented clearly. Ablation tests are provided to demonstrate the importance of S++."
            },
            "weaknesses": {
                "value": "Novelty: Langevin sampling has long been recognized as one of the best approach to learn the distribution in diffusion models. This paper adapts it to the graph diffusion modeling task.\n\nExperiment: The environment of the experiment is not specified.\n\nAcceleration measurement: S++ is claimed to be able to generate good samples faster by using fewer steps of reverse diffusion. Experiment results showed that it could achieve satisfying samples in fewer steps. However, whether it costs more time in each step due to the extra computational burden is not discussed."
            },
            "questions": {
                "value": "Can you elaborate more about how graph diffusion modeling is different from the general diffusion modeling regarding the two bias?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 8
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}