{
    "id": "JIlIYIHMuv",
    "title": "LVLM-CL: Make Large Vision-Language Models Work Better under Continual Learning Settings",
    "abstract": "The development of Large Vision-Language Models\n(LVLMs) is striving to catch up with the success of Large\nLanguage Models (LLMs), yet it faces more challenges to\nbe resolved. When finetuning LVLMs with user-specific\ndata in the practical use, the pretrained weights would face\nthe problems of forgetting and performance degradation.\nSo it is important to improve LVLM\u2019s performance under\nthe continual learning settings. Some existing CL methods\nhave explored continual learning on VLM. However, the\ncontinual learning settings they have proposed couldn\u2019t\nbe adopted to LVLMs smoothly because the training and\nfinetuning process of LVLMs need amount of data while\nprevious VLM continual learning settings built on limited\ndata and different model architectures. In this work, we first\ndevise a task-specific continual learning setting especially\nfor LVLMs by classifying the instruction tuning data\nfor the second finetune process of LVLMs into several\ndifferent tasks. Mimicking the process of finetuning with\nuser-specific task data, we found that the performance of\nLVLMs would decline without any modules designed for\ncontinual learning settings. So we present LVLM-CL, a\nnovel approach capable of continual learning settings for\nlarge vision-language models when finetuning with different\nkinds of tasks. Specifically, our LVLM-CL consists of a\ntext feature based prompt that are different between tasks\nto keep the special feature of different tasks. To meet the\nsetting of continual learning, we also design a memory bank\nwhich storage previous trained tasks which helps LVLMs\napply knowledge to unfamiliar combinations. Extensive case\nstudies and quantitative evaluations show LVLM-CL has\nstrong capability in understanding the pivotal features of\ndifferent tasks and emerges impressive memory capabilities\nunder the continual learning settings. This work fosters the\nadvancements of LVLMs by enabling them to support better\ncontinual finetuning toward practical use in the real world.",
    "keywords": [
        "Continual Learning; Large vision-language model"
    ],
    "primary_area": "applications to computer vision, audio, language, and other modalities",
    "TLDR": "",
    "creation_date": "2024-09-24",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=JIlIYIHMuv",
    "pdf_link": "https://openreview.net/pdf?id=JIlIYIHMuv",
    "comments": [
        {
            "summary": {
                "value": "The paper introduces LVLM-CL, an approach aimed at enhancing the performance of LVLMs within CL settings. The primary goal is to address catastrophic forgetting, which arises when LVLMs are incrementally fine-tuned with new tasks. The proposed method integrates task-specific prompts and a memory bank to preserve previously acquired knowledge during the fine-tuning process."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "-   The focus on continual learning specifically within LVLMs, which more closely aligns with practical applications than conventional CL in VLMs.\n-   Development of a dataset that supports continual learning specifically tailored for LVLMs."
            },
            "weaknesses": {
                "value": "-   While the paper provides comparisons with a few models, a broader evaluation against some continual learning techniques would reinforce the findings. Continual learning is a well-researched area, and the paper references several existing CL strategies, yet direct comparisons are missing. Moreover, current comparisons with only zero-shot models limit the impact of the performance claims. For instance, existing CL methods could be directly applied to LVLMs as a baseline comparison.\n-   Certain aspects of the method description could be more detailed. In particular, the Task-specific feature section lacks clarity on critical details, such as which parameters are explicitly trained.\n-   The ablation study does not provide a thorough analysis of the roles and impact of Task-specific and Task-invariant Features.\n-   Given the number of related approaches in the VLM field, the paper should clarify the distinct challenges within LVLMs that their approach seeks to address. Without this, it may seem that the method merely adapts existing CL techniques to LVLMs, which could diminish its technical contribution."
            },
            "questions": {
                "value": "1. Even though the method is evaluated using LLaVA, is it possible to extend this approach to other LVLM architectures? If so, what considerations or adaptations would be necessary?\n2. See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 2
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper presents LVLM-CL, a methodology aimed at improving the performance of Large Vision-Language Models (LVLMs) in continual learning (CL) settings. The authors propose a task-based representation and memory buffer to address catastrophic forgetting, a common challenge in continual learning. They also build a custom benchmark for fine tuning LVLMs across multiple task types, emulating a real-world continual learning scenario. The architecture presented incorporates both task-specific and task-invariant features in the finetuning process, enhancing LVLMs\u2019 adaptability and knowledge retention."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "The strong points of the paper presented are the following:\n- The paper has some innovative approach, as it presents a methodology to address continual learning specifically with LVLMs, which is still an underexplored area.\n- The authors conducted an experimental plan on multiple visual question answering (VQA) datasets, showcasing some improvement in handling multimodal continual learning tasks with respect to the baseline model."
            },
            "weaknesses": {
                "value": "The paper present some flaws and weaknesses that are addressed in the following points:\n- Paper suffers from frequent grammatical errors, awkward phrasing and inconsistent terminology, which make it very challenging to understand and follow the contribution.\n- Most of the in-text citations are incorrectly formatted (e.g., \u201cZhang et al. (2023b)Zhang et al. (2023c)\u201d), which difficulties readability and diminishes professionalism.\n- References to images and tables within text are often incorrect (e.g., referencing wrongly the ablation study for the memory size, or the ablation study regarding the impact of hyperparameters)\n- While the paper applies the LVLM-CL methodology over a new benchmark, the work lacks an analysis or comparison between their CL method and other already existing CL approaches (i.e., LwF, EWC, or prompt based approaches like DualPrompt, to name a few), making it difficult to see the real impact and improvement.\n- There\u2019s no clear ablation study about how the two CL modules presented (i.e., the memory buffer and the concentration learning module) perform independently, being difficult to see the justification of those relatively standard techniques."
            },
            "questions": {
                "value": "- Could the authors provide more information about how LVLM-CL compares against other CL methods applied in this context?\n- How does the proposed concentration learning module compare to existing approaches in terms of memory usage and effectiveness? Are there specific innovations introduced here?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The paper proposes continual finetuning of Large Vision-Language Models through the usage of task-specific and task-invariant tokens. The task-invariant tokens are extracted as a moving average of the training data.  These tokens are then fused together to form the unified input to a standard decoder-based LLM. The proposed technique works with and without the usage of replay memory and furthermore, for the purpose of continual finetuning, a new training setup is proposed out of the TDIUC visual question answering dataset."
            },
            "soundness": {
                "value": 4
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- The paper touches a very timely topic of how to continually adapt large auto-regressive Vision Language Models on a sequentially arriving data setup. \n- To the best of my knowledge, the paper does establish the first step toward continual finetuning of such models. Also, the baselines used in the evaluation do look state-of-the-art.\n- Detailed evaluation on a number of multimodal datasets."
            },
            "weaknesses": {
                "value": "**On technical novelty**\n- I find the motivation for using the concentration module to be unclear. My doubt is further amplified by the lack of proper ablations on how the time/memory usage scales with the number of tokens produced by the concentration module. \n- To my understanding of standard CL models, these are usually evaluated as an average over multiple randomly ordered task sequences. As such, the ablation on the *effect of task order* seems redundant unless the paper reports some additional interesting finding besides the final performance.\n- I would like to see how the removal of the vision projection layer from Eq. (2) effects the performance and what cost does this layer add up to the total number of parameters stored?\n\n**On the motivation and the language usage**\n\n- Line 252: \"Our proposed continual learning method uses tasks as fundamental units.\": not sure what the fundamental unit here is referring to. If I am right, the work treats \"abstract concepts\" like color, counting, reasoning, etc. as learnable knowledge at a given incremental step. In light of this, I would suggest clearly stating that the tasks correspond to such concepts. See [1,2] for example settings.\n- Some design choices in the paper seem arbitrary without proper evidence to support the claims. E.g. Line 260: \"We\nremoved the absurd type, where questions cannot be answered.\" This leaves the reader wondering about what the answers are, and moreover, how do these answers compare to other question template types.\n- Why is it called the concentration learning module when if anything, the module seems to learn task-invariant features?\n- To my understanding from Fig. 2, E^q and E^v are two different encoders. However, Eq. (1) shows them both sharing the same encoding function *Enc()*. I would suggest modifying this equation and/or the definition of *Enc()* accordingly.\n- **Incoherent terminology:** $E_t$ in Line 317 is referred to as the expectation while line 323 says it is the textual embedding?\n- Eq. 5: justification for why the hyperbolic tangent function has been applied?\n\n\nMinor corrections: Overall, I find that the writing and the grammar of the paper can be significantly improved. I would highly recommend the usage of a third-party spell-checker app. For context, I have highlighted the following suggestions merely for the abstract:\n\n- Line 20: \"... LVLMs need amount of data while .. \" -> \"... LVLMs need *huge* amount of data while .. \" ?\n- I do not see the need for a bold sentence in the abstract.\n- Line 24: \"second *stage* finetuning of LVLMs\"?\n- Line 31: \"which *stores* previous trained tasks *and* helps .. \"?\n- Line 34: \" .. and *can lead to emergence of* impressive ..\"?\n- Line 79: \" .. will be *forgotten* .. \": also, catastrophic forgetting here needs to be distinguished from mere forgetting.\n- Lines 93-94: VQACL *[space]* [cite] and Triple *[space]* [cite] ..\n- Line 103: \" .. we also *propose* .. \"\n- Line 274: \"We *introduce* a task-based .. \"\n- Line 303: \".. In *experiment* \"\n- Lines 373-377 and in general: please use citations within parenthesis, i.e., \\citep{} when the entire citation id is to be parenthetical. E.g. MME \\citep{}, MMBench \\citep{}, etc.\n- Table 4: The best results have not been highlighted in bold, nor are the second best results underlined.\n\nReferences:\n[1] Smith, James et al. \u201cContinual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA.\u201d\n[2] Jha, Saurav et al. \u201cMining Your Own Secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models.\u201d"
            },
            "questions": {
                "value": "See the weaknesses. Overall, I find the current version of the paper to be rather weak in terms of writing, motivation, and technical novelty. I hope my suggestions help in a major revision of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper investigates continual learning in the Large Vision-Language Models (LVLMs), which is under-explored in the current community.  The author summarises the challenges in this area and then proposes a dataset for continual instruction tunning. Additionally, the author proposes a novel method to improve the performance. Extensive experiments demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 1
            },
            "contribution": {
                "value": 1
            },
            "strengths": {
                "value": "1. The paper explores the significant question of instruction continual learning in the current LLMs eras, which is underplored by existing work.\n2. The author proposed novel instruction data for continual learning, which has the potential to push the development of continual learning in large multimodal models.\n3. They propose a novel method for improving the performance of the proposed instruction continual learning setting."
            },
            "weaknesses": {
                "value": "1. The one core contribution is the ***proposed dataset*** in this paper, as the author claims there were no readily available datasets for use. If I do not make an error understanding, ***CoIN[1] is a continual instruction tunning benchmark for multimodal large language models***. The author should clarify this point and propose a sufficient description of the difference between them.\n2. The effectiveness of the proposed method needs to be deeply evaluated as the author proposed that `***LoRA-finetune is not good enough, so we don\u2019t show it***'.\n3. How does the proposed dataset ensure data quality during the data construction and rationality of the generation question?\n4. There lack of discussion for ***limitations and future work***.\n5. There is a lack of definition of E^q and E^v in equation (1).\n6. There lack of formal definition of how to evaluate forgetting.\n7. There exist some long-tailed sentences, such as lines 136 and 152, it is recommended to improve the expression.\n8. There are some typos, it is recommended to improve the expressive.\n    1. In line 097, there is an extra space.\n    2. in line 446, there also is an extra space.\n8. The tables are not properly referenced, such as in line 269, line 415, and line 427.\n\n[1]. COIN: A BENCHMARK OF CONTINUAL INSTRUCTION TUNING FOR MULTIMODEL LARGE LANGUAGE MODEL"
            },
            "questions": {
                "value": "see weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 1
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}