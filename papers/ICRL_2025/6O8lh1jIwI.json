{
    "id": "6O8lh1jIwI",
    "title": "Learning DAGs and Root Causes from Time-Series Data",
    "abstract": "We introduce DAG-TFRC, a novel method for learning directed acyclic graphs (DAGs) from time series with few root causes. By this, we mean that the data are generated by a small number of events at certain, unknown nodes and time points under a structural vector autoregression model. For such data, we (i) learn the DAGs representing both the instantaneous and time-lagged dependencies between nodes, and (ii) discover the location and time of the root causes. For synthetic data with few root causes, DAG-TFRC shows superior performance in accuracy and runtime over prior work, scaling up to thousands of nodes. Experiments on simulated and real-world financial data demonstrate the viability of our sparse root cause assumption. On S\\&P 500 data, DAG-TFRC successfully clusters stocks by sectors and discovers major stock movements as root causes.",
    "keywords": [
        "time-series data",
        "root causes",
        "sparsity",
        "structured vector autoregression",
        "directed acyclic graphs"
    ],
    "primary_area": "causal reasoning",
    "TLDR": "We propose DAG-TFRC, which learns directed acyclic graphs from time-series data generated by only a small number of events (root causes) in nodes and time points.",
    "creation_date": "2024-09-27",
    "original_date": "2024-10-04",
    "modification_date": "2024-10-13",
    "forum_link": "https://openreview.net/forum?id=6O8lh1jIwI",
    "pdf_link": "https://openreview.net/pdf?id=6O8lh1jIwI",
    "comments": [
        {
            "summary": {
                "value": "This paper proposes an L1-loss version of the vector autoregression (VAR) model to quantify the contribution of a non-autoregressive component, which the authors refer to as the \"root cause.\" \n\nWhile Granger causal learning using L2-loss combined with various regularizers has been extensively studied, the authors' motivation appears to be somewhat different. \n\nThe authors propose to use PyTorch (i.e., stochastic gradient) to solve the optimization problem but no details are provided."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 3
            },
            "strengths": {
                "value": "- Tackles the relatively new problem of sparse causal learning.\n- Presents a simple yet feasible formulation."
            },
            "weaknesses": {
                "value": "- Although the authors criticize existing methods as being ``generally inefficient for computing graphs with thousands of nodes,'' they do not provide detailed information on the optimization algorithm. It is mentioned that PyTorch was used, but Page 4 does not include specifics beyond this point.\n\n- There is extensive literature on VAR-based causal learning with various regularization methods. While Section 4's coverage is adequate, it does not clearly distinguish the proposed method from existing approaches."
            },
            "questions": {
                "value": "Address the weakness points. \n\nIf the proposed method turns out to be really novel and effective from an optimization perspective in light of the existing works, I will raise the rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": 6
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "The authors propose DAG-TRFC, a method to learn the so-called window graph of a time series under the assumption it was generated by a structural vector autoregression (SVAR) model. From the learned window graph (which quantifies how much the value of a time series at $t$ is influenced by values at $t-k$), an approximation of a \"root cause vector\" can be derived. Loosely defined, a root cause is an event which significantly influences the observed time series. There may be up to $T$ (length of time series) root cause but the vector is typically sparse. Learning the window graph is framed as a discrete optimization problem and applied to synthetic and real world data thereby showing good performance a) in terms of smaller structural Hamming distance compared with other methods, and b) the recovery of interesting stock market events."
            },
            "soundness": {
                "value": 3
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "Without being an expert in root cause analysis for time series data, it seems the experiments are conducted in a sound and rigorous manner. Using SHD seems a reasonable metric and Figure 3 nicely illustrates the interpretability of the learned events."
            },
            "weaknesses": {
                "value": "The introduction is hard to parse. For a reading unfamiliar with SVAR models, it is extremely hard to understand the link between graphs and time series. To remedy this, the first paragraph could explicitly link the both concepts when mentioning the examples. The used graph terms should be directly linked to the time series domain. In addition, the first paragraph on Structural vector autoregression reads like a \"related work\" section rather than an introduction to the model itself. Despite the authors defining the term \"root cause\" several times in the manuscript, I still have a hard time grasping the meaning of a root cause in the time series context. I don't think it is a good term. Overall, the first half of section 2 is hard to follow (see questions below). Lastly, given that I can't develop an intuition for the root cause vector which is a central element of the work, I can't sufficiently judge the impact this method would have on the broader TS community."
            },
            "questions": {
                "value": "* Will the method always find a root cause? What would we discover on a time series containing only gaussian noise?\n* My understanding is that $\\mathbf{C}$ is of dimension $\\[T, d\\]$. How does this relate to the upper Figure 1?\n* Eq. 1: Is it correct that $x_t$ is a function of itself? For VAR models that does not seem to be the case.\n* Section 2, Time-series data should start with definitions over time series and then link to the graph notations. This interplay is hard to understand. \n* When solving the optimization problem, how do you enforce the constraint that $B_0$ is acyclic?\n* To learn root causes, you apply a threshold (page 8 last paragraph), how did you arrive at this and how general is it? \n* In Figure 3, what is the direction of the influence in your legend (e.g., Meta/Amzn) would it be that meta influenced amzn or vice versa?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 5
            },
            "confidence": {
                "value": 3
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        {
            "summary": {
                "value": "This paper introduces DAG-TFRC, a method for learning directed acyclic graphs from time series data with few root causes, utilizing a structural vector autoregression model. The experiments were conducted on synthetic and real financial data to evaluate the effectiveness of this approach."
            },
            "soundness": {
                "value": 2
            },
            "presentation": {
                "value": 2
            },
            "contribution": {
                "value": 2
            },
            "strengths": {
                "value": "1. The experiments were carried out using both synthetic and real datasets.\n\n2. Learning causal structures from time series data is an interesting and important problem."
            },
            "weaknesses": {
                "value": "1. **Technical Novelty and Contributions**\n   - The proposed algorithm DAG-TFRC is just a scalable version of existing technique (SparseRC). \n   - The technique contribution is limited or incremental. The authors claimed that their major contribution is \"Our work expands the applicability of this assumption to the case of time series and, in addition, interprets the root causes in an experiment on real-world financial data\", but the work of  Misiakos et al., 2024 (LEARNING SIGNALS AND GRAPHS FROM TIME-SERIES GRAPH DATA WITH FEW CAUSES) has already applied SparseRC for learning graphs from time series.  Then the only contribution seems to be \"...interprets the root causes in an experiment on real-world financial data\". \n\n2.  **Overclaim in Title and Abstract**\n    - The title and abstract suggest that the proposed method can learn both Directed Acyclic Graphs (DAGs) and root causes from time series data. If this is the case, the authors should compare their approach with not only existing DAG learning algorithms, but also the root cause analysis algorithms, especially causal structure learning based root cause analysis methods, in both the related work section and the experiments.\n    - Consider changing the title, as it significantly overclaims the scope of this work.\n\n3. **Writing and Presentation**\n    - This paper is not well-written and not well-motivation, particularly the abstract and introduction. The introduction should be self-contained, but it fails to clarify the specific technical problem addressed, the motivation, why it is technically challenging, and what specific limitations of the existing approaches. \n   - While the assumption of sparse root causes is intriguing, it lacks motivation in the context of time series.\n   - The explanation regarding the maximum value of the time-lag \ud835\udc58 is insufficient. More clarity is needed to understand its implications and significance.\n\n4. **Experimental Section**\n   - Figure quality is low: e.g., From Fig. 2, there are so many lines. It is hard to do comparison.\n   - Different experimental settings are needed: e.g., only time-series of length T = 1000 is used in the experiments. \n   - Limited results on the effect of the parameter k or how to set it in practice. \n   - Current experimental results are unconvincing; only one real-world data (stock market) is used. The paper should include additional benchmark datasets (e.g., DREAM4 gene expression data) for a more comprehensive evaluation."
            },
            "questions": {
                "value": "1. The technical novelties and contributions, comparing to SparseRC (Misiakos et al. (2023b)) and Misiakos et al. (2024)?\n\n2. In the related work, \"...in our setting the root causes have a linear relation with the data\", what do you mean by \"root causes have a linear relation with the data\"?\n\n3. The authors claim that \"SID is computationally very expensive (times out) to run on DAGs with thousands of nodes and thus\nwas not used\", but why not trying different scales of graphs in the experiments? What the SID results would be on the small-scale graphs?\n\n4. The authors claim that scalability is one of their contributions. Which specific aspects of the algorithm's design enhance its scalability compared to other methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": 3
            },
            "confidence": {
                "value": 4
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        }
    ]
}